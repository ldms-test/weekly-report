2022-10-31 09:54:44 INFO: WORK_DIR: /mnt/300G/data/2022-10-31-095443
2022-10-31 09:54:44 INFO: LOG: /mnt/300G/data/2022-10-31-095443/cygnus-weekly.log
~/cron/ldms-test ~/cron/ldms-test
/mnt/300G/data/2022-10-31-095443 ~/cron/ldms-test ~/cron/ldms-test
2022-10-31 09:54:45 INFO: Skip building on host because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:54:45 INFO: Skip building containerized binary because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:54:45 INFO: -- Installation process succeeded --
2022-10-31 09:54:45 INFO: ---------------------------------------------------------------
~/cron/ldms-test /mnt/300G/data/2022-10-31-095443
~/cron/ldms-test/weekly-report ~/cron/ldms-test /mnt/300G/data/2022-10-31-095443
HEAD is now at daa44be 2022-10-31-083642
[master 9d89513] 2022-10-31-095443
 2 files changed, 14 insertions(+), 2041 deletions(-)
 rewrite test-all.log (99%)
To github.com:ldms-test/weekly-report
   daa44be..9d89513  master -> master
~/cron/ldms-test /mnt/300G/data/2022-10-31-095443
2022-10-31 09:54:46 INFO: ==== OVIS+SOS Installation Completed ====
2022-10-31 09:54:46 INFO: ==== Start batch testing ====
~/cron/ldms-test /mnt/300G/data/2022-10-31-095443 ~/cron/ldms-test ~/cron/ldms-test
2022-10-31 09:54:46 INFO: ======== direct_ldms_ls_conn_test ========
2022-10-31 09:54:46 INFO: CMD: python3 direct_ldms_ls_conn_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/direct_ldms_ls_conn_test
2022-10-31 09:54:47,620 TADA INFO starting test `direct_ldms_ls_conn_test`
2022-10-31 09:54:47,620 TADA INFO   test-id: cf27b3fec1bd38a2a02057b450c8f2048b112ac96e1fee0313e94733927c4723
2022-10-31 09:54:47,620 TADA INFO   test-suite: LDMSD
2022-10-31 09:54:47,620 TADA INFO   test-name: direct_ldms_ls_conn_test
2022-10-31 09:54:47,620 TADA INFO   test-user: narate
2022-10-31 09:54:47,620 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:54:48,114 __main__ INFO starting munged on cygnus-01-iw
2022-10-31 09:54:48,453 __main__ INFO starting munged on localhost
2022-10-31 09:54:48,684 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-31 09:54:48,982 TADA INFO assertion 0, Start ldmsd sampler and munged: OK, passed
2022-10-31 09:54:54,174 TADA INFO assertion 1, ldms_ls to the sampler: OK, passed
2022-10-31 09:54:54,174 __main__ INFO Stopping sampler daemon ...
2022-10-31 09:54:59,592 TADA INFO assertion 2, Kill the sampler: OK, passed
2022-10-31 09:54:59,631 TADA INFO assertion 3, ldms_ls to the dead sampler: got expected output, passed
2022-10-31 09:54:59,669 TADA INFO assertion 4, ldms_ls to a dead host: got expected output, passed
2022-10-31 09:54:59,670 TADA INFO test direct_ldms_ls_conn_test ended
2022-10-31 09:54:59,878 __main__ INFO stopping munged on cygnus-01-iw
2022-10-31 09:55:00,277 __main__ INFO stopping munged on localhost
2022-10-31 09:55:00 INFO: ----------------------------------------------
2022-10-31 09:55:00 INFO: ======== direct_prdcr_subscribe_test ========
2022-10-31 09:55:00 INFO: CMD: python3 direct_prdcr_subscribe_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/direct_prdcr_subscribe_test
2022-10-31 09:55:01,112 TADA INFO starting test `direct_prdcr_subscribe_test`
2022-10-31 09:55:01,112 TADA INFO   test-id: 8bf0ba41a3adc274a4119187e53f4a9a6df160c8acd0cdfdf5c6f6ca201dfc74
2022-10-31 09:55:01,112 TADA INFO   test-suite: LDMSD
2022-10-31 09:55:01,112 TADA INFO   test-name: direct_prdcr_subscribe_test
2022-10-31 09:55:01,112 TADA INFO   test-user: narate
2022-10-31 09:55:01,112 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:55:03,013 __main__ INFO starting munged on cygnus-01-iw
2022-10-31 09:55:03,781 __main__ INFO starting munged on cygnus-02-iw
2022-10-31 09:55:04,530 __main__ INFO starting munged on cygnus-03-iw
2022-10-31 09:55:05,286 __main__ INFO starting munged on cygnus-04-iw
2022-10-31 09:55:05,599 __main__ INFO starting munged on localhost
2022-10-31 09:55:05,824 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-31 09:55:06,317 __main__ INFO starting ldmsd on cygnus-02-iw
2022-10-31 09:55:06,813 __main__ INFO starting ldmsd on cygnus-03-iw
2022-10-31 09:55:07,301 __main__ INFO starting ldmsd on cygnus-04-iw
2022-10-31 09:55:14,217 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-31 09:55:14,218 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-31 09:55:14,219 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-31 09:55:14,219 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-31 09:55:14,220 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verified, passed
2022-10-31 09:55:14,253 TADA INFO assertion 5, Stopping the producers succeeds: agg-1 producers stopped, passed
2022-10-31 09:55:15,256 TADA INFO assertion 6, Restarting the producers succeeds: agg-1 producers started, passed
2022-10-31 09:55:21,885 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-31 09:55:21,886 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-31 09:55:21,887 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-31 09:55:21,887 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-31 09:55:21,888 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verified, passed
2022-10-31 09:55:21,888 __main__ INFO stopping sampler-1
2022-10-31 09:55:23,305 TADA INFO assertion 12, stream-sampler-1 is not running: sampler-1 stopped, passed
2022-10-31 09:55:23,306 __main__ INFO starting sampler-1
2022-10-31 09:55:24,561 TADA INFO assertion 13, stream-sampler-1 has restarted: sampler-1 running, passed
2022-10-31 09:55:24,561 __main__ INFO allow some time for prdcr to reconnect ...
2022-10-31 09:55:30,448 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-31 09:55:30,449 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-31 09:55:30,450 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verified, passed
2022-10-31 09:55:30,451 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: unsubscribed, passed
2022-10-31 09:55:32,694 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-31 09:55:32,698 __main__ INFO stopping agg-1
2022-10-31 09:55:37,918 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-31 09:55:37,919 TADA INFO test direct_prdcr_subscribe_test ended
2022-10-31 09:55:38,138 __main__ INFO stopping munged on cygnus-01-iw
2022-10-31 09:55:38,554 __main__ INFO stopping ldmsd on cygnus-01-iw
2022-10-31 09:55:38,968 __main__ INFO stopping munged on cygnus-02-iw
2022-10-31 09:55:39,375 __main__ INFO stopping ldmsd on cygnus-02-iw
2022-10-31 09:55:39,796 __main__ INFO stopping munged on cygnus-03-iw
2022-10-31 09:55:40,418 __main__ INFO stopping munged on cygnus-04-iw
2022-10-31 09:55:40,842 __main__ INFO stopping ldmsd on cygnus-04-iw
2022-10-31 09:55:41,055 __main__ INFO stopping munged on localhost
2022-10-31 09:55:41 INFO: ----------------------------------------------
2022-10-31 09:55:41 INFO: ======== agg_slurm_test ========
2022-10-31 09:55:41 INFO: CMD: python3 agg_slurm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/agg_slurm_test
2022-10-31 09:55:41,923 TADA INFO starting test `agg_slurm_test`
2022-10-31 09:55:41,924 TADA INFO   test-id: f14e3b17a44f2dbbebe621588e9c3c59ab56c4218ff36f8217a11334776e3283
2022-10-31 09:55:41,924 TADA INFO   test-suite: LDMSD
2022-10-31 09:55:41,924 TADA INFO   test-name: agg_slurm_test
2022-10-31 09:55:41,924 TADA INFO   test-user: narate
2022-10-31 09:55:41,924 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:55:41,925 __main__ INFO -- Get or create the cluster --
2022-10-31 09:55:56,054 __main__ INFO -- Preparing syspapi JSON file --
2022-10-31 09:55:56,160 __main__ INFO -- Preparing jobpapi JSON file --
2022-10-31 09:55:56,275 __main__ INFO -- Preparing job script & programs --
2022-10-31 09:55:57,691 __main__ INFO -- Start daemons --
2022-10-31 09:56:09,803 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:56:14,806 __main__ INFO -- ldms_ls to agg-2 --
2022-10-31 09:56:14,923 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-31 09:56:15,050 __main__ INFO -- Give syspapi some time to work before submitting job --
2022-10-31 09:56:20,055 __main__ INFO -- Submitting jobs --
2022-10-31 09:56:20,190 __main__ INFO job_one: 1
2022-10-31 09:56:20,314 __main__ INFO job_two: 2
2022-10-31 09:56:30,319 __main__ INFO -- Cancelling jobs --
2022-10-31 09:56:30,320 __main__ INFO job_one: 1
2022-10-31 09:56:30,442 __main__ INFO job_two: 2
2022-10-31 09:57:42,592 TADA INFO assertion 2, slurm data verification: get expected data from store, passed
2022-10-31 09:57:42,593 TADA INFO assertion 3, meminfo data verification: No data missing, passed
2022-10-31 09:57:42,594 TADA INFO assertion 4, (SYS/JOB) PAPI data verification: No data missing, passed
2022-10-31 09:57:42,594 TADA INFO test agg_slurm_test ended
2022-10-31 09:57:56 INFO: ----------------------------------------------
2022-10-31 09:57:57 INFO: ======== papi_sampler_test ========
2022-10-31 09:57:57 INFO: CMD: python3 papi_sampler_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/papi_sampler_test
2022-10-31 09:57:58,425 TADA INFO starting test `papi_sampler_test`
2022-10-31 09:57:58,425 TADA INFO   test-id: 6a79896a28752ca958b73758f31191494b76d628e3ce32df5345c5a81d88309b
2022-10-31 09:57:58,426 TADA INFO   test-suite: LDMSD
2022-10-31 09:57:58,426 TADA INFO   test-name: papi_sampler_test
2022-10-31 09:57:58,426 TADA INFO   test-user: narate
2022-10-31 09:57:58,426 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:57:58,426 __main__ INFO -- Get or create the cluster --
2022-10-31 09:58:03,658 __main__ INFO -- Start daemons --
2022-10-31 09:58:13,659 TADA INFO assertion 0, ldmsd has started: verified, passed
2022-10-31 09:58:13,887 TADA INFO assertion 1.1, Non-papi job is submitted: jobid(1) > 0, passed
2022-10-31 09:58:19,015 TADA INFO assertion 1.2, Non-papi job is running before ldms_ls: STATE = RUNNING, passed
2022-10-31 09:58:19,189 TADA INFO assertion 1.3, Non-papi job is running after ldms_ls: STATE = RUNNING, passed
2022-10-31 09:58:19,189 TADA INFO assertion 1, Non-papi job does not create set: verified, passed
2022-10-31 09:58:33,012 TADA INFO assertion 2, papi job creates set: PAPI set created, passed
2022-10-31 09:58:33,012 TADA INFO assertion 2.2, Schema name is set accordingly: schema name == papi0, passed
2022-10-31 09:58:33,012 TADA INFO assertion 2.1, Events in papi job set created according to config file: {'PAPI_TOT_INS'} == {'PAPI_TOT_INS'}, passed
2022-10-31 09:58:33,012 TADA INFO assertion 2.3, PAPI set has correct job_id: 2 == 2, passed
2022-10-31 09:58:33,219 TADA INFO assertion 2.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-31 09:58:39,032 TADA INFO assertion 3, papi job creates set: PAPI set created, passed
2022-10-31 09:58:39,033 TADA INFO assertion 3.2, Schema name is set accordingly: schema name == papi1, passed
2022-10-31 09:58:39,033 TADA INFO assertion 3.1, Events in papi job set created according to config file: {'PAPI_TOT_INS', 'PAPI_BR_MSP'} == {'PAPI_TOT_INS', 'PAPI_BR_MSP'}, passed
2022-10-31 09:58:39,033 TADA INFO assertion 3.3, PAPI set has correct job_id: 3 == 3, passed
2022-10-31 09:58:39,253 TADA INFO assertion 3.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-31 09:58:39,253 TADA INFO assertion 4, Multiple, concurrent jobs results in concurrent, multiple sets: LDMS sets ({'node-1/papi0/2.0', 'node-1/meminfo', 'node-1/papi1/3.0'}), passed
2022-10-31 09:58:49,799 TADA INFO assertion 6, PAPI set persists within `job_expiry` after job exited: verified, passed
2022-10-31 09:59:30,109 TADA INFO assertion 7, PAPI set is deleted after `2.2 x job_expiry` since job exited: node-1/meminfo deleted, passed
2022-10-31 09:59:32,471 TADA INFO assertion 8, Missing config file attribute is logged: : papi_sampler[519]: papi_config object must contain either the 'file' or 'config' attribute., passed
2022-10-31 09:59:37,934 TADA INFO assertion 9, Bad config file is logged: : papi_sampler: configuration file syntax error., passed
2022-10-31 09:59:43,361 TADA INFO assertion 10, Unsupported events are logged: : papi_sampler: PAPI error 'Event does not exist' translating event code 'FOO', passed
2022-10-31 09:59:43,361 __main__ INFO -- Finishing Test --
2022-10-31 09:59:43,362 TADA INFO test papi_sampler_test ended
2022-10-31 09:59:43,362 __main__ INFO -- Cleaning up files --
2022-10-31 09:59:43,362 __main__ INFO -- Removing the virtual cluster --
2022-10-31 09:59:54 INFO: ----------------------------------------------
2022-10-31 09:59:55 INFO: ======== papi_store_test ========
2022-10-31 09:59:55 INFO: CMD: python3 papi_store_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/papi_store_test
2022-10-31 09:59:56,338 TADA INFO starting test `papi_store_test`
2022-10-31 09:59:56,339 TADA INFO   test-id: 912f2e0b3e318b9ffad0ee1543f4d3b9869bf31812d54623713fbd87febdc6d0
2022-10-31 09:59:56,339 TADA INFO   test-suite: LDMSD
2022-10-31 09:59:56,339 TADA INFO   test-name: papi_store_test
2022-10-31 09:59:56,339 TADA INFO   test-user: narate
2022-10-31 09:59:56,340 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:59:56,341 __main__ INFO -- Get or create the cluster --
2022-10-31 10:00:03,955 __main__ INFO -- Start daemons --
2022-10-31 10:00:36,365 TADA INFO assertion 1, Every job in the input data is represented in the output: {1, 2, 3, 4} = {1, 2, 3, 4}, passed
2022-10-31 10:00:36,365 TADA INFO assertion 2, Every event in every job results in a separate row in the output: verified, passed
2022-10-31 10:00:36,365 TADA INFO assertion 3, The schema name in the output matches the event name: verified, passed
2022-10-31 10:00:36,365 TADA INFO assertion 4, Each rank in the job results in a row per event in the output: verified, passed
2022-10-31 10:00:36,366 TADA INFO test papi_store_test ended
2022-10-31 10:00:48 INFO: ----------------------------------------------
2022-10-31 10:00:49 INFO: ======== store_app_test ========
2022-10-31 10:00:49 INFO: CMD: python3 store_app_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/store_app_test
2022-10-31 10:00:50,305 TADA INFO starting test `store_app_test`
2022-10-31 10:00:50,306 TADA INFO   test-id: bf729329c9ae7bbefe2497043fa039e7e9d93360bfe7485931ef1732d954dc70
2022-10-31 10:00:50,306 TADA INFO   test-suite: LDMSD
2022-10-31 10:00:50,306 TADA INFO   test-name: store_app_test
2022-10-31 10:00:50,306 TADA INFO   test-user: narate
2022-10-31 10:00:50,306 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:00:50,307 __main__ INFO -- Get or create the cluster --
2022-10-31 10:01:04,806 __main__ INFO -- Preparing job script & programs --
2022-10-31 10:01:05,184 __main__ INFO -- Start daemons --
2022-10-31 10:01:17,453 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:01:22,460 __main__ INFO -- Submitting jobs --
2022-10-31 10:01:22,677 __main__ INFO job_one: 1
2022-10-31 10:01:27,791 __main__ INFO job_two: 2
2022-10-31 10:01:37,190 __main__ INFO Verifying data ...
2022-10-31 10:03:34,095 TADA INFO assertion 1, Verify data: sos data is not empty and sos data < ldms_ls data, passed
2022-10-31 10:03:34,095 TADA INFO test store_app_test ended
2022-10-31 10:03:48 INFO: ----------------------------------------------
2022-10-31 10:03:49 INFO: ======== syspapi_test ========
2022-10-31 10:03:49 INFO: CMD: python3 syspapi_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/syspapi_test
2022-10-31 10:03:49,905 TADA INFO starting test `syspapi_test`
2022-10-31 10:03:49,905 TADA INFO   test-id: f1535e349298b41cacae24ce0d1ce50385644d62a109868fe90e0db7af882140
2022-10-31 10:03:49,905 TADA INFO   test-suite: LDMSD
2022-10-31 10:03:49,905 TADA INFO   test-name: syspapi_test
2022-10-31 10:03:49,905 TADA INFO   test-user: narate
2022-10-31 10:03:49,905 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:03:49,906 __main__ INFO -- Get or create the cluster --
2022-10-31 10:04:01,278 __main__ INFO -- Write syspapi JSON config files --
2022-10-31 10:04:01,278 __main__ INFO    - db/syspapi-1.json
2022-10-31 10:04:01,279 __main__ INFO    - db/syspapi-bad.json
2022-10-31 10:04:01,280 __main__ INFO -- Start daemons --
2022-10-31 10:04:09,582 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:04:14,586 __main__ INFO -- Verifying --
2022-10-31 10:04:14,709 TADA INFO assertion 1, verify set creation by cfg_file: set existed (with correct instance name), passed
2022-10-31 10:04:14,710 TADA INFO assertion 2, verify schema name by cfg_file: verify schema name, passed
2022-10-31 10:04:14,835 TADA INFO assertion 3, verify metrics (events) by cfg_file: verify events (metrics), passed
2022-10-31 10:04:16,980 TADA INFO assertion 4, verify increment counters: verify increment of supported counters, passed
2022-10-31 10:04:17,121 TADA INFO assertion 5, verify cfg_file syntax error report: verify JSON parse error, passed
2022-10-31 10:04:17,230 TADA INFO assertion 6, verify cfg_file unsupported events report: verify unsupported event report, passed
2022-10-31 10:04:38,623 TADA INFO assertion 7, verify cfg_file for many events: each event has either 'sucees' or 'failed' report, passed
2022-10-31 10:04:38,623 __main__ INFO  events succeeded: 77
2022-10-31 10:04:38,624 __main__ INFO  events failed: 114
2022-10-31 10:04:38,624 TADA INFO test syspapi_test ended
2022-10-31 10:04:51 INFO: ----------------------------------------------
2022-10-31 10:04:52 INFO: ======== agg_test ========
2022-10-31 10:04:52 INFO: CMD: python3 agg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/agg_test
2022-10-31 10:04:53,506 TADA INFO starting test `agg_test`
2022-10-31 10:04:53,506 TADA INFO   test-id: 4032a97871e33b08b3c86f6b929a082c4afe561edc3a120b09849bfc07c28d4c
2022-10-31 10:04:53,506 TADA INFO   test-suite: LDMSD
2022-10-31 10:04:53,506 TADA INFO   test-name: agg_test
2022-10-31 10:04:53,506 TADA INFO   test-user: narate
2022-10-31 10:04:53,506 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:04:53,507 __main__ INFO -- Get or create the cluster --
2022-10-31 10:05:11,015 __main__ INFO -- Start daemons --
2022-10-31 10:05:20,214 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:05:25,220 __main__ INFO -- ldms_ls to agg-2 --
2022-10-31 10:05:25,335 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-31 10:05:26,119 TADA INFO assertion 2, meminfo data verification: data verified, passed
2022-10-31 10:05:26,119 __main__ INFO -- Terminating ldmsd on node-1 --
2022-10-31 10:05:28,437 TADA INFO assertion 3, node-1 ldmsd terminated, sets removed from agg-11: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-31 10:05:28,664 TADA INFO assertion 4, node-1 ldmsd terminated, sets removed from agg-2: list({'node-4/meminfo', 'node-3/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-31 10:05:28,664 __main__ INFO -- Resurrecting ldmsd on node-1 --
2022-10-31 10:05:34,327 TADA INFO assertion 5, node-1 ldmsd revived, sets added to agg-11: list({'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-31 10:05:34,445 TADA INFO assertion 6, node-1 ldmsd revived, sets added to agg-2: list({'node-4/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2022-10-31 10:05:34,446 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-31 10:05:36,779 TADA INFO assertion 7, agg-11 ldmsd terminated, sets removed from agg-2: list({'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-31 10:05:36,892 TADA INFO assertion 8, agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-31 10:05:37,014 TADA INFO assertion 9, agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-31 10:05:37,014 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-31 10:05:42,646 TADA INFO assertion 10, agg-11 ldmsd revived, sets added to agg-2: list({'node-4/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2022-10-31 10:05:42,647 TADA INFO test agg_test ended
2022-10-31 10:05:58 INFO: ----------------------------------------------
2022-10-31 10:05:59 INFO: ======== failover_test ========
2022-10-31 10:05:59 INFO: CMD: python3 failover_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/failover_test
2022-10-31 10:05:59,716 TADA INFO starting test `failover_test`
2022-10-31 10:05:59,716 TADA INFO   test-id: b2db919ff44124d2e1b58a341612ec9b44ef3476b91bce3c8c056031208a720a
2022-10-31 10:05:59,716 TADA INFO   test-suite: LDMSD
2022-10-31 10:05:59,716 TADA INFO   test-name: failover_test
2022-10-31 10:05:59,716 TADA INFO   test-user: narate
2022-10-31 10:05:59,716 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:05:59,717 __main__ INFO -- Get or create the cluster --
2022-10-31 10:06:17,406 __main__ INFO -- Start daemons --
2022-10-31 10:06:26,595 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:06:41,610 __main__ INFO -- ldms_ls to agg-2 --
2022-10-31 10:06:41,733 TADA INFO assertion 1, 
ldms_ls agg-2: dir result verified, passed
2022-10-31 10:06:42,499 TADA INFO assertion 2, 
meminfo data verification: data verified, passed
2022-10-31 10:06:42,499 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-31 10:06:47,829 TADA INFO assertion 3, 
agg-11 ldmsd terminated, sets added to agg-12: list({'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-31 10:06:47,942 TADA INFO assertion 4, 
agg-11 ldmsd terminated, all sets running on agg-2: list({'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-31 10:06:48,052 TADA INFO assertion 5, 
agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-31 10:06:48,164 TADA INFO assertion 6, 
agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-31 10:06:48,164 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-31 10:07:08,844 TADA INFO assertion 7, 
agg-11 ldmsd revived, sets removed from agg-12: list({'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-31 10:07:08,959 TADA INFO assertion 8, 
agg-11 ldmsd revived, all sets running on agg-2: list({'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-31 10:07:08,959 __main__ INFO -- Terminating ldmsd on agg-12 --
2022-10-31 10:07:14,322 TADA INFO assertion 9, 
agg-12 ldmsd terminated, sets added to agg-11: list({'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-31 10:07:14,441 TADA INFO assertion 10, 
agg-12 ldmsd terminated, all sets running on agg-2: list({'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-31 10:07:14,541 TADA INFO assertion 11, 
agg-12 ldmsd terminated, node-2 ldmsd is still running: list({'node-2/meminfo'}) == expect({'node-2/meminfo'}), passed
2022-10-31 10:07:14,645 TADA INFO assertion 12, 
agg-12 ldmsd terminated, node-4 ldmsd is still running: list({'node-4/meminfo'}) == expect({'node-4/meminfo'}), passed
2022-10-31 10:07:14,645 __main__ INFO -- Resurrecting ldmsd on agg-12 --
2022-10-31 10:07:35,323 TADA INFO assertion 13, 
agg-12 ldmsd revived, sets removed from agg-11: list({'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo'}), passed
2022-10-31 10:07:35,448 TADA INFO assertion 14, 
agg-12 ldmsd revived, all sets running on agg-2: list({'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-31 10:07:35,449 TADA INFO test failover_test ended
2022-10-31 10:07:50 INFO: ----------------------------------------------
2022-10-31 10:07:51 INFO: ======== ldmsd_auth_ovis_test ========
2022-10-31 10:07:51 INFO: CMD: python3 ldmsd_auth_ovis_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldmsd_auth_ovis_test
2022-10-31 10:07:52,304 TADA INFO starting test `ldmsd_auth_ovis_test`
2022-10-31 10:07:52,304 TADA INFO   test-id: 5aa36a7e0f1e6e8b21184b45497ccaef85102ced073d0a6ff2e523b9d367b503
2022-10-31 10:07:52,304 TADA INFO   test-suite: LDMSD
2022-10-31 10:07:52,304 TADA INFO   test-name: ldmsd_auth_ovis_test
2022-10-31 10:07:52,304 TADA INFO   test-user: narate
2022-10-31 10:07:52,305 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:07:52,305 __main__ INFO -- Get or create the cluster --
2022-10-31 10:07:57,409 __main__ INFO -- Start daemons --
2022-10-31 10:07:59,346 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:08:04,457 TADA INFO assertion 1, ldms_ls with auth none: verified, passed
2022-10-31 10:08:04,572 TADA INFO assertion 2, ldms_ls with wrong secret: verified, passed
2022-10-31 10:08:04,693 TADA INFO assertion 3, ldms_ls 'dir' with right secret: verified, passed
2022-10-31 10:08:04,974 TADA INFO assertion 4, ldms_ls 'read' with right secret: verified, passed
2022-10-31 10:08:04,974 TADA INFO test ldmsd_auth_ovis_test ended
2022-10-31 10:08:16 INFO: ----------------------------------------------
2022-10-31 10:08:17 INFO: ======== ldmsd_auth_test ========
2022-10-31 10:08:17 INFO: CMD: python3 ldmsd_auth_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldmsd_auth_test
2022-10-31 10:08:17,951 TADA INFO starting test `ldmsd_auth_test`
2022-10-31 10:08:17,952 TADA INFO   test-id: 098f316121c337ca61edcf928f0ab75dd397ceb1438e75c0665ed72cfa04921f
2022-10-31 10:08:17,952 TADA INFO   test-suite: LDMSD
2022-10-31 10:08:17,952 TADA INFO   test-name: ldmsd_auth_test
2022-10-31 10:08:17,952 TADA INFO   test-user: narate
2022-10-31 10:08:17,952 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:08:17,953 __main__ INFO -- Get or create the cluster --
2022-10-31 10:08:35,728 __main__ INFO -- Start daemons --
2022-10-31 10:08:54,461 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:08:59,605 TADA INFO assertion 1, root@agg-2(dom3) ldms_ls to agg-2:10000: see all sets, passed
2022-10-31 10:08:59,728 TADA INFO assertion 2, user@agg-2(dom3) ldms_ls to agg-2:10000: see only meminfo, passed
2022-10-31 10:08:59,851 TADA INFO assertion 3, root@headnode(dom4) ldms_ls to agg-2:10001: see all sets, passed
2022-10-31 10:08:59,956 TADA INFO assertion 4, user@headnode(dom4) ldms_ls to agg-2:10001: see only meminfo, passed
2022-10-31 10:09:00,059 TADA INFO assertion 5, root@headnode(dom4) ldms_ls to agg-11:10000: connection rejected, passed
2022-10-31 10:09:00,060 TADA INFO test ldmsd_auth_test ended
2022-10-31 10:09:15 INFO: ----------------------------------------------
2022-10-31 10:09:16 INFO: ======== ldmsd_ctrl_test ========
2022-10-31 10:09:16 INFO: CMD: python3 ldmsd_ctrl_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldmsd_ctrl_test
2022-10-31 10:09:17,084 TADA INFO starting test `ldmsd_ctrl_test`
2022-10-31 10:09:17,084 TADA INFO   test-id: c2cb2dd04c7efa96d5fcf4c351e87a516ab323202e289cdd8bf24c09e899b062
2022-10-31 10:09:17,084 TADA INFO   test-suite: LDMSD
2022-10-31 10:09:17,084 TADA INFO   test-name: ldmsd_ctrl_test
2022-10-31 10:09:17,084 TADA INFO   test-user: narate
2022-10-31 10:09:17,084 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:09:17,085 __main__ INFO -- Get or create the cluster --
2022-10-31 10:09:26,243 __main__ INFO -- Start daemons --
2022-10-31 10:09:30,763 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:09:36,879 TADA INFO assertion 1, ldmsd_controller interactive session: connected, passed
2022-10-31 10:09:37,995 TADA INFO assertion 2, ldmsctl interactive session: connected, passed
2022-10-31 10:09:38,596 TADA INFO assertion 3, ldmsd_controller start bogus producer: expected output verified, passed
2022-10-31 10:09:39,198 TADA INFO assertion 4, ldmsctl start bogus producer: expected output verified, passed
2022-10-31 10:09:39,799 TADA INFO assertion 5, ldmsd_controller bogus command: expected output verified, passed
2022-10-31 10:09:40,401 TADA INFO assertion 6, ldmsctl bogus command: expected output verified, passed
2022-10-31 10:09:41,002 TADA INFO assertion 7, ldmsd_controller load bogus plugin: expected output verified, passed
2022-10-31 10:09:41,604 TADA INFO assertion 8, ldmsctl load bogus plugin: expected output verified, passed
2022-10-31 10:09:58,787 TADA INFO assertion 9, ldmsd_controller prdcr/updtr: verified, passed
2022-10-31 10:10:15,973 TADA INFO assertion 10, ldmsctl prdcr/updtr: verified, passed
2022-10-31 10:10:15,973 TADA INFO test ldmsd_ctrl_test ended
2022-10-31 10:10:28 INFO: ----------------------------------------------
2022-10-31 10:10:29 INFO: ======== ldmsd_stream_test ========
2022-10-31 10:10:29 INFO: CMD: python3 ldmsd_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldmsd_stream_test
2022-10-31 10:10:30,219 TADA INFO starting test `ldmsd_stream_test`
2022-10-31 10:10:30,219 TADA INFO   test-id: bcb01b54272dead133d22581c10196f7caca447374e794afacc7458de8469fd2
2022-10-31 10:10:30,220 TADA INFO   test-suite: LDMSD
2022-10-31 10:10:30,220 TADA INFO   test-name: ldmsd_stream_test
2022-10-31 10:10:30,220 TADA INFO   test-user: narate
2022-10-31 10:10:30,220 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:10:41,307 __main__ INFO waiting for libraries to be available across all containers...
2022-10-31 10:10:42,151 __main__ INFO _lib_avail: True
2022-10-31 10:11:49,469 __main__ INFO test ldmsd_stream_subscribe with large json streams
2022-10-31 10:11:55,597 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-31 10:12:09,012 __main__ INFO --- Verifying the received streams
2022-10-31 10:12:10,614 TADA INFO assertion 1, ldmsd_stream_subscribe receives large json streams: Verify all streams were received correctly, passed
2022-10-31 10:12:10,826 __main__ INFO test LDMSD with large json streams
2022-10-31 10:12:16,897 __main__ INFO --- Sending stream to samplerd
2022-10-31 10:12:35,674 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 10:12:38,085 TADA INFO assertion 2, samplerd receives large json streams: Verify all streams were received correctly, passed
2022-10-31 10:12:38,085 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 10:12:40,482 TADA INFO assertion 3, agg receives large json streams: Verify all streams were received correctly, passed
2022-10-31 10:12:40,482 __main__ INFO test ldmsd_stream_subscribe with small json streams
2022-10-31 10:12:46,602 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-31 10:14:42,710 __main__ INFO --- Verifying the received streams
2022-10-31 10:14:44,571 TADA INFO assertion 4, ldmsd_stream_subscribe receives small json streams: Verify all streams were received correctly, passed
2022-10-31 10:14:44,789 __main__ INFO test LDMSD with small json streams
2022-10-31 10:14:50,794 __main__ INFO --- Sending stream to samplerd
2022-10-31 10:16:51,654 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 10:16:54,707 TADA INFO assertion 5, samplerd receives small json streams: Verify all streams were received correctly, passed
2022-10-31 10:16:54,707 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 10:16:57,704 TADA INFO assertion 6, agg receives small json streams: Verify all streams were received correctly, passed
2022-10-31 10:16:57,704 __main__ INFO test ldmsd_stream_subscribe with large string streams
2022-10-31 10:17:03,815 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-31 10:17:17,047 __main__ INFO --- Verifying the received streams
2022-10-31 10:17:18,633 TADA INFO assertion 7, ldmsd_stream_subscribe receives large string streams: Verify all streams were received correctly, passed
2022-10-31 10:17:18,839 __main__ INFO test LDMSD with large string streams
2022-10-31 10:17:24,855 __main__ INFO --- Sending stream to samplerd
2022-10-31 10:17:43,607 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 10:17:44,759 TADA INFO assertion 8, samplerd receives large string streams: Verify all streams were received correctly, passed
2022-10-31 10:17:44,759 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 10:17:45,896 TADA INFO assertion 9, agg receives large string streams: Verify all streams were received correctly, passed
2022-10-31 10:17:45,896 __main__ INFO test ldmsd_stream_subscribe with small string streams
2022-10-31 10:17:52,021 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-31 10:19:47,794 __main__ INFO --- Verifying the received streams
2022-10-31 10:19:49,699 TADA INFO assertion 10, ldmsd_stream_subscribe receives small string streams: Verify all streams were received correctly, passed
2022-10-31 10:19:49,931 __main__ INFO test LDMSD with small string streams
2022-10-31 10:19:55,932 __main__ INFO --- Sending stream to samplerd
2022-10-31 10:21:57,293 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 10:21:58,495 TADA INFO assertion 11, samplerd receives small string streams: Verify all streams were received correctly, passed
2022-10-31 10:21:58,495 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 10:21:59,688 TADA INFO assertion 12, agg receives small string streams: Verify all streams were received correctly, passed
2022-10-31 10:21:59,689 TADA INFO test ldmsd_stream_test ended
2022-10-31 10:22:13 INFO: ----------------------------------------------
2022-10-31 10:22:15 INFO: ======== maestro_cfg_test ========
2022-10-31 10:22:15 INFO: CMD: python3 maestro_cfg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/maestro_cfg_test
2022-10-31 10:22:16,097 TADA INFO starting test `maestro_cfg_test`
2022-10-31 10:22:16,098 TADA INFO   test-id: f9f32caf81d35e9ded108997893bcb322ec0c18edf26456b4db444903ee58780
2022-10-31 10:22:16,098 TADA INFO   test-suite: LDMSD
2022-10-31 10:22:16,098 TADA INFO   test-name: maestro_cfg_test
2022-10-31 10:22:16,098 TADA INFO   test-user: narate
2022-10-31 10:22:16,098 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:22:26,109 __main__ INFO -- Get or create cluster --
2022-10-31 10:22:52,068 __main__ INFO -- Start daemons --
2022-10-31 10:23:06,793 __main__ INFO ... make sure ldmsd's are up
2022-10-31 10:23:14,450 TADA INFO assertion 1, load maestro etcd cluster: etcd cluster loaded successfully, passed
2022-10-31 10:23:54,491 TADA INFO assertion 2, config ldmsd cluster with maestro: Maestro ldmsd configuration successful, passed
2022-10-31 10:23:56,044 TADA INFO assertion 3, verify sampler daemons: OK, passed
2022-10-31 10:23:56,637 TADA INFO assertion 4, verify L1 aggregator daemons: OK, passed
2022-10-31 10:23:56,899 TADA INFO assertion 5, verify L2 aggregator daemon: OK, passed
2022-10-31 10:23:57,205 TADA INFO assertion 6, verify data storage: OK, passed
---Wait for config to write to file---
2022-10-31 10:23:57,206 TADA INFO test maestro_cfg_test ended
2022-10-31 10:24:15 INFO: ----------------------------------------------
2022-10-31 10:24:16 INFO: ======== mt-slurm-test ========
2022-10-31 10:24:16 INFO: CMD: python3 mt-slurm-test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/mt-slurm-test
-- Get or create the cluster --
-- Start daemons --
... wait a bit to make sure ldmsd's are up
Every job in input data represented in output: : Passed
['# task_rank,timestamp', '0,1667229895.956810', '1,1667229895.956810', '2,1667229895.956810', '3,1667229896.959210', '4,1667229896.959210', '5,1667229896.959210', '6,1667229896.959210', '7,1667229896.959210', '8,1667229896.959210', '9,1667229897.950876', '10,1667229898.952225', '11,1667229898.952225', '12,1667229898.952225', '13,1667229898.952225', '14,1667229898.952225', '15,1667229898.952225', '16,1667229898.952225', '17,1667229898.952225', '18,1667229900.937433', '19,1667229900.937433', '20,1667229900.937433', '21,1667229900.937433', '22,1667229900.937433', '23,1667229900.937433', '24,1667229900.937433', '25,1667229900.937433', '26,1667229901.917292', '# Records 27/27.', '']
Job 10000 has 27 rank: : Passed
Job 10100 has 64 rank: : Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
Job 10000 has 3 nodes: node count 3 correct: Passed
Job 10100 has 4 nodes: node count 4 correct: Passed
2022-10-31 10:25:34 INFO: ----------------------------------------------
2022-10-31 10:25:35 INFO: ======== ovis_ev_test ========
2022-10-31 10:25:35 INFO: CMD: python3 ovis_ev_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ovis_ev_test
2022-10-31 10:25:36,381 __main__ INFO -- Create the cluster -- 
2022-10-31 10:25:45,908 TADA INFO starting test `ovis_ev_test`
2022-10-31 10:25:45,909 TADA INFO   test-id: 5fb9dcbd488a280e05bcd6650d19437a82dfde382facfd06a0e99577909032df
2022-10-31 10:25:45,909 TADA INFO   test-suite: test_ovis_ev
2022-10-31 10:25:45,909 TADA INFO   test-name: ovis_ev_test
2022-10-31 10:25:45,909 TADA INFO   test-user: narate
2022-10-31 10:25:45,909 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:25:45,909 TADA INFO assertion 1, Test posting an event without timeout: ovis_ev delivered the expected event., passed
2022-10-31 10:25:45,910 TADA INFO assertion 2, Test posting an event with a current timeout: ovis_ev delivered the expected event., passed
2022-10-31 10:25:45,910 TADA INFO assertion 3, Test posting an event with a future timeout: ovis_ev delivered the expected event., passed
2022-10-31 10:25:45,910 TADA INFO assertion 4, Test reposting a posted event: ev_post returned EBUSY when posted an already posted event, passed
2022-10-31 10:25:45,910 TADA INFO assertion 5, Test canceling a posted event: ovis_ev delivered the expected event., passed
2022-10-31 10:25:45,910 TADA INFO assertion 6, Test rescheduling a posted event: ovis_ev delivered the expected event., passed
2022-10-31 10:25:45,911 TADA INFO assertion 7, Test event deliver order: The event delivery order was correct., passed
2022-10-31 10:25:45,911 TADA INFO assertion 8, Test flushing events: Expected status (1) == delivered status (1), passed
2022-10-31 10:25:45,911 TADA INFO assertion 9, Test posting event on a flushed worker: Expected status (0) == delivered status (0), passed
2022-10-31 10:25:45,911 TADA INFO assertion 10, Test the case that multiple threads post the same event: ev_post returned the expected return code., passed
2022-10-31 10:25:45,911 TADA INFO test ovis_ev_test ended
2022-10-31 10:25:56 INFO: ----------------------------------------------
2022-10-31 10:25:57 INFO: ======== prdcr_subscribe_test ========
2022-10-31 10:25:57 INFO: CMD: python3 prdcr_subscribe_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/prdcr_subscribe_test
2022-10-31 10:25:58,270 TADA INFO starting test `prdcr_subscribe_test`
2022-10-31 10:25:58,270 TADA INFO   test-id: 809fe431739f1c29d1d6eaac52bec9275bbe5fd60db96292b14d99c8a051460c
2022-10-31 10:25:58,270 TADA INFO   test-suite: LDMSD
2022-10-31 10:25:58,270 TADA INFO   test-name: prdcr_subscribe_test
2022-10-31 10:25:58,270 TADA INFO   test-user: narate
2022-10-31 10:25:58,270 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:26:33,743 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-31 10:26:33,743 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-31 10:26:33,744 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-31 10:26:33,744 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-31 10:26:33,745 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verification, passed
2022-10-31 10:26:34,090 TADA INFO assertion 5, Stopping the producers succeeds: , passed
2022-10-31 10:26:34,455 TADA INFO assertion 6, Restarting the producers succeeds: , passed
2022-10-31 10:26:42,426 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-31 10:26:42,427 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-31 10:26:42,427 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-31 10:26:42,427 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-31 10:26:42,428 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verification, passed
2022-10-31 10:26:43,639 TADA INFO assertion 12, stream-sampler-1 is not running: (running == False), passed
2022-10-31 10:26:45,157 TADA INFO assertion 13, stream-sampler-1 has restarted: (running == True), passed
2022-10-31 10:26:52,687 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-31 10:26:52,687 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-31 10:26:52,688 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verification, passed
2022-10-31 10:26:53,047 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: , passed
2022-10-31 10:26:56,339 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-31 10:27:02,127 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-31 10:27:02,128 TADA INFO test prdcr_subscribe_test ended
2022-10-31 10:27:14 INFO: ----------------------------------------------
2022-10-31 10:27:15 INFO: ======== set_array_test ========
2022-10-31 10:27:15 INFO: CMD: python3 set_array_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/set_array_test
2022-10-31 10:27:16,371 TADA INFO starting test `set_array_test`
2022-10-31 10:27:16,371 TADA INFO   test-id: 2380836a71372cec3b6e5870e3e0a77b936169b4c9dd00e296d49be206cf5a68
2022-10-31 10:27:16,371 TADA INFO   test-suite: LDMSD
2022-10-31 10:27:16,371 TADA INFO   test-name: set_array_test
2022-10-31 10:27:16,371 TADA INFO   test-user: narate
2022-10-31 10:27:16,371 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:27:16,372 __main__ INFO -- Get or create the cluster --
2022-10-31 10:27:21,469 __main__ INFO -- Start daemons --
2022-10-31 10:27:23,424 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:27:50,534 TADA INFO assertion 1, 1st update got some callbacks: verified hunk of 8 snapshots, passed
2022-10-31 10:27:50,534 TADA INFO assertion 2, 2nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-31 10:27:50,535 TADA INFO assertion 3, 3nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-31 10:27:50,535 TADA INFO test set_array_test ended
2022-10-31 10:28:01 INFO: ----------------------------------------------
2022-10-31 10:28:02 INFO: ======== setgroup_test ========
2022-10-31 10:28:02 INFO: CMD: python3 setgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/setgroup_test
2022-10-31 10:28:03,530 TADA INFO starting test `setgroup_test`
2022-10-31 10:28:03,530 TADA INFO   test-id: f6d2fa84e4fa4d6d8d1b35052d99431631752a16ec16fe58128a4ea657b86079
2022-10-31 10:28:03,530 TADA INFO   test-suite: LDMSD
2022-10-31 10:28:03,530 TADA INFO   test-name: setgroup_test
2022-10-31 10:28:03,531 TADA INFO   test-user: narate
2022-10-31 10:28:03,531 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:28:03,532 __main__ INFO -- Get or create the cluster --
2022-10-31 10:28:12,719 __main__ INFO -- Start daemons --
2022-10-31 10:28:17,148 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:28:22,153 __main__ INFO -- ldms_ls to agg-2 --
2022-10-31 10:28:22,287 TADA INFO assertion 1, ldms_ls grp on agg-2: dir result verified, passed
2022-10-31 10:28:24,557 TADA INFO assertion 2, members on agg-2 are being updated: data verified, passed
2022-10-31 10:28:24,557 __main__ INFO -- Removing test_2 from grp --
2022-10-31 10:28:25,028 TADA INFO assertion 3, test_2 is removed fom grp on sampler: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2022-10-31 10:28:29,138 TADA INFO assertion 4, test_2 is removed from grp on agg-1: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2022-10-31 10:28:33,254 TADA INFO assertion 5, test_2 is removed from grp on agg-2: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2022-10-31 10:28:37,255 __main__ INFO -- Adding test_2 back into grp --
2022-10-31 10:28:37,750 TADA INFO assertion 6, test_2 is added back to grp on sampler: expect {'node-1/test_2', 'node-1/grp', 'node-1/test_1'}, got {'node-1/test_2', 'node-1/grp', 'node-1/test_1'}, passed
2022-10-31 10:28:41,868 TADA INFO assertion 7, test_2 is added back to grp on agg-1: expect {'node-1/test_2', 'node-1/grp', 'node-1/test_1'}, got {'node-1/test_2', 'node-1/grp', 'node-1/test_1'}, passed
2022-10-31 10:28:43,989 TADA INFO assertion 8, test_2 is added back to grp on agg-2: expect {'node-1/test_2', 'node-1/grp', 'node-1/test_1'}, got {'node-1/test_2', 'node-1/grp', 'node-1/test_1'}, passed
2022-10-31 10:28:45,992 TADA INFO test setgroup_test ended
2022-10-31 10:28:58 INFO: ----------------------------------------------
2022-10-31 10:28:59 INFO: ======== slurm_stream_test ========
2022-10-31 10:28:59 INFO: CMD: python3 slurm_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/slurm_stream_test
2022-10-31 10:29:00,306 TADA INFO starting test `slurm_stream_test`
2022-10-31 10:29:00,307 TADA INFO   test-id: 4d0c19cfa0de48e6a5ad8166decf182a595e0ea420927dc623ca39fa75462394
2022-10-31 10:29:00,307 TADA INFO   test-suite: LDMSD
2022-10-31 10:29:00,307 TADA INFO   test-name: slurm_stream_test
2022-10-31 10:29:00,307 TADA INFO   test-user: narate
2022-10-31 10:29:00,307 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:29:00,307 __main__ INFO -- Get or create the cluster --
2022-10-31 10:29:07,187 __main__ INFO -- Start daemons --
2022-10-31 10:29:09,790 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:29:39,543 TADA INFO assertion 1, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:39,543 __main__ INFO 12345
2022-10-31 10:29:39,543 __main__ INFO 12345
2022-10-31 10:29:39,544 TADA INFO assertion 2, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,544 TADA INFO assertion 3, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-31 10:29:39,544 TADA INFO assertion 4, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,544 TADA INFO assertion 5, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,544 TADA INFO assertion 6, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,544 TADA INFO assertion 7, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,647 TADA INFO assertion 8, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:39,648 __main__ INFO 12345
2022-10-31 10:29:39,648 __main__ INFO 12345
2022-10-31 10:29:39,648 TADA INFO assertion 9, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,648 TADA INFO assertion 10, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-31 10:29:39,648 TADA INFO assertion 11, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,648 TADA INFO assertion 12, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,648 TADA INFO assertion 13, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,649 TADA INFO assertion 14, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 10:29:39,774 TADA INFO assertion 15, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:39,774 __main__ INFO 12346
2022-10-31 10:29:39,774 __main__ INFO 12346
2022-10-31 10:29:39,774 TADA INFO assertion 16, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,774 TADA INFO assertion 17, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-31 10:29:39,775 TADA INFO assertion 18, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,775 TADA INFO assertion 19, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,775 TADA INFO assertion 20, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,775 TADA INFO assertion 21, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,883 TADA INFO assertion 22, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:39,883 __main__ INFO 12346
2022-10-31 10:29:39,883 __main__ INFO 12346
2022-10-31 10:29:39,883 TADA INFO assertion 23, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,883 TADA INFO assertion 24, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-31 10:29:39,883 TADA INFO assertion 25, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,883 TADA INFO assertion 26, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,884 TADA INFO assertion 27, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,884 TADA INFO assertion 28, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 10:29:39,990 TADA INFO assertion 29, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:39,990 __main__ INFO 12347
2022-10-31 10:29:39,990 __main__ INFO 12347
2022-10-31 10:29:39,990 TADA INFO assertion 30, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-31 10:29:39,990 TADA INFO assertion 31, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-31 10:29:39,991 TADA INFO assertion 32, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 10:29:39,991 TADA INFO assertion 33, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 10:29:39,991 TADA INFO assertion 34, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 10:29:39,991 TADA INFO assertion 35, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 10:29:40,098 TADA INFO assertion 36, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,098 __main__ INFO 12347
2022-10-31 10:29:40,098 __main__ INFO 12347
2022-10-31 10:29:40,098 TADA INFO assertion 37, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-31 10:29:40,099 TADA INFO assertion 38, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-31 10:29:40,099 TADA INFO assertion 39, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 10:29:40,099 TADA INFO assertion 40, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 10:29:40,099 TADA INFO assertion 41, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 10:29:40,099 TADA INFO assertion 42, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 10:29:40,211 TADA INFO assertion 43, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,211 __main__ INFO 12348
2022-10-31 10:29:40,211 __main__ INFO 12348
2022-10-31 10:29:40,211 TADA INFO assertion 44, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,211 TADA INFO assertion 45, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-31 10:29:40,211 TADA INFO assertion 46, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,212 TADA INFO assertion 47, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,212 TADA INFO assertion 48, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,212 TADA INFO assertion 49, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,315 TADA INFO assertion 50, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,315 __main__ INFO 12348
2022-10-31 10:29:40,316 __main__ INFO 12348
2022-10-31 10:29:40,316 TADA INFO assertion 51, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,316 TADA INFO assertion 52, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-31 10:29:40,316 TADA INFO assertion 53, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,316 TADA INFO assertion 54, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,316 TADA INFO assertion 55, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,316 TADA INFO assertion 56, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 10:29:40,430 TADA INFO assertion 57, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,430 __main__ INFO 12355
2022-10-31 10:29:40,430 __main__ INFO 12355
2022-10-31 10:29:40,430 TADA INFO assertion 58, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,430 TADA INFO assertion 59, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-31 10:29:40,430 TADA INFO assertion 60, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,431 TADA INFO assertion 61, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,431 TADA INFO assertion 62, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,431 TADA INFO assertion 63, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,431 TADA INFO assertion 64, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,431 TADA INFO assertion 65, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,431 TADA INFO assertion 66, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,432 TADA INFO assertion 67, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,533 TADA INFO assertion 68, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,533 __main__ INFO 12355
2022-10-31 10:29:40,533 __main__ INFO 12355
2022-10-31 10:29:40,534 TADA INFO assertion 69, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,534 TADA INFO assertion 70, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-31 10:29:40,534 TADA INFO assertion 71, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,534 TADA INFO assertion 72, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,534 TADA INFO assertion 73, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,534 TADA INFO assertion 74, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,535 TADA INFO assertion 75, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,535 TADA INFO assertion 76, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,535 TADA INFO assertion 77, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,535 TADA INFO assertion 78, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 10:29:40,640 TADA INFO assertion 79, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,640 __main__ INFO 12356
2022-10-31 10:29:40,640 __main__ INFO 12356
2022-10-31 10:29:40,641 TADA INFO assertion 80, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,641 TADA INFO assertion 81, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-31 10:29:40,641 TADA INFO assertion 82, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,641 TADA INFO assertion 83, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,642 TADA INFO assertion 84, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,642 TADA INFO assertion 85, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,642 TADA INFO assertion 86, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,642 TADA INFO assertion 87, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,643 TADA INFO assertion 88, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,643 TADA INFO assertion 89, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,751 TADA INFO assertion 90, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,751 __main__ INFO 12356
2022-10-31 10:29:40,751 __main__ INFO 12356
2022-10-31 10:29:40,751 TADA INFO assertion 91, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,751 TADA INFO assertion 92, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-31 10:29:40,751 TADA INFO assertion 93, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,751 TADA INFO assertion 94, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,752 TADA INFO assertion 95, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,752 TADA INFO assertion 96, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,752 TADA INFO assertion 97, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,752 TADA INFO assertion 98, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,752 TADA INFO assertion 99, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,752 TADA INFO assertion 100, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 10:29:40,863 TADA INFO assertion 101, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,863 __main__ INFO 12357
2022-10-31 10:29:40,864 __main__ INFO 12357
2022-10-31 10:29:40,864 TADA INFO assertion 102, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,864 TADA INFO assertion 103, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-31 10:29:40,864 TADA INFO assertion 104, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,864 TADA INFO assertion 105, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,864 TADA INFO assertion 106, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,864 TADA INFO assertion 107, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,865 TADA INFO assertion 108, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,865 TADA INFO assertion 109, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,865 TADA INFO assertion 110, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,865 TADA INFO assertion 111, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,977 TADA INFO assertion 112, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:40,977 __main__ INFO 12357
2022-10-31 10:29:40,978 __main__ INFO 12357
2022-10-31 10:29:40,978 TADA INFO assertion 113, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,978 TADA INFO assertion 114, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-31 10:29:40,979 TADA INFO assertion 115, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,979 TADA INFO assertion 116, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,979 TADA INFO assertion 117, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,979 TADA INFO assertion 118, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,979 TADA INFO assertion 119, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,979 TADA INFO assertion 120, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,979 TADA INFO assertion 121, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:40,980 TADA INFO assertion 122, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 10:29:41,097 TADA INFO assertion 123, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:41,097 __main__ INFO 12358
2022-10-31 10:29:41,097 __main__ INFO 12358
2022-10-31 10:29:41,097 TADA INFO assertion 124, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,097 TADA INFO assertion 125, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-31 10:29:41,097 TADA INFO assertion 126, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,098 TADA INFO assertion 127, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,098 TADA INFO assertion 128, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,098 TADA INFO assertion 129, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,098 TADA INFO assertion 130, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,098 TADA INFO assertion 131, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,098 TADA INFO assertion 132, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,098 TADA INFO assertion 133, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,199 TADA INFO assertion 134, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 10:29:41,199 __main__ INFO 12358
2022-10-31 10:29:41,199 __main__ INFO 12358
2022-10-31 10:29:41,199 TADA INFO assertion 135, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,199 TADA INFO assertion 136, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-31 10:29:41,200 TADA INFO assertion 137, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,200 TADA INFO assertion 138, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,200 TADA INFO assertion 139, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,200 TADA INFO assertion 140, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,200 TADA INFO assertion 141, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,201 TADA INFO assertion 142, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,201 TADA INFO assertion 143, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:41,201 TADA INFO assertion 144, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 10:29:43,294 TADA INFO assertion 145, new job correctly replaces oldest slot: correct job_id fills next slot, passed
2022-10-31 10:29:43,294 __main__ INFO 12353
2022-10-31 10:29:43,294 __main__ INFO 12353
2022-10-31 10:29:43,294 TADA INFO assertion 146, new job_start correctly represented in metric set: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,294 TADA INFO assertion 147, new job_end correctly represented in metric set: with mutl jobs running, for Job 12353, passed
2022-10-31 10:29:43,294 TADA INFO assertion 148, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,295 TADA INFO assertion 149, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,295 TADA INFO assertion 150, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,295 TADA INFO assertion 151, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,295 TADA INFO assertion 152, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,295 TADA INFO assertion 153, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,295 TADA INFO assertion 154, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,295 TADA INFO assertion 155, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 10:29:43,295 __main__ INFO -- Test Finished --
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
2022-10-31 10:29:43,296 TADA INFO test slurm_stream_test ended
2022-10-31 10:29:54 INFO: ----------------------------------------------
2022-10-31 10:29:55 INFO: ======== spank_notifier_test ========
2022-10-31 10:29:55 INFO: CMD: python3 spank_notifier_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/spank_notifier_test
2022-10-31 10:29:56,222 TADA INFO starting test `spank_notifier_test`
2022-10-31 10:29:56,222 TADA INFO   test-id: 167d2e1757fc4eb1b8dc0a01b74074e416e5691d4e0df323a6b0561e7cc661d3
2022-10-31 10:29:56,222 TADA INFO   test-suite: Slurm_Plugins
2022-10-31 10:29:56,222 TADA INFO   test-name: spank_notifier_test
2022-10-31 10:29:56,223 TADA INFO   test-user: narate
2022-10-31 10:29:56,223 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:29:56,223 __main__ INFO -- Create the cluster --
2022-10-31 10:30:21,871 __main__ INFO -- Cleanup output --
2022-10-31 10:30:22,189 __main__ INFO -- Test bad plugstack config --
2022-10-31 10:30:22,189 __main__ INFO Starting slurm ...
2022-10-31 10:30:36,534 __main__ INFO Starting slurm ... OK
2022-10-31 10:30:57,004 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 10:30:57,120 __main__ INFO   jobid = 1
2022-10-31 10:30:57,325 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 10:30:57,433 __main__ INFO   jobid = 2
2022-10-31 10:30:57,641 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 10:30:57,757 __main__ INFO   jobid = 3
2022-10-31 10:30:57,968 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 10:30:58,088 __main__ INFO   jobid = 4
2022-10-31 10:31:08,813 TADA INFO assertion 60, Bad config does not affect jobs: jobs verified, passed
2022-10-31 10:31:08,813 __main__ INFO Killin slurm ...
2022-10-31 10:31:11,675 __main__ INFO Killin slurm ... OK
2022-10-31 10:31:31,679 __main__ INFO -- Start daemons --
2022-10-31 10:31:42,382 __main__ INFO Starting slurm ... OK
2022-10-31 10:32:02,639 __main__ INFO -- Submitting job with no stream listener --
2022-10-31 10:32:02,846 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-31 10:32:02,964 __main__ INFO   jobid = 5
2022-10-31 10:32:18,915 TADA INFO assertion 0, Missing stream listener on node-1 does not affect job execution: job output file created, passed
2022-10-31 10:32:18,915 TADA INFO assertion 1, Missing stream listener on node-2 does not affect job execution: job output file created, passed
2022-10-31 10:32:24,790 __main__ INFO -- Submitting job with listener --
2022-10-31 10:32:24,991 __main__ INFO -- Submitting job with num_tasks 1 --
2022-10-31 10:32:25,114 __main__ INFO   jobid = 6
2022-10-31 10:32:25,307 __main__ INFO -- Submitting job with num_tasks 2 --
2022-10-31 10:32:25,424 __main__ INFO   jobid = 7
2022-10-31 10:32:25,643 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 10:32:25,747 __main__ INFO   jobid = 8
2022-10-31 10:32:26,000 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-31 10:32:26,132 __main__ INFO   jobid = 9
2022-10-31 10:32:26,350 __main__ INFO -- Submitting job with num_tasks 27 --
2022-10-31 10:32:26,474 __main__ INFO   jobid = 10
2022-10-31 10:32:48,185 __main__ INFO -- Verifying Events --
2022-10-31 10:32:48,186 TADA INFO assertion 2, 1-task job: first event is 'init': `init` verified, passed
2022-10-31 10:32:48,186 TADA INFO assertion 3, 1-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 10:32:48,186 TADA INFO assertion 4, 1-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 10:32:48,187 TADA INFO assertion 5, 1-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 10:32:48,187 TADA INFO assertion 6, 1-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 10:32:48,187 TADA INFO assertion 7, 2-task job: first event is 'init': `init` verified, passed
2022-10-31 10:32:48,187 TADA INFO assertion 8, 2-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 10:32:48,187 TADA INFO assertion 9, 2-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 10:32:48,188 TADA INFO assertion 10, 2-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 10:32:48,188 TADA INFO assertion 11, 2-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 10:32:48,188 TADA INFO assertion 12, 4-task job: first event is 'init': `init` verified, passed
2022-10-31 10:32:48,188 TADA INFO assertion 13, 4-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 10:32:48,188 TADA INFO assertion 14, 4-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 10:32:48,188 TADA INFO assertion 15, 4-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 10:32:48,189 TADA INFO assertion 16, 4-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 10:32:48,189 TADA INFO assertion 17, 8-task job: first event is 'init': `init` verified, passed
2022-10-31 10:32:48,189 TADA INFO assertion 18, 8-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 10:32:48,189 TADA INFO assertion 19, 8-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 10:32:48,189 TADA INFO assertion 20, 8-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 10:32:48,189 TADA INFO assertion 21, 8-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 10:32:48,190 TADA INFO assertion 22, 27-task job: first event is 'init': `init` verified, passed
2022-10-31 10:32:48,190 TADA INFO assertion 23, 27-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 10:32:48,190 TADA INFO assertion 24, 27-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 10:32:48,190 TADA INFO assertion 25, 27-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 10:32:48,191 TADA INFO assertion 26, 27-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 10:32:48,191 __main__ INFO job 6 multi-tenant with dict_keys([7])
2022-10-31 10:32:48,191 __main__ INFO job 10 multi-tenant with dict_keys([7, 6])
2022-10-31 10:32:48,191 __main__ INFO job 10 multi-tenant with dict_keys([8])
2022-10-31 10:32:48,191 __main__ INFO job 10 multi-tenant with dict_keys([9])
2022-10-31 10:32:48,191 __main__ INFO job 9 multi-tenant with dict_keys([10])
2022-10-31 10:32:48,191 TADA INFO assertion 50, Multi-tenant verification: Multi-tenant jobs found, passed
2022-10-31 10:32:48,394 __main__ INFO -- Submitting job that crashes listener --
2022-10-31 10:32:48,510 __main__ INFO   jobid = 11
2022-10-31 10:32:58,723 TADA INFO assertion 51, Killing stream listener does not affect job execution on node-1: job output file created, passed
2022-10-31 10:32:58,833 TADA INFO assertion 52, Killing stream listener does not affect job execution on node-2: job output file created, passed
2022-10-31 10:32:58,833 TADA INFO test spank_notifier_test ended
2022-10-31 10:33:15 INFO: ----------------------------------------------
2022-10-31 10:33:15 INFO: ======== ldms_list_test ========
2022-10-31 10:33:15 INFO: CMD: python3 ldms_list_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldms_list_test
2022-10-31 10:33:16,689 TADA INFO starting test `ldms_list_test`
2022-10-31 10:33:16,690 TADA INFO   test-id: 0d1369a51a063be105dcc0ad15b3be22ac67bfc118f6c69dfa9ccc5154eb1309
2022-10-31 10:33:16,690 TADA INFO   test-suite: LDMSD
2022-10-31 10:33:16,690 TADA INFO   test-name: ldms_list_test
2022-10-31 10:33:16,690 TADA INFO   test-user: narate
2022-10-31 10:33:16,690 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:33:16,690 __main__ INFO -- Get or create the cluster --
2022-10-31 10:33:19,847 __main__ INFO -- Start daemons --
2022-10-31 10:33:26,211 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:33:28,213 __main__ INFO start list_samp.py and list_agg.py interactive sessions
2022-10-31 10:33:34,245 TADA INFO assertion 1, check list_sampler on list_agg.py: OK, passed
2022-10-31 10:33:34,245 TADA INFO assertion 2, (1st update) check set1 on list_samp.py: OK, passed
2022-10-31 10:33:34,245 TADA INFO assertion 3, (1st update) check set3_p on list_samp.py: OK, passed
2022-10-31 10:33:34,246 TADA INFO assertion 4, (1st update)check set3_c on list_samp.py: OK, passed
2022-10-31 10:33:34,246 TADA INFO assertion 5, (1st update)check set1 on list_agg.py: OK, passed
2022-10-31 10:33:34,246 TADA INFO assertion 6, (1st update)check set3_p on list_agg.py: OK, passed
2022-10-31 10:33:34,247 TADA INFO assertion 7, (1st update)check set3_c on list_agg.py: OK, passed
2022-10-31 10:33:34,247 __main__ INFO 2nd sampling on the sampler...
2022-10-31 10:33:41,456 TADA INFO assertion 8, (2nd update) check set1 on list_samp.py: OK, passed
2022-10-31 10:33:41,457 TADA INFO assertion 9, (2nd update) check set3_p on list_samp.py: OK, passed
2022-10-31 10:33:41,457 TADA INFO assertion 10, (2nd update) check set3_c on list_samp.py: OK, passed
2022-10-31 10:33:41,457 __main__ INFO 2nd update on the aggregator...
2022-10-31 10:33:48,666 TADA INFO assertion 11, (2nd update) check set1 on list_agg.py: OK, passed
2022-10-31 10:33:48,666 TADA INFO assertion 12, (2nd update) check set3_p on list_agg.py: OK, passed
2022-10-31 10:33:48,667 TADA INFO assertion 13, (2nd update) check set3_c on list_agg.py: OK, passed
2022-10-31 10:33:48,667 __main__ INFO 3rd sampling on the sampler...
2022-10-31 10:33:55,874 TADA INFO assertion 14, (3rd update) check set1 on list_samp.py: OK, passed
2022-10-31 10:33:55,875 TADA INFO assertion 15, (3rd update) check set3_p on list_samp.py: OK, passed
2022-10-31 10:33:55,875 TADA INFO assertion 16, (3rd update) check set3_c on list_samp.py: OK, passed
2022-10-31 10:33:55,875 __main__ INFO 3rd update on the aggregator...
2022-10-31 10:34:03,085 TADA INFO assertion 17, (3rd update) check set1 on list_agg.py: OK, passed
2022-10-31 10:34:03,085 TADA INFO assertion 18, (3rd update) check set3_p on list_agg.py: OK, passed
2022-10-31 10:34:03,085 TADA INFO assertion 19, (3rd update) check set3_c on list_agg.py: OK, passed
2022-10-31 10:34:03,085 __main__ INFO 4th sampling on the sampler...
2022-10-31 10:34:10,295 TADA INFO assertion 20, (4th update; list uncahnged) check set1 on list_samp.py: OK, passed
2022-10-31 10:34:10,295 TADA INFO assertion 21, (4th update; list uncahnged) check set3_p on list_samp.py: OK, passed
2022-10-31 10:34:10,295 TADA INFO assertion 22, (4th update; list uncahnged) check set3_c on list_samp.py: OK, passed
2022-10-31 10:34:10,296 __main__ INFO 4th update on the aggregator...
2022-10-31 10:34:17,505 TADA INFO assertion 23, (4th update; list uncahnged) check set1 on list_agg.py: OK, passed
2022-10-31 10:34:17,505 TADA INFO assertion 24, (4th update; list uncahnged) check set3_p on list_agg.py: OK, passed
2022-10-31 10:34:17,505 TADA INFO assertion 25, (4th update; list uncahnged) check set3_c on list_agg.py: OK, passed
2022-10-31 10:34:17,506 __main__ INFO 5th sampling on the sampler...
2022-10-31 10:34:24,714 TADA INFO assertion 26, (5th update; list del) check set1 on list_samp.py: OK, passed
2022-10-31 10:34:24,715 TADA INFO assertion 27, (5th update; list del) check set3_p on list_samp.py: OK, passed
2022-10-31 10:34:24,715 TADA INFO assertion 28, (5th update; list del) check set3_c on list_samp.py: OK, passed
2022-10-31 10:34:24,715 __main__ INFO 5th update on the aggregator...
2022-10-31 10:34:31,924 TADA INFO assertion 29, (5th update; list del) check set1 on list_agg.py: OK, passed
2022-10-31 10:34:31,924 TADA INFO assertion 30, (5th update; list del) check set3_p on list_agg.py: OK, passed
2022-10-31 10:34:31,924 TADA INFO assertion 31, (5th update; list del) check set3_c on list_agg.py: OK, passed
2022-10-31 10:34:31,925 __main__ INFO 6th sampling on the sampler...
2022-10-31 10:34:39,133 TADA INFO assertion 32, (6th update; list unchanged) check set1 on list_samp.py: OK, passed
2022-10-31 10:34:39,133 TADA INFO assertion 33, (6th update; list unchanged) check set3_p on list_samp.py: OK, passed
2022-10-31 10:34:39,133 TADA INFO assertion 34, (6th update; list unchanged) check set3_c on list_samp.py: OK, passed
2022-10-31 10:34:39,134 __main__ INFO 6th update on the updator...
2022-10-31 10:34:46,342 TADA INFO assertion 35, (6th update; list unchanged) check set1 on list_agg.py: OK, passed
2022-10-31 10:34:46,342 TADA INFO assertion 36, (6th update; list unchanged) check set3_p on list_agg.py: OK, passed
2022-10-31 10:34:46,343 TADA INFO assertion 37, (6th update; list unchanged) check set3_c on list_agg.py: OK, passed
2022-10-31 10:34:46,343 TADA INFO test ldms_list_test ended
2022-10-31 10:34:57 INFO: ----------------------------------------------
2022-10-31 10:34:57 INFO: ======== quick_set_add_rm_test ========
2022-10-31 10:34:57 INFO: CMD: python3 quick_set_add_rm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/quick_set_add_rm_test
2022-10-31 10:34:58,593 TADA INFO starting test `quick_set_add_rm_test`
2022-10-31 10:34:58,594 TADA INFO   test-id: d0486a43fb794a8c49490530a72904b3c1a03edcb3fc7c0f09722d8b09a73935
2022-10-31 10:34:58,594 TADA INFO   test-suite: LDMSD
2022-10-31 10:34:58,594 TADA INFO   test-name: quick_set_add_rm_test
2022-10-31 10:34:58,594 TADA INFO   test-user: narate
2022-10-31 10:34:58,594 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:34:58,595 __main__ INFO -- Get or create the cluster --
2022-10-31 10:35:05,811 __main__ INFO -- Start samp.py --
2022-10-31 10:35:10,924 TADA INFO assertion 1, start samp.py: prompt checked, passed
2022-10-31 10:35:10,924 __main__ INFO -- Start daemons --
2022-10-31 10:35:18,666 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:35:24,256 TADA INFO assertion 2, verify data: verified, passed
2022-10-31 10:35:28,850 TADA INFO assertion 3, samp.py adds set1 / verify data: verified, passed
2022-10-31 10:35:33,451 TADA INFO assertion 4, samp.py removes set1 / verify data: verified, passed
2022-10-31 10:35:38,000 TADA INFO assertion 5, samp.py quickly adds and removes set2 / verify data: verified, passed
2022-10-31 10:35:43,108 TADA INFO assertion 6, agg-1 log stays empty: verified, passed
2022-10-31 10:35:43,109 TADA INFO test quick_set_add_rm_test ended
2022-10-31 10:35:55 INFO: ----------------------------------------------
2022-10-31 10:35:56 INFO: ======== set_array_hang_test ========
2022-10-31 10:35:56 INFO: CMD: python3 set_array_hang_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/set_array_hang_test
2022-10-31 10:35:56,719 TADA INFO starting test `set_array_hang_test`
2022-10-31 10:35:56,719 TADA INFO   test-id: bd42f6e7d2efc73619f4691cbf14e1a52872574d8a4ea136bc7f40d51744b8fa
2022-10-31 10:35:56,719 TADA INFO   test-suite: LDMSD
2022-10-31 10:35:56,719 TADA INFO   test-name: set_array_hang_test
2022-10-31 10:35:56,719 TADA INFO   test-user: narate
2022-10-31 10:35:56,719 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:35:56,720 __main__ INFO -- Get or create the cluster --
2022-10-31 10:35:59,809 __main__ INFO -- Start processes --
2022-10-31 10:35:59,809 __main__ INFO starting interactive set_array_samp.py
2022-10-31 10:36:02,825 TADA INFO assertion 1, start set_array_samp.py: data verified, passed
2022-10-31 10:36:05,841 TADA INFO assertion 2, start set_array_agg.py: data verified, passed
2022-10-31 10:36:13,050 TADA INFO assertion 3, agg update before the 1st sample: data verified, passed
2022-10-31 10:36:20,260 TADA INFO assertion 4, sampling 2 times then agg update: data verified, passed
2022-10-31 10:36:23,865 TADA INFO assertion 5, agg update w/o new sampling: data verified, passed
2022-10-31 10:36:31,074 TADA INFO assertion 6, sampling 5 times then agg update: data verified, passed
2022-10-31 10:36:31,075 TADA INFO test set_array_hang_test ended
2022-10-31 10:36:41 INFO: ----------------------------------------------
2022-10-31 10:36:42 INFO: ======== ldmsd_autointerval_test ========
2022-10-31 10:36:42 INFO: CMD: python3 ldmsd_autointerval_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldmsd_autointerval_test
2022-10-31 10:36:43,396 TADA INFO starting test `ldmsd_autointerval_test`
2022-10-31 10:36:43,396 TADA INFO   test-id: 6775adc9553a7165a296c5de20aa2bd40d3ae1796961cfb69afafe89ae4ebffa
2022-10-31 10:36:43,396 TADA INFO   test-suite: LDMSD
2022-10-31 10:36:43,396 TADA INFO   test-name: ldmsd_autointerval_test
2022-10-31 10:36:43,396 TADA INFO   test-user: narate
2022-10-31 10:36:43,396 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:36:43,397 __main__ INFO -- Get or create the cluster --
2022-10-31 10:36:50,572 __main__ INFO -- Start daemons --
2022-10-31 10:36:54,360 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:37:00,880 TADA INFO assertion 1, start all daemons and interactive controller: OK, passed
2022-10-31 10:37:03,121 TADA INFO assertion 2, verify sampling interval and update hints: verified, passed
2022-10-31 10:37:03,122 __main__ INFO Let them run for a while to collect data ...
2022-10-31 10:37:13,124 __main__ INFO Setting sample interval to 1000000 ...
2022-10-31 10:37:21,380 TADA INFO assertion 3, set and verify 2nd sampling interval / update hints: verified, passed
2022-10-31 10:37:21,380 __main__ INFO Let them run for a while to collect data ...
2022-10-31 10:37:31,381 __main__ INFO Setting sample interval to 2000000 ...
2022-10-31 10:37:39,636 TADA INFO assertion 4, set and verify 3rd sampling interval / update hints: verified, passed
2022-10-31 10:37:39,636 __main__ INFO Let them run for a while to collect data ...
2022-10-31 10:37:49,873 TADA INFO assertion 5, verify SOS data: timestamp differences in SOS show all 3 intervals, passed
2022-10-31 10:37:49,998 TADA INFO assertion 6, verify 'oversampled' in the agg2 log: OK, passed
2022-10-31 10:37:49,998 TADA INFO test ldmsd_autointerval_test ended
2022-10-31 10:38:02 INFO: ----------------------------------------------
2022-10-31 10:38:02 INFO: ======== ldms_record_test ========
2022-10-31 10:38:02 INFO: CMD: python3 ldms_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldms_record_test
2022-10-31 10:38:03,697 TADA INFO starting test `ldms_record_test`
2022-10-31 10:38:03,697 TADA INFO   test-id: 2c54d409eb965634d13984788eee7eed0465f666bdf6b7a037d6d948ececfa6a
2022-10-31 10:38:03,697 TADA INFO   test-suite: LDMSD
2022-10-31 10:38:03,697 TADA INFO   test-name: ldms_record_test
2022-10-31 10:38:03,697 TADA INFO   test-user: narate
2022-10-31 10:38:03,697 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:38:03,698 __main__ INFO -- Get or create the cluster --
2022-10-31 10:38:06,837 __main__ INFO -- Start daemons --
2022-10-31 10:38:13,141 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:38:15,143 __main__ INFO start record_samp.py and record_agg.py interactive sessions
2022-10-31 10:38:21,181 TADA INFO assertion 1, check record_sampler on record_agg.py: OK, passed
2022-10-31 10:38:21,181 TADA INFO assertion 2, (1st update) check set1 on record_samp.py: OK, passed
2022-10-31 10:38:21,181 TADA INFO assertion 3, (1st update) check set3_p on record_samp.py: OK, passed
2022-10-31 10:38:21,182 TADA INFO assertion 4, (1st update) check set3_c on record_samp.py: OK, passed
2022-10-31 10:38:21,182 TADA INFO assertion 5, (1st update) check set1 on record_agg.py: OK, passed
2022-10-31 10:38:21,182 TADA INFO assertion 6, (1st update) check set3_p on record_agg.py: OK, passed
2022-10-31 10:38:21,183 TADA INFO assertion 7, (1st update) check set3_c on record_agg.py: OK, passed
2022-10-31 10:38:21,183 __main__ INFO 2nd sampling on the sampler...
2022-10-31 10:38:28,392 TADA INFO assertion 8, (2nd update) check set1 on record_samp.py: OK, passed
2022-10-31 10:38:28,393 TADA INFO assertion 9, (2nd update) check set3_p on record_samp.py: OK, passed
2022-10-31 10:38:28,393 TADA INFO assertion 10, (2nd update) check set3_c on record_samp.py: OK, passed
2022-10-31 10:38:28,393 __main__ INFO 2nd update on the aggregator...
2022-10-31 10:38:35,601 TADA INFO assertion 11, (2nd update) check set1 on record_agg.py: OK, passed
2022-10-31 10:38:35,602 TADA INFO assertion 12, (2nd update) check set3_p on record_agg.py: OK, passed
2022-10-31 10:38:35,602 TADA INFO assertion 13, (2nd update) check set3_c on record_agg.py: OK, passed
2022-10-31 10:38:35,602 __main__ INFO 3rd sampling on the sampler...
2022-10-31 10:38:42,811 TADA INFO assertion 14, (3rd update) check set1 on record_samp.py: OK, passed
2022-10-31 10:38:42,811 TADA INFO assertion 15, (3rd update) check set3_p on record_samp.py: OK, passed
2022-10-31 10:38:42,812 TADA INFO assertion 16, (3rd update) check set3_c on record_samp.py: OK, passed
2022-10-31 10:38:42,812 __main__ INFO 3rd update on the aggregator...
2022-10-31 10:38:50,021 TADA INFO assertion 17, (3rd update) check set1 on record_agg.py: OK, passed
2022-10-31 10:38:50,022 TADA INFO assertion 18, (3rd update) check set3_p on record_agg.py: OK, passed
2022-10-31 10:38:50,022 TADA INFO assertion 19, (3rd update) check set3_c on record_agg.py: OK, passed
2022-10-31 10:38:50,022 __main__ INFO 4th sampling on the sampler...
2022-10-31 10:38:57,231 TADA INFO assertion 20, (4th update; record uncahnged) check set1 on record_samp.py: OK, passed
2022-10-31 10:38:57,232 TADA INFO assertion 21, (4th update; record uncahnged) check set3_p on record_samp.py: OK, passed
2022-10-31 10:38:57,232 TADA INFO assertion 22, (4th update; record uncahnged) check set3_c on record_samp.py: OK, passed
2022-10-31 10:38:57,232 __main__ INFO 4th update on the aggregator...
2022-10-31 10:39:04,441 TADA INFO assertion 23, (4th update; record uncahnged) check set1 on record_agg.py: OK, passed
2022-10-31 10:39:04,442 TADA INFO assertion 24, (4th update; record uncahnged) check set3_p on record_agg.py: OK, passed
2022-10-31 10:39:04,442 TADA INFO assertion 25, (4th update; record uncahnged) check set3_c on record_agg.py: OK, passed
2022-10-31 10:39:04,442 __main__ INFO 5th sampling on the sampler...
2022-10-31 10:39:11,651 TADA INFO assertion 26, (5th update; record del) check set1 on record_samp.py: OK, passed
2022-10-31 10:39:11,652 TADA INFO assertion 27, (5th update; record del) check set3_p on record_samp.py: OK, passed
2022-10-31 10:39:11,652 TADA INFO assertion 28, (5th update; record del) check set3_c on record_samp.py: OK, passed
2022-10-31 10:39:11,652 __main__ INFO 5th update on the aggregator...
2022-10-31 10:39:18,861 TADA INFO assertion 29, (5th update; record del) check set1 on record_agg.py: OK, passed
2022-10-31 10:39:18,861 TADA INFO assertion 30, (5th update; record del) check set3_p on record_agg.py: OK, passed
2022-10-31 10:39:18,861 TADA INFO assertion 31, (5th update; record del) check set3_c on record_agg.py: OK, passed
2022-10-31 10:39:18,861 __main__ INFO 6th sampling on the sampler...
2022-10-31 10:39:26,069 TADA INFO assertion 32, (6th update; record unchanged) check set1 on record_samp.py: OK, passed
2022-10-31 10:39:26,070 TADA INFO assertion 33, (6th update; record unchanged) check set3_p on record_samp.py: OK, passed
2022-10-31 10:39:26,070 TADA INFO assertion 34, (6th update; record unchanged) check set3_c on record_samp.py: OK, passed
2022-10-31 10:39:26,070 __main__ INFO 6th update on the updator...
2022-10-31 10:39:33,280 TADA INFO assertion 35, (6th update; record unchanged) check set1 on record_agg.py: OK, passed
2022-10-31 10:39:33,280 TADA INFO assertion 36, (6th update; record unchanged) check set3_p on record_agg.py: OK, passed
2022-10-31 10:39:33,280 TADA INFO assertion 37, (6th update; record unchanged) check set3_c on record_agg.py: OK, passed
2022-10-31 10:39:33,281 TADA INFO test ldms_record_test ended
2022-10-31 10:39:43 INFO: ----------------------------------------------
2022-10-31 10:39:44 INFO: ======== ldms_schema_digest_test ========
2022-10-31 10:39:44 INFO: CMD: python3 ldms_schema_digest_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldms_schema_digest_test
2022-10-31 10:39:45,549 TADA INFO starting test `ldms_schema_digest_test`
2022-10-31 10:39:45,549 TADA INFO   test-id: 2d81ecb6753774e0c3ffa3d89d88863cdebada28351f08846d62b11d050089d5
2022-10-31 10:39:45,549 TADA INFO   test-suite: LDMSD
2022-10-31 10:39:45,549 TADA INFO   test-name: ldms_schema_digest_test
2022-10-31 10:39:45,549 TADA INFO   test-user: narate
2022-10-31 10:39:45,550 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:39:45,550 __main__ INFO -- Get or create the cluster --
2022-10-31 10:39:52,846 __main__ INFO -- Start daemons --
2022-10-31 10:39:56,093 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:40:01,206 TADA INFO assertion 1, No schema digest from ldms_ls -v sampler: verified, passed
2022-10-31 10:40:01,336 TADA INFO assertion 2, Schema digest from ldms_ls -vv sampler is not empty: verified, passed
2022-10-31 10:40:01,450 TADA INFO assertion 3, Schema digest from ldms_ls -vv agg-1 is not empty: verified, passed
2022-10-31 10:40:01,622 TADA INFO assertion 4, Schema digest from Python ldms dir agg-1 is not empty: verified, passed
2022-10-31 10:40:01,623 TADA INFO assertion 5, Schema digest from Python ldms lokoup agg-1 is not empty: verified, passed
2022-10-31 10:40:01,623 TADA INFO assertion 6, All digests of the same set are the same: , passed
2022-10-31 10:40:04,028 TADA INFO assertion 7, Sets of same schema yield the same digest: check, passed
2022-10-31 10:40:04,029 TADA INFO assertion 8, Different schema (1-off metric) yield different digest: check, passed
2022-10-31 10:40:04,029 TADA INFO test ldms_schema_digest_test ended
2022-10-31 10:40:16 INFO: ----------------------------------------------
2022-10-31 10:40:16 INFO: ======== ldmsd_decomp_test ========
2022-10-31 10:40:16 INFO: CMD: python3 ldmsd_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldmsd_decomp_test
2022-10-31 10:40:17,665 TADA INFO starting test `ldmsd_decomp_test`
2022-10-31 10:40:17,665 TADA INFO   test-id: b0e116d3a52bd3c9c4da8db499215b636658a47c778542435b99f8c95c9abd59
2022-10-31 10:40:17,665 TADA INFO   test-suite: LDMSD
2022-10-31 10:40:17,665 TADA INFO   test-name: ldmsd_decomp_test
2022-10-31 10:40:17,665 TADA INFO   test-user: narate
2022-10-31 10:40:17,665 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:40:17,666 __main__ INFO -- Get or create the cluster --
2022-10-31 10:40:33,423 __main__ INFO -- Start daemons --
2022-10-31 10:40:43,740 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:41:38,398 TADA INFO assertion 1, `as_is` decomposition, test_sampler_8d2b8bd sos schema check: OK, passed
2022-10-31 10:41:38,398 TADA INFO assertion 2, `as_is` decomposition, test_sampler_95772b6 sos schema check: OK, passed
2022-10-31 10:41:38,399 TADA INFO assertion 3, `as_is` decomposition, record_sampler_e1f021f sos schema check: OK, passed
2022-10-31 10:41:38,399 TADA INFO assertion 4, `static` decomposition, fill sos schema check: OK, passed
2022-10-31 10:41:38,399 TADA INFO assertion 5, `static` decomposition, filter sos schema check: OK, passed
2022-10-31 10:41:38,399 TADA INFO assertion 6, `static` decomposition, record sos schema check: OK, passed
2022-10-31 10:41:38,399 TADA INFO assertion 7, `as_is` decomposition, test_sampler_8d2b8bd csv schema check: OK, passed
2022-10-31 10:41:38,399 TADA INFO assertion 8, `as_is` decomposition, test_sampler_95772b6 csv schema check: OK, passed
2022-10-31 10:41:38,399 TADA INFO assertion 9, `as_is` decomposition, record_sampler_e1f021f csv schema check: OK, passed
2022-10-31 10:41:38,400 TADA INFO assertion 10, `static` decomposition, fill csv schema check: OK, passed
2022-10-31 10:41:38,400 TADA INFO assertion 11, `static` decomposition, filter csv schema check: OK, passed
2022-10-31 10:41:38,400 TADA INFO assertion 12, `static` decomposition, record csv schema check: OK, passed
2022-10-31 10:41:38,400 TADA INFO assertion 13, `as_is` decomposition, test_sampler_8d2b8bd kafka schema check: OK, passed
2022-10-31 10:41:38,400 TADA INFO assertion 14, `as_is` decomposition, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-31 10:41:38,400 TADA INFO assertion 15, `as_is` decomposition, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-31 10:41:38,401 TADA INFO assertion 16, `static` decomposition, fill kafka schema check: OK, passed
2022-10-31 10:41:38,401 TADA INFO assertion 17, `static` decomposition, filter kafka schema check: OK, passed
2022-10-31 10:41:38,401 TADA INFO assertion 18, `static` decomposition, record kafka schema check: OK, passed
2022-10-31 10:41:38,402 TADA INFO assertion 19, `as_is` decomposition, test_sampler_8d2b8bd sos data check: OK, passed
2022-10-31 10:41:38,404 TADA INFO assertion 20, `as_is` decomposition, test_sampler_95772b6 sos data check: OK, passed
2022-10-31 10:41:38,479 TADA INFO assertion 21, `as_is` decomposition, record_sampler_e1f021f sos data check: OK, passed
2022-10-31 10:41:38,483 TADA INFO assertion 22, `static` decomposition, fill sos data check: OK, passed
2022-10-31 10:41:38,486 TADA INFO assertion 23, `static` decomposition, filter sos data check: OK, passed
2022-10-31 10:41:38,495 TADA INFO assertion 24, `static` decomposition, record sos data check: OK, passed
2022-10-31 10:41:38,497 TADA INFO assertion 25, `as_is` decomposition, test_sampler_8d2b8bd csv data check: OK, passed
2022-10-31 10:41:38,498 TADA INFO assertion 26, `as_is` decomposition, test_sampler_95772b6 csv data check: OK, passed
2022-10-31 10:41:38,571 TADA INFO assertion 27, `as_is` decomposition, record_sampler_e1f021f csv data check: OK, passed
2022-10-31 10:41:38,575 TADA INFO assertion 28, `static` decomposition, fill csv data check: OK, passed
2022-10-31 10:41:38,578 TADA INFO assertion 29, `static` decomposition, filter csv data check: OK, passed
2022-10-31 10:41:38,586 TADA INFO assertion 30, `static` decomposition, record csv data check: OK, passed
2022-10-31 10:41:38,587 TADA INFO assertion 31, `as_is` decomposition, test_sampler_8d2b8bd kafka data check: OK, passed
2022-10-31 10:41:38,587 TADA INFO assertion 32, `as_is` decomposition, test_sampler_95772b6 kafka data check: OK, passed
2022-10-31 10:41:38,617 TADA INFO assertion 33, `as_is` decomposition, record_sampler_e1f021f kafka data check: OK, passed
2022-10-31 10:41:38,619 TADA INFO assertion 34, `static` decomposition, fill kafka data check: OK, passed
2022-10-31 10:41:38,620 TADA INFO assertion 35, `static` decomposition, filter kafka data check: OK, passed
2022-10-31 10:41:38,625 TADA INFO assertion 36, `static` decomposition, record kafka data check: OK, passed
2022-10-31 10:41:38,625 TADA INFO test ldmsd_decomp_test ended
2022-10-31 10:41:38,625 TADA INFO test ldmsd_decomp_test ended
2022-10-31 10:41:53 INFO: ----------------------------------------------
2022-10-31 10:41:54 INFO: ======== ldmsd_stream_dir_test ========
2022-10-31 10:41:54 INFO: CMD: python3 ldmsd_stream_dir_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldmsd_stream_dir_test
2022-10-31 10:41:55,317 __main__ INFO -- Get or create the cluster --
2022-10-31 10:41:55,317 TADA INFO starting test `ldmsd_stream_dir`
2022-10-31 10:41:55,317 TADA INFO   test-id: d0a2476c71f41ad11b714d9ded551a3c8b55aea29cb84f82ae53508f884dc611
2022-10-31 10:41:55,317 TADA INFO   test-suite: LDMSD
2022-10-31 10:41:55,317 TADA INFO   test-name: ldmsd_stream_dir
2022-10-31 10:41:55,317 TADA INFO   test-user: narate
2022-10-31 10:41:55,317 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:42:04,172 __main__ INFO -- Start daemons --
2022-10-31 10:42:07,947 __main__ INFO waiting ... for all LDMSDs to start
2022-10-31 10:42:08,259 __main__ INFO All LDMSDs are up.
2022-10-31 10:42:09,476 TADA INFO assertion 1, No Stream data: {} == {}, passed
2022-10-31 10:42:10,810 TADA INFO assertion 2, stream_dir -- one stream message: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667230929, 'last_ts': 1667230929, 'count': 1, 'total_bytes': 6}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1667230929, 'last_ts': 1667230929, 'count': 1, 'total_bytes': 6}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1667230929, 'last_ts': 1667230929}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1667230929, 'last_ts': 1667230929}}}, passed
2022-10-31 10:42:13,266 TADA INFO assertion 3, stream_dir --  multiple stream messages: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667230929, 'last_ts': 1667230932, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1667230929, 'last_ts': 1667230932, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667230929, 'last_ts': 1667230932, 'bytes/sec': 6.0, 'msg/sec': 1.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667230929, 'last_ts': 1667230932, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, passed
2022-10-31 10:42:14,483 TADA INFO assertion 4, prdcr_stream_dir to agg -- one producer: {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1667230932, 'first_ts': 1667230929, 'bytes/sec': 6.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1667230932, 'first_ts': 1667230929, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667230929, 'last_ts': 1667230932, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667230929, 'last_ts': 1667230932, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}}, passed
2022-10-31 10:42:18,256 TADA INFO assertion 5, stream_dir -- mulitple streams: {'bar': {'mode': 'not subscribed', 'info': {'first_ts': 1667230935, 'last_ts': 1667230937, 'count': 3, 'total_bytes': 48, 'msg/sec': 1.5, 'bytes/sec': 24.0}, 'publishers': {}}, 'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667230934, 'last_ts': 1667230935, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1667230934, 'last_ts': 1667230937, 'count': 5, 'total_bytes': 60, 'msg/sec': 1.666667, 'bytes/sec': 20.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667230934, 'last_ts': 1667230935, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {}}, 'bar': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1667230935, 'last_ts': 1667230937, 'bytes/sec': 24.0, 'msg/sec': 1.5}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1667230934, 'last_ts': 1667230937, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}, passed
2022-10-31 10:42:19,471 TADA INFO assertion 6, prdcr_stream_dir to agg -- two producers: {'foo': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 2.0, 'total_bytes': 12, 'last_ts': 1667230935, 'first_ts': 1667230934, 'bytes/sec': 12.0, 'count': 2}}, 'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1667230932, 'first_ts': 1667230929, 'bytes/sec': 6.0, 'count': 3}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 1.5, 'total_bytes': 48, 'last_ts': 1667230937, 'first_ts': 1667230935, 'bytes/sec': 24.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-2': {'info': {'msg/sec': 1.666667, 'total_bytes': 60, 'last_ts': 1667230937, 'first_ts': 1667230934, 'bytes/sec': 20.0, 'count': 5}}, 'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1667230932, 'first_ts': 1667230929, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667230929, 'last_ts': 1667230932, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667230934, 'last_ts': 1667230935, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1667230935, 'last_ts': 1667230937, 'bytes/sec': 24.0, 'msg/sec': 1.5}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667230929, 'last_ts': 1667230932, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1667230934, 'last_ts': 1667230937, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}}, passed
2022-10-31 10:42:23,149 TADA INFO assertion 7, stream_dir to agg after one producer republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667230940, 'last_ts': 1667230941, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1667230940, 'last_ts': 1667230941, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}}}, '_AGGREGATED_': {'info': {'first_ts': 1667230940, 'last_ts': 1667230941, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667230940, 'last_ts': 1667230941, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667230940, 'last_ts': 1667230941, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}}, '_AGGREGATED_': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667230940, 'last_ts': 1667230941, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, passed
2022-10-31 10:42:24,676 TADA INFO assertion 8, stream_dir to agg after two producers republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667230940, 'last_ts': 1667230943, 'count': 5, 'total_bytes': 30, 'msg/sec': 1.666667, 'bytes/sec': 10.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1667230940, 'last_ts': 1667230941, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}, 'samplerd-2': {'info': {'first_ts': 1667230943, 'last_ts': 1667230943, 'count': 3, 'total_bytes': 18}}}}, '_AGGREGATED_': {'info': {'first_ts': 1667230940, 'last_ts': 1667230943, 'count': 5, 'total_bytes': 30, 'msg/sec': 1.666667, 'bytes/sec': 10.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1667230940, 'last_ts': 1667230943, 'bytes/sec': 10.0, 'msg/sec': 1.666667}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667230940, 'last_ts': 1667230941, 'bytes/sec': 12.0, 'msg/sec': 2.0}}, 'samplerd-2': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667230943, 'last_ts': 1667230943}}}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1667230940, 'last_ts': 1667230943, 'bytes/sec': 10.0, 'msg/sec': 1.666667}}}, passed
2022-10-31 10:42:24,676 TADA INFO test ldmsd_stream_dir ended
2022-10-31 10:42:36 INFO: ----------------------------------------------
2022-10-31 10:42:37 INFO: ======== store_list_record_test ========
2022-10-31 10:42:37 INFO: CMD: python3 store_list_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/store_list_record_test
2022-10-31 10:42:38,232 __main__ INFO -- Get or create the cluster --
2022-10-31 10:42:38,233 TADA INFO starting test `store_sos_lists_test`
2022-10-31 10:42:38,233 TADA INFO   test-id: 246e2a78f64ab882e994f914ed2bd1146d962498034c98b5b07c702b9eafd8a3
2022-10-31 10:42:38,233 TADA INFO   test-suite: LDMSD
2022-10-31 10:42:38,233 TADA INFO   test-name: store_sos_lists_test
2022-10-31 10:42:38,233 TADA INFO   test-user: narate
2022-10-31 10:42:38,233 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:42:45,537 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:42:49,327 __main__ INFO All sampler daemons are up.
2022-10-31 10:42:49,433 TADA INFO assertion 1, aggregator with store_sos has started properly.: agg_sos.check_ldmsd(), passed
2022-10-31 10:42:49,546 TADA INFO assertion 2, aggregator with store_csv has started properly.: agg_csv.check_ldmsd(), passed
2022-10-31 10:43:02,957 TADA INFO assertion 3, store_sos is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-31 10:43:06,291 TADA INFO assertion 4, store_sos stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-31 10:43:15,069 TADA INFO assertion 5, store_sos stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-31 10:43:16,459 TADA INFO assertion 6, store_csv is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-31 10:43:27,554 TADA INFO assertion 7, store_csv stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-31 10:43:37,129 TADA INFO assertion 8, store_csv stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-31 10:43:37,130 TADA INFO test store_sos_lists_test ended
2022-10-31 10:43:50 INFO: ----------------------------------------------
2022-10-31 10:43:51 INFO: ======== maestro_raft_test ========
2022-10-31 10:43:51 INFO: CMD: python3 maestro_raft_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/maestro_raft_test
2022-10-31 10:43:51,820 TADA INFO starting test `maestro_raft_test`
2022-10-31 10:43:51,820 TADA INFO   test-id: 646fec9c3ddd706e8aae5247c1facdac5f96e5ce57bee5d1f6e387682cdd5ba9
2022-10-31 10:43:51,820 TADA INFO   test-suite: LDMSD
2022-10-31 10:43:51,820 TADA INFO   test-name: maestro_raft_test
2022-10-31 10:43:51,820 TADA INFO   test-user: narate
2022-10-31 10:43:51,820 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:44:01,832 __main__ INFO -- Get or create cluster --
2022-10-31 10:44:36,172 __main__ INFO -- Start daemons --
2022-10-31 10:45:46,855 __main__ INFO -- making known hosts (ssh) --
2022-10-31 10:45:53,791 __main__ INFO ... make sure ldmsd's are up
2022-10-31 10:46:10,842 TADA INFO assertion 1, Statuses of maestros, 1 leader + 2 followers: [('FOLLOWER', 2), ('LEADER', 1)], passed
2022-10-31 10:46:23,294 TADA INFO assertion 2, All ldmsds are up and configured: sets verified, passed
2022-10-31 10:46:23,590 TADA INFO assertion 3, Data are being stored: data check, passed
2022-10-31 10:46:28,476 TADA INFO assertion 4, New leader elected: checked, passed
2022-10-31 10:46:40,255 TADA INFO assertion 5, Restarted ldmsd is configured: sets verified, passed
2022-10-31 10:46:40,549 TADA INFO assertion 6, New data are presented in the store: data check, passed
2022-10-31 10:46:51,539 TADA INFO assertion 7, The restarted maestro becomes a follower: checked, passed
---Wait for config to write to file---
2022-10-31 10:46:51,539 TADA INFO test maestro_raft_test ended
2022-10-31 10:47:12 INFO: ----------------------------------------------
2022-10-31 10:47:13 INFO: ======== ovis_json_test ========
2022-10-31 10:47:13 INFO: CMD: python3 ovis_json_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ovis_json_test
2022-10-31 10:47:13,934 __main__ INFO -- Create the cluster -- 
2022-10-31 10:47:19,273 TADA INFO starting test `ovis_json_test`
2022-10-31 10:47:19,273 TADA INFO   test-id: 4208618aa6b7218dbbc50530cf0cb855c48d45dd185568c5a2083852483689cf
2022-10-31 10:47:19,273 TADA INFO   test-suite: OVIS-LIB
2022-10-31 10:47:19,273 TADA INFO   test-name: ovis_json_test
2022-10-31 10:47:19,273 TADA INFO   test-user: narate
2022-10-31 10:47:19,273 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:47:19,274 TADA INFO assertion 1, Test creating a JSON integer entity: (type is JSON_INT_VALUE) && (1 == e->value.int_), passed
2022-10-31 10:47:19,274 TADA INFO assertion 2, Test creating a JSON boolean entity: (type is JSON_BOOL_VALUE) && (1 == e->value.bool_), passed
2022-10-31 10:47:19,274 TADA INFO assertion 3, Test creating a JSON float entity: (type is JSON_FLOAT_VALUE) && (1.1 == e->value.double_), passed
2022-10-31 10:47:19,274 TADA INFO assertion 4, Test creating a JSON string entity: (type is JSON_STRING_VALUE) && (foo == e->value.str_->str), passed
2022-10-31 10:47:19,275 TADA INFO assertion 5, Test creating a JSON attribute entity: (type is JSON_ATTR_VALUE) && (name == <attr name>) && (value == <attr value>), passed
2022-10-31 10:47:19,275 TADA INFO assertion 6, Test creating a JSON list entity: (type is JSON_LIST_VALUE) && (0 == Number of elements) && (list is empty), passed
2022-10-31 10:47:19,275 TADA INFO assertion 7, Test creating a JSON dictionary entity: (type is JSON_DICT_VALUE) && (dict table is empty), passed
2022-10-31 10:47:19,275 TADA INFO assertion 8, Test creating a JSON null entity: (type is JSON_NULL_VALUE) && (0 == e->value.int_), passed
2022-10-31 10:47:19,275 TADA INFO assertion 9, Test parsing a JSON integer string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 10:47:19,275 TADA INFO assertion 10, Test parsing a JSON false boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 10:47:19,275 TADA INFO assertion 11, Test parsing a JSON true boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 10:47:19,276 TADA INFO assertion 12, Test parsing a JSON float string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 10:47:19,276 TADA INFO assertion 13, Test parsing a JSON string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 10:47:19,276 TADA INFO assertion 15, Test parsing a JSON dict string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 10:47:19,276 TADA INFO assertion 16, Test parsing a JSON null string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 10:47:19,276 TADA INFO assertion 17, Test parsing an invalid string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 10:47:19,276 TADA INFO assertion 17, Test parsing an invalid string: 0 != json_parse_buffer(), passed
2022-10-31 10:47:19,276 TADA INFO assertion 18, Test dumping a JSON integer entity: 1 == 1, passed
2022-10-31 10:47:19,277 TADA INFO assertion 19, Test dumping a JSON false boolean entity: false == false, passed
2022-10-31 10:47:19,277 TADA INFO assertion 20, Test dumping a JSON true boolean entity: true == true, passed
2022-10-31 10:47:19,277 TADA INFO assertion 21, Test dumping a JSON float entity: 1.100000 == 1.100000, passed
2022-10-31 10:47:19,277 TADA INFO assertion 22, Test dumping a JSON string entity: "foo" == "foo", passed
2022-10-31 10:47:19,277 TADA INFO assertion 23, Test dumping a JSON attr entity: "name":"foo" == jb->buf, passed
2022-10-31 10:47:19,277 TADA INFO assertion 24, Test dumping a JSON list entity: [1,false,1.100000,"foo",[],{},null] == [1,false,1.100000,"foo",[],{},null], passed
2022-10-31 10:47:19,278 TADA INFO assertion 25, Test dumping a JSON dict entity: {"int":1,"bool":true,"float":1.100000,"string":"foo","list":[1,false,1.100000,"foo",[],{},null],"dict":{"attr_1":"value_1"},"null":null} == {"null":null,"list":[1,false,1.100000,"foo",[],{},null],"string":"foo","float":1.100000,"bool":true,"dict":{"attr_1":"value_1"},"int":1}, passed
2022-10-31 10:47:19,278 TADA INFO assertion 26, Test dumping a JSON null entity: null == null, passed
2022-10-31 10:47:19,278 TADA INFO assertion 27, Test dumping a JSON entity to a non-empty jbuf: This is a book."FOO" == This is a book."FOO", passed
2022-10-31 10:47:19,278 TADA INFO assertion 28, Test copying a JSON integer entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,278 TADA INFO assertion 29, Test copying a JSON false boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,278 TADA INFO assertion 30, Test copying a JSON true boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,278 TADA INFO assertion 31, Test copying a JSON float entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,279 TADA INFO assertion 32, Test copying a JSON string entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,279 TADA INFO assertion 33, Test copying a JSON attribute entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,279 TADA INFO assertion 34, Test copying a JSON list entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,279 TADA INFO assertion 35, Test copying a JSON dict entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,279 TADA INFO assertion 36, Test copying a JSON null entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 10:47:19,279 TADA INFO assertion 37, Test obtaining the number of attributes: 7 == json_attr_count(dict), passed
2022-10-31 10:47:19,280 TADA INFO assertion 38, Test finding an existing attribute: 0 != json_attr_find(), passed
2022-10-31 10:47:19,280 TADA INFO assertion 39, Test finding a non-existng attribute: 0 == json_attr_find(), passed
2022-10-31 10:47:19,280 TADA INFO assertion 40, Test finding the value of an existing attribute: 0 != json_value_find(), passed
2022-10-31 10:47:19,280 TADA INFO assertion 41, Test finding the value of a non-existing attribute: 0 == json_value_find(), passed
2022-10-31 10:47:19,280 TADA INFO assertion 42, Test adding a new attribute to a dictionary: (0 == json_attr_add() && (0 != json_attr_find()), passed
2022-10-31 10:47:19,280 TADA INFO assertion 43, Test replacing the value of an existing attribute: (0 == json_attr_add()) && (0 != json_value_find()) && (is_same_entity(old_v, new_v)), passed
2022-10-31 10:47:19,280 TADA INFO assertion 44, Test removing an existing attribute: (0 = json_attr_rem()) && (0 == json_attr_find()), passed
2022-10-31 10:47:19,281 TADA INFO assertion 45, Test removing a non-existing attribute: (ENOENT == json_attr_rem()), passed
2022-10-31 10:47:19,281 TADA INFO assertion 46, Test creating a dictionary by json_dict_build: expected == json_dict_build(...), passed
2022-10-31 10:47:19,281 TADA INFO assertion 47, Test adding attributes and replacing attribute values by json_dict_build: expected == json_dict_build(d, ...), passed
2022-10-31 10:47:19,281 TADA INFO assertion 48, Test json_dict_merge(): The merged dictionary is correct., passed
2022-10-31 10:47:19,281 TADA INFO assertion 49, Test json_list_len(): 7 == json_list_len(), passed
2022-10-31 10:47:19,281 TADA INFO assertion 50, Test adding items to a list: 0 == strcmp(exp_str, json_entity_dump(l)->buf, passed
2022-10-31 10:47:19,281 TADA INFO assertion 51, Test removing an existing item by json_item_rem(): 0 == json_item_rem(), passed
2022-10-31 10:47:19,282 TADA INFO assertion 52, Test removing a non-existing item by json_item_rem(): ENOENT == json_item_rem(), passed
2022-10-31 10:47:19,282 TADA INFO assertion 53, Test popping an existing item from a list by json_item_pop(): NULL == json_item_pop(len + 3), passed
2022-10-31 10:47:19,282 TADA INFO assertion 54, Test popping a non-existing item from a list by json_item_pop(): NULL != json_item_pop(len - 1), passed
2022-10-31 10:47:19,282 TADA INFO test ovis_json_test ended
2022-10-31 10:47:30 INFO: ----------------------------------------------
2022-10-31 10:47:30 INFO: ======== updtr_add_test ========
2022-10-31 10:47:30 INFO: CMD: python3 updtr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/updtr_add_test
2022-10-31 10:47:31,613 __main__ INFO -- Get or create the cluster --
2022-10-31 10:47:31,613 TADA INFO starting test `updtr_add test`
2022-10-31 10:47:31,613 TADA INFO   test-id: f3d04f2667b4e6e310c2eb05d1b6f2d98d300aa94e3cbe5fb2a786a13509a097
2022-10-31 10:47:31,613 TADA INFO   test-suite: LDMSD
2022-10-31 10:47:31,613 TADA INFO   test-name: updtr_add test
2022-10-31 10:47:31,614 TADA INFO   test-user: narate
2022-10-31 10:47:31,614 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:47:39,510 __main__ INFO -- Start daemons --
2022-10-31 10:47:43,206 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:47:43,532 __main__ INFO All LDMSDs are up.
2022-10-31 10:47:44,743 TADA INFO assertion 1, Add an updater with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:47:45,953 TADA INFO assertion 2, Add an updater with a zero interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:47:47,173 TADA INFO assertion 3, Add an updater with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:47:48,393 TADA INFO assertion 4, Add an updater with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-31 10:47:49,605 TADA INFO assertion 5, Add an updater with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:47:52,028 TADA INFO assertion 6, Add an updater without an offset: report(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-31 10:47:54,469 TADA INFO assertion 7, Add an updater with a valid offset: report(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-31 10:47:55,679 TADA INFO assertion 8, Add an updater with an existing name: report(rc = 17) == expect(rc = 17), passed
2022-10-31 10:47:55,679 __main__ INFO --- done ---
2022-10-31 10:47:55,680 TADA INFO test updtr_add test ended
2022-10-31 10:48:07 INFO: ----------------------------------------------
2022-10-31 10:48:08 INFO: ======== updtr_del_test ========
2022-10-31 10:48:08 INFO: CMD: python3 updtr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/updtr_del_test
2022-10-31 10:48:09,261 __main__ INFO -- Get or create the cluster --
2022-10-31 10:48:09,261 TADA INFO starting test `updtr_add test`
2022-10-31 10:48:09,261 TADA INFO   test-id: 40a4bec41cff38ad28fa930c9a4c252bcd926a3ae9f630cdce1c5f3b855a5bd1
2022-10-31 10:48:09,262 TADA INFO   test-suite: LDMSD
2022-10-31 10:48:09,262 TADA INFO   test-name: updtr_add test
2022-10-31 10:48:09,262 TADA INFO   test-user: narate
2022-10-31 10:48:09,262 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:48:16,888 __main__ INFO -- Start daemons --
2022-10-31 10:48:20,620 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:48:20,922 __main__ INFO All LDMSDs are up.
2022-10-31 10:48:22,129 TADA INFO assertion 1, updtr_del a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 10:48:23,363 TADA INFO assertion 2, updtr_del a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-31 10:48:24,576 TADA INFO assertion 3, updtr_del a stopped updater: report(rc = 0) == expect(rc = 0), passed
2022-10-31 10:48:25,789 TADA INFO assertion 4, updtr_del a just-added updater: report(rc = 0) == expect(rc = 0), passed
2022-10-31 10:48:25,789 __main__ INFO --- done ---
2022-10-31 10:48:25,790 TADA INFO test updtr_add test ended
2022-10-31 10:48:37 INFO: ----------------------------------------------
2022-10-31 10:48:38 INFO: ======== updtr_match_add_test ========
2022-10-31 10:48:38 INFO: CMD: python3 updtr_match_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/updtr_match_add_test
2022-10-31 10:48:39,449 __main__ INFO -- Get or create the cluster --
2022-10-31 10:48:39,449 TADA INFO starting test `updtr_add test`
2022-10-31 10:48:39,449 TADA INFO   test-id: c880cd5bf591c9fd9b111b2b52e30ba72b5a824c155cf19dc56422bce54b593e
2022-10-31 10:48:39,449 TADA INFO   test-suite: LDMSD
2022-10-31 10:48:39,449 TADA INFO   test-name: updtr_add test
2022-10-31 10:48:39,449 TADA INFO   test-user: narate
2022-10-31 10:48:39,449 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:48:47,279 __main__ INFO -- Start daemons --
2022-10-31 10:48:50,871 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:48:51,177 __main__ INFO All LDMSDs are up.
2022-10-31 10:48:52,379 TADA INFO assertion 1, updtr_match_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:48:53,599 TADA INFO assertion 2, updtr_match_add with an invalid match: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:48:54,807 TADA INFO assertion 3, updtr_match_add of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 10:48:56,027 TADA INFO assertion 4, A success updtr_match_add: report(rc = 0) == expect(rc = 0), passed
2022-10-31 10:48:57,233 TADA INFO assertion 5, updtr_match_add of a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-31 10:48:57,233 __main__ INFO --- done ---
2022-10-31 10:48:57,233 TADA INFO test updtr_add test ended
2022-10-31 10:49:09 INFO: ----------------------------------------------
2022-10-31 10:49:10 INFO: ======== updtr_match_del_test ========
2022-10-31 10:49:10 INFO: CMD: python3 updtr_match_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/updtr_match_del_test
2022-10-31 10:49:10,891 __main__ INFO -- Get or create the cluster --
2022-10-31 10:49:10,891 TADA INFO starting test `updtr_add test`
2022-10-31 10:49:10,891 TADA INFO   test-id: 6aaa76efb7dfc8c2d973c0c17aca8dbfe1aecf6f8f1f2ea5d2c5df2f0f4e6367
2022-10-31 10:49:10,891 TADA INFO   test-suite: LDMSD
2022-10-31 10:49:10,891 TADA INFO   test-name: updtr_add test
2022-10-31 10:49:10,891 TADA INFO   test-user: narate
2022-10-31 10:49:10,891 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:49:18,548 __main__ INFO -- Start daemons --
2022-10-31 10:49:22,129 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:49:22,427 __main__ INFO All LDMSDs are up.
2022-10-31 10:49:23,640 TADA INFO assertion 1, Send updtr_match_del with an invalid regex: report(rc = 2) == expect(rc = 22), passed
2022-10-31 10:49:24,855 TADA INFO assertion 2, Send updtr_match_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 10:49:26,071 TADA INFO assertion 3, Send updtr_match_del with a non-existing inst match: report(rc = 2) == expect(rc = 2), passed
2022-10-31 10:49:27,284 TADA INFO assertion 4, Send updtr_match_del with a non-existing schema match: report(rc = 2) == expect(rc = 2), passed
2022-10-31 10:49:28,497 TADA INFO assertion 5, Send updater_match_del with an invalid match type: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:49:29,717 TADA INFO assertion 6, Send updater_match_del with a valid regex of the inst type: report(rc = 0) == expect(rc = 0), passed
2022-10-31 10:49:30,925 TADA INFO assertion 7, Send updater_match_del with a valid regex of the schema type: report(rc = 0) == expect(rc = 0), passed
2022-10-31 10:49:30,925 __main__ INFO --- done ---
2022-10-31 10:49:30,926 TADA INFO test updtr_add test ended
2022-10-31 10:49:42 INFO: ----------------------------------------------
2022-10-31 10:49:43 INFO: ======== updtr_prdcr_add_test ========
2022-10-31 10:49:43 INFO: CMD: python3 updtr_prdcr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/updtr_prdcr_add_test
2022-10-31 10:49:44,477 __main__ INFO -- Get or create the cluster --
2022-10-31 10:49:44,477 TADA INFO starting test `updtr_add test`
2022-10-31 10:49:44,478 TADA INFO   test-id: 3a6f73f8a3aed12c867b813ed0590254a7957c3c54d68cd2482f288c905a29ab
2022-10-31 10:49:44,478 TADA INFO   test-suite: LDMSD
2022-10-31 10:49:44,478 TADA INFO   test-name: updtr_add test
2022-10-31 10:49:44,478 TADA INFO   test-user: narate
2022-10-31 10:49:44,478 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:49:52,193 __main__ INFO -- Start daemons --
2022-10-31 10:49:55,828 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:49:56,152 __main__ INFO All LDMSDs are up.
2022-10-31 10:49:57,363 TADA INFO assertion 1, Send updtr_prdcr_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:49:59,810 TADA INFO assertion 2, Send updtr_prdcr_add with a regex matching no prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-31 10:50:02,233 TADA INFO assertion 3, Send updtr_prdcdr_add with a regex matching some prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-31 10:50:03,445 TADA INFO assertion 4, Send updtr_prdcdr_add to a running updtr: report(rc = 16) == expect(rc = 16), passed
2022-10-31 10:50:04,662 TADA INFO assertion 5, Send updtr_prdcr_add to a not-existing updtr: report(rc = 2) == expect(rc = 2), passed
2022-10-31 10:50:04,662 __main__ INFO --- done ---
2022-10-31 10:50:04,662 TADA INFO test updtr_add test ended
2022-10-31 10:50:16 INFO: ----------------------------------------------
2022-10-31 10:50:17 INFO: ======== updtr_prdcr_del_test ========
2022-10-31 10:50:17 INFO: CMD: python3 updtr_prdcr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/updtr_prdcr_del_test
2022-10-31 10:50:18,320 __main__ INFO -- Get or create the cluster --
2022-10-31 10:50:18,320 TADA INFO starting test `updtr_add test`
2022-10-31 10:50:18,320 TADA INFO   test-id: fb53aea4966f50f94c857aca3f98469e7daf5d5df0ae49eb97968e6e1f66f007
2022-10-31 10:50:18,320 TADA INFO   test-suite: LDMSD
2022-10-31 10:50:18,320 TADA INFO   test-name: updtr_add test
2022-10-31 10:50:18,320 TADA INFO   test-user: narate
2022-10-31 10:50:18,320 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:50:26,011 __main__ INFO -- Start daemons --
2022-10-31 10:50:29,651 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:50:29,951 __main__ INFO All LDMSDs are up.
2022-10-31 10:50:31,168 TADA INFO assertion 1, Send updtr_prdcr_del with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:50:32,366 TADA INFO assertion 2, Send updtr_prdcr_del to a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-31 10:50:33,564 TADA INFO assertion 3, Send updtr_prdcr_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 10:50:35,992 TADA INFO assertion 4, Send updtr_prdcr_del successfully: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}], passed
2022-10-31 10:50:35,992 __main__ INFO --- done ---
2022-10-31 10:50:35,992 TADA INFO test updtr_add test ended
2022-10-31 10:50:48 INFO: ----------------------------------------------
2022-10-31 10:50:48 INFO: ======== updtr_start_test ========
2022-10-31 10:50:48 INFO: CMD: python3 updtr_start_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/updtr_start_test
2022-10-31 10:50:49,663 __main__ INFO -- Get or create the cluster --
2022-10-31 10:50:49,664 TADA INFO starting test `updtr_add test`
2022-10-31 10:50:49,664 TADA INFO   test-id: 4734c2caa7c521ff6a0e3e04fa1b6fee71a1f1b6cbc0ad1045af97b3d50e392b
2022-10-31 10:50:49,664 TADA INFO   test-suite: LDMSD
2022-10-31 10:50:49,664 TADA INFO   test-name: updtr_add test
2022-10-31 10:50:49,664 TADA INFO   test-user: narate
2022-10-31 10:50:49,664 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:50:57,396 __main__ INFO -- Start daemons --
2022-10-31 10:51:01,052 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:51:01,366 __main__ INFO All LDMSDs are up.
2022-10-31 10:51:02,589 TADA INFO assertion 1, updtr_start with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:51:03,808 TADA INFO assertion 2, updtr_start with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:51:05,027 TADA INFO assertion 3, updtr_start with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-31 10:51:06,237 TADA INFO assertion 4, updtr_start with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:51:07,461 TADA INFO assertion 5, updtr_start without an offset larger than interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 10:51:09,885 TADA INFO assertion 6, updtr_start that changes offset to no offset: report(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-31 10:51:11,085 TADA INFO assertion 7, updtr_start of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 10:51:13,522 TADA INFO assertion 8, updtr_start with a valid interval: report(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-31 10:51:15,950 TADA INFO assertion 9, updtr_start with a valid offset: report(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-31 10:51:18,399 TADA INFO assertion 10, updtr_start without giving interval and offset: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-31 10:51:19,610 TADA INFO assertion 11, updtr_start a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-31 10:51:19,610 __main__ INFO --- done ---
2022-10-31 10:51:19,610 TADA INFO test updtr_add test ended
2022-10-31 10:51:31 INFO: ----------------------------------------------
2022-10-31 10:51:32 INFO: ======== updtr_status_test ========
2022-10-31 10:51:32 INFO: CMD: python3 updtr_status_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/updtr_status_test
2022-10-31 10:51:33,104 __main__ INFO -- Get or create the cluster --
2022-10-31 10:51:33,104 TADA INFO starting test `updtr_status test`
2022-10-31 10:51:33,104 TADA INFO   test-id: cf35e1fc98a8e7db07f8fa817cff471952175d6aed78af0744f3fd8d6b77d737
2022-10-31 10:51:33,104 TADA INFO   test-suite: LDMSD
2022-10-31 10:51:33,104 TADA INFO   test-name: updtr_status test
2022-10-31 10:51:33,104 TADA INFO   test-user: narate
2022-10-31 10:51:33,104 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:51:42,943 __main__ INFO -- Start daemons --
2022-10-31 10:51:47,817 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 10:51:48,229 __main__ INFO All LDMSDs are up.
2022-10-31 10:51:49,434 TADA INFO assertion 1, Send 'updtr_status' to an LDMSD without any Updaters: [], passed
2022-10-31 10:51:50,652 TADA INFO assertion 2, Send 'updtr_status name=foo', where updtr 'foo' doesn't exist.: report(updtr 'foo' doesn't exist.) == expect(updtr 'foo' doesn't exist.), passed
2022-10-31 10:51:51,874 TADA INFO assertion 3, Send 'updtr_status name=all', where 'all' exists.: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-31 10:51:53,085 TADA INFO assertion 4, Send 'updtr_status' to an LDMSD with a single Updater: report([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-31 10:51:54,307 TADA INFO assertion 5, Send 'updtr_status' to an LDMSD with 2 updaters: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-31 10:51:54,307 __main__ INFO --- done ---
2022-10-31 10:51:54,307 TADA INFO test updtr_status test ended
2022-10-31 10:52:07 INFO: ----------------------------------------------
2022-10-31 10:52:07 INFO: ======== ldmsd_flex_decomp_test ========
2022-10-31 10:52:07 INFO: CMD: python3 ldmsd_flex_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldmsd_flex_decomp_test
2022-10-31 10:52:08,587 TADA INFO starting test `ldmsd_flex_decomp_test`
2022-10-31 10:52:08,587 TADA INFO   test-id: 78ea8b6eea168b1852b9b4daaa01a91a15262a35f5f3bf54a3669bf508a84ccb
2022-10-31 10:52:08,587 TADA INFO   test-suite: LDMSD
2022-10-31 10:52:08,587 TADA INFO   test-name: ldmsd_flex_decomp_test
2022-10-31 10:52:08,587 TADA INFO   test-user: narate
2022-10-31 10:52:08,587 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:52:08,588 __main__ INFO -- Get or create the cluster --
2022-10-31 10:52:24,400 __main__ INFO -- Start daemons --
2022-10-31 10:52:34,629 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 10:53:23,790 TADA INFO assertion 1, test_sampler_95772b6 sos schema check: OK, passed
2022-10-31 10:53:23,791 TADA INFO assertion 2, record_sampler_e1f021f sos schema check: OK, passed
2022-10-31 10:53:23,791 TADA INFO assertion 3, fill sos schema check: OK, passed
2022-10-31 10:53:23,791 TADA INFO assertion 4, filter sos schema check: OK, passed
2022-10-31 10:53:23,791 TADA INFO assertion 5, record sos schema check: OK, passed
2022-10-31 10:53:23,791 TADA INFO assertion 6, test_sampler_95772b6 csv schema check: OK, passed
2022-10-31 10:53:23,791 TADA INFO assertion 7, record_sampler_e1f021f csv schema check: OK, passed
2022-10-31 10:53:23,791 TADA INFO assertion 8, fill csv schema check: OK, passed
2022-10-31 10:53:23,792 TADA INFO assertion 9, filter csv schema check: OK, passed
2022-10-31 10:53:23,792 TADA INFO assertion 10, record csv schema check: OK, passed
2022-10-31 10:53:23,792 TADA INFO assertion 11, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-31 10:53:23,792 TADA INFO assertion 12, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-31 10:53:23,792 TADA INFO assertion 13, fill kafka schema check: OK, passed
2022-10-31 10:53:23,792 TADA INFO assertion 14, filter kafka schema check: OK, passed
2022-10-31 10:53:23,793 TADA INFO assertion 15, record kafka schema check: OK, passed
2022-10-31 10:53:23,794 TADA INFO assertion 16, test_sampler_95772b6 sos data check: OK, passed
2022-10-31 10:53:23,862 TADA INFO assertion 17, record_sampler_e1f021f sos data check: OK, passed
2022-10-31 10:53:23,865 TADA INFO assertion 18, fill sos data check: OK, passed
2022-10-31 10:53:23,866 TADA INFO assertion 19, filter sos data check: OK, passed
2022-10-31 10:53:23,874 TADA INFO assertion 20, record sos data check: OK, passed
2022-10-31 10:53:23,876 TADA INFO assertion 21, test_sampler_95772b6 csv data check: OK, passed
2022-10-31 10:53:23,938 TADA INFO assertion 22, record_sampler_e1f021f csv data check: OK, passed
2022-10-31 10:53:23,941 TADA INFO assertion 23, fill csv data check: OK, passed
2022-10-31 10:53:23,942 TADA INFO assertion 24, filter csv data check: OK, passed
2022-10-31 10:53:23,950 TADA INFO assertion 25, record csv data check: OK, passed
2022-10-31 10:53:23,951 TADA INFO assertion 26, test_sampler_95772b6 kafka data check: OK, passed
2022-10-31 10:53:23,974 TADA INFO assertion 27, record_sampler_e1f021f kafka data check: OK, passed
2022-10-31 10:53:23,975 TADA INFO assertion 28, fill kafka data check: OK, passed
2022-10-31 10:53:23,976 TADA INFO assertion 29, filter kafka data check: OK, passed
2022-10-31 10:53:23,980 TADA INFO assertion 30, record kafka data check: OK, passed
2022-10-31 10:53:23,980 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-31 10:53:23,980 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-31 10:53:39 INFO: ----------------------------------------------
2022-10-31 10:53:40 INFO: ======== ldms_set_info_test ========
2022-10-31 10:53:40 INFO: CMD: python3 ldms_set_info_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/ldms_set_info_test
2022-10-31 10:53:50,433 TADA INFO starting test `ldms_set_info_test`
2022-10-31 10:53:50,433 TADA INFO   test-id: 8f8ea6060dee822bad2cde2ef461f48174cff9b099910afffe1e8d3a4733f04e
2022-10-31 10:53:50,434 TADA INFO   test-suite: LDMSD
2022-10-31 10:53:50,434 TADA INFO   test-name: ldms_set_info_test
2022-10-31 10:53:50,434 TADA INFO   test-user: narate
2022-10-31 10:53:50,434 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:53:50,435 TADA INFO assertion 1, Adding set info key value pairs : -, passed
2022-10-31 10:53:50,435 TADA INFO assertion 2, Reset value of an existing pair : -, passed
2022-10-31 10:53:50,435 TADA INFO assertion 3, Get a value : -, passed
2022-10-31 10:53:50,435 TADA INFO assertion 4, Unset a pair : -, passed
2022-10-31 10:53:50,436 TADA INFO assertion 5, Traverse the local set info : -, passed
2022-10-31 10:53:50,436 TADA INFO assertion 6, Verifying the set info at the 1st level : -, passed
2022-10-31 10:53:50,436 TADA INFO assertion 7, Server resetting a key : -, passed
2022-10-31 10:53:50,436 TADA INFO assertion 8, Server unset a key : -, passed
2022-10-31 10:53:50,436 TADA INFO assertion 9, Server add a key : -, passed
2022-10-31 10:53:50,436 TADA INFO assertion 10, Adding a key : -, passed
2022-10-31 10:53:50,436 TADA INFO assertion 11, Add a key that is already in the remote list : -, passed
2022-10-31 10:53:50,437 TADA INFO assertion 12, Unset a key that appears in both local and remote list : -, passed
2022-10-31 10:53:50,437 TADA INFO assertion 13, Verifying the set_info at the 2nd level : -, passed
2022-10-31 10:53:50,437 TADA INFO assertion 14, Test set info propagation: resetting a key on the set origin : -, passed
2022-10-31 10:53:50,437 TADA INFO assertion 15, Test set info propagation: unsetting a key on the set origin : -, passed
2022-10-31 10:53:50,437 TADA INFO assertion 16, Test set info propagation: adding a key on the set origin : -, passed
2022-10-31 10:53:50,437 TADA INFO test ldms_set_info_test ended
2022-10-31 10:54:01 INFO: ----------------------------------------------
2022-10-31 10:54:02 INFO: ======== slurm_sampler2_test ========
2022-10-31 10:54:02 INFO: CMD: python3 slurm_sampler2_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-095443/data/slurm_sampler2_test
2022-10-31 10:54:02,723 TADA INFO starting test `slurm_sampler2_test`
2022-10-31 10:54:02,723 TADA INFO   test-id: 2d122ddce8a2e929c0f703cf8fd398a74f89826f77d85211f5dfd001ac287c8a
2022-10-31 10:54:02,724 TADA INFO   test-suite: LDMSD
2022-10-31 10:54:02,724 TADA INFO   test-name: slurm_sampler2_test
2022-10-31 10:54:02,724 TADA INFO   test-user: narate
2022-10-31 10:54:02,724 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 10:54:02,724 __main__ INFO -- Get or create the cluster --
2022-10-31 10:54:16,028 __main__ INFO -- Add users --
2022-10-31 10:54:21,618 __main__ INFO -- Preparing job script & programs --
2022-10-31 10:54:22,356 __main__ INFO -- Start daemons --
2022-10-31 10:54:44,305 TADA INFO assertion 1, Processing the stream data from slurm_notifier: The metric values are as expected on all nodes., passed
2022-10-31 10:54:47,937 TADA INFO assertion 2.1, Deleting completed jobs -- job_init: The metric values are as expected on all nodes., passed
2022-10-31 10:54:49,599 TADA INFO assertion 2.2, Deleting completed jobs -- step_init: The metric values are as expected on all nodes., passed
2022-10-31 10:54:51,275 TADA INFO assertion 2.3, Deleting completed jobs -- task_init: The metric values are as expected on all nodes., passed
2022-10-31 10:54:52,884 TADA INFO assertion 2.4, Deleting completed jobs -- task_exit: The metric values are as expected on all nodes., passed
2022-10-31 10:54:54,570 TADA INFO assertion 2.5, Deleting completed jobs -- job_exit: The metric values are as expected on all nodes., passed
2022-10-31 10:54:58,251 TADA INFO assertion 3.1, Expanding the set heap -- job_init: The metric values are as expected on all nodes., passed
2022-10-31 10:54:59,903 TADA INFO assertion 3.2, Expanding the set heap -- step_init: The metric values are as expected on all nodes., passed
2022-10-31 10:55:02,909 TADA INFO assertion 3.3, Expanding the set heap -- task_init: The metric values are as expected on all nodes., passed
2022-10-31 10:55:05,897 TADA INFO assertion 3.4, Expanding the set heap -- task_exit: The metric values are as expected on all nodes., passed
2022-10-31 10:55:07,536 TADA INFO assertion 3.5, Expanding the set heap -- job_exit: The metric values are as expected on all nodes., passed
2022-10-31 10:55:13,703 TADA INFO assertion 4.1, Multi-tenant -- job_init: The metric values are as expected on all nodes., passed
2022-10-31 10:55:15,355 TADA INFO assertion 4.2, Multi-tenant -- step_init: The metric values are as expected on all nodes., passed
2022-10-31 10:55:18,007 TADA INFO assertion 4.3, Multi-tenant -- task_init: The metric values are as expected on all nodes., passed
2022-10-31 10:55:20,523 TADA INFO assertion 4.4, Multi-tenant -- task_exit: The metric values are as expected on all nodes., passed
2022-10-31 10:55:22,148 TADA INFO assertion 4.5, Multi-tenant -- job_exit: The metric values are as expected on all nodes., passed
2022-10-31 10:55:22,149 TADA INFO test slurm_sampler2_test ended
2022-10-31 10:55:36 INFO: ----------------------------------------------
2022-10-31 10:55:37 INFO: ======== test-ldms ========
2022-10-31 10:55:37 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-ldms/test.sh
2022-10-31T10:55:37-05:00 INFO: starting test-samp-1
8d86eb339e2f794248bdb6ff32058ae3d4ea677954ac8a40827f85c6ce02664e
2022-10-31T10:55:39-05:00 INFO: starting test-samp-2
8deb11de71ab8cebc3d069d52e5ab34e9e64841e119980d9e4e1a83c9220f21e
2022-10-31T10:55:41-05:00 INFO: starting test-samp-3
43bf64118c119b1933d273e4f4f6a06eec2bb90dce2d6ba491f9de763aef2122
2022-10-31T10:55:43-05:00 INFO: starting test-samp-4
047fdbe4d8ef416a460b2f136c79f9cb004a3133007740cfbbb93a9535ed6317
2022-10-31T10:55:45-05:00 INFO: test-samp-1 is running
2022-10-31T10:55:45-05:00 INFO: test-samp-2 is running
2022-10-31T10:55:45-05:00 INFO: test-samp-3 is running
2022-10-31T10:55:45-05:00 INFO: test-samp-4 is running
2022-10-31T10:55:45-05:00 INFO: starting test-agg-11
b8b153f6a24fc93e57dc3e5f67f9072cf2958a45b6e649672a2231871af8c9f5
2022-10-31T10:55:46-05:00 INFO: starting test-agg-12
6e1e94e48f76b8fa282e91d4844d502ed75c74fbf105923fe4ce1104ea6c060a
2022-10-31T10:55:48-05:00 INFO: test-agg-11 is running
2022-10-31T10:55:48-05:00 INFO: test-agg-12 is running
2022-10-31T10:55:48-05:00 INFO: starting test-agg-2
a4d21d3724e49e89ec950fddf282f567b495941c23ec7bf8529a1a361c7b4440
2022-10-31T10:55:51-05:00 INFO: test-agg-2 is running
2022-10-31T10:55:51-05:00 INFO: Collecting data (into SOS)
2022-10-31T10:56:01-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-31T10:56:03-05:00 INFO: check rc: 0
2022-10-31T10:56:03-05:00 INFO: Cleaning up ...
test-samp-1
test-samp-2
test-samp-3
test-samp-4
test-agg-11
test-agg-12
test-agg-2
2022-10-31T10:56:07-05:00 INFO: DONE
2022-10-31 10:56:17 INFO: ----------------------------------------------
2022-10-31 10:56:17 INFO: ======== test-maestro ========
2022-10-31 10:56:17 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro/test.sh
2022-10-31T10:56:17-05:00 INFO: starting mtest-maestro
ed4927d1536af2d59dce6aa22358120b041f1e8ad41cc6bb6e4027c9aa4ed376
2022-10-31T10:56:19-05:00 INFO: starting mtest-samp-1
d53dafd0cb0d5ed1e279e2409dc11398e0dd46e34a3af180aba998f8b37c7b0e
2022-10-31T10:56:21-05:00 INFO: starting mtest-samp-2
f27e810acd94c768a562b43c29d91ee042b6180b6e89e49afe0bdaaeb041e26e
2022-10-31T10:56:23-05:00 INFO: starting mtest-samp-3
bf3751f0e6c2871974a3c7f3ca50197357f1d66855cb032df26b3fc19b4091dd
2022-10-31T10:56:25-05:00 INFO: starting mtest-samp-4
14df14ea818f53a2216c31959b570506624ec91eb0f39c91fce5a17fc54effd0
2022-10-31T10:56:26-05:00 INFO: mtest-samp-1 is running
2022-10-31T10:56:26-05:00 INFO: mtest-samp-2 is running
2022-10-31T10:56:26-05:00 INFO: mtest-samp-3 is running
2022-10-31T10:56:26-05:00 INFO: mtest-samp-4 is running
2022-10-31T10:56:26-05:00 INFO: starting mtest-agg-11
8aaa89d8df4318b5adae382f850a48f8f3e51bfa5134c8619bdb33903ba55f52
2022-10-31T10:56:28-05:00 INFO: starting mtest-agg-12
96ff5e4af4d455c70fbc9a84e2f61cbf3fee77fffc241df0d408ef5f4198a7fa
2022-10-31T10:56:29-05:00 INFO: mtest-agg-11 is running
2022-10-31T10:56:29-05:00 INFO: mtest-agg-12 is running
2022-10-31T10:56:29-05:00 INFO: starting mtest-agg-2
38d604ce31d3c85493099c55af222641ea436de32349447688c2587346f31100
2022-10-31T10:56:31-05:00 INFO: mtest-agg-2 is running
2022-10-31T10:56:31-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-31T10:56:42-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-31T10:56:44-05:00 INFO: sos check rc: 0
2022-10-31T10:56:45-05:00 INFO: starting mtest-ui
f55ddd4ad097e7be80927195f77df6698e8af8cbe0d132b0ee602af4bf38fc0b
2022-10-31T10:56:52-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4381180, 1667231793001.534], [4381180, 1667231793001.537], [4381552, 1667231794000.897], [4381552, 1667231794001.102], [4381552, 1667231795000.364], [4381552, 1667231795001.461], [4381552, 1667231795002.031], [4381552, 1667231795002.063], [4381552, 1667231796001.209], [4381552, 1667231796001.2212], [4381552, 1667231796001.3088], [4381552, 1667231796001.615], [4381552, 1667231797000.397], [4381552, 1667231797000.9011], [4381552, 1667231797001.3599], [4381552, 1667231797001.412], [4381552, 1667231798001.5051], [4381552, 1667231798001.541], [4381552, 1667231798001.55], [4381552, 1667231798001.551], [4381552, 1667231799000.862], [4381552, 1667231799001.3499], [4381552, 1667231799001.3618], [4381552, 1667231799001.6619], [4381552, 1667231800001.3162], [4381552, 1667231800001.3188], [4381552, 1667231800001.324], [4381552, 1667231800001.494]]}, {"target": "component_id", "datapoints": [[3, 1667231793001.534], [1, 1667231793001.537], [1, 1667231794000.897], [3, 1667231794001.102], [3, 1667231795000.364], [4, 1667231795001.461], [1, 1667231795002.031], [2, 1667231795002.063], [1, 1667231796001.209], [2, 1667231796001.2212], [3, 1667231796001.3088], [4, 1667231796001.615], [2, 1667231797000.397], [4, 1667231797000.9011], [1, 1667231797001.3599], [3, 1667231797001.412], [1, 1667231798001.5051], [3, 1667231798001.541], [4, 1667231798001.55], [2, 1667231798001.551], [1, 1667231799000.862], [4, 1667231799001.3499], [2, 1667231799001.3618], [3, 1667231799001.6619], [1, 1667231800001.3162], [2, 1667231800001.3188], [3, 1667231800001.324], [4, 1667231800001.494]]}, {"target": "job_id", "datapoints": [[0, 1667231793001.534], [0, 1667231793001.537], [0, 1667231794000.897], [0, 1667231794001.102], [0, 1667231795000.364], [0, 1667231795001.461], [0, 1667231795002.031], [0, 1667231795002.063], [0, 1667231796001.209], [0, 1667231796001.2212], [0, 1667231796001.3088], [0, 1667231796001.615], [0, 1667231797000.397], [0, 1667231797000.9011], [0, 1667231797001.3599], [0, 1667231797001.412], [0, 1667231798001.5051], [0, 1667231798001.541], [0, 1667231798001.55], [0, 1667231798001.551], [0, 1667231799000.862], [0, 1667231799001.3499], [0, 1667231799001.3618], [0, 1667231799001.6619], [0, 1667231800001.3162], [0, 1667231800001.3188], [0, 1667231800001.324], [0, 1667231800001.494]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-31T10:56:54-05:00 INFO: query check RC: 0
9de1954f2b55c75ea6b1fa36b3ce5efaaf7b9032ed093816abd803f7b48f3653
2022-10-31T10:57:25-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2857    882 --:--:-- --:--:-- --:--:--  3771
{"datasource":{"id":1,"uid":"fx52M_N4z","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-31T10:57:27-05:00 INFO: Checking grafana data
2022-10-31T10:57:27-05:00 INFO: Grafana data check, rc: 0
2022-10-31T10:57:27-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-31T10:57:32-05:00 INFO: DONE
2022-10-31 10:57:42 INFO: ----------------------------------------------
2022-10-31 10:57:42 INFO: ======== test-maestro-hostmunge ========
2022-10-31 10:57:42 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-hostmunge/test.sh
2022-10-31T10:57:42-05:00 INFO: Checking munge on localhost
2022-10-31T10:57:42-05:00 INFO: munge encode/decode successfully
2022-10-31T10:57:42-05:00 INFO: starting mtest-maestro
780b851f04cb40dd5ae27192444297b173a20dc06b0843668e75d6f1628771be
2022-10-31T10:57:44-05:00 INFO: starting mtest-samp-1
531a17caf0802cd266a80aad2499861bea71b4e48eb3af947e772dad24c8293d
2022-10-31T10:57:45-05:00 INFO: starting mtest-samp-2
2ca4c2e6100483e992f89ded5d91783e539bd949872832b2406340e874c4de9e
2022-10-31T10:57:47-05:00 INFO: starting mtest-samp-3
213a7a0d10fca109957bcf5abe53afb1f0845ab5b60a3aad3341e25b4b4b6c1b
2022-10-31T10:57:49-05:00 INFO: starting mtest-samp-4
0df807302cd37f00d7440922f16c9bec33067738050ca3c9c21e798e99a1ae48
2022-10-31T10:57:50-05:00 INFO: mtest-samp-1 is running
2022-10-31T10:57:50-05:00 INFO: mtest-samp-2 is running
2022-10-31T10:57:51-05:00 INFO: mtest-samp-3 is running
2022-10-31T10:57:51-05:00 INFO: mtest-samp-4 is running
2022-10-31T10:57:51-05:00 INFO: starting mtest-agg-11
e4306866819468b32891971a4538fd85729582643e0932967e9ba6c9a67f6b5c
2022-10-31T10:57:52-05:00 INFO: starting mtest-agg-12
3e9740a48695d5b10dbd160c45dd10cd4e30d9b4843a0dcaf3531b855f8b0615
2022-10-31T10:57:54-05:00 INFO: mtest-agg-11 is running
2022-10-31T10:57:54-05:00 INFO: mtest-agg-12 is running
2022-10-31T10:57:54-05:00 INFO: starting mtest-agg-2
20c4feef4e99c1d84d44837b6b328aafe8d6ef12c8df20c30f36f23be36a4b3b
2022-10-31T10:57:55-05:00 INFO: mtest-agg-2 is running
2022-10-31T10:57:55-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-31T10:58:06-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-31T10:58:08-05:00 INFO: sos check rc: 0
2022-10-31T10:58:10-05:00 INFO: starting mtest-ui
2b4b0b38fbc2c7e06015618986284ca681d4d365bcdc55da6093bcb4be45a832
2022-10-31T10:58:11-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4381472, 1667231878001.3289], [4381472, 1667231878001.427], [4381744, 1667231879001.2988], [4381744, 1667231879001.494], [4381744, 1667231879001.507], [4381744, 1667231879001.516], [4381844, 1667231880001.3188], [4381844, 1667231880001.449], [4381844, 1667231880001.451], [4381844, 1667231880001.604], [4381840, 1667231881000.822], [4381840, 1667231881000.8298], [4381840, 1667231881001.468], [4381840, 1667231881001.56], [4381840, 1667231882001.619], [4381840, 1667231882001.703], [4381840, 1667231882001.705], [4381840, 1667231882001.991], [4381840, 1667231883001.0088], [4381840, 1667231883001.2988], [4381840, 1667231883001.856], [4381840, 1667231883002.147], [4381840, 1667231884001.186], [4381840, 1667231884001.1992], [4381840, 1667231884001.2969], [4381840, 1667231884001.984], [4381840, 1667231885001.312], [4381840, 1667231885001.3179], [4381840, 1667231885001.3298], [4381840, 1667231885001.802]]}, {"target": "component_id", "datapoints": [[3, 1667231878001.3289], [1, 1667231878001.427], [2, 1667231879001.2988], [3, 1667231879001.494], [1, 1667231879001.507], [4, 1667231879001.516], [1, 1667231880001.3188], [2, 1667231880001.449], [4, 1667231880001.451], [3, 1667231880001.604], [4, 1667231881000.822], [3, 1667231881000.8298], [1, 1667231881001.468], [2, 1667231881001.56], [1, 1667231882001.619], [4, 1667231882001.703], [2, 1667231882001.705], [3, 1667231882001.991], [2, 1667231883001.0088], [1, 1667231883001.2988], [4, 1667231883001.856], [3, 1667231883002.147], [2, 1667231884001.186], [1, 1667231884001.1992], [3, 1667231884001.2969], [4, 1667231884001.984], [2, 1667231885001.312], [1, 1667231885001.3179], [3, 1667231885001.3298], [4, 1667231885001.802]]}, {"target": "job_id", "datapoints": [[0, 1667231878001.3289], [0, 1667231878001.427], [0, 1667231879001.2988], [0, 1667231879001.494], [0, 1667231879001.507], [0, 1667231879001.516], [0, 1667231880001.3188], [0, 1667231880001.449], [0, 1667231880001.451], [0, 1667231880001.604], [0, 1667231881000.822], [0, 1667231881000.8298], [0, 1667231881001.468], [0, 1667231881001.56], [0, 1667231882001.619], [0, 1667231882001.703], [0, 1667231882001.705], [0, 1667231882001.991], [0, 1667231883001.0088], [0, 1667231883001.2988], [0, 1667231883001.856], [0, 1667231883002.147], [0, 1667231884001.186], [0, 1667231884001.1992], [0, 1667231884001.2969], [0, 1667231884001.984], [0, 1667231885001.312], [0, 1667231885001.3179], [0, 1667231885001.3298], [0, 1667231885001.802]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-31T10:58:13-05:00 INFO: query check RC: 0
11c7270cc81f497fe84e56d3ebf68b9f82c3aace712446c6284bf1ac900aa404
2022-10-31T10:58:45-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2437    752 --:--:-- --:--:-- --:--:--  3214
{"datasource":{"id":1,"uid":"FzlAG_H4z","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-31T10:58:46-05:00 INFO: Checking grafana data
2022-10-31T10:58:46-05:00 INFO: Grafana data check, rc: 0
2022-10-31T10:58:46-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-31T10:58:51-05:00 INFO: DONE
2022-10-31 10:59:01 INFO: ----------------------------------------------
2022-10-31 10:59:01 INFO: ======== test-maestro-munge ========
2022-10-31 10:59:01 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-munge/test.sh
1+0 records in
1+0 records out
4096 bytes (4.1 kB, 4.0 KiB) copied, 0.000273971 s, 15.0 MB/s
2022-10-31T10:59:02-05:00 INFO: starting mtest-maestro
5de64de81caa378903ebac2e0e2a05e6b9d4c375ba466eed1b742a718ce199df
2022-10-31T10:59:05-05:00 INFO: starting mtest-samp-1
d374fae7e2e42172880c0335d0d165ffe3d98785fac538988878dc438ab7778a
2022-10-31T10:59:06-05:00 INFO: starting mtest-samp-2
67ccecee060c2ba2a3f46e06fa026177ebbfdb6fb88c8fdcf8141ecef5f9128f
2022-10-31T10:59:08-05:00 INFO: starting mtest-samp-3
fb26d48505808d438d710eddcabbb39bcfa6159e3bfbf5d8be22e4340659e15b
2022-10-31T10:59:10-05:00 INFO: starting mtest-samp-4
df3151d796ff86910c4cfad0b1234ca548d796f9f577a12e6f30ba4ac4208c7f
2022-10-31T10:59:11-05:00 INFO: mtest-samp-1 is running
2022-10-31T10:59:11-05:00 INFO: mtest-samp-2 is running
2022-10-31T10:59:11-05:00 INFO: mtest-samp-3 is running
2022-10-31T10:59:11-05:00 INFO: mtest-samp-4 is running
2022-10-31T10:59:11-05:00 INFO: starting mtest-agg-11
6f14fdbb55bf26c38ec355a3c92bb9ff57dcfb21bdd0861f3d3c8b841ebb3a3f
2022-10-31T10:59:13-05:00 INFO: starting mtest-agg-12
cb3180cbc24c02bc897ab4e8b8181effa1570517be8b82d29ba9e54837fcc2ba
2022-10-31T10:59:14-05:00 INFO: mtest-agg-11 is running
2022-10-31T10:59:14-05:00 INFO: mtest-agg-12 is running
2022-10-31T10:59:14-05:00 INFO: starting mtest-agg-2
a55b6f201fc600673cc5a1faf03692ecf38e1f1b856b34babca75a683a36256f
2022-10-31T10:59:16-05:00 INFO: mtest-agg-2 is running
2022-10-31T10:59:16-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-31T10:59:27-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-31T10:59:29-05:00 INFO: sos check rc: 0
2022-10-31T10:59:30-05:00 INFO: starting mtest-ui
3942b61c80aaee4c01b2c6303653a2e6a2c743b013d31026e4fe365d5f1fb1a2
2022-10-31T10:59:32-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4381756, 1667231960000.904], [4381756, 1667231960001.4531], [4382128, 1667231961001.331], [4382128, 1667231961001.344], [4382128, 1667231961001.6099], [4382128, 1667231961001.665], [4382128, 1667231962000.558], [4382128, 1667231962001.472], [4382128, 1667231962001.656], [4382128, 1667231962001.7468], [4382128, 1667231963000.638], [4382128, 1667231963001.7139], [4382128, 1667231963001.797], [4382128, 1667231963001.864], [4382128, 1667231964000.9622], [4382128, 1667231964001.835], [4382128, 1667231964001.9321], [4382128, 1667231964002.002], [4382128, 1667231965000.964], [4382128, 1667231965001.972], [4382128, 1667231965001.994], [4382128, 1667231965002.07]]}, {"target": "component_id", "datapoints": [[1, 1667231960000.904], [3, 1667231960001.4531], [1, 1667231961001.331], [2, 1667231961001.344], [3, 1667231961001.6099], [4, 1667231961001.665], [1, 1667231962000.558], [2, 1667231962001.472], [4, 1667231962001.656], [3, 1667231962001.7468], [2, 1667231963000.638], [1, 1667231963001.7139], [4, 1667231963001.797], [3, 1667231963001.864], [2, 1667231964000.9622], [1, 1667231964001.835], [4, 1667231964001.9321], [3, 1667231964002.002], [3, 1667231965000.964], [2, 1667231965001.972], [1, 1667231965001.994], [4, 1667231965002.07]]}, {"target": "job_id", "datapoints": [[0, 1667231960000.904], [0, 1667231960001.4531], [0, 1667231961001.331], [0, 1667231961001.344], [0, 1667231961001.6099], [0, 1667231961001.665], [0, 1667231962000.558], [0, 1667231962001.472], [0, 1667231962001.656], [0, 1667231962001.7468], [0, 1667231963000.638], [0, 1667231963001.7139], [0, 1667231963001.797], [0, 1667231963001.864], [0, 1667231964000.9622], [0, 1667231964001.835], [0, 1667231964001.9321], [0, 1667231964002.002], [0, 1667231965000.964], [0, 1667231965001.972], [0, 1667231965001.994], [0, 1667231965002.07]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-31T10:59:34-05:00 INFO: query check RC: 0
67325b6dacec6856526044c7c44fce58b1296a981db4d67e50d6b969a1814ed1
2022-10-31T11:00:06-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2723    840 --:--:-- --:--:-- --:--:--  3574
{"datasource":{"id":1,"uid":"kRD-GlHVk","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-31T11:00:07-05:00 INFO: Checking grafana data
2022-10-31T11:00:07-05:00 INFO: Grafana data check, rc: 0
2022-10-31T11:00:07-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-31T11:00:12-05:00 INFO: DONE
2022-10-31 11:00:22 INFO: ----------------------------------------------
2022-10-31 11:00:22 INFO: ==== Summary ====
ldmsd_ctrl_test: [01;32mPASSED[0m
papi_store_test: [01;32mPASSED[0m
updtr_status_test: [01;32mPASSED[0m
ldmsd_auth_ovis_test: [01;32mPASSED[0m
store_app_test: [01;32mPASSED[0m
store_list_record_test: [01;32mPASSED[0m
set_array_test: [01;32mPASSED[0m
ovis_ev_test: [01;32mPASSED[0m
setgroup_test: [01;32mPASSED[0m
ldms_list_test: [01;32mPASSED[0m
slurm_stream_test: [01;32mPASSED[0m
maestro_cfg_test: [01;32mPASSED[0m
ldms_set_info_test: [01;32mPASSED[0m
spank_notifier_test: [01;32mPASSED[0m
agg_slurm_test: [01;32mPASSED[0m
updtr_match_add_test: [01;32mPASSED[0m
updtr_match_del_test: [01;32mPASSED[0m
ldmsd_stream_dir_test: [01;32mPASSED[0m
direct_prdcr_subscribe_test: [01;32mPASSED[0m
ldmsd_auth_test: [01;32mPASSED[0m
cont-test-maestro-munge: [01;32mPASSED[0m
cont-test-ldms: [01;32mPASSED[0m
prdcr_subscribe_test: [01;32mPASSED[0m
cont-test-maestro-hostmunge: [01;32mPASSED[0m
maestro_raft_test: [01;32mPASSED[0m
updtr_start_test: [01;32mPASSED[0m
failover_test: [01;32mPASSED[0m
ldms_record_test: [01;32mPASSED[0m
cont-test-maestro: [01;32mPASSED[0m
ldmsd_decomp_test: [01;32mPASSED[0m
ldmsd_flex_decomp_test: [01;32mPASSED[0m
quick_set_add_rm_test: [01;32mPASSED[0m
updtr_prdcr_del_test: [01;32mPASSED[0m
updtr_prdcr_add_test: [01;32mPASSED[0m
mt-slurm-test: [01;32mPASSED[0m
ovis_json_test: [01;32mPASSED[0m
papi_sampler_test: [01;32mPASSED[0m
syspapi_test: [01;32mPASSED[0m
updtr_del_test: [01;32mPASSED[0m
ldmsd_autointerval_test: [01;32mPASSED[0m
updtr_add_test: [01;32mPASSED[0m
ldmsd_stream_test: [01;32mPASSED[0m
direct_ldms_ls_conn_test: [01;32mPASSED[0m
set_array_hang_test: [01;32mPASSED[0m
slurm_sampler2_test: [01;32mPASSED[0m
ldms_schema_digest_test: [01;32mPASSED[0m
agg_test: [01;32mPASSED[0m
------------------------------------------
Total tests passed: 47/47
------------------------------------------
