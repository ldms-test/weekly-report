2022-10-27 22:19:05 INFO: WORK_DIR: /mnt/300G/data/2022-10-27-221905
2022-10-27 22:19:05 INFO: LOG: /mnt/300G/data/2022-10-27-221905/cygnus-weekly.log
~/cron/ldms-test ~/cron/ldms-test
/mnt/300G/data/2022-10-27-221905 ~/cron/ldms-test ~/cron/ldms-test
2022-10-27 22:19:06 INFO: Skip building on host because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:19:06 INFO: Skip building containerized binary because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:19:06 INFO: -- Installation process succeeded --
2022-10-27 22:19:06 INFO: ---------------------------------------------------------------
~/cron/ldms-test /mnt/300G/data/2022-10-27-221905
~/cron/ldms-test/weekly-report ~/cron/ldms-test /mnt/300G/data/2022-10-27-221905
HEAD is now at b7c0e56 2022-10-27-204339
[master f3dc88d] 2022-10-27-221905
 2 files changed, 14 insertions(+), 2036 deletions(-)
 rewrite test-all.log (99%)
To github.com:ldms-test/weekly-report
   b7c0e56..f3dc88d  master -> master
~/cron/ldms-test /mnt/300G/data/2022-10-27-221905
2022-10-27 22:19:08 INFO: ==== OVIS+SOS Installation Completed ====
2022-10-27 22:19:08 INFO: ==== Start batch testing ====
~/cron/ldms-test /mnt/300G/data/2022-10-27-221905 ~/cron/ldms-test ~/cron/ldms-test
2022-10-27 22:19:08 INFO: ======== direct_ldms_ls_conn_test ========
2022-10-27 22:19:08 INFO: CMD: python3 direct_ldms_ls_conn_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/direct_ldms_ls_conn_test
2022-10-27 22:19:09,222 TADA INFO starting test `direct_ldms_ls_conn_test`
2022-10-27 22:19:09,223 TADA INFO   test-id: bfff3edb331a3e444b44a39d0972dfcf8e6344fd78560f2f6a573b9522104ca5
2022-10-27 22:19:09,223 TADA INFO   test-suite: LDMSD
2022-10-27 22:19:09,223 TADA INFO   test-name: direct_ldms_ls_conn_test
2022-10-27 22:19:09,223 TADA INFO   test-user: narate
2022-10-27 22:19:09,223 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:19:09,674 __main__ INFO starting munged on cygnus-01-iw
2022-10-27 22:19:10,014 __main__ INFO starting munged on localhost
2022-10-27 22:19:10,236 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-27 22:19:10,530 TADA INFO assertion 0, Start ldmsd sampler and munged: OK, passed
2022-10-27 22:19:15,722 TADA INFO assertion 1, ldms_ls to the sampler: OK, passed
2022-10-27 22:19:15,723 __main__ INFO Stopping sampler daemon ...
2022-10-27 22:19:21,141 TADA INFO assertion 2, Kill the sampler: OK, passed
2022-10-27 22:19:21,184 TADA INFO assertion 3, ldms_ls to the dead sampler: got expected output, passed
2022-10-27 22:19:21,217 TADA INFO assertion 4, ldms_ls to a dead host: got expected output, passed
2022-10-27 22:19:21,218 TADA INFO test direct_ldms_ls_conn_test ended
2022-10-27 22:19:21,431 __main__ INFO stopping munged on cygnus-01-iw
2022-10-27 22:19:21,829 __main__ INFO stopping munged on localhost
2022-10-27 22:19:21 INFO: ----------------------------------------------
2022-10-27 22:19:21 INFO: ======== direct_prdcr_subscribe_test ========
2022-10-27 22:19:21 INFO: CMD: python3 direct_prdcr_subscribe_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/direct_prdcr_subscribe_test
2022-10-27 22:19:22,654 TADA INFO starting test `direct_prdcr_subscribe_test`
2022-10-27 22:19:22,654 TADA INFO   test-id: 88b13359c9f6adccf45f5e4fd675a031b6ee94cf46faa79f241a268cc5ea1df5
2022-10-27 22:19:22,654 TADA INFO   test-suite: LDMSD
2022-10-27 22:19:22,654 TADA INFO   test-name: direct_prdcr_subscribe_test
2022-10-27 22:19:22,655 TADA INFO   test-user: narate
2022-10-27 22:19:22,655 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:19:24,564 __main__ INFO starting munged on cygnus-01-iw
2022-10-27 22:19:25,310 __main__ INFO starting munged on cygnus-02-iw
2022-10-27 22:19:26,034 __main__ INFO starting munged on cygnus-03-iw
2022-10-27 22:19:26,785 __main__ INFO starting munged on cygnus-04-iw
2022-10-27 22:19:27,104 __main__ INFO starting munged on localhost
2022-10-27 22:19:27,345 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-27 22:19:27,848 __main__ INFO starting ldmsd on cygnus-02-iw
2022-10-27 22:19:28,377 __main__ INFO starting ldmsd on cygnus-03-iw
2022-10-27 22:19:28,881 __main__ INFO starting ldmsd on cygnus-04-iw
2022-10-27 22:19:35,754 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-27 22:19:35,754 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-27 22:19:35,755 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-27 22:19:35,755 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-27 22:19:35,757 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verified, passed
2022-10-27 22:19:35,794 TADA INFO assertion 5, Stopping the producers succeeds: agg-1 producers stopped, passed
2022-10-27 22:19:36,796 TADA INFO assertion 6, Restarting the producers succeeds: agg-1 producers started, passed
2022-10-27 22:19:43,392 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-27 22:19:43,393 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-27 22:19:43,394 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-27 22:19:43,394 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-27 22:19:43,395 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verified, passed
2022-10-27 22:19:43,395 __main__ INFO stopping sampler-1
2022-10-27 22:19:44,812 TADA INFO assertion 12, stream-sampler-1 is not running: sampler-1 stopped, passed
2022-10-27 22:19:44,813 __main__ INFO starting sampler-1
2022-10-27 22:19:46,062 TADA INFO assertion 13, stream-sampler-1 has restarted: sampler-1 running, passed
2022-10-27 22:19:46,063 __main__ INFO allow some time for prdcr to reconnect ...
2022-10-27 22:19:51,979 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-27 22:19:51,980 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-27 22:19:51,980 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verified, passed
2022-10-27 22:19:51,982 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: unsubscribed, passed
2022-10-27 22:19:54,182 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-27 22:19:54,187 __main__ INFO stopping agg-1
2022-10-27 22:19:59,411 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-27 22:19:59,412 TADA INFO test direct_prdcr_subscribe_test ended
2022-10-27 22:19:59,631 __main__ INFO stopping munged on cygnus-01-iw
2022-10-27 22:20:00,045 __main__ INFO stopping ldmsd on cygnus-01-iw
2022-10-27 22:20:00,464 __main__ INFO stopping munged on cygnus-02-iw
2022-10-27 22:20:00,874 __main__ INFO stopping ldmsd on cygnus-02-iw
2022-10-27 22:20:01,291 __main__ INFO stopping munged on cygnus-03-iw
2022-10-27 22:20:01,930 __main__ INFO stopping munged on cygnus-04-iw
2022-10-27 22:20:02,350 __main__ INFO stopping ldmsd on cygnus-04-iw
2022-10-27 22:20:02,564 __main__ INFO stopping munged on localhost
2022-10-27 22:20:02 INFO: ----------------------------------------------
2022-10-27 22:20:02 INFO: ======== agg_slurm_test ========
2022-10-27 22:20:02 INFO: CMD: python3 agg_slurm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/agg_slurm_test
2022-10-27 22:20:03,437 TADA INFO starting test `agg_slurm_test`
2022-10-27 22:20:03,437 TADA INFO   test-id: ecdc9ac8e49a57191e9edd7d6662e0343b0ba9ace94d32f78d4415a542392a4f
2022-10-27 22:20:03,437 TADA INFO   test-suite: LDMSD
2022-10-27 22:20:03,438 TADA INFO   test-name: agg_slurm_test
2022-10-27 22:20:03,438 TADA INFO   test-user: narate
2022-10-27 22:20:03,438 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:20:03,439 __main__ INFO -- Get or create the cluster --
2022-10-27 22:20:17,386 __main__ INFO -- Preparing syspapi JSON file --
2022-10-27 22:20:17,485 __main__ INFO -- Preparing jobpapi JSON file --
2022-10-27 22:20:17,585 __main__ INFO -- Preparing job script & programs --
2022-10-27 22:20:18,950 __main__ INFO -- Start daemons --
2022-10-27 22:20:31,303 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:20:36,306 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 22:20:36,439 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-27 22:20:36,552 __main__ INFO -- Give syspapi some time to work before submitting job --
2022-10-27 22:20:41,554 __main__ INFO -- Submitting jobs --
2022-10-27 22:20:41,678 __main__ INFO job_one: 1
2022-10-27 22:20:41,805 __main__ INFO job_two: 2
2022-10-27 22:20:51,816 __main__ INFO -- Cancelling jobs --
2022-10-27 22:20:51,816 __main__ INFO job_one: 1
2022-10-27 22:20:51,939 __main__ INFO job_two: 2
2022-10-27 22:22:03,977 TADA INFO assertion 2, slurm data verification: get expected data from store, passed
2022-10-27 22:22:03,977 TADA INFO assertion 3, meminfo data verification: No data missing, passed
2022-10-27 22:22:03,978 TADA INFO assertion 4, (SYS/JOB) PAPI data verification: No data missing, passed
2022-10-27 22:22:03,979 TADA INFO test agg_slurm_test ended
2022-10-27 22:22:18 INFO: ----------------------------------------------
2022-10-27 22:22:19 INFO: ======== papi_sampler_test ========
2022-10-27 22:22:19 INFO: CMD: python3 papi_sampler_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/papi_sampler_test
2022-10-27 22:22:19,806 TADA INFO starting test `papi_sampler_test`
2022-10-27 22:22:19,806 TADA INFO   test-id: ac355eebaba32654b7430d756dcc944b0a0b962848c07d17923b7300e8459324
2022-10-27 22:22:19,807 TADA INFO   test-suite: LDMSD
2022-10-27 22:22:19,807 TADA INFO   test-name: papi_sampler_test
2022-10-27 22:22:19,807 TADA INFO   test-user: narate
2022-10-27 22:22:19,807 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:22:19,807 __main__ INFO -- Get or create the cluster --
2022-10-27 22:22:25,124 __main__ INFO -- Start daemons --
2022-10-27 22:22:35,185 TADA INFO assertion 0, ldmsd has started: verified, passed
2022-10-27 22:22:35,408 TADA INFO assertion 1.1, Non-papi job is submitted: jobid(1) > 0, passed
2022-10-27 22:22:40,542 TADA INFO assertion 1.2, Non-papi job is running before ldms_ls: STATE = RUNNING, passed
2022-10-27 22:22:40,722 TADA INFO assertion 1.3, Non-papi job is running after ldms_ls: STATE = RUNNING, passed
2022-10-27 22:22:40,722 TADA INFO assertion 1, Non-papi job does not create set: verified, passed
2022-10-27 22:22:54,548 TADA INFO assertion 2, papi job creates set: PAPI set created, passed
2022-10-27 22:22:54,548 TADA INFO assertion 2.2, Schema name is set accordingly: schema name == papi0, passed
2022-10-27 22:22:54,549 TADA INFO assertion 2.1, Events in papi job set created according to config file: {'PAPI_TOT_INS'} == {'PAPI_TOT_INS'}, passed
2022-10-27 22:22:54,549 TADA INFO assertion 2.3, PAPI set has correct job_id: 2 == 2, passed
2022-10-27 22:22:54,755 TADA INFO assertion 2.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-27 22:23:00,542 TADA INFO assertion 3, papi job creates set: PAPI set created, passed
2022-10-27 22:23:00,543 TADA INFO assertion 3.2, Schema name is set accordingly: schema name == papi1, passed
2022-10-27 22:23:00,543 TADA INFO assertion 3.1, Events in papi job set created according to config file: {'PAPI_TOT_INS', 'PAPI_BR_MSP'} == {'PAPI_TOT_INS', 'PAPI_BR_MSP'}, passed
2022-10-27 22:23:00,543 TADA INFO assertion 3.3, PAPI set has correct job_id: 3 == 3, passed
2022-10-27 22:23:00,755 TADA INFO assertion 3.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-27 22:23:00,755 TADA INFO assertion 4, Multiple, concurrent jobs results in concurrent, multiple sets: LDMS sets ({'node-1/papi1/3.0', 'node-1/meminfo', 'node-1/papi0/2.0'}), passed
2022-10-27 22:23:11,225 TADA INFO assertion 6, PAPI set persists within `job_expiry` after job exited: verified, passed
2022-10-27 22:23:51,552 TADA INFO assertion 7, PAPI set is deleted after `2.2 x job_expiry` since job exited: node-1/meminfo deleted, passed
2022-10-27 22:23:53,876 TADA INFO assertion 8, Missing config file attribute is logged: : papi_sampler[519]: papi_config object must contain either the 'file' or 'config' attribute., passed
2022-10-27 22:23:59,324 TADA INFO assertion 9, Bad config file is logged: : papi_sampler: configuration file syntax error., passed
2022-10-27 22:24:04,789 TADA INFO assertion 10, Unsupported events are logged: : papi_sampler: PAPI error 'Event does not exist' translating event code 'FOO', passed
2022-10-27 22:24:04,790 __main__ INFO -- Finishing Test --
2022-10-27 22:24:04,790 TADA INFO test papi_sampler_test ended
2022-10-27 22:24:04,790 __main__ INFO -- Cleaning up files --
2022-10-27 22:24:04,791 __main__ INFO -- Removing the virtual cluster --
2022-10-27 22:24:16 INFO: ----------------------------------------------
2022-10-27 22:24:17 INFO: ======== papi_store_test ========
2022-10-27 22:24:17 INFO: CMD: python3 papi_store_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/papi_store_test
2022-10-27 22:24:17,810 TADA INFO starting test `papi_store_test`
2022-10-27 22:24:17,811 TADA INFO   test-id: 05cd1ca285ae5fb8180466b7921895bbe4ef41431892d7fcfd327aa3a3545746
2022-10-27 22:24:17,811 TADA INFO   test-suite: LDMSD
2022-10-27 22:24:17,811 TADA INFO   test-name: papi_store_test
2022-10-27 22:24:17,811 TADA INFO   test-user: narate
2022-10-27 22:24:17,812 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:24:17,813 __main__ INFO -- Get or create the cluster --
2022-10-27 22:24:25,271 __main__ INFO -- Start daemons --
2022-10-27 22:24:57,933 TADA INFO assertion 1, Every job in the input data is represented in the output: {1, 2, 3, 4} = {1, 2, 3, 4}, passed
2022-10-27 22:24:57,933 TADA INFO assertion 2, Every event in every job results in a separate row in the output: verified, passed
2022-10-27 22:24:57,934 TADA INFO assertion 3, The schema name in the output matches the event name: verified, passed
2022-10-27 22:24:57,934 TADA INFO assertion 4, Each rank in the job results in a row per event in the output: verified, passed
2022-10-27 22:24:57,934 TADA INFO test papi_store_test ended
2022-10-27 22:25:10 INFO: ----------------------------------------------
2022-10-27 22:25:11 INFO: ======== store_app_test ========
2022-10-27 22:25:11 INFO: CMD: python3 store_app_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/store_app_test
2022-10-27 22:25:11,954 TADA INFO starting test `store_app_test`
2022-10-27 22:25:11,954 TADA INFO   test-id: 4ffcd9c74748f5f2513ec06b2c1ebc0885fecd64da3d93bf220cce02c48e5478
2022-10-27 22:25:11,954 TADA INFO   test-suite: LDMSD
2022-10-27 22:25:11,954 TADA INFO   test-name: store_app_test
2022-10-27 22:25:11,954 TADA INFO   test-user: narate
2022-10-27 22:25:11,955 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:25:11,955 __main__ INFO -- Get or create the cluster --
2022-10-27 22:25:26,327 __main__ INFO -- Preparing job script & programs --
2022-10-27 22:25:26,720 __main__ INFO -- Start daemons --
2022-10-27 22:25:38,989 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:25:43,995 __main__ INFO -- Submitting jobs --
2022-10-27 22:25:44,205 __main__ INFO job_one: 1
2022-10-27 22:25:49,400 __main__ INFO job_two: 2
2022-10-27 22:25:58,692 __main__ INFO Verifying data ...
2022-10-27 22:27:55,440 TADA INFO assertion 1, Verify data: sos data is not empty and sos data < ldms_ls data, passed
2022-10-27 22:27:55,440 TADA INFO test store_app_test ended
2022-10-27 22:28:09 INFO: ----------------------------------------------
2022-10-27 22:28:10 INFO: ======== syspapi_test ========
2022-10-27 22:28:10 INFO: CMD: python3 syspapi_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/syspapi_test
2022-10-27 22:28:10,988 TADA INFO starting test `syspapi_test`
2022-10-27 22:28:10,988 TADA INFO   test-id: 7e088bcd5dd37bc81809bb2418344f6e12ee3edfc9677d2456a466b810d9ea7a
2022-10-27 22:28:10,988 TADA INFO   test-suite: LDMSD
2022-10-27 22:28:10,988 TADA INFO   test-name: syspapi_test
2022-10-27 22:28:10,988 TADA INFO   test-user: narate
2022-10-27 22:28:10,989 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:28:10,989 __main__ INFO -- Get or create the cluster --
2022-10-27 22:28:22,326 __main__ INFO -- Write syspapi JSON config files --
2022-10-27 22:28:22,326 __main__ INFO    - db/syspapi-1.json
2022-10-27 22:28:22,327 __main__ INFO    - db/syspapi-bad.json
2022-10-27 22:28:22,327 __main__ INFO -- Start daemons --
2022-10-27 22:28:30,681 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:28:35,682 __main__ INFO -- Verifying --
2022-10-27 22:28:35,803 TADA INFO assertion 1, verify set creation by cfg_file: set existed (with correct instance name), passed
2022-10-27 22:28:35,803 TADA INFO assertion 2, verify schema name by cfg_file: verify schema name, passed
2022-10-27 22:28:35,904 TADA INFO assertion 3, verify metrics (events) by cfg_file: verify events (metrics), passed
2022-10-27 22:28:38,037 TADA INFO assertion 4, verify increment counters: verify increment of supported counters, passed
2022-10-27 22:28:38,143 TADA INFO assertion 5, verify cfg_file syntax error report: verify JSON parse error, passed
2022-10-27 22:28:38,247 TADA INFO assertion 6, verify cfg_file unsupported events report: verify unsupported event report, passed
2022-10-27 22:28:59,532 TADA INFO assertion 7, verify cfg_file for many events: each event has either 'sucees' or 'failed' report, passed
2022-10-27 22:28:59,532 __main__ INFO  events succeeded: 77
2022-10-27 22:28:59,532 __main__ INFO  events failed: 114
2022-10-27 22:28:59,532 TADA INFO test syspapi_test ended
2022-10-27 22:29:12 INFO: ----------------------------------------------
2022-10-27 22:29:13 INFO: ======== agg_test ========
2022-10-27 22:29:13 INFO: CMD: python3 agg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/agg_test
2022-10-27 22:29:14,340 TADA INFO starting test `agg_test`
2022-10-27 22:29:14,340 TADA INFO   test-id: 5cee169fda46e7405acd8a7cf2eefc4d855d978f791eb2e78720c80ffa557811
2022-10-27 22:29:14,340 TADA INFO   test-suite: LDMSD
2022-10-27 22:29:14,340 TADA INFO   test-name: agg_test
2022-10-27 22:29:14,340 TADA INFO   test-user: narate
2022-10-27 22:29:14,340 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:29:14,341 __main__ INFO -- Get or create the cluster --
2022-10-27 22:29:31,835 __main__ INFO -- Start daemons --
2022-10-27 22:29:41,016 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:29:46,017 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 22:29:46,143 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-27 22:29:46,948 TADA INFO assertion 2, meminfo data verification: data verified, passed
2022-10-27 22:29:46,949 __main__ INFO -- Terminating ldmsd on node-1 --
2022-10-27 22:29:49,285 TADA INFO assertion 3, node-1 ldmsd terminated, sets removed from agg-11: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 22:29:49,519 TADA INFO assertion 4, node-1 ldmsd terminated, sets removed from agg-2: list({'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:29:49,519 __main__ INFO -- Resurrecting ldmsd on node-1 --
2022-10-27 22:29:55,182 TADA INFO assertion 5, node-1 ldmsd revived, sets added to agg-11: list({'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo'}), passed
2022-10-27 22:29:55,294 TADA INFO assertion 6, node-1 ldmsd revived, sets added to agg-2: list({'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:29:55,294 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-27 22:29:57,632 TADA INFO assertion 7, agg-11 ldmsd terminated, sets removed from agg-2: list({'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:29:57,748 TADA INFO assertion 8, agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-27 22:29:57,853 TADA INFO assertion 9, agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 22:29:57,853 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-27 22:30:03,531 TADA INFO assertion 10, agg-11 ldmsd revived, sets added to agg-2: list({'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:30:03,531 TADA INFO test agg_test ended
2022-10-27 22:30:19 INFO: ----------------------------------------------
2022-10-27 22:30:20 INFO: ======== failover_test ========
2022-10-27 22:30:20 INFO: CMD: python3 failover_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/failover_test
2022-10-27 22:30:20,819 TADA INFO starting test `failover_test`
2022-10-27 22:30:20,819 TADA INFO   test-id: a30b4ffcdd1cff94d311f8c79595800859076397201dbc5af8e32d01462301de
2022-10-27 22:30:20,819 TADA INFO   test-suite: LDMSD
2022-10-27 22:30:20,819 TADA INFO   test-name: failover_test
2022-10-27 22:30:20,819 TADA INFO   test-user: narate
2022-10-27 22:30:20,819 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:30:20,820 __main__ INFO -- Get or create the cluster --
2022-10-27 22:30:38,429 __main__ INFO -- Start daemons --
2022-10-27 22:30:47,660 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:31:02,662 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 22:31:02,794 TADA INFO assertion 1, 
ldms_ls agg-2: dir result verified, passed
2022-10-27 22:31:03,570 TADA INFO assertion 2, 
meminfo data verification: data verified, passed
2022-10-27 22:31:03,570 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-27 22:31:08,914 TADA INFO assertion 3, 
agg-11 ldmsd terminated, sets added to agg-12: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:31:09,038 TADA INFO assertion 4, 
agg-11 ldmsd terminated, all sets running on agg-2: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:31:09,158 TADA INFO assertion 5, 
agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-27 22:31:09,266 TADA INFO assertion 6, 
agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 22:31:09,266 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-27 22:31:29,932 TADA INFO assertion 7, 
agg-11 ldmsd revived, sets removed from agg-12: list({'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:31:30,049 TADA INFO assertion 8, 
agg-11 ldmsd revived, all sets running on agg-2: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:31:30,051 __main__ INFO -- Terminating ldmsd on agg-12 --
2022-10-27 22:31:35,400 TADA INFO assertion 9, 
agg-12 ldmsd terminated, sets added to agg-11: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:31:35,509 TADA INFO assertion 10, 
agg-12 ldmsd terminated, all sets running on agg-2: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:31:35,616 TADA INFO assertion 11, 
agg-12 ldmsd terminated, node-2 ldmsd is still running: list({'node-2/meminfo'}) == expect({'node-2/meminfo'}), passed
2022-10-27 22:31:35,733 TADA INFO assertion 12, 
agg-12 ldmsd terminated, node-4 ldmsd is still running: list({'node-4/meminfo'}) == expect({'node-4/meminfo'}), passed
2022-10-27 22:31:35,733 __main__ INFO -- Resurrecting ldmsd on agg-12 --
2022-10-27 22:31:56,392 TADA INFO assertion 13, 
agg-12 ldmsd revived, sets removed from agg-11: list({'node-1/meminfo', 'node-3/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo'}), passed
2022-10-27 22:31:56,503 TADA INFO assertion 14, 
agg-12 ldmsd revived, all sets running on agg-2: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 22:31:56,503 TADA INFO test failover_test ended
2022-10-27 22:32:11 INFO: ----------------------------------------------
2022-10-27 22:32:12 INFO: ======== ldmsd_auth_ovis_test ========
2022-10-27 22:32:12 INFO: CMD: python3 ldmsd_auth_ovis_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldmsd_auth_ovis_test
2022-10-27 22:32:13,442 TADA INFO starting test `ldmsd_auth_ovis_test`
2022-10-27 22:32:13,443 TADA INFO   test-id: a5660e3283f33f12ff1ae598c809d4c242e45d53dacab6b105a02c590bbf4dfc
2022-10-27 22:32:13,443 TADA INFO   test-suite: LDMSD
2022-10-27 22:32:13,443 TADA INFO   test-name: ldmsd_auth_ovis_test
2022-10-27 22:32:13,443 TADA INFO   test-user: narate
2022-10-27 22:32:13,443 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:32:13,444 __main__ INFO -- Get or create the cluster --
2022-10-27 22:32:18,541 __main__ INFO -- Start daemons --
2022-10-27 22:32:20,431 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:32:25,561 TADA INFO assertion 1, ldms_ls with auth none: verified, passed
2022-10-27 22:32:25,687 TADA INFO assertion 2, ldms_ls with wrong secret: verified, passed
2022-10-27 22:32:25,809 TADA INFO assertion 3, ldms_ls 'dir' with right secret: verified, passed
2022-10-27 22:32:26,100 TADA INFO assertion 4, ldms_ls 'read' with right secret: verified, passed
2022-10-27 22:32:26,101 TADA INFO test ldmsd_auth_ovis_test ended
2022-10-27 22:32:37 INFO: ----------------------------------------------
2022-10-27 22:32:38 INFO: ======== ldmsd_auth_test ========
2022-10-27 22:32:38 INFO: CMD: python3 ldmsd_auth_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldmsd_auth_test
2022-10-27 22:32:39,085 TADA INFO starting test `ldmsd_auth_test`
2022-10-27 22:32:39,085 TADA INFO   test-id: 2c9fd0cb9931613ee2df688485c86e9857f29304eae7082d6da318dd2496cb9c
2022-10-27 22:32:39,085 TADA INFO   test-suite: LDMSD
2022-10-27 22:32:39,085 TADA INFO   test-name: ldmsd_auth_test
2022-10-27 22:32:39,085 TADA INFO   test-user: narate
2022-10-27 22:32:39,085 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:32:39,086 __main__ INFO -- Get or create the cluster --
2022-10-27 22:32:57,117 __main__ INFO -- Start daemons --
2022-10-27 22:33:15,913 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:33:21,056 TADA INFO assertion 1, root@agg-2(dom3) ldms_ls to agg-2:10000: see all sets, passed
2022-10-27 22:33:21,169 TADA INFO assertion 2, user@agg-2(dom3) ldms_ls to agg-2:10000: see only meminfo, passed
2022-10-27 22:33:21,284 TADA INFO assertion 3, root@headnode(dom4) ldms_ls to agg-2:10001: see all sets, passed
2022-10-27 22:33:21,399 TADA INFO assertion 4, user@headnode(dom4) ldms_ls to agg-2:10001: see only meminfo, passed
2022-10-27 22:33:21,516 TADA INFO assertion 5, root@headnode(dom4) ldms_ls to agg-11:10000: connection rejected, passed
2022-10-27 22:33:21,517 TADA INFO test ldmsd_auth_test ended
2022-10-27 22:33:37 INFO: ----------------------------------------------
2022-10-27 22:33:37 INFO: ======== ldmsd_ctrl_test ========
2022-10-27 22:33:37 INFO: CMD: python3 ldmsd_ctrl_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldmsd_ctrl_test
2022-10-27 22:33:38,688 TADA INFO starting test `ldmsd_ctrl_test`
2022-10-27 22:33:38,688 TADA INFO   test-id: cb34c969262666fa815ce01ab64c093059d2326f569b17ad1ab41267f6a81337
2022-10-27 22:33:38,688 TADA INFO   test-suite: LDMSD
2022-10-27 22:33:38,688 TADA INFO   test-name: ldmsd_ctrl_test
2022-10-27 22:33:38,688 TADA INFO   test-user: narate
2022-10-27 22:33:38,688 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:33:38,689 __main__ INFO -- Get or create the cluster --
2022-10-27 22:33:48,293 __main__ INFO -- Start daemons --
2022-10-27 22:33:52,702 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:33:58,824 TADA INFO assertion 1, ldmsd_controller interactive session: connected, passed
2022-10-27 22:33:59,939 TADA INFO assertion 2, ldmsctl interactive session: connected, passed
2022-10-27 22:34:00,541 TADA INFO assertion 3, ldmsd_controller start bogus producer: expected output verified, passed
2022-10-27 22:34:01,143 TADA INFO assertion 4, ldmsctl start bogus producer: expected output verified, passed
2022-10-27 22:34:01,744 TADA INFO assertion 5, ldmsd_controller bogus command: expected output verified, passed
2022-10-27 22:34:02,345 TADA INFO assertion 6, ldmsctl bogus command: expected output verified, passed
2022-10-27 22:34:02,947 TADA INFO assertion 7, ldmsd_controller load bogus plugin: expected output verified, passed
2022-10-27 22:34:03,549 TADA INFO assertion 8, ldmsctl load bogus plugin: expected output verified, passed
2022-10-27 22:34:20,733 TADA INFO assertion 9, ldmsd_controller prdcr/updtr: verified, passed
2022-10-27 22:34:37,939 TADA INFO assertion 10, ldmsctl prdcr/updtr: verified, passed
2022-10-27 22:34:37,940 TADA INFO test ldmsd_ctrl_test ended
2022-10-27 22:34:50 INFO: ----------------------------------------------
2022-10-27 22:34:51 INFO: ======== ldmsd_stream_test ========
2022-10-27 22:34:51 INFO: CMD: python3 ldmsd_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldmsd_stream_test
2022-10-27 22:34:52,048 TADA INFO starting test `ldmsd_stream_test`
2022-10-27 22:34:52,048 TADA INFO   test-id: 42fa8cdfda4b7aadfe5f3cfbc33c63abdfec9590ae224b97c62f2b3c9c25c961
2022-10-27 22:34:52,048 TADA INFO   test-suite: LDMSD
2022-10-27 22:34:52,048 TADA INFO   test-name: ldmsd_stream_test
2022-10-27 22:34:52,048 TADA INFO   test-user: narate
2022-10-27 22:34:52,049 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:35:03,043 __main__ INFO waiting for libraries to be available across all containers...
2022-10-27 22:35:03,871 __main__ INFO _lib_avail: True
2022-10-27 22:36:11,114 __main__ INFO test ldmsd_stream_subscribe with large json streams
2022-10-27 22:36:17,238 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 22:36:30,734 __main__ INFO --- Verifying the received streams
2022-10-27 22:36:32,350 TADA INFO assertion 1, ldmsd_stream_subscribe receives large json streams: Verify all streams were received correctly, passed
2022-10-27 22:36:32,551 __main__ INFO test LDMSD with large json streams
2022-10-27 22:36:38,630 __main__ INFO --- Sending stream to samplerd
2022-10-27 22:36:57,353 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 22:36:59,745 TADA INFO assertion 2, samplerd receives large json streams: Verify all streams were received correctly, passed
2022-10-27 22:36:59,745 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 22:37:02,136 TADA INFO assertion 3, agg receives large json streams: Verify all streams were received correctly, passed
2022-10-27 22:37:02,136 __main__ INFO test ldmsd_stream_subscribe with small json streams
2022-10-27 22:37:08,248 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 22:39:03,583 __main__ INFO --- Verifying the received streams
2022-10-27 22:39:05,484 TADA INFO assertion 4, ldmsd_stream_subscribe receives small json streams: Verify all streams were received correctly, passed
2022-10-27 22:39:05,689 __main__ INFO test LDMSD with small json streams
2022-10-27 22:39:11,705 __main__ INFO --- Sending stream to samplerd
2022-10-27 22:41:12,360 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 22:41:15,191 TADA INFO assertion 5, samplerd receives small json streams: Verify all streams were received correctly, passed
2022-10-27 22:41:15,191 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 22:41:18,184 TADA INFO assertion 6, agg receives small json streams: Verify all streams were received correctly, passed
2022-10-27 22:41:18,184 __main__ INFO test ldmsd_stream_subscribe with large string streams
2022-10-27 22:41:24,313 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 22:41:37,500 __main__ INFO --- Verifying the received streams
2022-10-27 22:41:39,077 TADA INFO assertion 7, ldmsd_stream_subscribe receives large string streams: Verify all streams were received correctly, passed
2022-10-27 22:41:39,307 __main__ INFO test LDMSD with large string streams
2022-10-27 22:41:45,359 __main__ INFO --- Sending stream to samplerd
2022-10-27 22:42:03,790 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 22:42:04,959 TADA INFO assertion 8, samplerd receives large string streams: Verify all streams were received correctly, passed
2022-10-27 22:42:04,959 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 22:42:06,142 TADA INFO assertion 9, agg receives large string streams: Verify all streams were received correctly, passed
2022-10-27 22:42:06,142 __main__ INFO test ldmsd_stream_subscribe with small string streams
2022-10-27 22:42:12,256 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 22:44:07,672 __main__ INFO --- Verifying the received streams
2022-10-27 22:44:09,615 TADA INFO assertion 10, ldmsd_stream_subscribe receives small string streams: Verify all streams were received correctly, passed
2022-10-27 22:44:09,832 __main__ INFO test LDMSD with small string streams
2022-10-27 22:44:15,858 __main__ INFO --- Sending stream to samplerd
2022-10-27 22:46:16,444 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 22:46:17,640 TADA INFO assertion 11, samplerd receives small string streams: Verify all streams were received correctly, passed
2022-10-27 22:46:17,641 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 22:46:18,832 TADA INFO assertion 12, agg receives small string streams: Verify all streams were received correctly, passed
2022-10-27 22:46:18,832 TADA INFO test ldmsd_stream_test ended
2022-10-27 22:46:32 INFO: ----------------------------------------------
2022-10-27 22:46:34 INFO: ======== maestro_cfg_test ========
2022-10-27 22:46:34 INFO: CMD: python3 maestro_cfg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/maestro_cfg_test
2022-10-27 22:46:35,059 TADA INFO starting test `maestro_cfg_test`
2022-10-27 22:46:35,059 TADA INFO   test-id: 9a591fd5e3e5e7ea051d9e3f8306225d3a207bfcebcfccb4b93205835fd9e546
2022-10-27 22:46:35,059 TADA INFO   test-suite: LDMSD
2022-10-27 22:46:35,059 TADA INFO   test-name: maestro_cfg_test
2022-10-27 22:46:35,059 TADA INFO   test-user: narate
2022-10-27 22:46:35,059 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:46:45,069 __main__ INFO -- Get or create cluster --
2022-10-27 22:47:11,438 __main__ INFO -- Start daemons --
2022-10-27 22:47:26,155 __main__ INFO ... make sure ldmsd's are up
2022-10-27 22:47:33,639 TADA INFO assertion 1, load maestro etcd cluster: etcd cluster loaded successfully, passed
2022-10-27 22:48:13,659 TADA INFO assertion 2, config ldmsd cluster with maestro: Maestro ldmsd configuration successful, passed
2022-10-27 22:48:15,239 TADA INFO assertion 3, verify sampler daemons: OK, passed
2022-10-27 22:48:15,825 TADA INFO assertion 4, verify L1 aggregator daemons: OK, passed
2022-10-27 22:48:16,072 TADA INFO assertion 5, verify L2 aggregator daemon: OK, passed
2022-10-27 22:48:16,371 TADA INFO assertion 6, verify data storage: OK, passed
---Wait for config to write to file---
2022-10-27 22:48:16,372 TADA INFO test maestro_cfg_test ended
2022-10-27 22:48:34 INFO: ----------------------------------------------
2022-10-27 22:48:35 INFO: ======== mt-slurm-test ========
2022-10-27 22:48:35 INFO: CMD: python3 mt-slurm-test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/mt-slurm-test
-- Get or create the cluster --
-- Start daemons --
... wait a bit to make sure ldmsd's are up
Every job in input data represented in output: : Passed
['# task_rank,timestamp', '0,1666928954.888428', '1,1666928954.888428', '2,1666928954.888428', '3,1666928955.973322', '4,1666928955.973322', '5,1666928955.973322', '6,1666928955.973322', '7,1666928955.973322', '8,1666928955.973322', '9,1666928956.975655', '10,1666928956.975655', '11,1666928957.951213', '12,1666928957.951213', '13,1666928957.951213', '14,1666928957.951213', '15,1666928957.951213', '16,1666928957.951213', '17,1666928957.951213', '18,1666928959.933477', '19,1666928959.933477', '20,1666928959.933477', '21,1666928959.933477', '22,1666928959.933477', '23,1666928959.933477', '24,1666928959.933477', '25,1666928959.933477', '26,1666928959.933477', '# Records 27/27.', '']
Job 10000 has 27 rank: : Passed
Job 10100 has 64 rank: : Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
Job 10000 has 3 nodes: node count 3 correct: Passed
Job 10100 has 4 nodes: node count 4 correct: Passed
2022-10-27 22:49:53 INFO: ----------------------------------------------
2022-10-27 22:49:54 INFO: ======== ovis_ev_test ========
2022-10-27 22:49:54 INFO: CMD: python3 ovis_ev_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ovis_ev_test
2022-10-27 22:49:55,387 __main__ INFO -- Create the cluster -- 
2022-10-27 22:50:04,636 TADA INFO starting test `ovis_ev_test`
2022-10-27 22:50:04,636 TADA INFO   test-id: a10ca8f34cc928d0b87ae13477b88288589d0f0415ffcdc59e60d0495045e87c
2022-10-27 22:50:04,636 TADA INFO   test-suite: test_ovis_ev
2022-10-27 22:50:04,636 TADA INFO   test-name: ovis_ev_test
2022-10-27 22:50:04,636 TADA INFO   test-user: narate
2022-10-27 22:50:04,636 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:50:04,637 TADA INFO assertion 1, Test posting an event without timeout: ovis_ev delivered the expected event., passed
2022-10-27 22:50:04,638 TADA INFO assertion 2, Test posting an event with a current timeout: ovis_ev delivered the expected event., passed
2022-10-27 22:50:04,638 TADA INFO assertion 3, Test posting an event with a future timeout: ovis_ev delivered the expected event., passed
2022-10-27 22:50:04,638 TADA INFO assertion 4, Test reposting a posted event: ev_post returned EBUSY when posted an already posted event, passed
2022-10-27 22:50:04,638 TADA INFO assertion 5, Test canceling a posted event: ovis_ev delivered the expected event., passed
2022-10-27 22:50:04,639 TADA INFO assertion 6, Test rescheduling a posted event: ovis_ev delivered the expected event., passed
2022-10-27 22:50:04,639 TADA INFO assertion 7, Test event deliver order: The event delivery order was correct., passed
2022-10-27 22:50:04,639 TADA INFO assertion 8, Test flushing events: Expected status (1) == delivered status (1), passed
2022-10-27 22:50:04,639 TADA INFO assertion 9, Test posting event on a flushed worker: Expected status (0) == delivered status (0), passed
2022-10-27 22:50:04,639 TADA INFO assertion 10, Test the case that multiple threads post the same event: ev_post returned the expected return code., passed
2022-10-27 22:50:04,640 TADA INFO test ovis_ev_test ended
2022-10-27 22:50:15 INFO: ----------------------------------------------
2022-10-27 22:50:16 INFO: ======== prdcr_subscribe_test ========
2022-10-27 22:50:16 INFO: CMD: python3 prdcr_subscribe_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/prdcr_subscribe_test
2022-10-27 22:50:16,940 TADA INFO starting test `prdcr_subscribe_test`
2022-10-27 22:50:16,940 TADA INFO   test-id: e46ee312758f3dcbda6e0a4573eaac127c1351cefd97657a17525cc34f393e21
2022-10-27 22:50:16,940 TADA INFO   test-suite: LDMSD
2022-10-27 22:50:16,940 TADA INFO   test-name: prdcr_subscribe_test
2022-10-27 22:50:16,940 TADA INFO   test-user: narate
2022-10-27 22:50:16,940 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:50:52,403 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-27 22:50:52,403 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-27 22:50:52,404 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-27 22:50:52,404 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-27 22:50:52,404 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verification, passed
2022-10-27 22:50:52,753 TADA INFO assertion 5, Stopping the producers succeeds: , passed
2022-10-27 22:50:53,102 TADA INFO assertion 6, Restarting the producers succeeds: , passed
2022-10-27 22:51:01,102 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-27 22:51:01,102 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-27 22:51:01,103 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-27 22:51:01,103 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-27 22:51:01,103 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verification, passed
2022-10-27 22:51:02,303 TADA INFO assertion 12, stream-sampler-1 is not running: (running == False), passed
2022-10-27 22:51:03,843 TADA INFO assertion 13, stream-sampler-1 has restarted: (running == True), passed
2022-10-27 22:51:11,404 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-27 22:51:11,404 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-27 22:51:11,405 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verification, passed
2022-10-27 22:51:11,758 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: , passed
2022-10-27 22:51:15,083 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-27 22:51:20,856 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-27 22:51:20,857 TADA INFO test prdcr_subscribe_test ended
2022-10-27 22:51:33 INFO: ----------------------------------------------
2022-10-27 22:51:34 INFO: ======== set_array_test ========
2022-10-27 22:51:34 INFO: CMD: python3 set_array_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/set_array_test
2022-10-27 22:51:35,083 TADA INFO starting test `set_array_test`
2022-10-27 22:51:35,083 TADA INFO   test-id: 9fdc8a1d2da18eceb4da55ed22d946154fb1bdaa444425d43988db0d8d7572f9
2022-10-27 22:51:35,083 TADA INFO   test-suite: LDMSD
2022-10-27 22:51:35,083 TADA INFO   test-name: set_array_test
2022-10-27 22:51:35,083 TADA INFO   test-user: narate
2022-10-27 22:51:35,083 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:51:35,084 __main__ INFO -- Get or create the cluster --
2022-10-27 22:51:40,315 __main__ INFO -- Start daemons --
2022-10-27 22:51:42,281 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:52:10,535 TADA INFO assertion 1, 1st update got some callbacks: verified hunk of 9 snapshots, passed
2022-10-27 22:52:10,536 TADA INFO assertion 2, 2nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-27 22:52:10,536 TADA INFO assertion 3, 3nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-27 22:52:10,536 TADA INFO test set_array_test ended
2022-10-27 22:52:21 INFO: ----------------------------------------------
2022-10-27 22:52:22 INFO: ======== setgroup_test ========
2022-10-27 22:52:22 INFO: CMD: python3 setgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/setgroup_test
2022-10-27 22:52:23,522 TADA INFO starting test `setgroup_test`
2022-10-27 22:52:23,522 TADA INFO   test-id: beee5e8cb6855d2ebff6c3510af9b6bbec6cadf5db3b8f2d8b9120d3f67228c0
2022-10-27 22:52:23,522 TADA INFO   test-suite: LDMSD
2022-10-27 22:52:23,522 TADA INFO   test-name: setgroup_test
2022-10-27 22:52:23,523 TADA INFO   test-user: narate
2022-10-27 22:52:23,523 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:52:23,523 __main__ INFO -- Get or create the cluster --
2022-10-27 22:52:32,782 __main__ INFO -- Start daemons --
2022-10-27 22:52:37,214 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:52:42,216 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 22:52:42,329 TADA INFO assertion 1, ldms_ls grp on agg-2: dir result verified, passed
2022-10-27 22:52:44,579 TADA INFO assertion 2, members on agg-2 are being updated: data verified, passed
2022-10-27 22:52:44,579 __main__ INFO -- Removing test_2 from grp --
2022-10-27 22:52:45,056 TADA INFO assertion 3, test_2 is removed fom grp on sampler: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 22:52:49,170 TADA INFO assertion 4, test_2 is removed from grp on agg-1: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 22:52:53,294 TADA INFO assertion 5, test_2 is removed from grp on agg-2: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 22:52:57,295 __main__ INFO -- Adding test_2 back into grp --
2022-10-27 22:52:57,774 TADA INFO assertion 6, test_2 is added back to grp on sampler: expect {'node-1/test_1', 'node-1/test_2', 'node-1/grp'}, got {'node-1/test_1', 'node-1/test_2', 'node-1/grp'}, passed
2022-10-27 22:53:01,893 TADA INFO assertion 7, test_2 is added back to grp on agg-1: expect {'node-1/test_1', 'node-1/test_2', 'node-1/grp'}, got {'node-1/test_1', 'node-1/test_2', 'node-1/grp'}, passed
2022-10-27 22:53:04,002 TADA INFO assertion 8, test_2 is added back to grp on agg-2: expect {'node-1/test_1', 'node-1/test_2', 'node-1/grp'}, got {'node-1/test_1', 'node-1/test_2', 'node-1/grp'}, passed
2022-10-27 22:53:06,005 TADA INFO test setgroup_test ended
2022-10-27 22:53:18 INFO: ----------------------------------------------
2022-10-27 22:53:19 INFO: ======== slurm_stream_test ========
2022-10-27 22:53:19 INFO: CMD: python3 slurm_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/slurm_stream_test
2022-10-27 22:53:20,478 TADA INFO starting test `slurm_stream_test`
2022-10-27 22:53:20,479 TADA INFO   test-id: 63d0bd0efeffdf481c15bff03dfc6209729593d699c9d2455aaf3f547af013ba
2022-10-27 22:53:20,479 TADA INFO   test-suite: LDMSD
2022-10-27 22:53:20,479 TADA INFO   test-name: slurm_stream_test
2022-10-27 22:53:20,479 TADA INFO   test-user: narate
2022-10-27 22:53:20,479 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:53:20,479 __main__ INFO -- Get or create the cluster --
2022-10-27 22:53:27,379 __main__ INFO -- Start daemons --
2022-10-27 22:53:30,038 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:53:59,682 TADA INFO assertion 1, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:53:59,682 __main__ INFO 12345
2022-10-27 22:53:59,682 __main__ INFO 12345
2022-10-27 22:53:59,682 TADA INFO assertion 2, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,682 TADA INFO assertion 3, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-27 22:53:59,682 TADA INFO assertion 4, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,683 TADA INFO assertion 5, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,683 TADA INFO assertion 6, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,683 TADA INFO assertion 7, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,778 TADA INFO assertion 8, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:53:59,778 __main__ INFO 12345
2022-10-27 22:53:59,778 __main__ INFO 12345
2022-10-27 22:53:59,778 TADA INFO assertion 9, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,778 TADA INFO assertion 10, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-27 22:53:59,778 TADA INFO assertion 11, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,779 TADA INFO assertion 12, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,779 TADA INFO assertion 13, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,779 TADA INFO assertion 14, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 22:53:59,897 TADA INFO assertion 15, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:53:59,897 __main__ INFO 12346
2022-10-27 22:53:59,897 __main__ INFO 12346
2022-10-27 22:53:59,897 TADA INFO assertion 16, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,897 TADA INFO assertion 17, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-27 22:53:59,897 TADA INFO assertion 18, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,898 TADA INFO assertion 19, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,898 TADA INFO assertion 20, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,898 TADA INFO assertion 21, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,996 TADA INFO assertion 22, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:53:59,996 __main__ INFO 12346
2022-10-27 22:53:59,996 __main__ INFO 12346
2022-10-27 22:53:59,996 TADA INFO assertion 23, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,996 TADA INFO assertion 24, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-27 22:53:59,996 TADA INFO assertion 25, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,996 TADA INFO assertion 26, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,997 TADA INFO assertion 27, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 22:53:59,997 TADA INFO assertion 28, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 22:54:00,097 TADA INFO assertion 29, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:00,097 __main__ INFO 12347
2022-10-27 22:54:00,097 __main__ INFO 12347
2022-10-27 22:54:00,098 TADA INFO assertion 30, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,098 TADA INFO assertion 31, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-27 22:54:00,098 TADA INFO assertion 32, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,098 TADA INFO assertion 33, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,098 TADA INFO assertion 34, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,098 TADA INFO assertion 35, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,208 TADA INFO assertion 36, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:00,208 __main__ INFO 12347
2022-10-27 22:54:00,208 __main__ INFO 12347
2022-10-27 22:54:00,208 TADA INFO assertion 37, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,208 TADA INFO assertion 38, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-27 22:54:00,208 TADA INFO assertion 39, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,209 TADA INFO assertion 40, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,209 TADA INFO assertion 41, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,209 TADA INFO assertion 42, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 22:54:00,319 TADA INFO assertion 43, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:00,319 __main__ INFO 12348
2022-10-27 22:54:00,319 __main__ INFO 12348
2022-10-27 22:54:00,319 TADA INFO assertion 44, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,319 TADA INFO assertion 45, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-27 22:54:00,320 TADA INFO assertion 46, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,320 TADA INFO assertion 47, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,320 TADA INFO assertion 48, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,320 TADA INFO assertion 49, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,427 TADA INFO assertion 50, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:00,428 __main__ INFO 12348
2022-10-27 22:54:00,428 __main__ INFO 12348
2022-10-27 22:54:00,428 TADA INFO assertion 51, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,428 TADA INFO assertion 52, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-27 22:54:00,428 TADA INFO assertion 53, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,428 TADA INFO assertion 54, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,428 TADA INFO assertion 55, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,429 TADA INFO assertion 56, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 22:54:00,550 TADA INFO assertion 57, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:00,550 __main__ INFO 12355
2022-10-27 22:54:00,550 __main__ INFO 12355
2022-10-27 22:54:00,550 TADA INFO assertion 58, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,550 TADA INFO assertion 59, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-27 22:54:00,551 TADA INFO assertion 60, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,551 TADA INFO assertion 61, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,551 TADA INFO assertion 62, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,551 TADA INFO assertion 63, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,551 TADA INFO assertion 64, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,551 TADA INFO assertion 65, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,552 TADA INFO assertion 66, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,552 TADA INFO assertion 67, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,655 TADA INFO assertion 68, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:00,655 __main__ INFO 12355
2022-10-27 22:54:00,655 __main__ INFO 12355
2022-10-27 22:54:00,655 TADA INFO assertion 69, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,656 TADA INFO assertion 70, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-27 22:54:00,656 TADA INFO assertion 71, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,656 TADA INFO assertion 72, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,656 TADA INFO assertion 73, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,656 TADA INFO assertion 74, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,656 TADA INFO assertion 75, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,657 TADA INFO assertion 76, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,657 TADA INFO assertion 77, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,657 TADA INFO assertion 78, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 22:54:00,772 TADA INFO assertion 79, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:00,772 __main__ INFO 12356
2022-10-27 22:54:00,772 __main__ INFO 12356
2022-10-27 22:54:00,772 TADA INFO assertion 80, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,773 TADA INFO assertion 81, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-27 22:54:00,773 TADA INFO assertion 82, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,773 TADA INFO assertion 83, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,773 TADA INFO assertion 84, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,773 TADA INFO assertion 85, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,773 TADA INFO assertion 86, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,774 TADA INFO assertion 87, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,774 TADA INFO assertion 88, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,774 TADA INFO assertion 89, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,896 TADA INFO assertion 90, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:00,896 __main__ INFO 12356
2022-10-27 22:54:00,896 __main__ INFO 12356
2022-10-27 22:54:00,896 TADA INFO assertion 91, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,897 TADA INFO assertion 92, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-27 22:54:00,897 TADA INFO assertion 93, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,897 TADA INFO assertion 94, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,897 TADA INFO assertion 95, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,897 TADA INFO assertion 96, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,897 TADA INFO assertion 97, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,898 TADA INFO assertion 98, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,898 TADA INFO assertion 99, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:00,898 TADA INFO assertion 100, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 22:54:01,000 TADA INFO assertion 101, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:01,000 __main__ INFO 12357
2022-10-27 22:54:01,000 __main__ INFO 12357
2022-10-27 22:54:01,000 TADA INFO assertion 102, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,000 TADA INFO assertion 103, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-27 22:54:01,000 TADA INFO assertion 104, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,001 TADA INFO assertion 105, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,001 TADA INFO assertion 106, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,001 TADA INFO assertion 107, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,001 TADA INFO assertion 108, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,001 TADA INFO assertion 109, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,001 TADA INFO assertion 110, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,002 TADA INFO assertion 111, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,111 TADA INFO assertion 112, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:01,111 __main__ INFO 12357
2022-10-27 22:54:01,112 __main__ INFO 12357
2022-10-27 22:54:01,112 TADA INFO assertion 113, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,112 TADA INFO assertion 114, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-27 22:54:01,112 TADA INFO assertion 115, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,112 TADA INFO assertion 116, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,112 TADA INFO assertion 117, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,113 TADA INFO assertion 118, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,113 TADA INFO assertion 119, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,113 TADA INFO assertion 120, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,113 TADA INFO assertion 121, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,113 TADA INFO assertion 122, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 22:54:01,229 TADA INFO assertion 123, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:01,229 __main__ INFO 12358
2022-10-27 22:54:01,229 __main__ INFO 12358
2022-10-27 22:54:01,229 TADA INFO assertion 124, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,229 TADA INFO assertion 125, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-27 22:54:01,230 TADA INFO assertion 126, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,230 TADA INFO assertion 127, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,230 TADA INFO assertion 128, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,230 TADA INFO assertion 129, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,230 TADA INFO assertion 130, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,230 TADA INFO assertion 131, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,231 TADA INFO assertion 132, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,231 TADA INFO assertion 133, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,344 TADA INFO assertion 134, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 22:54:01,344 __main__ INFO 12358
2022-10-27 22:54:01,344 __main__ INFO 12358
2022-10-27 22:54:01,345 TADA INFO assertion 135, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,345 TADA INFO assertion 136, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-27 22:54:01,345 TADA INFO assertion 137, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,345 TADA INFO assertion 138, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,345 TADA INFO assertion 139, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,346 TADA INFO assertion 140, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,346 TADA INFO assertion 141, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,346 TADA INFO assertion 142, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,346 TADA INFO assertion 143, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:01,346 TADA INFO assertion 144, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 22:54:03,398 TADA INFO assertion 145, new job correctly replaces oldest slot: correct job_id fills next slot, passed
2022-10-27 22:54:03,398 __main__ INFO 12353
2022-10-27 22:54:03,398 __main__ INFO 12353
2022-10-27 22:54:03,398 TADA INFO assertion 146, new job_start correctly represented in metric set: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,398 TADA INFO assertion 147, new job_end correctly represented in metric set: with mutl jobs running, for Job 12353, passed
2022-10-27 22:54:03,398 TADA INFO assertion 148, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,399 TADA INFO assertion 149, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,399 TADA INFO assertion 150, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,399 TADA INFO assertion 151, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,399 TADA INFO assertion 152, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,399 TADA INFO assertion 153, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,399 TADA INFO assertion 154, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,400 TADA INFO assertion 155, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 22:54:03,400 __main__ INFO -- Test Finished --
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
2022-10-27 22:54:03,400 TADA INFO test slurm_stream_test ended
2022-10-27 22:54:14 INFO: ----------------------------------------------
2022-10-27 22:54:15 INFO: ======== spank_notifier_test ========
2022-10-27 22:54:15 INFO: CMD: python3 spank_notifier_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/spank_notifier_test
2022-10-27 22:54:16,392 TADA INFO starting test `spank_notifier_test`
2022-10-27 22:54:16,392 TADA INFO   test-id: b8f2c4522252eea6bf62c35a3bacf78d012c454cf40762ec69e7d79d39b099ef
2022-10-27 22:54:16,392 TADA INFO   test-suite: Slurm_Plugins
2022-10-27 22:54:16,392 TADA INFO   test-name: spank_notifier_test
2022-10-27 22:54:16,392 TADA INFO   test-user: narate
2022-10-27 22:54:16,392 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:54:16,393 __main__ INFO -- Create the cluster --
2022-10-27 22:54:41,803 __main__ INFO -- Cleanup output --
2022-10-27 22:54:42,136 __main__ INFO -- Test bad plugstack config --
2022-10-27 22:54:42,136 __main__ INFO Starting slurm ...
2022-10-27 22:54:56,608 __main__ INFO Starting slurm ... OK
2022-10-27 22:55:17,072 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 22:55:17,183 __main__ INFO   jobid = 1
2022-10-27 22:55:17,389 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 22:55:17,502 __main__ INFO   jobid = 2
2022-10-27 22:55:17,706 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 22:55:17,821 __main__ INFO   jobid = 3
2022-10-27 22:55:18,051 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 22:55:18,162 __main__ INFO   jobid = 4
2022-10-27 22:55:27,743 TADA INFO assertion 60, Bad config does not affect jobs: jobs verified, passed
2022-10-27 22:55:27,743 __main__ INFO Killin slurm ...
2022-10-27 22:55:30,693 __main__ INFO Killin slurm ... OK
2022-10-27 22:55:50,713 __main__ INFO -- Start daemons --
2022-10-27 22:56:01,566 __main__ INFO Starting slurm ... OK
2022-10-27 22:56:21,810 __main__ INFO -- Submitting job with no stream listener --
2022-10-27 22:56:22,019 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-27 22:56:22,131 __main__ INFO   jobid = 5
2022-10-27 22:56:38,132 TADA INFO assertion 0, Missing stream listener on node-1 does not affect job execution: job output file created, passed
2022-10-27 22:56:38,132 TADA INFO assertion 1, Missing stream listener on node-2 does not affect job execution: job output file created, passed
2022-10-27 22:56:44,007 __main__ INFO -- Submitting job with listener --
2022-10-27 22:56:44,228 __main__ INFO -- Submitting job with num_tasks 1 --
2022-10-27 22:56:44,351 __main__ INFO   jobid = 6
2022-10-27 22:56:44,541 __main__ INFO -- Submitting job with num_tasks 2 --
2022-10-27 22:56:44,650 __main__ INFO   jobid = 7
2022-10-27 22:56:44,854 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 22:56:44,988 __main__ INFO   jobid = 8
2022-10-27 22:56:45,192 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-27 22:56:45,310 __main__ INFO   jobid = 9
2022-10-27 22:56:45,507 __main__ INFO -- Submitting job with num_tasks 27 --
2022-10-27 22:56:45,611 __main__ INFO   jobid = 10
2022-10-27 22:57:07,382 __main__ INFO -- Verifying Events --
2022-10-27 22:57:07,383 TADA INFO assertion 2, 1-task job: first event is 'init': `init` verified, passed
2022-10-27 22:57:07,383 TADA INFO assertion 3, 1-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 22:57:07,383 TADA INFO assertion 4, 1-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 22:57:07,383 TADA INFO assertion 5, 1-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 22:57:07,384 TADA INFO assertion 6, 1-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 22:57:07,384 TADA INFO assertion 7, 2-task job: first event is 'init': `init` verified, passed
2022-10-27 22:57:07,384 TADA INFO assertion 8, 2-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 22:57:07,384 TADA INFO assertion 9, 2-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 22:57:07,384 TADA INFO assertion 10, 2-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 22:57:07,385 TADA INFO assertion 11, 2-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 22:57:07,385 TADA INFO assertion 12, 4-task job: first event is 'init': `init` verified, passed
2022-10-27 22:57:07,385 TADA INFO assertion 13, 4-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 22:57:07,385 TADA INFO assertion 14, 4-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 22:57:07,385 TADA INFO assertion 15, 4-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 22:57:07,386 TADA INFO assertion 16, 4-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 22:57:07,386 TADA INFO assertion 17, 8-task job: first event is 'init': `init` verified, passed
2022-10-27 22:57:07,386 TADA INFO assertion 18, 8-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 22:57:07,386 TADA INFO assertion 19, 8-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 22:57:07,386 TADA INFO assertion 20, 8-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 22:57:07,387 TADA INFO assertion 21, 8-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 22:57:07,387 TADA INFO assertion 25, 27-task job: third event is 'task_exit': Unexpected `task_exit`, failed
Traceback (most recent call last):
  File "spank_notifier_test", line 492, in <module>
    verify_jobinfo(cluster, test, node_events, jobinfo)
  File "spank_notifier_test", line 180, in verify_jobinfo
    test.assert_test(assert_no + 3, False, "Unexpected `task_exit`")
  File "/home/narate/cron/ldms-test/TADA.py", line 157, in assert_test
    raise AssertionException(self.test_desc + ", " + cond_str + ": FAILED")
TADA.AssertionException: The test to verify ldmsd-stream SPANK notifier., Unexpected `task_exit`: FAILED
2022-10-27 22:57:07,388 TADA INFO assertion 22, 27-task job: first event is 'init': skipped
2022-10-27 22:57:07,388 TADA INFO assertion 23, 27-task job: 'step_init' event contains subscriber data: skipped
2022-10-27 22:57:07,389 TADA INFO assertion 24, 27-task job: second event is 'task_init_priv': skipped
2022-10-27 22:57:07,389 TADA INFO assertion 26, 27-task job: fourth event is 'exit': skipped
2022-10-27 22:57:07,389 TADA INFO assertion 50, Multi-tenant verification: skipped
2022-10-27 22:57:07,389 TADA INFO assertion 51, Killing stream listener does not affect job execution on node-1: skipped
2022-10-27 22:57:07,389 TADA INFO assertion 52, Killing stream listener does not affect job execution on node-2: skipped
2022-10-27 22:57:07,389 TADA INFO test spank_notifier_test ended
2022-10-27 22:57:23 INFO: ----------------------------------------------
2022-10-27 22:57:24 INFO: ======== ldms_list_test ========
2022-10-27 22:57:24 INFO: CMD: python3 ldms_list_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldms_list_test
2022-10-27 22:57:25,338 TADA INFO starting test `ldms_list_test`
2022-10-27 22:57:25,338 TADA INFO   test-id: 650a9a14dcd48779ae0a6eb068182bfc18c379ebafa16ed8ba684a340dc29e1f
2022-10-27 22:57:25,338 TADA INFO   test-suite: LDMSD
2022-10-27 22:57:25,338 TADA INFO   test-name: ldms_list_test
2022-10-27 22:57:25,338 TADA INFO   test-user: narate
2022-10-27 22:57:25,338 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:57:25,339 __main__ INFO -- Get or create the cluster --
2022-10-27 22:57:28,370 __main__ INFO -- Start daemons --
2022-10-27 22:57:34,692 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:57:36,693 __main__ INFO start list_samp.py and list_agg.py interactive sessions
2022-10-27 22:57:42,726 TADA INFO assertion 1, check list_sampler on list_agg.py: OK, passed
2022-10-27 22:57:42,726 TADA INFO assertion 2, (1st update) check set1 on list_samp.py: OK, passed
2022-10-27 22:57:42,726 TADA INFO assertion 3, (1st update) check set3_p on list_samp.py: OK, passed
2022-10-27 22:57:42,727 TADA INFO assertion 4, (1st update)check set3_c on list_samp.py: OK, passed
2022-10-27 22:57:42,727 TADA INFO assertion 5, (1st update)check set1 on list_agg.py: OK, passed
2022-10-27 22:57:42,727 TADA INFO assertion 6, (1st update)check set3_p on list_agg.py: OK, passed
2022-10-27 22:57:42,727 TADA INFO assertion 7, (1st update)check set3_c on list_agg.py: OK, passed
2022-10-27 22:57:42,728 __main__ INFO 2nd sampling on the sampler...
2022-10-27 22:57:49,936 TADA INFO assertion 8, (2nd update) check set1 on list_samp.py: OK, passed
2022-10-27 22:57:49,937 TADA INFO assertion 9, (2nd update) check set3_p on list_samp.py: OK, passed
2022-10-27 22:57:49,937 TADA INFO assertion 10, (2nd update) check set3_c on list_samp.py: OK, passed
2022-10-27 22:57:49,937 __main__ INFO 2nd update on the aggregator...
2022-10-27 22:57:57,147 TADA INFO assertion 11, (2nd update) check set1 on list_agg.py: OK, passed
2022-10-27 22:57:57,147 TADA INFO assertion 12, (2nd update) check set3_p on list_agg.py: OK, passed
2022-10-27 22:57:57,147 TADA INFO assertion 13, (2nd update) check set3_c on list_agg.py: OK, passed
2022-10-27 22:57:57,148 __main__ INFO 3rd sampling on the sampler...
2022-10-27 22:58:04,357 TADA INFO assertion 14, (3rd update) check set1 on list_samp.py: OK, passed
2022-10-27 22:58:04,357 TADA INFO assertion 15, (3rd update) check set3_p on list_samp.py: OK, passed
2022-10-27 22:58:04,358 TADA INFO assertion 16, (3rd update) check set3_c on list_samp.py: OK, passed
2022-10-27 22:58:04,358 __main__ INFO 3rd update on the aggregator...
2022-10-27 22:58:11,567 TADA INFO assertion 17, (3rd update) check set1 on list_agg.py: OK, passed
2022-10-27 22:58:11,568 TADA INFO assertion 18, (3rd update) check set3_p on list_agg.py: OK, passed
2022-10-27 22:58:11,568 TADA INFO assertion 19, (3rd update) check set3_c on list_agg.py: OK, passed
2022-10-27 22:58:11,568 __main__ INFO 4th sampling on the sampler...
2022-10-27 22:58:18,777 TADA INFO assertion 20, (4th update; list uncahnged) check set1 on list_samp.py: OK, passed
2022-10-27 22:58:18,778 TADA INFO assertion 21, (4th update; list uncahnged) check set3_p on list_samp.py: OK, passed
2022-10-27 22:58:18,778 TADA INFO assertion 22, (4th update; list uncahnged) check set3_c on list_samp.py: OK, passed
2022-10-27 22:58:18,778 __main__ INFO 4th update on the aggregator...
2022-10-27 22:58:25,987 TADA INFO assertion 23, (4th update; list uncahnged) check set1 on list_agg.py: OK, passed
2022-10-27 22:58:25,987 TADA INFO assertion 24, (4th update; list uncahnged) check set3_p on list_agg.py: OK, passed
2022-10-27 22:58:25,988 TADA INFO assertion 25, (4th update; list uncahnged) check set3_c on list_agg.py: OK, passed
2022-10-27 22:58:25,988 __main__ INFO 5th sampling on the sampler...
2022-10-27 22:58:33,196 TADA INFO assertion 26, (5th update; list del) check set1 on list_samp.py: OK, passed
2022-10-27 22:58:33,197 TADA INFO assertion 27, (5th update; list del) check set3_p on list_samp.py: OK, passed
2022-10-27 22:58:33,197 TADA INFO assertion 28, (5th update; list del) check set3_c on list_samp.py: OK, passed
2022-10-27 22:58:33,197 __main__ INFO 5th update on the aggregator...
2022-10-27 22:58:40,407 TADA INFO assertion 29, (5th update; list del) check set1 on list_agg.py: OK, passed
2022-10-27 22:58:40,407 TADA INFO assertion 30, (5th update; list del) check set3_p on list_agg.py: OK, passed
2022-10-27 22:58:40,407 TADA INFO assertion 31, (5th update; list del) check set3_c on list_agg.py: OK, passed
2022-10-27 22:58:40,407 __main__ INFO 6th sampling on the sampler...
2022-10-27 22:58:47,616 TADA INFO assertion 32, (6th update; list unchanged) check set1 on list_samp.py: OK, passed
2022-10-27 22:58:47,617 TADA INFO assertion 33, (6th update; list unchanged) check set3_p on list_samp.py: OK, passed
2022-10-27 22:58:47,617 TADA INFO assertion 34, (6th update; list unchanged) check set3_c on list_samp.py: OK, passed
2022-10-27 22:58:47,617 __main__ INFO 6th update on the updator...
2022-10-27 22:58:54,826 TADA INFO assertion 35, (6th update; list unchanged) check set1 on list_agg.py: OK, passed
2022-10-27 22:58:54,826 TADA INFO assertion 36, (6th update; list unchanged) check set3_p on list_agg.py: OK, passed
2022-10-27 22:58:54,826 TADA INFO assertion 37, (6th update; list unchanged) check set3_c on list_agg.py: OK, passed
2022-10-27 22:58:54,827 TADA INFO test ldms_list_test ended
2022-10-27 22:59:05 INFO: ----------------------------------------------
2022-10-27 22:59:06 INFO: ======== quick_set_add_rm_test ========
2022-10-27 22:59:06 INFO: CMD: python3 quick_set_add_rm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/quick_set_add_rm_test
2022-10-27 22:59:07,136 TADA INFO starting test `quick_set_add_rm_test`
2022-10-27 22:59:07,137 TADA INFO   test-id: d082b03f589ad11360e8c6620b277a38d08d9ea69c58b72f95026f5a331eda2e
2022-10-27 22:59:07,137 TADA INFO   test-suite: LDMSD
2022-10-27 22:59:07,137 TADA INFO   test-name: quick_set_add_rm_test
2022-10-27 22:59:07,137 TADA INFO   test-user: narate
2022-10-27 22:59:07,137 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 22:59:07,138 __main__ INFO -- Get or create the cluster --
2022-10-27 22:59:14,341 __main__ INFO -- Start samp.py --
2022-10-27 22:59:19,458 TADA INFO assertion 1, start samp.py: prompt checked, passed
2022-10-27 22:59:19,459 __main__ INFO -- Start daemons --
2022-10-27 22:59:27,136 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 22:59:32,728 TADA INFO assertion 2, verify data: verified, passed
2022-10-27 22:59:37,323 TADA INFO assertion 3, samp.py adds set1 / verify data: verified, passed
2022-10-27 22:59:41,915 TADA INFO assertion 4, samp.py removes set1 / verify data: verified, passed
2022-10-27 22:59:46,515 TADA INFO assertion 5, samp.py quickly adds and removes set2 / verify data: verified, passed
2022-10-27 22:59:51,632 TADA INFO assertion 6, agg-1 log stays empty: verified, passed
2022-10-27 22:59:51,632 TADA INFO test quick_set_add_rm_test ended
2022-10-27 23:00:03 INFO: ----------------------------------------------
2022-10-27 23:00:04 INFO: ======== set_array_hang_test ========
2022-10-27 23:00:04 INFO: CMD: python3 set_array_hang_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/set_array_hang_test
2022-10-27 23:00:05,360 TADA INFO starting test `set_array_hang_test`
2022-10-27 23:00:05,360 TADA INFO   test-id: 28c1489ec8887963731186004cc511b46463d8d85c71767a4f91e9ceb02089e4
2022-10-27 23:00:05,360 TADA INFO   test-suite: LDMSD
2022-10-27 23:00:05,360 TADA INFO   test-name: set_array_hang_test
2022-10-27 23:00:05,360 TADA INFO   test-user: narate
2022-10-27 23:00:05,360 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:00:05,361 __main__ INFO -- Get or create the cluster --
2022-10-27 23:00:08,361 __main__ INFO -- Start processes --
2022-10-27 23:00:08,361 __main__ INFO starting interactive set_array_samp.py
2022-10-27 23:00:11,375 TADA INFO assertion 1, start set_array_samp.py: data verified, passed
2022-10-27 23:00:14,392 TADA INFO assertion 2, start set_array_agg.py: data verified, passed
2022-10-27 23:00:21,601 TADA INFO assertion 3, agg update before the 1st sample: data verified, passed
2022-10-27 23:00:28,811 TADA INFO assertion 4, sampling 2 times then agg update: data verified, passed
2022-10-27 23:00:32,416 TADA INFO assertion 5, agg update w/o new sampling: data verified, passed
2022-10-27 23:00:39,626 TADA INFO assertion 6, sampling 5 times then agg update: data verified, passed
2022-10-27 23:00:39,626 TADA INFO test set_array_hang_test ended
2022-10-27 23:00:50 INFO: ----------------------------------------------
2022-10-27 23:00:51 INFO: ======== ldmsd_autointerval_test ========
2022-10-27 23:00:51 INFO: CMD: python3 ldmsd_autointerval_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldmsd_autointerval_test
2022-10-27 23:00:51,828 TADA INFO starting test `ldmsd_autointerval_test`
2022-10-27 23:00:51,828 TADA INFO   test-id: 890a916e9ca055f7065642f3560fb71fbacd32eb1fac2ab0df376117020ff0a4
2022-10-27 23:00:51,828 TADA INFO   test-suite: LDMSD
2022-10-27 23:00:51,828 TADA INFO   test-name: ldmsd_autointerval_test
2022-10-27 23:00:51,828 TADA INFO   test-user: narate
2022-10-27 23:00:51,828 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:00:51,829 __main__ INFO -- Get or create the cluster --
2022-10-27 23:00:59,157 __main__ INFO -- Start daemons --
2022-10-27 23:01:02,903 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 23:01:09,423 TADA INFO assertion 1, start all daemons and interactive controller: OK, passed
2022-10-27 23:01:11,668 TADA INFO assertion 2, verify sampling interval and update hints: verified, passed
2022-10-27 23:01:11,668 __main__ INFO Let them run for a while to collect data ...
2022-10-27 23:01:21,678 __main__ INFO Setting sample interval to 1000000 ...
2022-10-27 23:01:29,931 TADA INFO assertion 3, set and verify 2nd sampling interval / update hints: verified, passed
2022-10-27 23:01:29,931 __main__ INFO Let them run for a while to collect data ...
2022-10-27 23:01:39,941 __main__ INFO Setting sample interval to 2000000 ...
2022-10-27 23:01:48,179 TADA INFO assertion 4, set and verify 3rd sampling interval / update hints: verified, passed
2022-10-27 23:01:48,179 __main__ INFO Let them run for a while to collect data ...
2022-10-27 23:01:58,399 TADA INFO assertion 5, verify SOS data: timestamp differences in SOS show all 3 intervals, passed
2022-10-27 23:01:58,536 TADA INFO assertion 6, verify 'oversampled' in the agg2 log: OK, passed
2022-10-27 23:01:58,537 TADA INFO test ldmsd_autointerval_test ended
2022-10-27 23:02:10 INFO: ----------------------------------------------
2022-10-27 23:02:11 INFO: ======== ldms_record_test ========
2022-10-27 23:02:11 INFO: CMD: python3 ldms_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldms_record_test
2022-10-27 23:02:12,204 TADA INFO starting test `ldms_record_test`
2022-10-27 23:02:12,204 TADA INFO   test-id: 7ca92cc5a0bfc5ebceea17226698c4c1238a71bb85d24bd4675f3daeb54e053e
2022-10-27 23:02:12,204 TADA INFO   test-suite: LDMSD
2022-10-27 23:02:12,204 TADA INFO   test-name: ldms_record_test
2022-10-27 23:02:12,204 TADA INFO   test-user: narate
2022-10-27 23:02:12,204 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:02:12,205 __main__ INFO -- Get or create the cluster --
2022-10-27 23:02:15,269 __main__ INFO -- Start daemons --
2022-10-27 23:02:21,596 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 23:02:23,598 __main__ INFO start record_samp.py and record_agg.py interactive sessions
2022-10-27 23:02:29,634 TADA INFO assertion 1, check record_sampler on record_agg.py: OK, passed
2022-10-27 23:02:29,634 TADA INFO assertion 2, (1st update) check set1 on record_samp.py: OK, passed
2022-10-27 23:02:29,635 TADA INFO assertion 3, (1st update) check set3_p on record_samp.py: OK, passed
2022-10-27 23:02:29,635 TADA INFO assertion 4, (1st update) check set3_c on record_samp.py: OK, passed
2022-10-27 23:02:29,635 TADA INFO assertion 5, (1st update) check set1 on record_agg.py: OK, passed
2022-10-27 23:02:29,635 TADA INFO assertion 6, (1st update) check set3_p on record_agg.py: OK, passed
2022-10-27 23:02:29,636 TADA INFO assertion 7, (1st update) check set3_c on record_agg.py: OK, passed
2022-10-27 23:02:29,636 __main__ INFO 2nd sampling on the sampler...
2022-10-27 23:02:36,845 TADA INFO assertion 8, (2nd update) check set1 on record_samp.py: OK, passed
2022-10-27 23:02:36,845 TADA INFO assertion 9, (2nd update) check set3_p on record_samp.py: OK, passed
2022-10-27 23:02:36,846 TADA INFO assertion 10, (2nd update) check set3_c on record_samp.py: OK, passed
2022-10-27 23:02:36,846 __main__ INFO 2nd update on the aggregator...
2022-10-27 23:02:44,055 TADA INFO assertion 11, (2nd update) check set1 on record_agg.py: OK, passed
2022-10-27 23:02:44,056 TADA INFO assertion 12, (2nd update) check set3_p on record_agg.py: OK, passed
2022-10-27 23:02:44,056 TADA INFO assertion 13, (2nd update) check set3_c on record_agg.py: OK, passed
2022-10-27 23:02:44,056 __main__ INFO 3rd sampling on the sampler...
2022-10-27 23:02:51,266 TADA INFO assertion 14, (3rd update) check set1 on record_samp.py: OK, passed
2022-10-27 23:02:51,266 TADA INFO assertion 15, (3rd update) check set3_p on record_samp.py: OK, passed
2022-10-27 23:02:51,266 TADA INFO assertion 16, (3rd update) check set3_c on record_samp.py: OK, passed
2022-10-27 23:02:51,266 __main__ INFO 3rd update on the aggregator...
2022-10-27 23:02:58,476 TADA INFO assertion 17, (3rd update) check set1 on record_agg.py: OK, passed
2022-10-27 23:02:58,476 TADA INFO assertion 18, (3rd update) check set3_p on record_agg.py: OK, passed
2022-10-27 23:02:58,477 TADA INFO assertion 19, (3rd update) check set3_c on record_agg.py: OK, passed
2022-10-27 23:02:58,477 __main__ INFO 4th sampling on the sampler...
2022-10-27 23:03:05,685 TADA INFO assertion 20, (4th update; record uncahnged) check set1 on record_samp.py: OK, passed
2022-10-27 23:03:05,686 TADA INFO assertion 21, (4th update; record uncahnged) check set3_p on record_samp.py: OK, passed
2022-10-27 23:03:05,686 TADA INFO assertion 22, (4th update; record uncahnged) check set3_c on record_samp.py: OK, passed
2022-10-27 23:03:05,686 __main__ INFO 4th update on the aggregator...
2022-10-27 23:03:12,895 TADA INFO assertion 23, (4th update; record uncahnged) check set1 on record_agg.py: OK, passed
2022-10-27 23:03:12,896 TADA INFO assertion 24, (4th update; record uncahnged) check set3_p on record_agg.py: OK, passed
2022-10-27 23:03:12,896 TADA INFO assertion 25, (4th update; record uncahnged) check set3_c on record_agg.py: OK, passed
2022-10-27 23:03:12,896 __main__ INFO 5th sampling on the sampler...
2022-10-27 23:03:20,105 TADA INFO assertion 26, (5th update; record del) check set1 on record_samp.py: OK, passed
2022-10-27 23:03:20,106 TADA INFO assertion 27, (5th update; record del) check set3_p on record_samp.py: OK, passed
2022-10-27 23:03:20,106 TADA INFO assertion 28, (5th update; record del) check set3_c on record_samp.py: OK, passed
2022-10-27 23:03:20,106 __main__ INFO 5th update on the aggregator...
2022-10-27 23:03:27,315 TADA INFO assertion 29, (5th update; record del) check set1 on record_agg.py: OK, passed
2022-10-27 23:03:27,316 TADA INFO assertion 30, (5th update; record del) check set3_p on record_agg.py: OK, passed
2022-10-27 23:03:27,316 TADA INFO assertion 31, (5th update; record del) check set3_c on record_agg.py: OK, passed
2022-10-27 23:03:27,316 __main__ INFO 6th sampling on the sampler...
2022-10-27 23:03:34,524 TADA INFO assertion 32, (6th update; record unchanged) check set1 on record_samp.py: OK, passed
2022-10-27 23:03:34,525 TADA INFO assertion 33, (6th update; record unchanged) check set3_p on record_samp.py: OK, passed
2022-10-27 23:03:34,525 TADA INFO assertion 34, (6th update; record unchanged) check set3_c on record_samp.py: OK, passed
2022-10-27 23:03:34,525 __main__ INFO 6th update on the updator...
2022-10-27 23:03:41,734 TADA INFO assertion 35, (6th update; record unchanged) check set1 on record_agg.py: OK, passed
2022-10-27 23:03:41,734 TADA INFO assertion 36, (6th update; record unchanged) check set3_p on record_agg.py: OK, passed
2022-10-27 23:03:41,735 TADA INFO assertion 37, (6th update; record unchanged) check set3_c on record_agg.py: OK, passed
2022-10-27 23:03:41,735 TADA INFO test ldms_record_test ended
2022-10-27 23:03:52 INFO: ----------------------------------------------
2022-10-27 23:03:53 INFO: ======== ldms_schema_digest_test ========
2022-10-27 23:03:53 INFO: CMD: python3 ldms_schema_digest_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldms_schema_digest_test
2022-10-27 23:03:53,999 TADA INFO starting test `ldms_schema_digest_test`
2022-10-27 23:03:54,000 TADA INFO   test-id: 04dceaca58d150aebb53e5a1e73de69b2b5e1ec5640ce3795d912bb5b58c1103
2022-10-27 23:03:54,000 TADA INFO   test-suite: LDMSD
2022-10-27 23:03:54,000 TADA INFO   test-name: ldms_schema_digest_test
2022-10-27 23:03:54,000 TADA INFO   test-user: narate
2022-10-27 23:03:54,000 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:03:54,001 __main__ INFO -- Get or create the cluster --
2022-10-27 23:04:01,298 __main__ INFO -- Start daemons --
2022-10-27 23:04:04,468 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 23:04:09,600 TADA INFO assertion 1, No schema digest from ldms_ls -v sampler: verified, passed
2022-10-27 23:04:09,703 TADA INFO assertion 2, Schema digest from ldms_ls -vv sampler is not empty: verified, passed
2022-10-27 23:04:09,806 TADA INFO assertion 3, Schema digest from ldms_ls -vv agg-1 is not empty: verified, passed
2022-10-27 23:04:09,982 TADA INFO assertion 4, Schema digest from Python ldms dir agg-1 is not empty: verified, passed
2022-10-27 23:04:09,982 TADA INFO assertion 5, Schema digest from Python ldms lokoup agg-1 is not empty: verified, passed
2022-10-27 23:04:09,983 TADA INFO assertion 6, All digests of the same set are the same: , passed
2022-10-27 23:04:12,430 TADA INFO assertion 7, Sets of same schema yield the same digest: check, passed
2022-10-27 23:04:12,431 TADA INFO assertion 8, Different schema (1-off metric) yield different digest: check, passed
2022-10-27 23:04:12,431 TADA INFO test ldms_schema_digest_test ended
2022-10-27 23:04:24 INFO: ----------------------------------------------
2022-10-27 23:04:25 INFO: ======== ldmsd_decomp_test ========
2022-10-27 23:04:25 INFO: CMD: python3 ldmsd_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldmsd_decomp_test
2022-10-27 23:04:26,163 TADA INFO starting test `ldmsd_decomp_test`
2022-10-27 23:04:26,163 TADA INFO   test-id: 24d60f31cb6cc9fd50ae83107f5496b7e984b438a4f6984ee998ea47bb5e1655
2022-10-27 23:04:26,163 TADA INFO   test-suite: LDMSD
2022-10-27 23:04:26,164 TADA INFO   test-name: ldmsd_decomp_test
2022-10-27 23:04:26,164 TADA INFO   test-user: narate
2022-10-27 23:04:26,164 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:04:26,164 __main__ INFO -- Get or create the cluster --
2022-10-27 23:04:41,770 __main__ INFO -- Start daemons --
2022-10-27 23:04:52,094 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 23:05:46,779 TADA INFO assertion 1, `as_is` decomposition, test_sampler_8d2b8bd sos schema check: OK, passed
2022-10-27 23:05:46,779 TADA INFO assertion 2, `as_is` decomposition, test_sampler_95772b6 sos schema check: OK, passed
2022-10-27 23:05:46,779 TADA INFO assertion 3, `as_is` decomposition, record_sampler_e1f021f sos schema check: OK, passed
2022-10-27 23:05:46,780 TADA INFO assertion 4, `static` decomposition, fill sos schema check: OK, passed
2022-10-27 23:05:46,780 TADA INFO assertion 5, `static` decomposition, filter sos schema check: OK, passed
2022-10-27 23:05:46,780 TADA INFO assertion 6, `static` decomposition, record sos schema check: OK, passed
2022-10-27 23:05:46,780 TADA INFO assertion 7, `as_is` decomposition, test_sampler_8d2b8bd csv schema check: OK, passed
2022-10-27 23:05:46,780 TADA INFO assertion 8, `as_is` decomposition, test_sampler_95772b6 csv schema check: OK, passed
2022-10-27 23:05:46,780 TADA INFO assertion 9, `as_is` decomposition, record_sampler_e1f021f csv schema check: OK, passed
2022-10-27 23:05:46,781 TADA INFO assertion 10, `static` decomposition, fill csv schema check: OK, passed
2022-10-27 23:05:46,781 TADA INFO assertion 11, `static` decomposition, filter csv schema check: OK, passed
2022-10-27 23:05:46,781 TADA INFO assertion 12, `static` decomposition, record csv schema check: OK, passed
2022-10-27 23:05:46,781 TADA INFO assertion 13, `as_is` decomposition, test_sampler_8d2b8bd kafka schema check: OK, passed
2022-10-27 23:05:46,781 TADA INFO assertion 14, `as_is` decomposition, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-27 23:05:46,781 TADA INFO assertion 15, `as_is` decomposition, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-27 23:05:46,782 TADA INFO assertion 16, `static` decomposition, fill kafka schema check: OK, passed
2022-10-27 23:05:46,782 TADA INFO assertion 17, `static` decomposition, filter kafka schema check: OK, passed
2022-10-27 23:05:46,782 TADA INFO assertion 18, `static` decomposition, record kafka schema check: OK, passed
2022-10-27 23:05:46,783 TADA INFO assertion 19, `as_is` decomposition, test_sampler_8d2b8bd sos data check: OK, passed
2022-10-27 23:05:46,785 TADA INFO assertion 20, `as_is` decomposition, test_sampler_95772b6 sos data check: OK, passed
2022-10-27 23:05:46,854 TADA INFO assertion 21, `as_is` decomposition, record_sampler_e1f021f sos data check: OK, passed
2022-10-27 23:05:46,858 TADA INFO assertion 22, `static` decomposition, fill sos data check: OK, passed
2022-10-27 23:05:46,861 TADA INFO assertion 23, `static` decomposition, filter sos data check: OK, passed
2022-10-27 23:05:46,868 TADA INFO assertion 24, `static` decomposition, record sos data check: OK, passed
2022-10-27 23:05:46,870 TADA INFO assertion 25, `as_is` decomposition, test_sampler_8d2b8bd csv data check: OK, passed
2022-10-27 23:05:46,871 TADA INFO assertion 26, `as_is` decomposition, test_sampler_95772b6 csv data check: OK, passed
2022-10-27 23:05:46,942 TADA INFO assertion 27, `as_is` decomposition, record_sampler_e1f021f csv data check: OK, passed
2022-10-27 23:05:46,946 TADA INFO assertion 28, `static` decomposition, fill csv data check: OK, passed
2022-10-27 23:05:46,949 TADA INFO assertion 29, `static` decomposition, filter csv data check: OK, passed
2022-10-27 23:05:46,958 TADA INFO assertion 30, `static` decomposition, record csv data check: OK, passed
2022-10-27 23:05:46,959 TADA INFO assertion 31, `as_is` decomposition, test_sampler_8d2b8bd kafka data check: OK, passed
2022-10-27 23:05:46,959 TADA INFO assertion 32, `as_is` decomposition, test_sampler_95772b6 kafka data check: OK, passed
2022-10-27 23:05:46,989 TADA INFO assertion 33, `as_is` decomposition, record_sampler_e1f021f kafka data check: OK, passed
2022-10-27 23:05:46,991 TADA INFO assertion 34, `static` decomposition, fill kafka data check: OK, passed
2022-10-27 23:05:46,992 TADA INFO assertion 35, `static` decomposition, filter kafka data check: OK, passed
2022-10-27 23:05:46,997 TADA INFO assertion 36, `static` decomposition, record kafka data check: OK, passed
2022-10-27 23:05:46,997 TADA INFO test ldmsd_decomp_test ended
2022-10-27 23:05:46,998 TADA INFO test ldmsd_decomp_test ended
2022-10-27 23:06:02 INFO: ----------------------------------------------
2022-10-27 23:06:03 INFO: ======== ldmsd_stream_dir_test ========
2022-10-27 23:06:03 INFO: CMD: python3 ldmsd_stream_dir_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldmsd_stream_dir_test
2022-10-27 23:06:03,840 __main__ INFO -- Get or create the cluster --
2022-10-27 23:06:03,840 TADA INFO starting test `ldmsd_stream_dir`
2022-10-27 23:06:03,840 TADA INFO   test-id: 3f0428826f1cb23128b158d8028295eb33f5a222b211c2c9bee743cea5f3dfce
2022-10-27 23:06:03,841 TADA INFO   test-suite: LDMSD
2022-10-27 23:06:03,841 TADA INFO   test-name: ldmsd_stream_dir
2022-10-27 23:06:03,841 TADA INFO   test-user: narate
2022-10-27 23:06:03,841 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:06:12,341 __main__ INFO -- Start daemons --
2022-10-27 23:06:16,145 __main__ INFO waiting ... for all LDMSDs to start
2022-10-27 23:06:16,472 __main__ INFO All LDMSDs are up.
2022-10-27 23:06:17,697 TADA INFO assertion 1, No Stream data: {} == {}, passed
2022-10-27 23:06:19,021 TADA INFO assertion 2, stream_dir -- one stream message: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666929977, 'last_ts': 1666929977, 'count': 1, 'total_bytes': 6}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666929977, 'last_ts': 1666929977, 'count': 1, 'total_bytes': 6}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1666929977, 'last_ts': 1666929977}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1666929977, 'last_ts': 1666929977}}}, passed
2022-10-27 23:06:21,448 TADA INFO assertion 3, stream_dir --  multiple stream messages: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666929977, 'last_ts': 1666929980, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666929977, 'last_ts': 1666929980, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666929977, 'last_ts': 1666929980, 'bytes/sec': 6.0, 'msg/sec': 1.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666929977, 'last_ts': 1666929980, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, passed
2022-10-27 23:06:22,678 TADA INFO assertion 4, prdcr_stream_dir to agg -- one producer: {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666929980, 'first_ts': 1666929977, 'bytes/sec': 6.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666929980, 'first_ts': 1666929977, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666929977, 'last_ts': 1666929980, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666929977, 'last_ts': 1666929980, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}}, passed
2022-10-27 23:06:26,455 TADA INFO assertion 5, stream_dir -- mulitple streams: {'bar': {'mode': 'not subscribed', 'info': {'first_ts': 1666929984, 'last_ts': 1666929985, 'count': 3, 'total_bytes': 48, 'msg/sec': 3.0, 'bytes/sec': 48.0}, 'publishers': {}}, 'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666929982, 'last_ts': 1666929983, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666929982, 'last_ts': 1666929985, 'count': 5, 'total_bytes': 60, 'msg/sec': 1.666667, 'bytes/sec': 20.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666929982, 'last_ts': 1666929983, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {}}, 'bar': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1666929984, 'last_ts': 1666929985, 'bytes/sec': 48.0, 'msg/sec': 3.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1666929982, 'last_ts': 1666929985, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}, passed
2022-10-27 23:06:27,707 TADA INFO assertion 6, prdcr_stream_dir to agg -- two producers: {'foo': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 2.0, 'total_bytes': 12, 'last_ts': 1666929983, 'first_ts': 1666929982, 'bytes/sec': 12.0, 'count': 2}}, 'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666929980, 'first_ts': 1666929977, 'bytes/sec': 6.0, 'count': 3}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 3.0, 'total_bytes': 48, 'last_ts': 1666929985, 'first_ts': 1666929984, 'bytes/sec': 48.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-2': {'info': {'msg/sec': 1.666667, 'total_bytes': 60, 'last_ts': 1666929985, 'first_ts': 1666929982, 'bytes/sec': 20.0, 'count': 5}}, 'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666929980, 'first_ts': 1666929977, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666929977, 'last_ts': 1666929980, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666929982, 'last_ts': 1666929983, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1666929984, 'last_ts': 1666929985, 'bytes/sec': 48.0, 'msg/sec': 3.0}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666929977, 'last_ts': 1666929980, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1666929982, 'last_ts': 1666929985, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}}, passed
2022-10-27 23:06:31,366 TADA INFO assertion 7, stream_dir to agg after one producer republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666929989, 'last_ts': 1666929990, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1666929989, 'last_ts': 1666929990, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}}}, '_AGGREGATED_': {'info': {'first_ts': 1666929989, 'last_ts': 1666929990, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666929989, 'last_ts': 1666929990, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666929989, 'last_ts': 1666929990, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}}, '_AGGREGATED_': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666929989, 'last_ts': 1666929990, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, passed
2022-10-27 23:06:32,922 TADA INFO assertion 8, stream_dir to agg after two producers republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666929989, 'last_ts': 1666929991, 'count': 5, 'total_bytes': 30, 'msg/sec': 2.5, 'bytes/sec': 15.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1666929989, 'last_ts': 1666929990, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}, 'samplerd-2': {'info': {'first_ts': 1666929991, 'last_ts': 1666929991, 'count': 3, 'total_bytes': 18}}}}, '_AGGREGATED_': {'info': {'first_ts': 1666929989, 'last_ts': 1666929991, 'count': 5, 'total_bytes': 30, 'msg/sec': 2.5, 'bytes/sec': 15.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1666929989, 'last_ts': 1666929991, 'bytes/sec': 15.0, 'msg/sec': 2.5}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666929989, 'last_ts': 1666929990, 'bytes/sec': 12.0, 'msg/sec': 2.0}}, 'samplerd-2': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666929991, 'last_ts': 1666929991}}}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1666929989, 'last_ts': 1666929991, 'bytes/sec': 15.0, 'msg/sec': 2.5}}}, passed
2022-10-27 23:06:32,922 TADA INFO test ldmsd_stream_dir ended
2022-10-27 23:06:44 INFO: ----------------------------------------------
2022-10-27 23:06:45 INFO: ======== store_list_record_test ========
2022-10-27 23:06:45 INFO: CMD: python3 store_list_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/store_list_record_test
2022-10-27 23:06:46,473 __main__ INFO -- Get or create the cluster --
2022-10-27 23:06:46,474 TADA INFO starting test `store_sos_lists_test`
2022-10-27 23:06:46,474 TADA INFO   test-id: 4b4da2be79525ce7ec7a9cd5cacf151c3a023e460d484a23e791948de4a6ec03
2022-10-27 23:06:46,474 TADA INFO   test-suite: LDMSD
2022-10-27 23:06:46,474 TADA INFO   test-name: store_sos_lists_test
2022-10-27 23:06:46,474 TADA INFO   test-user: narate
2022-10-27 23:06:46,474 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:06:53,671 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:06:57,478 __main__ INFO All sampler daemons are up.
2022-10-27 23:06:57,583 TADA INFO assertion 1, aggregator with store_sos has started properly.: agg_sos.check_ldmsd(), passed
2022-10-27 23:06:57,684 TADA INFO assertion 2, aggregator with store_csv has started properly.: agg_csv.check_ldmsd(), passed
2022-10-27 23:07:05,752 TADA INFO assertion 3, store_sos is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-27 23:07:09,037 TADA INFO assertion 4, store_sos stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-27 23:07:17,943 TADA INFO assertion 5, store_sos stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-27 23:07:19,344 TADA INFO assertion 6, store_csv is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-27 23:07:30,373 TADA INFO assertion 7, store_csv stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-27 23:07:39,932 TADA INFO assertion 8, store_csv stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-27 23:07:39,933 TADA INFO test store_sos_lists_test ended
2022-10-27 23:07:53 INFO: ----------------------------------------------
2022-10-27 23:07:53 INFO: ======== maestro_raft_test ========
2022-10-27 23:07:53 INFO: CMD: python3 maestro_raft_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/maestro_raft_test
2022-10-27 23:07:54,605 TADA INFO starting test `maestro_raft_test`
2022-10-27 23:07:54,605 TADA INFO   test-id: d0caa921fa47acfc12b4d2ac30555ab5987b67eba9526735e0aa8dedd22e548a
2022-10-27 23:07:54,605 TADA INFO   test-suite: LDMSD
2022-10-27 23:07:54,605 TADA INFO   test-name: maestro_raft_test
2022-10-27 23:07:54,605 TADA INFO   test-user: narate
2022-10-27 23:07:54,605 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:08:04,617 __main__ INFO -- Get or create cluster --
2022-10-27 23:08:38,887 __main__ INFO -- Start daemons --
2022-10-27 23:09:50,038 __main__ INFO -- making known hosts (ssh) --
2022-10-27 23:09:57,018 __main__ INFO ... make sure ldmsd's are up
2022-10-27 23:10:12,792 TADA INFO assertion 1, Statuses of maestros, 1 leader + 2 followers: [('FOLLOWER', 2), ('LEADER', 1)], passed
2022-10-27 23:10:25,188 TADA INFO assertion 2, All ldmsds are up and configured: sets verified, passed
2022-10-27 23:10:25,467 TADA INFO assertion 3, Data are being stored: data check, passed
2022-10-27 23:10:30,343 TADA INFO assertion 4, New leader elected: checked, passed
2022-10-27 23:10:42,191 TADA INFO assertion 5, Restarted ldmsd is configured: sets verified, passed
2022-10-27 23:10:42,463 TADA INFO assertion 6, New data are presented in the store: data check, passed
2022-10-27 23:10:53,479 TADA INFO assertion 7, The restarted maestro becomes a follower: checked, passed
---Wait for config to write to file---
2022-10-27 23:10:53,479 TADA INFO test maestro_raft_test ended
2022-10-27 23:11:14 INFO: ----------------------------------------------
2022-10-27 23:11:15 INFO: ======== ovis_json_test ========
2022-10-27 23:11:15 INFO: CMD: python3 ovis_json_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ovis_json_test
2022-10-27 23:11:16,401 __main__ INFO -- Create the cluster -- 
2022-10-27 23:11:21,637 TADA INFO starting test `ovis_json_test`
2022-10-27 23:11:21,637 TADA INFO   test-id: f2241084828930b2df0d51b66286e8576bafde4135c69851965af1d2b261dc79
2022-10-27 23:11:21,637 TADA INFO   test-suite: OVIS-LIB
2022-10-27 23:11:21,637 TADA INFO   test-name: ovis_json_test
2022-10-27 23:11:21,637 TADA INFO   test-user: narate
2022-10-27 23:11:21,637 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:11:21,638 TADA INFO assertion 1, Test creating a JSON integer entity: (type is JSON_INT_VALUE) && (1 == e->value.int_), passed
2022-10-27 23:11:21,638 TADA INFO assertion 2, Test creating a JSON boolean entity: (type is JSON_BOOL_VALUE) && (1 == e->value.bool_), passed
2022-10-27 23:11:21,638 TADA INFO assertion 3, Test creating a JSON float entity: (type is JSON_FLOAT_VALUE) && (1.1 == e->value.double_), passed
2022-10-27 23:11:21,638 TADA INFO assertion 4, Test creating a JSON string entity: (type is JSON_STRING_VALUE) && (foo == e->value.str_->str), passed
2022-10-27 23:11:21,639 TADA INFO assertion 5, Test creating a JSON attribute entity: (type is JSON_ATTR_VALUE) && (name == <attr name>) && (value == <attr value>), passed
2022-10-27 23:11:21,639 TADA INFO assertion 6, Test creating a JSON list entity: (type is JSON_LIST_VALUE) && (0 == Number of elements) && (list is empty), passed
2022-10-27 23:11:21,639 TADA INFO assertion 7, Test creating a JSON dictionary entity: (type is JSON_DICT_VALUE) && (dict table is empty), passed
2022-10-27 23:11:21,639 TADA INFO assertion 8, Test creating a JSON null entity: (type is JSON_NULL_VALUE) && (0 == e->value.int_), passed
2022-10-27 23:11:21,639 TADA INFO assertion 9, Test parsing a JSON integer string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 23:11:21,639 TADA INFO assertion 10, Test parsing a JSON false boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 23:11:21,640 TADA INFO assertion 11, Test parsing a JSON true boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 23:11:21,640 TADA INFO assertion 12, Test parsing a JSON float string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 23:11:21,640 TADA INFO assertion 13, Test parsing a JSON string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 23:11:21,640 TADA INFO assertion 15, Test parsing a JSON dict string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 23:11:21,640 TADA INFO assertion 16, Test parsing a JSON null string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 23:11:21,640 TADA INFO assertion 17, Test parsing an invalid string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 23:11:21,640 TADA INFO assertion 17, Test parsing an invalid string: 0 != json_parse_buffer(), passed
2022-10-27 23:11:21,641 TADA INFO assertion 18, Test dumping a JSON integer entity: 1 == 1, passed
2022-10-27 23:11:21,641 TADA INFO assertion 19, Test dumping a JSON false boolean entity: false == false, passed
2022-10-27 23:11:21,641 TADA INFO assertion 20, Test dumping a JSON true boolean entity: true == true, passed
2022-10-27 23:11:21,641 TADA INFO assertion 21, Test dumping a JSON float entity: 1.100000 == 1.100000, passed
2022-10-27 23:11:21,641 TADA INFO assertion 22, Test dumping a JSON string entity: "foo" == "foo", passed
2022-10-27 23:11:21,641 TADA INFO assertion 23, Test dumping a JSON attr entity: "name":"foo" == jb->buf, passed
2022-10-27 23:11:21,642 TADA INFO assertion 24, Test dumping a JSON list entity: [1,false,1.100000,"foo",[],{},null] == [1,false,1.100000,"foo",[],{},null], passed
2022-10-27 23:11:21,642 TADA INFO assertion 25, Test dumping a JSON dict entity: {"int":1,"bool":true,"float":1.100000,"string":"foo","list":[1,false,1.100000,"foo",[],{},null],"dict":{"attr_1":"value_1"},"null":null} == {"null":null,"list":[1,false,1.100000,"foo",[],{},null],"string":"foo","float":1.100000,"bool":true,"dict":{"attr_1":"value_1"},"int":1}, passed
2022-10-27 23:11:21,642 TADA INFO assertion 26, Test dumping a JSON null entity: null == null, passed
2022-10-27 23:11:21,642 TADA INFO assertion 27, Test dumping a JSON entity to a non-empty jbuf: This is a book."FOO" == This is a book."FOO", passed
2022-10-27 23:11:21,642 TADA INFO assertion 28, Test copying a JSON integer entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,642 TADA INFO assertion 29, Test copying a JSON false boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,642 TADA INFO assertion 30, Test copying a JSON true boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,643 TADA INFO assertion 31, Test copying a JSON float entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,643 TADA INFO assertion 32, Test copying a JSON string entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,643 TADA INFO assertion 33, Test copying a JSON attribute entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,643 TADA INFO assertion 34, Test copying a JSON list entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,643 TADA INFO assertion 35, Test copying a JSON dict entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,643 TADA INFO assertion 36, Test copying a JSON null entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 23:11:21,644 TADA INFO assertion 37, Test obtaining the number of attributes: 7 == json_attr_count(dict), passed
2022-10-27 23:11:21,644 TADA INFO assertion 38, Test finding an existing attribute: 0 != json_attr_find(), passed
2022-10-27 23:11:21,644 TADA INFO assertion 39, Test finding a non-existng attribute: 0 == json_attr_find(), passed
2022-10-27 23:11:21,644 TADA INFO assertion 40, Test finding the value of an existing attribute: 0 != json_value_find(), passed
2022-10-27 23:11:21,644 TADA INFO assertion 41, Test finding the value of a non-existing attribute: 0 == json_value_find(), passed
2022-10-27 23:11:21,644 TADA INFO assertion 42, Test adding a new attribute to a dictionary: (0 == json_attr_add() && (0 != json_attr_find()), passed
2022-10-27 23:11:21,645 TADA INFO assertion 43, Test replacing the value of an existing attribute: (0 == json_attr_add()) && (0 != json_value_find()) && (is_same_entity(old_v, new_v)), passed
2022-10-27 23:11:21,645 TADA INFO assertion 44, Test removing an existing attribute: (0 = json_attr_rem()) && (0 == json_attr_find()), passed
2022-10-27 23:11:21,645 TADA INFO assertion 45, Test removing a non-existing attribute: (ENOENT == json_attr_rem()), passed
2022-10-27 23:11:21,645 TADA INFO assertion 46, Test creating a dictionary by json_dict_build: expected == json_dict_build(...), passed
2022-10-27 23:11:21,645 TADA INFO assertion 47, Test adding attributes and replacing attribute values by json_dict_build: expected == json_dict_build(d, ...), passed
2022-10-27 23:11:21,645 TADA INFO assertion 48, Test json_dict_merge(): The merged dictionary is correct., passed
2022-10-27 23:11:21,646 TADA INFO assertion 49, Test json_list_len(): 7 == json_list_len(), passed
2022-10-27 23:11:21,646 TADA INFO assertion 50, Test adding items to a list: 0 == strcmp(exp_str, json_entity_dump(l)->buf, passed
2022-10-27 23:11:21,646 TADA INFO assertion 51, Test removing an existing item by json_item_rem(): 0 == json_item_rem(), passed
2022-10-27 23:11:21,646 TADA INFO assertion 52, Test removing a non-existing item by json_item_rem(): ENOENT == json_item_rem(), passed
2022-10-27 23:11:21,646 TADA INFO assertion 53, Test popping an existing item from a list by json_item_pop(): NULL == json_item_pop(len + 3), passed
2022-10-27 23:11:21,646 TADA INFO assertion 54, Test popping a non-existing item from a list by json_item_pop(): NULL != json_item_pop(len - 1), passed
2022-10-27 23:11:21,646 TADA INFO test ovis_json_test ended
2022-10-27 23:11:32 INFO: ----------------------------------------------
2022-10-27 23:11:33 INFO: ======== updtr_add_test ========
2022-10-27 23:11:33 INFO: CMD: python3 updtr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/updtr_add_test
2022-10-27 23:11:33,979 __main__ INFO -- Get or create the cluster --
2022-10-27 23:11:33,979 TADA INFO starting test `updtr_add test`
2022-10-27 23:11:33,979 TADA INFO   test-id: 6bce4e4640a30d4f6c59eefee82811535649de5c58ba230c16cabeeb89c9636d
2022-10-27 23:11:33,980 TADA INFO   test-suite: LDMSD
2022-10-27 23:11:33,980 TADA INFO   test-name: updtr_add test
2022-10-27 23:11:33,980 TADA INFO   test-user: narate
2022-10-27 23:11:33,980 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:11:41,967 __main__ INFO -- Start daemons --
2022-10-27 23:11:45,560 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:11:45,865 __main__ INFO All LDMSDs are up.
2022-10-27 23:11:47,080 TADA INFO assertion 1, Add an updater with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:11:48,307 TADA INFO assertion 2, Add an updater with a zero interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:11:49,532 TADA INFO assertion 3, Add an updater with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:11:50,752 TADA INFO assertion 4, Add an updater with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-27 23:11:51,962 TADA INFO assertion 5, Add an updater with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:11:54,386 TADA INFO assertion 6, Add an updater without an offset: report(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 23:11:56,826 TADA INFO assertion 7, Add an updater with a valid offset: report(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 23:11:58,045 TADA INFO assertion 8, Add an updater with an existing name: report(rc = 17) == expect(rc = 17), passed
2022-10-27 23:11:58,045 __main__ INFO --- done ---
2022-10-27 23:11:58,045 TADA INFO test updtr_add test ended
2022-10-27 23:12:10 INFO: ----------------------------------------------
2022-10-27 23:12:11 INFO: ======== updtr_del_test ========
2022-10-27 23:12:11 INFO: CMD: python3 updtr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/updtr_del_test
2022-10-27 23:12:11,717 __main__ INFO -- Get or create the cluster --
2022-10-27 23:12:11,717 TADA INFO starting test `updtr_add test`
2022-10-27 23:12:11,718 TADA INFO   test-id: 10308d723e0f94f9f3b81320ef78d22d96ba000eae3c4cb8780ed02b634b5103
2022-10-27 23:12:11,718 TADA INFO   test-suite: LDMSD
2022-10-27 23:12:11,718 TADA INFO   test-name: updtr_add test
2022-10-27 23:12:11,718 TADA INFO   test-user: narate
2022-10-27 23:12:11,718 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:12:19,559 __main__ INFO -- Start daemons --
2022-10-27 23:12:23,205 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:12:23,524 __main__ INFO All LDMSDs are up.
2022-10-27 23:12:24,728 TADA INFO assertion 1, updtr_del a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 23:12:25,954 TADA INFO assertion 2, updtr_del a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 23:12:27,167 TADA INFO assertion 3, updtr_del a stopped updater: report(rc = 0) == expect(rc = 0), passed
2022-10-27 23:12:28,371 TADA INFO assertion 4, updtr_del a just-added updater: report(rc = 0) == expect(rc = 0), passed
2022-10-27 23:12:28,371 __main__ INFO --- done ---
2022-10-27 23:12:28,371 TADA INFO test updtr_add test ended
2022-10-27 23:12:40 INFO: ----------------------------------------------
2022-10-27 23:12:41 INFO: ======== updtr_match_add_test ========
2022-10-27 23:12:41 INFO: CMD: python3 updtr_match_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/updtr_match_add_test
2022-10-27 23:12:42,088 __main__ INFO -- Get or create the cluster --
2022-10-27 23:12:42,088 TADA INFO starting test `updtr_add test`
2022-10-27 23:12:42,088 TADA INFO   test-id: 025f544437786d8a905b7f8f110f448e4dd131dd12289fd8bb641ff30a8e8826
2022-10-27 23:12:42,088 TADA INFO   test-suite: LDMSD
2022-10-27 23:12:42,088 TADA INFO   test-name: updtr_add test
2022-10-27 23:12:42,088 TADA INFO   test-user: narate
2022-10-27 23:12:42,088 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:12:49,827 __main__ INFO -- Start daemons --
2022-10-27 23:12:53,566 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:12:53,886 __main__ INFO All LDMSDs are up.
2022-10-27 23:12:55,092 TADA INFO assertion 1, updtr_match_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:12:56,305 TADA INFO assertion 2, updtr_match_add with an invalid match: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:12:57,507 TADA INFO assertion 3, updtr_match_add of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 23:12:58,723 TADA INFO assertion 4, A success updtr_match_add: report(rc = 0) == expect(rc = 0), passed
2022-10-27 23:12:59,931 TADA INFO assertion 5, updtr_match_add of a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 23:12:59,931 __main__ INFO --- done ---
2022-10-27 23:12:59,932 TADA INFO test updtr_add test ended
2022-10-27 23:13:12 INFO: ----------------------------------------------
2022-10-27 23:13:12 INFO: ======== updtr_match_del_test ========
2022-10-27 23:13:12 INFO: CMD: python3 updtr_match_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/updtr_match_del_test
2022-10-27 23:13:13,657 __main__ INFO -- Get or create the cluster --
2022-10-27 23:13:13,658 TADA INFO starting test `updtr_add test`
2022-10-27 23:13:13,658 TADA INFO   test-id: cead4eca4657e9de32de29d9a4a614017dc35a5611af0ecbc9de0835c93255b0
2022-10-27 23:13:13,658 TADA INFO   test-suite: LDMSD
2022-10-27 23:13:13,658 TADA INFO   test-name: updtr_add test
2022-10-27 23:13:13,658 TADA INFO   test-user: narate
2022-10-27 23:13:13,658 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:13:21,343 __main__ INFO -- Start daemons --
2022-10-27 23:13:25,002 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:13:25,322 __main__ INFO All LDMSDs are up.
2022-10-27 23:13:26,535 TADA INFO assertion 1, Send updtr_match_del with an invalid regex: report(rc = 2) == expect(rc = 22), passed
2022-10-27 23:13:27,741 TADA INFO assertion 2, Send updtr_match_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 23:13:28,950 TADA INFO assertion 3, Send updtr_match_del with a non-existing inst match: report(rc = 2) == expect(rc = 2), passed
2022-10-27 23:13:30,171 TADA INFO assertion 4, Send updtr_match_del with a non-existing schema match: report(rc = 2) == expect(rc = 2), passed
2022-10-27 23:13:31,376 TADA INFO assertion 5, Send updater_match_del with an invalid match type: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:13:32,580 TADA INFO assertion 6, Send updater_match_del with a valid regex of the inst type: report(rc = 0) == expect(rc = 0), passed
2022-10-27 23:13:33,796 TADA INFO assertion 7, Send updater_match_del with a valid regex of the schema type: report(rc = 0) == expect(rc = 0), passed
2022-10-27 23:13:33,796 __main__ INFO --- done ---
2022-10-27 23:13:33,797 TADA INFO test updtr_add test ended
2022-10-27 23:13:45 INFO: ----------------------------------------------
2022-10-27 23:13:46 INFO: ======== updtr_prdcr_add_test ========
2022-10-27 23:13:46 INFO: CMD: python3 updtr_prdcr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/updtr_prdcr_add_test
2022-10-27 23:13:47,498 __main__ INFO -- Get or create the cluster --
2022-10-27 23:13:47,499 TADA INFO starting test `updtr_add test`
2022-10-27 23:13:47,499 TADA INFO   test-id: 30697ed0a5ec47259da368b01c96c522593aba3dcdb21361cb00de82d79a20f8
2022-10-27 23:13:47,499 TADA INFO   test-suite: LDMSD
2022-10-27 23:13:47,499 TADA INFO   test-name: updtr_add test
2022-10-27 23:13:47,499 TADA INFO   test-user: narate
2022-10-27 23:13:47,499 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:13:55,306 __main__ INFO -- Start daemons --
2022-10-27 23:13:58,985 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:13:59,305 __main__ INFO All LDMSDs are up.
2022-10-27 23:14:00,524 TADA INFO assertion 1, Send updtr_prdcr_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:14:02,977 TADA INFO assertion 2, Send updtr_prdcr_add with a regex matching no prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 23:14:05,403 TADA INFO assertion 3, Send updtr_prdcdr_add with a regex matching some prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 23:14:06,608 TADA INFO assertion 4, Send updtr_prdcdr_add to a running updtr: report(rc = 16) == expect(rc = 16), passed
2022-10-27 23:14:07,820 TADA INFO assertion 5, Send updtr_prdcr_add to a not-existing updtr: report(rc = 2) == expect(rc = 2), passed
2022-10-27 23:14:07,820 __main__ INFO --- done ---
2022-10-27 23:14:07,820 TADA INFO test updtr_add test ended
2022-10-27 23:14:20 INFO: ----------------------------------------------
2022-10-27 23:14:20 INFO: ======== updtr_prdcr_del_test ========
2022-10-27 23:14:20 INFO: CMD: python3 updtr_prdcr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/updtr_prdcr_del_test
2022-10-27 23:14:21,623 __main__ INFO -- Get or create the cluster --
2022-10-27 23:14:21,623 TADA INFO starting test `updtr_add test`
2022-10-27 23:14:21,624 TADA INFO   test-id: f33f50b10ae6331acf0282c796a7373ee4b870bcd10d572534db4acfe6a12b0d
2022-10-27 23:14:21,624 TADA INFO   test-suite: LDMSD
2022-10-27 23:14:21,624 TADA INFO   test-name: updtr_add test
2022-10-27 23:14:21,624 TADA INFO   test-user: narate
2022-10-27 23:14:21,624 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:14:29,468 __main__ INFO -- Start daemons --
2022-10-27 23:14:33,114 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:14:33,440 __main__ INFO All LDMSDs are up.
2022-10-27 23:14:34,664 TADA INFO assertion 1, Send updtr_prdcr_del with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:14:35,882 TADA INFO assertion 2, Send updtr_prdcr_del to a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 23:14:37,105 TADA INFO assertion 3, Send updtr_prdcr_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 23:14:39,541 TADA INFO assertion 4, Send updtr_prdcr_del successfully: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}], passed
2022-10-27 23:14:39,542 __main__ INFO --- done ---
2022-10-27 23:14:39,542 TADA INFO test updtr_add test ended
2022-10-27 23:14:51 INFO: ----------------------------------------------
2022-10-27 23:14:52 INFO: ======== updtr_start_test ========
2022-10-27 23:14:52 INFO: CMD: python3 updtr_start_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/updtr_start_test
2022-10-27 23:14:53,273 __main__ INFO -- Get or create the cluster --
2022-10-27 23:14:53,273 TADA INFO starting test `updtr_add test`
2022-10-27 23:14:53,273 TADA INFO   test-id: a91af4f397ae612862a71a9a0c610ee509a3d29e2ace692c943854295254bfbc
2022-10-27 23:14:53,273 TADA INFO   test-suite: LDMSD
2022-10-27 23:14:53,273 TADA INFO   test-name: updtr_add test
2022-10-27 23:14:53,274 TADA INFO   test-user: narate
2022-10-27 23:14:53,274 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:15:01,123 __main__ INFO -- Start daemons --
2022-10-27 23:15:04,827 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:15:05,144 __main__ INFO All LDMSDs are up.
2022-10-27 23:15:06,363 TADA INFO assertion 1, updtr_start with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:15:07,580 TADA INFO assertion 2, updtr_start with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:15:08,791 TADA INFO assertion 3, updtr_start with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-27 23:15:10,008 TADA INFO assertion 4, updtr_start with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:15:11,216 TADA INFO assertion 5, updtr_start without an offset larger than interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 23:15:13,639 TADA INFO assertion 6, updtr_start that changes offset to no offset: report(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 23:15:14,866 TADA INFO assertion 7, updtr_start of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 23:15:17,301 TADA INFO assertion 8, updtr_start with a valid interval: report(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 23:15:19,732 TADA INFO assertion 9, updtr_start with a valid offset: report(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 23:15:22,165 TADA INFO assertion 10, updtr_start without giving interval and offset: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 23:15:23,388 TADA INFO assertion 11, updtr_start a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 23:15:23,388 __main__ INFO --- done ---
2022-10-27 23:15:23,388 TADA INFO test updtr_add test ended
2022-10-27 23:15:35 INFO: ----------------------------------------------
2022-10-27 23:15:36 INFO: ======== updtr_status_test ========
2022-10-27 23:15:36 INFO: CMD: python3 updtr_status_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/updtr_status_test
2022-10-27 23:15:37,206 __main__ INFO -- Get or create the cluster --
2022-10-27 23:15:37,207 TADA INFO starting test `updtr_status test`
2022-10-27 23:15:37,207 TADA INFO   test-id: bc9c5756a322914aa3f2d433dbce0e730c7d83d6748c1cf1e22054c4b4b9c897
2022-10-27 23:15:37,207 TADA INFO   test-suite: LDMSD
2022-10-27 23:15:37,207 TADA INFO   test-name: updtr_status test
2022-10-27 23:15:37,207 TADA INFO   test-user: narate
2022-10-27 23:15:37,207 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:15:47,484 __main__ INFO -- Start daemons --
2022-10-27 23:15:52,362 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 23:15:52,787 __main__ INFO All LDMSDs are up.
2022-10-27 23:15:54,004 TADA INFO assertion 1, Send 'updtr_status' to an LDMSD without any Updaters: [], passed
2022-10-27 23:15:55,219 TADA INFO assertion 2, Send 'updtr_status name=foo', where updtr 'foo' doesn't exist.: report(updtr 'foo' doesn't exist.) == expect(updtr 'foo' doesn't exist.), passed
2022-10-27 23:15:56,444 TADA INFO assertion 3, Send 'updtr_status name=all', where 'all' exists.: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 23:15:57,659 TADA INFO assertion 4, Send 'updtr_status' to an LDMSD with a single Updater: report([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 23:15:58,884 TADA INFO assertion 5, Send 'updtr_status' to an LDMSD with 2 updaters: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 23:15:58,884 __main__ INFO --- done ---
2022-10-27 23:15:58,885 TADA INFO test updtr_status test ended
2022-10-27 23:16:11 INFO: ----------------------------------------------
2022-10-27 23:16:12 INFO: ======== ldmsd_flex_decomp_test ========
2022-10-27 23:16:12 INFO: CMD: python3 ldmsd_flex_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldmsd_flex_decomp_test
2022-10-27 23:16:13,274 TADA INFO starting test `ldmsd_flex_decomp_test`
2022-10-27 23:16:13,275 TADA INFO   test-id: ed20f6608be5f9f554a6e1d75e5b1dbdc6de0b1e47c51df985c5c02db8ec4ca6
2022-10-27 23:16:13,275 TADA INFO   test-suite: LDMSD
2022-10-27 23:16:13,275 TADA INFO   test-name: ldmsd_flex_decomp_test
2022-10-27 23:16:13,275 TADA INFO   test-user: narate
2022-10-27 23:16:13,275 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:16:13,276 __main__ INFO -- Get or create the cluster --
2022-10-27 23:16:29,024 __main__ INFO -- Start daemons --
2022-10-27 23:16:39,433 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 23:17:28,469 TADA INFO assertion 1, test_sampler_95772b6 sos schema check: OK, passed
2022-10-27 23:17:28,469 TADA INFO assertion 2, record_sampler_e1f021f sos schema check: OK, passed
2022-10-27 23:17:28,469 TADA INFO assertion 3, fill sos schema check: OK, passed
2022-10-27 23:17:28,470 TADA INFO assertion 4, filter sos schema check: OK, passed
2022-10-27 23:17:28,470 TADA INFO assertion 5, record sos schema check: OK, passed
2022-10-27 23:17:28,470 TADA INFO assertion 6, test_sampler_95772b6 csv schema check: OK, passed
2022-10-27 23:17:28,470 TADA INFO assertion 7, record_sampler_e1f021f csv schema check: OK, passed
2022-10-27 23:17:28,470 TADA INFO assertion 8, fill csv schema check: OK, passed
2022-10-27 23:17:28,471 TADA INFO assertion 9, filter csv schema check: OK, passed
2022-10-27 23:17:28,471 TADA INFO assertion 10, record csv schema check: OK, passed
2022-10-27 23:17:28,471 TADA INFO assertion 11, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-27 23:17:28,471 TADA INFO assertion 12, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-27 23:17:28,471 TADA INFO assertion 13, fill kafka schema check: OK, passed
2022-10-27 23:17:28,471 TADA INFO assertion 14, filter kafka schema check: OK, passed
2022-10-27 23:17:28,472 TADA INFO assertion 15, record kafka schema check: OK, passed
2022-10-27 23:17:28,473 TADA INFO assertion 16, test_sampler_95772b6 sos data check: OK, passed
2022-10-27 23:17:28,543 TADA INFO assertion 17, record_sampler_e1f021f sos data check: OK, passed
2022-10-27 23:17:28,546 TADA INFO assertion 18, fill sos data check: OK, passed
2022-10-27 23:17:28,548 TADA INFO assertion 19, filter sos data check: OK, passed
2022-10-27 23:17:28,556 TADA INFO assertion 20, record sos data check: OK, passed
2022-10-27 23:17:28,557 TADA INFO assertion 21, test_sampler_95772b6 csv data check: OK, passed
2022-10-27 23:17:28,620 TADA INFO assertion 22, record_sampler_e1f021f csv data check: OK, passed
2022-10-27 23:17:28,623 TADA INFO assertion 23, fill csv data check: OK, passed
2022-10-27 23:17:28,624 TADA INFO assertion 24, filter csv data check: OK, passed
2022-10-27 23:17:28,632 TADA INFO assertion 25, record csv data check: OK, passed
2022-10-27 23:17:28,633 TADA INFO assertion 26, test_sampler_95772b6 kafka data check: OK, passed
2022-10-27 23:17:28,656 TADA INFO assertion 27, record_sampler_e1f021f kafka data check: OK, passed
2022-10-27 23:17:28,657 TADA INFO assertion 28, fill kafka data check: OK, passed
2022-10-27 23:17:28,658 TADA INFO assertion 29, filter kafka data check: OK, passed
2022-10-27 23:17:28,662 TADA INFO assertion 30, record kafka data check: OK, passed
2022-10-27 23:17:28,662 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-27 23:17:28,662 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-27 23:17:43 INFO: ----------------------------------------------
2022-10-27 23:17:44 INFO: ======== ldms_set_info_test ========
2022-10-27 23:17:44 INFO: CMD: python3 ldms_set_info_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/ldms_set_info_test
2022-10-27 23:17:55,083 TADA INFO starting test `ldms_set_info_test`
2022-10-27 23:17:55,083 TADA INFO   test-id: 94b13647ae598a004aa13ef4d6f57b69cd8c38eb6510987b8625b1eab7f3e8a9
2022-10-27 23:17:55,083 TADA INFO   test-suite: LDMSD
2022-10-27 23:17:55,083 TADA INFO   test-name: ldms_set_info_test
2022-10-27 23:17:55,083 TADA INFO   test-user: narate
2022-10-27 23:17:55,083 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:17:55,084 TADA INFO assertion 1, Adding set info key value pairs : -, passed
2022-10-27 23:17:55,084 TADA INFO assertion 2, Reset value of an existing pair : -, passed
2022-10-27 23:17:55,084 TADA INFO assertion 3, Get a value : -, passed
2022-10-27 23:17:55,084 TADA INFO assertion 4, Unset a pair : -, passed
2022-10-27 23:17:55,084 TADA INFO assertion 5, Traverse the local set info : -, passed
2022-10-27 23:17:55,085 TADA INFO assertion 6, Verifying the set info at the 1st level : -, passed
2022-10-27 23:17:55,085 TADA INFO assertion 7, Server resetting a key : -, passed
2022-10-27 23:17:55,085 TADA INFO assertion 8, Server unset a key : -, passed
2022-10-27 23:17:55,085 TADA INFO assertion 9, Server add a key : -, passed
2022-10-27 23:17:55,085 TADA INFO assertion 10, Adding a key : -, passed
2022-10-27 23:17:55,085 TADA INFO assertion 11, Add a key that is already in the remote list : -, passed
2022-10-27 23:17:55,086 TADA INFO assertion 12, Unset a key that appears in both local and remote list : -, passed
2022-10-27 23:17:55,086 TADA INFO assertion 13, Verifying the set_info at the 2nd level : -, passed
2022-10-27 23:17:55,086 TADA INFO assertion 14, Test set info propagation: resetting a key on the set origin : -, passed
2022-10-27 23:17:55,086 TADA INFO assertion 15, Test set info propagation: unsetting a key on the set origin : -, passed
2022-10-27 23:17:55,086 TADA INFO assertion 16, Test set info propagation: adding a key on the set origin : -, passed
2022-10-27 23:17:55,086 TADA INFO test ldms_set_info_test ended
2022-10-27 23:18:05 INFO: ----------------------------------------------
2022-10-27 23:18:06 INFO: ======== slurm_sampler2_test ========
2022-10-27 23:18:06 INFO: CMD: python3 slurm_sampler2_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-221905/data/slurm_sampler2_test
2022-10-27 23:18:07,355 TADA INFO starting test `slurm_sampler2_test`
2022-10-27 23:18:07,356 TADA INFO   test-id: af720504887bc44c590e799f3d359604af6d0a0f29fcffa126170312b1972672
2022-10-27 23:18:07,356 TADA INFO   test-suite: LDMSD
2022-10-27 23:18:07,356 TADA INFO   test-name: slurm_sampler2_test
2022-10-27 23:18:07,356 TADA INFO   test-user: narate
2022-10-27 23:18:07,356 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 23:18:07,356 __main__ INFO -- Get or create the cluster --
2022-10-27 23:18:21,107 __main__ INFO -- Add users --
2022-10-27 23:18:26,289 __main__ INFO -- Preparing job script & programs --
2022-10-27 23:18:26,989 __main__ INFO -- Start daemons --
2022-10-27 23:18:49,007 TADA INFO assertion 1, Processing the stream data from slurm_notifier: The metric values are as expected on all nodes., passed
2022-10-27 23:18:52,675 TADA INFO assertion 2.1, Deleting completed jobs -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 23:18:54,312 TADA INFO assertion 2.2, Deleting completed jobs -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 23:18:55,993 TADA INFO assertion 2.3, Deleting completed jobs -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 23:18:57,649 TADA INFO assertion 2.4, Deleting completed jobs -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 23:18:59,304 TADA INFO assertion 2.5, Deleting completed jobs -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 23:19:02,971 TADA INFO assertion 3.1, Expanding the set heap -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 23:19:04,607 TADA INFO assertion 3.2, Expanding the set heap -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 23:19:07,577 TADA INFO assertion 3.3, Expanding the set heap -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 23:19:10,522 TADA INFO assertion 3.4, Expanding the set heap -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 23:19:12,147 TADA INFO assertion 3.5, Expanding the set heap -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 23:19:18,392 TADA INFO assertion 4.1, Multi-tenant -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 23:19:20,039 TADA INFO assertion 4.2, Multi-tenant -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 23:19:22,524 TADA INFO assertion 4.3, Multi-tenant -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 23:19:25,033 TADA INFO assertion 4.4, Multi-tenant -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 23:19:26,666 TADA INFO assertion 4.5, Multi-tenant -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 23:19:26,666 TADA INFO test slurm_sampler2_test ended
2022-10-27 23:19:40 INFO: ----------------------------------------------
2022-10-27 23:19:41 INFO: ======== test-ldms ========
2022-10-27 23:19:41 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-ldms/test.sh
2022-10-27T23:19:41-05:00 INFO: starting test-samp-1
a6a6260278a0785b6633346006ce2115d8f1bd1f803949a0430ac1ec2bc5e60e
2022-10-27T23:19:44-05:00 INFO: starting test-samp-2
118a86ca7703f1aaf16ee2e5f8969bb19fae5716b2a2d72f042cd1858f2e23f6
2022-10-27T23:19:46-05:00 INFO: starting test-samp-3
a664807b30c7a6e54d1d4b6731c22febb88e4770b6344f1dd6fa73621029c94b
2022-10-27T23:19:48-05:00 INFO: starting test-samp-4
83b81a8484da10b2e2d07f8044a74fed2d9c0697e03ab734f6a6e28335d9f056
2022-10-27T23:19:49-05:00 INFO: test-samp-1 is running
2022-10-27T23:19:50-05:00 INFO: test-samp-2 is running
2022-10-27T23:19:50-05:00 INFO: test-samp-3 is running
2022-10-27T23:19:50-05:00 INFO: test-samp-4 is running
2022-10-27T23:19:50-05:00 INFO: starting test-agg-11
833ccc8d52393c82060acf141d6d1fc8e615ee9bafd3377e94056826589495f7
2022-10-27T23:19:52-05:00 INFO: starting test-agg-12
a18c8ea256f4ae749b2ed3c9f2c2ab4cbcfa79126f4463b3d0dd150503d41924
2022-10-27T23:19:53-05:00 INFO: test-agg-11 is running
2022-10-27T23:19:53-05:00 INFO: test-agg-12 is running
2022-10-27T23:19:53-05:00 INFO: starting test-agg-2
393ad2b464ff84048015bf0ee9411e0fde3cd89719f457dfe73993441358e5c2
2022-10-27T23:19:55-05:00 INFO: test-agg-2 is running
2022-10-27T23:19:55-05:00 INFO: Collecting data (into SOS)
2022-10-27T23:20:05-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T23:20:07-05:00 INFO: check rc: 0
2022-10-27T23:20:07-05:00 INFO: Cleaning up ...
test-samp-1
test-samp-2
test-samp-3
test-samp-4
test-agg-11
test-agg-12
test-agg-2
2022-10-27T23:20:12-05:00 INFO: DONE
2022-10-27 23:20:22 INFO: ----------------------------------------------
2022-10-27 23:20:22 INFO: ======== test-maestro ========
2022-10-27 23:20:22 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro/test.sh
2022-10-27T23:20:22-05:00 INFO: starting mtest-maestro
8fb1ae7ba882ec5088232c0b7961073b059e1852869dfe0949543e4816b908c7
2022-10-27T23:20:24-05:00 INFO: starting mtest-samp-1
75e60d3fa3f84846b8ef4418722015bfb7608836b5c3588dad882e1fc5b24d01
2022-10-27T23:20:25-05:00 INFO: starting mtest-samp-2
becbb70aa590979003d633f042d668c1d630b1a2957bfa622e482b316d75d915
2022-10-27T23:20:27-05:00 INFO: starting mtest-samp-3
2c76d8920e63ee25efab8c610154afcc9b90f8d5c641cecfedf86c7c637cc2ef
2022-10-27T23:20:29-05:00 INFO: starting mtest-samp-4
c932cbb707dadf7c71e8e8852bd07d207c7495b0bae2ea85a917c9d215255417
2022-10-27T23:20:31-05:00 INFO: mtest-samp-1 is running
2022-10-27T23:20:31-05:00 INFO: mtest-samp-2 is running
2022-10-27T23:20:31-05:00 INFO: mtest-samp-3 is running
2022-10-27T23:20:31-05:00 INFO: mtest-samp-4 is running
2022-10-27T23:20:31-05:00 INFO: starting mtest-agg-11
f77561ea6a18fe915753b2ec0cd4bc3b60d7ab08ea0bbf93edf17c14ae318335
2022-10-27T23:20:32-05:00 INFO: starting mtest-agg-12
7e1341bb98e538c6704182e16e97f11ff6617f7dee7c780781f8a831b3adeba3
2022-10-27T23:20:34-05:00 INFO: mtest-agg-11 is running
2022-10-27T23:20:34-05:00 INFO: mtest-agg-12 is running
2022-10-27T23:20:34-05:00 INFO: starting mtest-agg-2
612eae70f07b7206885a348412d7c175de0d9b3989faef68fea8ea93b92aa746
2022-10-27T23:20:35-05:00 INFO: mtest-agg-2 is running
2022-10-27T23:20:35-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T23:20:47-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T23:20:49-05:00 INFO: sos check rc: 0
2022-10-27T23:20:50-05:00 INFO: starting mtest-ui
50c615ac28097b4535c11e1e130ead009cd86313f1b4c85ff36de1fbb2c81c33
2022-10-27T23:20:57-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4372836, 1666930838000.7449], [4373108, 1666930839001.3188], [4373108, 1666930839001.334], [4373208, 1666930840001.3599], [4373208, 1666930840001.3901], [4373208, 1666930840001.392], [4373208, 1666930840001.409], [4373208, 1666930841000.859], [4373208, 1666930841001.304], [4373208, 1666930841001.516], [4373208, 1666930841001.544], [4373208, 1666930842001.4521], [4373208, 1666930842001.657], [4373208, 1666930842001.681], [4373208, 1666930842001.687], [4373208, 1666930843001.547], [4373208, 1666930843001.558], [4373208, 1666930843001.8071], [4373208, 1666930843001.84], [4373208, 1666930844001.6099], [4373208, 1666930844001.705], [4373208, 1666930844001.709], [4373208, 1666930844001.964], [4373208, 1666930845001.3289], [4373208, 1666930845001.615], [4373208, 1666930845001.847], [4373208, 1666930845001.8691]]}, {"target": "component_id", "datapoints": [[1, 1666930838000.7449], [3, 1666930839001.3188], [1, 1666930839001.334], [1, 1666930840001.3599], [2, 1666930840001.3901], [4, 1666930840001.392], [3, 1666930840001.409], [1, 1666930841000.859], [4, 1666930841001.304], [2, 1666930841001.516], [3, 1666930841001.544], [4, 1666930842001.4521], [1, 1666930842001.657], [2, 1666930842001.681], [3, 1666930842001.687], [4, 1666930843001.547], [1, 1666930843001.558], [2, 1666930843001.8071], [3, 1666930843001.84], [4, 1666930844001.6099], [1, 1666930844001.705], [2, 1666930844001.709], [3, 1666930844001.964], [4, 1666930845001.3289], [1, 1666930845001.615], [3, 1666930845001.847], [2, 1666930845001.8691]]}, {"target": "job_id", "datapoints": [[0, 1666930838000.7449], [0, 1666930839001.3188], [0, 1666930839001.334], [0, 1666930840001.3599], [0, 1666930840001.3901], [0, 1666930840001.392], [0, 1666930840001.409], [0, 1666930841000.859], [0, 1666930841001.304], [0, 1666930841001.516], [0, 1666930841001.544], [0, 1666930842001.4521], [0, 1666930842001.657], [0, 1666930842001.681], [0, 1666930842001.687], [0, 1666930843001.547], [0, 1666930843001.558], [0, 1666930843001.8071], [0, 1666930843001.84], [0, 1666930844001.6099], [0, 1666930844001.705], [0, 1666930844001.709], [0, 1666930844001.964], [0, 1666930845001.3289], [0, 1666930845001.615], [0, 1666930845001.847], [0, 1666930845001.8691]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T23:20:59-05:00 INFO: query check RC: 0
27cc63a6218fb29ae0c44510cc4459b0cba0fb425412a922f4d8da3af70c21cb
2022-10-27T23:21:30-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2477    764 --:--:-- --:--:-- --:--:--  3258
{"datasource":{"id":1,"uid":"uVet7JH4z","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T23:21:32-05:00 INFO: Checking grafana data
2022-10-27T23:21:32-05:00 INFO: Grafana data check, rc: 0
2022-10-27T23:21:32-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T23:21:37-05:00 INFO: DONE
2022-10-27 23:21:47 INFO: ----------------------------------------------
2022-10-27 23:21:47 INFO: ======== test-maestro-hostmunge ========
2022-10-27 23:21:47 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-hostmunge/test.sh
2022-10-27T23:21:47-05:00 INFO: Checking munge on localhost
2022-10-27T23:21:47-05:00 INFO: munge encode/decode successfully
2022-10-27T23:21:47-05:00 INFO: starting mtest-maestro
dd956a0f7dadb758601a81faecc233d3d11f2ed01f089393913cd84bc64d4631
2022-10-27T23:21:49-05:00 INFO: starting mtest-samp-1
6e0757cf0300bbd096e3edf23d2896f65203edd8e7ae4c432497b23a8ff5a95a
2022-10-27T23:21:51-05:00 INFO: starting mtest-samp-2
c0e1e02e8a1acd3d67bdbc0bbe8e1b73a8de68843b6a5b8b083561fac9d437e4
2022-10-27T23:21:53-05:00 INFO: starting mtest-samp-3
9e6b5a060000c1836da7c635abc8e80346bc5120eac0485267204dfe6e9746ba
2022-10-27T23:21:54-05:00 INFO: starting mtest-samp-4
4ec988a29d190cbd79c4fad0f490b7af45bcbef067a3f1f697621f0ea48c55b6
2022-10-27T23:21:56-05:00 INFO: mtest-samp-1 is running
2022-10-27T23:21:56-05:00 INFO: mtest-samp-2 is running
2022-10-27T23:21:56-05:00 INFO: mtest-samp-3 is running
2022-10-27T23:21:56-05:00 INFO: mtest-samp-4 is running
2022-10-27T23:21:56-05:00 INFO: starting mtest-agg-11
9a1a4b4586fbe48e19fb43a722e7503bfe7d6d2bba8bb84e4c07b1d60f1284b3
2022-10-27T23:21:57-05:00 INFO: starting mtest-agg-12
2ecac825a6f2375626deddc9ceffdfba0e354af3f1da10c66844a72ed1c70f57
2022-10-27T23:21:59-05:00 INFO: mtest-agg-11 is running
2022-10-27T23:21:59-05:00 INFO: mtest-agg-12 is running
2022-10-27T23:21:59-05:00 INFO: starting mtest-agg-2
63009c4e86b796d3f5702be024cd9503ea769ccb75ec6a91acad884b61efc85b
2022-10-27T23:22:00-05:00 INFO: mtest-agg-2 is running
2022-10-27T23:22:00-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T23:22:12-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T23:22:14-05:00 INFO: sos check rc: 0
2022-10-27T23:22:15-05:00 INFO: starting mtest-ui
cf2acbfcb75dcbcd46939ec777a2fad64a46087b37437817dcee6a3d5893a3a3
2022-10-27T23:22:17-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4373096, 1666930924001.498], [4373096, 1666930924001.4988], [4373468, 1666930925001.3508], [4373468, 1666930925001.4731], [4373468, 1666930925001.6052], [4373468, 1666930925001.6099], [4373468, 1666930926001.014], [4373468, 1666930926001.018], [4373468, 1666930926001.289], [4373468, 1666930926001.31], [4373468, 1666930927000.19], [4373468, 1666930927000.311], [4373468, 1666930927001.2878], [4373468, 1666930927001.461], [4373468, 1666930928001.28], [4373468, 1666930928001.3152], [4373468, 1666930928001.3271], [4373468, 1666930928001.6099], [4373468, 1666930929001.279], [4373468, 1666930929001.3171], [4373468, 1666930929001.4568], [4373468, 1666930929001.761], [4373468, 1666930930001.3381], [4373468, 1666930930001.474], [4373468, 1666930930001.483], [4373468, 1666930930001.529]]}, {"target": "component_id", "datapoints": [[3, 1666930924001.498], [1, 1666930924001.4988], [4, 1666930925001.3508], [3, 1666930925001.4731], [1, 1666930925001.6052], [2, 1666930925001.6099], [3, 1666930926001.014], [1, 1666930926001.018], [2, 1666930926001.289], [4, 1666930926001.31], [3, 1666930927000.19], [1, 1666930927000.311], [2, 1666930927001.2878], [4, 1666930927001.461], [2, 1666930928001.28], [1, 1666930928001.3152], [3, 1666930928001.3271], [4, 1666930928001.6099], [3, 1666930929001.279], [2, 1666930929001.3171], [1, 1666930929001.4568], [4, 1666930929001.761], [3, 1666930930001.3381], [2, 1666930930001.474], [4, 1666930930001.483], [1, 1666930930001.529]]}, {"target": "job_id", "datapoints": [[0, 1666930924001.498], [0, 1666930924001.4988], [0, 1666930925001.3508], [0, 1666930925001.4731], [0, 1666930925001.6052], [0, 1666930925001.6099], [0, 1666930926001.014], [0, 1666930926001.018], [0, 1666930926001.289], [0, 1666930926001.31], [0, 1666930927000.19], [0, 1666930927000.311], [0, 1666930927001.2878], [0, 1666930927001.461], [0, 1666930928001.28], [0, 1666930928001.3152], [0, 1666930928001.3271], [0, 1666930928001.6099], [0, 1666930929001.279], [0, 1666930929001.3171], [0, 1666930929001.4568], [0, 1666930929001.761], [0, 1666930930001.3381], [0, 1666930930001.474], [0, 1666930930001.483], [0, 1666930930001.529]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T23:22:19-05:00 INFO: query check RC: 0
773e4e8b06794312e1f4c781d692544ef04fed2bea6b78a209b817b0bdad3432
2022-10-27T23:22:51-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2478    765 --:--:-- --:--:-- --:--:--  3258
{"datasource":{"id":1,"uid":"zwpAnJN4k","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T23:22:52-05:00 INFO: Checking grafana data
2022-10-27T23:22:52-05:00 INFO: Grafana data check, rc: 0
2022-10-27T23:22:52-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T23:22:57-05:00 INFO: DONE
2022-10-27 23:23:07 INFO: ----------------------------------------------
2022-10-27 23:23:07 INFO: ======== test-maestro-munge ========
2022-10-27 23:23:07 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-munge/test.sh
1+0 records in
1+0 records out
4096 bytes (4.1 kB, 4.0 KiB) copied, 0.000310667 s, 13.2 MB/s
2022-10-27T23:23:08-05:00 INFO: starting mtest-maestro
d8ee0220828e73ef488e7580ea4e9fb1701d4590ec1656ce0fcab6d150f8e08d
2022-10-27T23:23:11-05:00 INFO: starting mtest-samp-1
7f8ed90773df9eab4bd8318c7a4edce7cf190f4cae0e0fef8262bafcdfaa0b9e
2022-10-27T23:23:12-05:00 INFO: starting mtest-samp-2
23388036d5cea862b9470ae6b6fc92dee220a27fb5422b627201836066501ccb
2022-10-27T23:23:14-05:00 INFO: starting mtest-samp-3
1a355cfaed0721633deeb36076093038776b6f81f68c0e8797263cfb9e0e2279
2022-10-27T23:23:16-05:00 INFO: starting mtest-samp-4
164de0b4dd9c271cebb97b607b93b8fef4fcd758471cf18256ff8d14c45a138f
2022-10-27T23:23:17-05:00 INFO: mtest-samp-1 is running
2022-10-27T23:23:17-05:00 INFO: mtest-samp-2 is running
2022-10-27T23:23:18-05:00 INFO: mtest-samp-3 is running
2022-10-27T23:23:18-05:00 INFO: mtest-samp-4 is running
2022-10-27T23:23:18-05:00 INFO: starting mtest-agg-11
da86ec8cbfeb8db9d1e52563f43b4523d6e95f94f9af75528708ded7d56893c6
2022-10-27T23:23:19-05:00 INFO: starting mtest-agg-12
3b2ff9ab8d19267b724fe598de7e5832f8dc719fed9dfdfe73bb492929f56bfe
2022-10-27T23:23:21-05:00 INFO: mtest-agg-11 is running
2022-10-27T23:23:21-05:00 INFO: mtest-agg-12 is running
2022-10-27T23:23:21-05:00 INFO: starting mtest-agg-2
d4e75452102451bb991a2ab27175aaeee5fd26627039a41805584f3db6f96b78
2022-10-27T23:23:22-05:00 INFO: mtest-agg-2 is running
2022-10-27T23:23:22-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T23:23:33-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T23:23:35-05:00 INFO: sos check rc: 0
2022-10-27T23:23:37-05:00 INFO: starting mtest-ui
69362c87e2571269714b3bb0783b23ac19e6d265caa19bb9914d4bf916255aab
2022-10-27T23:23:38-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4373372, 1666931008000.898], [4373744, 1666931009001.3062], [4373744, 1666931009001.313], [4373744, 1666931009001.663], [4373744, 1666931009002.039], [4373744, 1666931010001.121], [4373744, 1666931010001.4238], [4373744, 1666931010001.447], [4373744, 1666931010001.6692], [4373744, 1666931011001.046], [4373744, 1666931011001.2942], [4373744, 1666931011001.3], [4373744, 1666931011001.8088], [4373748, 1666931012000.9312], [4373748, 1666931012001.422], [4373748, 1666931012001.45], [4373748, 1666931012001.955]]}, {"target": "component_id", "datapoints": [[3, 1666931008000.898], [3, 1666931009001.3062], [4, 1666931009001.313], [2, 1666931009001.663], [1, 1666931009002.039], [1, 1666931010001.121], [3, 1666931010001.4238], [4, 1666931010001.447], [2, 1666931010001.6692], [4, 1666931011001.046], [3, 1666931011001.2942], [1, 1666931011001.3], [2, 1666931011001.8088], [4, 1666931012000.9312], [3, 1666931012001.422], [1, 1666931012001.45], [2, 1666931012001.955]]}, {"target": "job_id", "datapoints": [[0, 1666931008000.898], [0, 1666931009001.3062], [0, 1666931009001.313], [0, 1666931009001.663], [0, 1666931009002.039], [0, 1666931010001.121], [0, 1666931010001.4238], [0, 1666931010001.447], [0, 1666931010001.6692], [0, 1666931011001.046], [0, 1666931011001.2942], [0, 1666931011001.3], [0, 1666931011001.8088], [0, 1666931012000.9312], [0, 1666931012001.422], [0, 1666931012001.45], [0, 1666931012001.955]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T23:23:40-05:00 INFO: query check RC: 0
de8724708e2036f09ec13dfc0e3172d4209e3b19359b6270916ed88a7d62da1b
2022-10-27T23:24:12-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2300    710 --:--:-- --:--:-- --:--:--  3031
{"datasource":{"id":1,"uid":"Xj9xnJHVz","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T23:24:13-05:00 INFO: Checking grafana data
2022-10-27T23:24:13-05:00 INFO: Grafana data check, rc: 0
2022-10-27T23:24:13-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T23:24:18-05:00 INFO: DONE
2022-10-27 23:24:28 INFO: ----------------------------------------------
2022-10-27 23:24:28 INFO: ==== Summary ====
ldmsd_ctrl_test: [01;32mPASSED[0m
papi_store_test: [01;32mPASSED[0m
updtr_status_test: [01;32mPASSED[0m
ldmsd_auth_ovis_test: [01;32mPASSED[0m
store_app_test: [01;32mPASSED[0m
store_list_record_test: [01;32mPASSED[0m
set_array_test: [01;32mPASSED[0m
ovis_ev_test: [01;32mPASSED[0m
setgroup_test: [01;32mPASSED[0m
ldms_list_test: [01;32mPASSED[0m
slurm_stream_test: [01;32mPASSED[0m
maestro_cfg_test: [01;32mPASSED[0m
ldms_set_info_test: [01;32mPASSED[0m
spank_notifier_test: [01;31mFAILED[0m
agg_slurm_test: [01;32mPASSED[0m
updtr_match_add_test: [01;32mPASSED[0m
updtr_match_del_test: [01;32mPASSED[0m
ldmsd_stream_dir_test: [01;32mPASSED[0m
direct_prdcr_subscribe_test: [01;32mPASSED[0m
ldmsd_auth_test: [01;32mPASSED[0m
cont-test-maestro-munge: [01;32mPASSED[0m
cont-test-ldms: [01;32mPASSED[0m
prdcr_subscribe_test: [01;32mPASSED[0m
cont-test-maestro-hostmunge: [01;32mPASSED[0m
maestro_raft_test: [01;32mPASSED[0m
updtr_start_test: [01;32mPASSED[0m
failover_test: [01;32mPASSED[0m
ldms_record_test: [01;32mPASSED[0m
cont-test-maestro: [01;32mPASSED[0m
ldmsd_decomp_test: [01;32mPASSED[0m
ldmsd_flex_decomp_test: [01;32mPASSED[0m
quick_set_add_rm_test: [01;32mPASSED[0m
updtr_prdcr_del_test: [01;32mPASSED[0m
updtr_prdcr_add_test: [01;32mPASSED[0m
mt-slurm-test: [01;32mPASSED[0m
ovis_json_test: [01;32mPASSED[0m
papi_sampler_test: [01;32mPASSED[0m
syspapi_test: [01;32mPASSED[0m
updtr_del_test: [01;32mPASSED[0m
ldmsd_autointerval_test: [01;32mPASSED[0m
updtr_add_test: [01;32mPASSED[0m
ldmsd_stream_test: [01;32mPASSED[0m
direct_ldms_ls_conn_test: [01;32mPASSED[0m
set_array_hang_test: [01;32mPASSED[0m
slurm_sampler2_test: [01;32mPASSED[0m
ldms_schema_digest_test: [01;32mPASSED[0m
agg_test: [01;32mPASSED[0m
------------------------------------------
Total tests passed: 46/47
------------------------------------------
