2022-10-27 10:26:20 INFO: WORK_DIR: /mnt/300G/data/2022-10-27-102619
2022-10-27 10:26:20 INFO: LOG: /mnt/300G/data/2022-10-27-102619/cygnus-weekly.log
~/cron/ldms-test ~
/mnt/300G/data/2022-10-27-102619 ~/cron/ldms-test ~
2022-10-27 10:26:21 INFO: Skip building on host because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:26:21 INFO: Skip building containerized binary because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:26:21 INFO: -- Installation process succeeded --
2022-10-27 10:26:21 INFO: ---------------------------------------------------------------
~/cron/ldms-test /mnt/300G/data/2022-10-27-102619
~/cron/ldms-test/weekly-report ~/cron/ldms-test /mnt/300G/data/2022-10-27-102619
HEAD is now at 600a748 2022-10-27-003001
[master 3a6777e] 2022-10-27-102619
 2 files changed, 14 insertions(+), 14479 deletions(-)
 rewrite test-all.log (99%)
To github.com:ldms-test/weekly-report
   600a748..3a6777e  master -> master
~/cron/ldms-test /mnt/300G/data/2022-10-27-102619
2022-10-27 10:26:22 INFO: ==== OVIS+SOS Installation Completed ====
2022-10-27 10:26:22 INFO: ==== Start batch testing ====
~/cron/ldms-test /mnt/300G/data/2022-10-27-102619 ~/cron/ldms-test ~
2022-10-27 10:26:22 INFO: ======== direct_ldms_ls_conn_test ========
2022-10-27 10:26:22 INFO: CMD: python3 direct_ldms_ls_conn_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/direct_ldms_ls_conn_test
2022-10-27 10:26:23,615 TADA INFO starting test `direct_ldms_ls_conn_test`
2022-10-27 10:26:23,616 TADA INFO   test-id: 448b679a9faf92aca7ed3463a5b2cd2022e9eb0df9e0d8127b98318d2151a4b0
2022-10-27 10:26:23,616 TADA INFO   test-suite: LDMSD
2022-10-27 10:26:23,616 TADA INFO   test-name: direct_ldms_ls_conn_test
2022-10-27 10:26:23,616 TADA INFO   test-user: narate
2022-10-27 10:26:23,616 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:26:24,063 __main__ INFO starting munged on cygnus-01-iw
2022-10-27 10:26:24,388 __main__ INFO starting munged on localhost
2022-10-27 10:26:24,620 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-27 10:26:24,923 TADA INFO assertion 0, Start ldmsd sampler and munged: OK, passed
2022-10-27 10:26:30,115 TADA INFO assertion 1, ldms_ls to the sampler: OK, passed
2022-10-27 10:26:30,115 __main__ INFO Stopping sampler daemon ...
2022-10-27 10:26:35,529 TADA INFO assertion 2, Kill the sampler: OK, passed
2022-10-27 10:26:35,568 TADA INFO assertion 3, ldms_ls to the dead sampler: got expected output, passed
2022-10-27 10:26:35,605 TADA INFO assertion 4, ldms_ls to a dead host: got expected output, passed
2022-10-27 10:26:35,606 TADA INFO test direct_ldms_ls_conn_test ended
2022-10-27 10:26:35,810 __main__ INFO stopping munged on cygnus-01-iw
2022-10-27 10:26:36,225 __main__ INFO stopping munged on localhost
2022-10-27 10:26:36 INFO: ----------------------------------------------
2022-10-27 10:26:36 INFO: ======== direct_prdcr_subscribe_test ========
2022-10-27 10:26:36 INFO: CMD: python3 direct_prdcr_subscribe_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/direct_prdcr_subscribe_test
2022-10-27 10:26:37,058 TADA INFO starting test `direct_prdcr_subscribe_test`
2022-10-27 10:26:37,058 TADA INFO   test-id: fa7c7948c91497b3222cdd6736cc97a34441e3dcd22c2cf741e126655c97e78f
2022-10-27 10:26:37,058 TADA INFO   test-suite: LDMSD
2022-10-27 10:26:37,058 TADA INFO   test-name: direct_prdcr_subscribe_test
2022-10-27 10:26:37,058 TADA INFO   test-user: narate
2022-10-27 10:26:37,058 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:26:38,965 __main__ INFO starting munged on cygnus-01-iw
2022-10-27 10:26:39,847 __main__ INFO starting munged on cygnus-02-iw
2022-10-27 10:26:40,579 __main__ INFO starting munged on cygnus-03-iw
2022-10-27 10:26:41,339 __main__ INFO starting munged on cygnus-04-iw
2022-10-27 10:26:41,654 __main__ INFO starting munged on localhost
2022-10-27 10:26:41,877 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-27 10:26:42,377 __main__ INFO starting ldmsd on cygnus-02-iw
2022-10-27 10:26:42,869 __main__ INFO starting ldmsd on cygnus-03-iw
2022-10-27 10:26:43,361 __main__ INFO starting ldmsd on cygnus-04-iw
2022-10-27 10:26:50,250 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-27 10:26:50,251 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-27 10:26:50,252 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-27 10:26:50,252 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-27 10:26:50,253 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verified, passed
2022-10-27 10:26:50,284 TADA INFO assertion 5, Stopping the producers succeeds: agg-1 producers stopped, passed
2022-10-27 10:26:51,286 TADA INFO assertion 6, Restarting the producers succeeds: agg-1 producers started, passed
2022-10-27 10:26:57,865 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-27 10:26:57,865 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-27 10:26:57,866 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-27 10:26:57,866 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-27 10:26:57,867 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verified, passed
2022-10-27 10:26:57,868 __main__ INFO stopping sampler-1
2022-10-27 10:26:59,284 TADA INFO assertion 12, stream-sampler-1 is not running: sampler-1 stopped, passed
2022-10-27 10:26:59,285 __main__ INFO starting sampler-1
2022-10-27 10:27:00,553 TADA INFO assertion 13, stream-sampler-1 has restarted: sampler-1 running, passed
2022-10-27 10:27:00,553 __main__ INFO allow some time for prdcr to reconnect ...
2022-10-27 10:27:06,470 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-27 10:27:06,470 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-27 10:27:06,471 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verified, passed
2022-10-27 10:27:06,472 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: unsubscribed, passed
2022-10-27 10:27:08,691 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-27 10:27:08,695 __main__ INFO stopping agg-1
2022-10-27 10:27:13,910 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-27 10:27:13,911 TADA INFO test direct_prdcr_subscribe_test ended
2022-10-27 10:27:14,123 __main__ INFO stopping munged on cygnus-01-iw
2022-10-27 10:27:14,526 __main__ INFO stopping ldmsd on cygnus-01-iw
2022-10-27 10:27:14,935 __main__ INFO stopping munged on cygnus-02-iw
2022-10-27 10:27:15,355 __main__ INFO stopping ldmsd on cygnus-02-iw
2022-10-27 10:27:15,771 __main__ INFO stopping munged on cygnus-03-iw
2022-10-27 10:27:16,407 __main__ INFO stopping munged on cygnus-04-iw
2022-10-27 10:27:16,830 __main__ INFO stopping ldmsd on cygnus-04-iw
2022-10-27 10:27:17,040 __main__ INFO stopping munged on localhost
2022-10-27 10:27:17 INFO: ----------------------------------------------
2022-10-27 10:27:17 INFO: ======== agg_slurm_test ========
2022-10-27 10:27:17 INFO: CMD: python3 agg_slurm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/agg_slurm_test
2022-10-27 10:27:17,912 TADA INFO starting test `agg_slurm_test`
2022-10-27 10:27:17,912 TADA INFO   test-id: 3b034f4ea452a40d0d03140528ce879239fc2de89564fae1428a930ebe41fc33
2022-10-27 10:27:17,912 TADA INFO   test-suite: LDMSD
2022-10-27 10:27:17,912 TADA INFO   test-name: agg_slurm_test
2022-10-27 10:27:17,913 TADA INFO   test-user: narate
2022-10-27 10:27:17,913 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:27:17,914 __main__ INFO -- Get or create the cluster --
2022-10-27 10:27:31,696 __main__ INFO -- Preparing syspapi JSON file --
2022-10-27 10:27:31,811 __main__ INFO -- Preparing jobpapi JSON file --
2022-10-27 10:27:31,921 __main__ INFO -- Preparing job script & programs --
2022-10-27 10:27:33,262 __main__ INFO -- Start daemons --
2022-10-27 10:27:45,537 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:27:50,542 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 10:27:50,665 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-27 10:27:50,804 __main__ INFO -- Give syspapi some time to work before submitting job --
2022-10-27 10:27:55,806 __main__ INFO -- Submitting jobs --
2022-10-27 10:27:55,941 __main__ INFO job_one: 1
2022-10-27 10:27:56,070 __main__ INFO job_two: 2
2022-10-27 10:28:06,081 __main__ INFO -- Cancelling jobs --
2022-10-27 10:28:06,081 __main__ INFO job_one: 1
2022-10-27 10:28:06,333 __main__ INFO job_two: 2
2022-10-27 10:29:13,344 TADA INFO assertion 2, slurm data verification: get expected data from store, passed
2022-10-27 10:29:13,345 TADA INFO assertion 3, meminfo data verification: No data missing, failed
Traceback (most recent call last):
  File "agg_slurm_test", line 590, in <module>
    test.assert_test(3, len(meminfo) > 5 and missing_counts == 0, "No data missing")
  File "/home/narate/cron/ldms-test/TADA.py", line 157, in assert_test
    raise AssertionException(self.test_desc + ", " + cond_str + ": FAILED")
TADA.AssertionException: LDMSD 2-level agg with slurm, No data missing: FAILED
2022-10-27 10:29:13,346 TADA INFO assertion 4, (SYS/JOB) PAPI data verification: skipped
2022-10-27 10:29:13,346 TADA INFO test agg_slurm_test ended
2022-10-27 10:29:27 INFO: ----------------------------------------------
2022-10-27 10:29:28 INFO: ======== papi_sampler_test ========
2022-10-27 10:29:28 INFO: CMD: python3 papi_sampler_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/papi_sampler_test
2022-10-27 10:29:29,176 TADA INFO starting test `papi_sampler_test`
2022-10-27 10:29:29,177 TADA INFO   test-id: 542f0f96397594328c185022ef3081a33737c3c285aca418579456c066109aff
2022-10-27 10:29:29,177 TADA INFO   test-suite: LDMSD
2022-10-27 10:29:29,177 TADA INFO   test-name: papi_sampler_test
2022-10-27 10:29:29,177 TADA INFO   test-user: narate
2022-10-27 10:29:29,177 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:29:29,178 __main__ INFO -- Get or create the cluster --
2022-10-27 10:29:34,367 __main__ INFO -- Start daemons --
2022-10-27 10:29:44,382 TADA INFO assertion 0, ldmsd has started: verified, passed
2022-10-27 10:29:44,610 TADA INFO assertion 1.1, Non-papi job is submitted: jobid(1) > 0, passed
2022-10-27 10:29:49,732 TADA INFO assertion 1.2, Non-papi job is running before ldms_ls: STATE = RUNNING, passed
2022-10-27 10:29:49,895 TADA INFO assertion 1.3, Non-papi job is running after ldms_ls: STATE = RUNNING, passed
2022-10-27 10:29:49,896 TADA INFO assertion 1, Non-papi job does not create set: verified, passed
2022-10-27 10:30:03,725 TADA INFO assertion 2, papi job creates set: PAPI set created, passed
2022-10-27 10:30:03,726 TADA INFO assertion 2.2, Schema name is set accordingly: schema name == papi0, passed
2022-10-27 10:30:03,726 TADA INFO assertion 2.1, Events in papi job set created according to config file: {'PAPI_TOT_INS'} == {'PAPI_TOT_INS'}, passed
2022-10-27 10:30:03,726 TADA INFO assertion 2.3, PAPI set has correct job_id: 2 == 2, passed
2022-10-27 10:30:03,939 TADA INFO assertion 2.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-27 10:30:09,751 TADA INFO assertion 3, papi job creates set: PAPI set created, passed
2022-10-27 10:30:09,751 TADA INFO assertion 3.2, Schema name is set accordingly: schema name == papi1, passed
2022-10-27 10:30:09,751 TADA INFO assertion 3.1, Events in papi job set created according to config file: {'PAPI_TOT_INS', 'PAPI_BR_MSP'} == {'PAPI_TOT_INS', 'PAPI_BR_MSP'}, passed
2022-10-27 10:30:09,751 TADA INFO assertion 3.3, PAPI set has correct job_id: 3 == 3, passed
2022-10-27 10:30:09,967 TADA INFO assertion 3.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-27 10:30:09,967 TADA INFO assertion 4, Multiple, concurrent jobs results in concurrent, multiple sets: LDMS sets ({'node-1/meminfo', 'node-1/papi1/3.0', 'node-1/papi0/2.0'}), passed
2022-10-27 10:30:20,546 TADA INFO assertion 6, PAPI set persists within `job_expiry` after job exited: verified, passed
2022-10-27 10:31:00,869 TADA INFO assertion 7, PAPI set is deleted after `2.2 x job_expiry` since job exited: node-1/meminfo deleted, passed
2022-10-27 10:31:03,216 TADA INFO assertion 8, Missing config file attribute is logged: : papi_sampler[519]: papi_config object must contain either the 'file' or 'config' attribute., passed
2022-10-27 10:31:08,686 TADA INFO assertion 9, Bad config file is logged: : papi_sampler: configuration file syntax error., passed
2022-10-27 10:31:14,139 TADA INFO assertion 10, Unsupported events are logged: : papi_sampler: PAPI error 'Event does not exist' translating event code 'FOO', passed
2022-10-27 10:31:14,140 __main__ INFO -- Finishing Test --
2022-10-27 10:31:14,140 TADA INFO test papi_sampler_test ended
2022-10-27 10:31:14,140 __main__ INFO -- Cleaning up files --
2022-10-27 10:31:14,141 __main__ INFO -- Removing the virtual cluster --
2022-10-27 10:31:25 INFO: ----------------------------------------------
2022-10-27 10:31:26 INFO: ======== papi_store_test ========
2022-10-27 10:31:26 INFO: CMD: python3 papi_store_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/papi_store_test
2022-10-27 10:31:27,414 TADA INFO starting test `papi_store_test`
2022-10-27 10:31:27,415 TADA INFO   test-id: cee7f186a687f4ad90f41826467f85a8b79fd73dc332f0996dcc46608c443ac9
2022-10-27 10:31:27,415 TADA INFO   test-suite: LDMSD
2022-10-27 10:31:27,415 TADA INFO   test-name: papi_store_test
2022-10-27 10:31:27,415 TADA INFO   test-user: narate
2022-10-27 10:31:27,415 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:31:27,416 __main__ INFO -- Get or create the cluster --
2022-10-27 10:31:35,083 __main__ INFO -- Start daemons --
2022-10-27 10:32:06,551 TADA INFO assertion 1, Every job in the input data is represented in the output: {1, 2, 3, 4} = {1, 2, 3, 4}, passed
2022-10-27 10:32:06,552 TADA INFO assertion 2, Every event in every job results in a separate row in the output: verified, passed
2022-10-27 10:32:06,552 TADA INFO assertion 3, The schema name in the output matches the event name: verified, passed
2022-10-27 10:32:06,552 TADA INFO assertion 4, Each rank in the job results in a row per event in the output: verified, passed
2022-10-27 10:32:06,552 TADA INFO test papi_store_test ended
2022-10-27 10:32:18 INFO: ----------------------------------------------
2022-10-27 10:32:19 INFO: ======== store_app_test ========
2022-10-27 10:32:19 INFO: CMD: python3 store_app_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/store_app_test
2022-10-27 10:32:20,373 TADA INFO starting test `store_app_test`
2022-10-27 10:32:20,374 TADA INFO   test-id: b90093e04d8f03e519067a27c9869d8c4317400ed13aba8206c510253831af16
2022-10-27 10:32:20,374 TADA INFO   test-suite: LDMSD
2022-10-27 10:32:20,374 TADA INFO   test-name: store_app_test
2022-10-27 10:32:20,374 TADA INFO   test-user: narate
2022-10-27 10:32:20,374 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:32:20,375 __main__ INFO -- Get or create the cluster --
2022-10-27 10:32:34,683 __main__ INFO -- Preparing job script & programs --
2022-10-27 10:32:35,083 __main__ INFO -- Start daemons --
2022-10-27 10:32:47,356 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:32:52,363 __main__ INFO -- Submitting jobs --
2022-10-27 10:32:52,608 __main__ INFO job_one: 1
2022-10-27 10:32:57,740 __main__ INFO job_two: 2
2022-10-27 10:33:07,100 __main__ INFO Verifying data ...
2022-10-27 10:35:04,047 TADA INFO assertion 1, Verify data: sos data is not empty and sos data < ldms_ls data, passed
2022-10-27 10:35:04,048 TADA INFO test store_app_test ended
2022-10-27 10:35:18 INFO: ----------------------------------------------
2022-10-27 10:35:18 INFO: ======== syspapi_test ========
2022-10-27 10:35:18 INFO: CMD: python3 syspapi_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/syspapi_test
2022-10-27 10:35:19,587 TADA INFO starting test `syspapi_test`
2022-10-27 10:35:19,587 TADA INFO   test-id: 9af61603db3c0a885b9e2d0858a349049c7817cfb3e7cb4384d2ea6f8a122756
2022-10-27 10:35:19,587 TADA INFO   test-suite: LDMSD
2022-10-27 10:35:19,587 TADA INFO   test-name: syspapi_test
2022-10-27 10:35:19,587 TADA INFO   test-user: narate
2022-10-27 10:35:19,587 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:35:19,588 __main__ INFO -- Get or create the cluster --
2022-10-27 10:35:31,365 __main__ INFO -- Write syspapi JSON config files --
2022-10-27 10:35:31,365 __main__ INFO    - db/syspapi-1.json
2022-10-27 10:35:31,367 __main__ INFO    - db/syspapi-bad.json
2022-10-27 10:35:31,368 __main__ INFO -- Start daemons --
2022-10-27 10:35:39,812 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:35:44,814 __main__ INFO -- Verifying --
2022-10-27 10:35:44,927 TADA INFO assertion 1, verify set creation by cfg_file: set existed (with correct instance name), passed
2022-10-27 10:35:44,928 TADA INFO assertion 2, verify schema name by cfg_file: verify schema name, passed
2022-10-27 10:35:45,036 TADA INFO assertion 3, verify metrics (events) by cfg_file: verify events (metrics), passed
2022-10-27 10:35:47,159 TADA INFO assertion 4, verify increment counters: verify increment of supported counters, passed
2022-10-27 10:35:47,271 TADA INFO assertion 5, verify cfg_file syntax error report: verify JSON parse error, passed
2022-10-27 10:35:47,389 TADA INFO assertion 6, verify cfg_file unsupported events report: verify unsupported event report, passed
2022-10-27 10:36:09,013 TADA INFO assertion 7, verify cfg_file for many events: each event has either 'sucees' or 'failed' report, passed
2022-10-27 10:36:09,013 __main__ INFO  events succeeded: 77
2022-10-27 10:36:09,013 __main__ INFO  events failed: 114
2022-10-27 10:36:09,013 TADA INFO test syspapi_test ended
2022-10-27 10:36:22 INFO: ----------------------------------------------
2022-10-27 10:36:23 INFO: ======== agg_test ========
2022-10-27 10:36:23 INFO: CMD: python3 agg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/agg_test
2022-10-27 10:36:23,875 TADA INFO starting test `agg_test`
2022-10-27 10:36:23,875 TADA INFO   test-id: 298d0938b51184b601a460b7609dbbf0817eb6129ee69a58c9e7c739e68bc9d2
2022-10-27 10:36:23,875 TADA INFO   test-suite: LDMSD
2022-10-27 10:36:23,875 TADA INFO   test-name: agg_test
2022-10-27 10:36:23,875 TADA INFO   test-user: narate
2022-10-27 10:36:23,875 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:36:23,876 __main__ INFO -- Get or create the cluster --
2022-10-27 10:36:41,503 __main__ INFO -- Start daemons --
2022-10-27 10:36:50,651 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:36:55,657 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 10:36:55,793 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-27 10:36:56,555 TADA INFO assertion 2, meminfo data verification: data verified, passed
2022-10-27 10:36:56,555 __main__ INFO -- Terminating ldmsd on node-1 --
2022-10-27 10:36:58,877 TADA INFO assertion 3, node-1 ldmsd terminated, sets removed from agg-11: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 10:36:59,110 TADA INFO assertion 4, node-1 ldmsd terminated, sets removed from agg-2: list({'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 10:36:59,110 __main__ INFO -- Resurrecting ldmsd on node-1 --
2022-10-27 10:37:04,812 TADA INFO assertion 5, node-1 ldmsd revived, sets added to agg-11: list({'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 10:37:04,920 TADA INFO assertion 6, node-1 ldmsd revived, sets added to agg-2: list({'node-3/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo', 'node-1/meminfo'}), passed
2022-10-27 10:37:04,920 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-27 10:37:07,276 TADA INFO assertion 7, agg-11 ldmsd terminated, sets removed from agg-2: list({'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 10:37:07,399 TADA INFO assertion 8, agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-27 10:37:07,515 TADA INFO assertion 9, agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 10:37:07,515 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-27 10:37:13,199 TADA INFO assertion 10, agg-11 ldmsd revived, sets added to agg-2: list({'node-3/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo', 'node-1/meminfo'}), passed
2022-10-27 10:37:13,199 TADA INFO test agg_test ended
2022-10-27 10:37:28 INFO: ----------------------------------------------
2022-10-27 10:37:29 INFO: ======== failover_test ========
2022-10-27 10:37:29 INFO: CMD: python3 failover_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/failover_test
2022-10-27 10:37:30,210 TADA INFO starting test `failover_test`
2022-10-27 10:37:30,210 TADA INFO   test-id: f6eb024f3712942f56ab506491ed3816a7240ef7570cadbd65f1f9f9ae01f0d1
2022-10-27 10:37:30,210 TADA INFO   test-suite: LDMSD
2022-10-27 10:37:30,210 TADA INFO   test-name: failover_test
2022-10-27 10:37:30,210 TADA INFO   test-user: narate
2022-10-27 10:37:30,210 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:37:30,211 __main__ INFO -- Get or create the cluster --
2022-10-27 10:37:47,825 __main__ INFO -- Start daemons --
2022-10-27 10:37:57,113 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:38:12,129 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 10:38:12,251 TADA INFO assertion 1, 
ldms_ls agg-2: dir result verified, passed
2022-10-27 10:38:13,042 TADA INFO assertion 2, 
meminfo data verification: data verified, passed
2022-10-27 10:38:13,042 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-27 10:38:18,373 TADA INFO assertion 3, 
agg-11 ldmsd terminated, sets added to agg-12: list({'node-1/meminfo', 'node-4/meminfo', 'node-3/meminfo', 'node-2/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 10:38:18,480 TADA INFO assertion 4, 
agg-11 ldmsd terminated, all sets running on agg-2: list({'node-1/meminfo', 'node-4/meminfo', 'node-3/meminfo', 'node-2/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 10:38:18,595 TADA INFO assertion 5, 
agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-27 10:38:18,723 TADA INFO assertion 6, 
agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 10:38:18,723 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-27 10:38:39,403 TADA INFO assertion 7, 
agg-11 ldmsd revived, sets removed from agg-12: list({'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-27 10:38:39,520 TADA INFO assertion 8, 
agg-11 ldmsd revived, all sets running on agg-2: list({'node-1/meminfo', 'node-4/meminfo', 'node-3/meminfo', 'node-2/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 10:38:39,520 __main__ INFO -- Terminating ldmsd on agg-12 --
2022-10-27 10:38:44,877 TADA INFO assertion 9, 
agg-12 ldmsd terminated, sets added to agg-11: list({'node-1/meminfo', 'node-4/meminfo', 'node-3/meminfo', 'node-2/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 10:38:44,988 TADA INFO assertion 10, 
agg-12 ldmsd terminated, all sets running on agg-2: list({'node-1/meminfo', 'node-4/meminfo', 'node-3/meminfo', 'node-2/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 10:38:45,096 TADA INFO assertion 11, 
agg-12 ldmsd terminated, node-2 ldmsd is still running: list({'node-2/meminfo'}) == expect({'node-2/meminfo'}), passed
2022-10-27 10:38:45,200 TADA INFO assertion 12, 
agg-12 ldmsd terminated, node-4 ldmsd is still running: list({'node-4/meminfo'}) == expect({'node-4/meminfo'}), passed
2022-10-27 10:38:45,200 __main__ INFO -- Resurrecting ldmsd on agg-12 --
2022-10-27 10:39:05,895 TADA INFO assertion 13, 
agg-12 ldmsd revived, sets removed from agg-11: list({'node-1/meminfo', 'node-3/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo'}), passed
2022-10-27 10:39:06,002 TADA INFO assertion 14, 
agg-12 ldmsd revived, all sets running on agg-2: list({'node-1/meminfo', 'node-4/meminfo', 'node-3/meminfo', 'node-2/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 10:39:06,002 TADA INFO test failover_test ended
2022-10-27 10:39:21 INFO: ----------------------------------------------
2022-10-27 10:39:22 INFO: ======== ldmsd_auth_ovis_test ========
2022-10-27 10:39:22 INFO: CMD: python3 ldmsd_auth_ovis_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldmsd_auth_ovis_test
2022-10-27 10:39:22,808 TADA INFO starting test `ldmsd_auth_ovis_test`
2022-10-27 10:39:22,808 TADA INFO   test-id: 8a8c3aaee3413b47aceb09fdc3af564a8665e181cc7b5c5cd17b5e4a5ff33a49
2022-10-27 10:39:22,808 TADA INFO   test-suite: LDMSD
2022-10-27 10:39:22,808 TADA INFO   test-name: ldmsd_auth_ovis_test
2022-10-27 10:39:22,808 TADA INFO   test-user: narate
2022-10-27 10:39:22,808 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:39:22,809 __main__ INFO -- Get or create the cluster --
2022-10-27 10:39:28,068 __main__ INFO -- Start daemons --
2022-10-27 10:39:30,020 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:39:35,145 TADA INFO assertion 1, ldms_ls with auth none: verified, passed
2022-10-27 10:39:35,266 TADA INFO assertion 2, ldms_ls with wrong secret: verified, passed
2022-10-27 10:39:35,399 TADA INFO assertion 3, ldms_ls 'dir' with right secret: verified, passed
2022-10-27 10:39:35,685 TADA INFO assertion 4, ldms_ls 'read' with right secret: verified, passed
2022-10-27 10:39:35,685 TADA INFO test ldmsd_auth_ovis_test ended
2022-10-27 10:39:47 INFO: ----------------------------------------------
2022-10-27 10:39:48 INFO: ======== ldmsd_auth_test ========
2022-10-27 10:39:48 INFO: CMD: python3 ldmsd_auth_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldmsd_auth_test
2022-10-27 10:39:48,727 TADA INFO starting test `ldmsd_auth_test`
2022-10-27 10:39:48,727 TADA INFO   test-id: 39af78b5826337300361272e9cf776fe866d1bfafe94b072262ab6b1a81dce42
2022-10-27 10:39:48,727 TADA INFO   test-suite: LDMSD
2022-10-27 10:39:48,727 TADA INFO   test-name: ldmsd_auth_test
2022-10-27 10:39:48,727 TADA INFO   test-user: narate
2022-10-27 10:39:48,728 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:39:48,728 __main__ INFO -- Get or create the cluster --
2022-10-27 10:40:06,748 __main__ INFO -- Start daemons --
2022-10-27 10:40:25,684 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:40:30,811 TADA INFO assertion 1, root@agg-2(dom3) ldms_ls to agg-2:10000: see all sets, passed
2022-10-27 10:40:30,921 TADA INFO assertion 2, user@agg-2(dom3) ldms_ls to agg-2:10000: see only meminfo, passed
2022-10-27 10:40:31,026 TADA INFO assertion 3, root@headnode(dom4) ldms_ls to agg-2:10001: see all sets, passed
2022-10-27 10:40:31,145 TADA INFO assertion 4, user@headnode(dom4) ldms_ls to agg-2:10001: see only meminfo, passed
2022-10-27 10:40:31,259 TADA INFO assertion 5, root@headnode(dom4) ldms_ls to agg-11:10000: connection rejected, passed
2022-10-27 10:40:31,259 TADA INFO test ldmsd_auth_test ended
2022-10-27 10:40:46 INFO: ----------------------------------------------
2022-10-27 10:40:47 INFO: ======== ldmsd_ctrl_test ========
2022-10-27 10:40:47 INFO: CMD: python3 ldmsd_ctrl_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldmsd_ctrl_test
2022-10-27 10:40:48,272 TADA INFO starting test `ldmsd_ctrl_test`
2022-10-27 10:40:48,272 TADA INFO   test-id: 01d2dadc33e6059bed43006592704b1d30014427ea499079b9527f6f0e61566d
2022-10-27 10:40:48,272 TADA INFO   test-suite: LDMSD
2022-10-27 10:40:48,272 TADA INFO   test-name: ldmsd_ctrl_test
2022-10-27 10:40:48,272 TADA INFO   test-user: narate
2022-10-27 10:40:48,272 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:40:48,273 __main__ INFO -- Get or create the cluster --
2022-10-27 10:40:57,510 __main__ INFO -- Start daemons --
2022-10-27 10:41:02,018 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:41:08,139 TADA INFO assertion 1, ldmsd_controller interactive session: connected, passed
2022-10-27 10:41:09,254 TADA INFO assertion 2, ldmsctl interactive session: connected, passed
2022-10-27 10:41:09,856 TADA INFO assertion 3, ldmsd_controller start bogus producer: expected output verified, passed
2022-10-27 10:41:10,457 TADA INFO assertion 4, ldmsctl start bogus producer: expected output verified, passed
2022-10-27 10:41:11,058 TADA INFO assertion 5, ldmsd_controller bogus command: expected output verified, passed
2022-10-27 10:41:11,660 TADA INFO assertion 6, ldmsctl bogus command: expected output verified, passed
2022-10-27 10:41:12,262 TADA INFO assertion 7, ldmsd_controller load bogus plugin: expected output verified, passed
2022-10-27 10:41:12,863 TADA INFO assertion 8, ldmsctl load bogus plugin: expected output verified, passed
2022-10-27 10:41:30,067 TADA INFO assertion 9, ldmsd_controller prdcr/updtr: verified, passed
2022-10-27 10:41:47,268 TADA INFO assertion 10, ldmsctl prdcr/updtr: verified, passed
2022-10-27 10:41:47,269 TADA INFO test ldmsd_ctrl_test ended
2022-10-27 10:41:59 INFO: ----------------------------------------------
2022-10-27 10:42:00 INFO: ======== ldmsd_stream_test ========
2022-10-27 10:42:00 INFO: CMD: python3 ldmsd_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldmsd_stream_test
2022-10-27 10:42:01,484 TADA INFO starting test `ldmsd_stream_test`
2022-10-27 10:42:01,484 TADA INFO   test-id: fa1fa9e9ff4d84f3d398cff35086439ceea61d22f2a08f0926105c17fb6c5406
2022-10-27 10:42:01,484 TADA INFO   test-suite: LDMSD
2022-10-27 10:42:01,484 TADA INFO   test-name: ldmsd_stream_test
2022-10-27 10:42:01,484 TADA INFO   test-user: narate
2022-10-27 10:42:01,484 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:42:12,404 __main__ INFO waiting for libraries to be available across all containers...
2022-10-27 10:42:13,285 __main__ INFO _lib_avail: True
2022-10-27 10:43:20,680 __main__ INFO test ldmsd_stream_subscribe with large json streams
2022-10-27 10:43:26,808 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 10:43:40,282 __main__ INFO --- Verifying the received streams
2022-10-27 10:43:41,922 TADA INFO assertion 1, ldmsd_stream_subscribe receives large json streams: Verify all streams were received correctly, passed
2022-10-27 10:43:42,133 __main__ INFO test LDMSD with large json streams
2022-10-27 10:43:48,227 __main__ INFO --- Sending stream to samplerd
2022-10-27 10:44:07,214 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 10:44:09,625 TADA INFO assertion 2, samplerd receives large json streams: Verify all streams were received correctly, passed
2022-10-27 10:44:09,625 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 10:44:12,039 TADA INFO assertion 3, agg receives large json streams: Verify all streams were received correctly, passed
2022-10-27 10:44:12,039 __main__ INFO test ldmsd_stream_subscribe with small json streams
2022-10-27 10:44:18,151 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 10:46:14,562 __main__ INFO --- Verifying the received streams
2022-10-27 10:46:16,455 TADA INFO assertion 4, ldmsd_stream_subscribe receives small json streams: Verify all streams were received correctly, passed
2022-10-27 10:46:16,681 __main__ INFO test LDMSD with small json streams
2022-10-27 10:46:22,693 __main__ INFO --- Sending stream to samplerd
2022-10-27 10:48:24,044 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 10:48:26,883 TADA INFO assertion 5, samplerd receives small json streams: Verify all streams were received correctly, passed
2022-10-27 10:48:26,883 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 10:48:29,704 TADA INFO assertion 6, agg receives small json streams: Verify all streams were received correctly, passed
2022-10-27 10:48:29,704 __main__ INFO test ldmsd_stream_subscribe with large string streams
2022-10-27 10:48:35,816 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 10:48:49,076 __main__ INFO --- Verifying the received streams
2022-10-27 10:48:50,671 TADA INFO assertion 7, ldmsd_stream_subscribe receives large string streams: Verify all streams were received correctly, passed
2022-10-27 10:48:50,904 __main__ INFO test LDMSD with large string streams
2022-10-27 10:48:56,918 __main__ INFO --- Sending stream to samplerd
2022-10-27 10:49:15,527 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 10:49:16,667 TADA INFO assertion 8, samplerd receives large string streams: Verify all streams were received correctly, passed
2022-10-27 10:49:16,667 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 10:49:17,788 TADA INFO assertion 9, agg receives large string streams: Verify all streams were received correctly, passed
2022-10-27 10:49:17,788 __main__ INFO test ldmsd_stream_subscribe with small string streams
2022-10-27 10:49:23,909 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 10:51:19,802 __main__ INFO --- Verifying the received streams
2022-10-27 10:51:21,751 TADA INFO assertion 10, ldmsd_stream_subscribe receives small string streams: Verify all streams were received correctly, passed
2022-10-27 10:51:21,992 __main__ INFO test LDMSD with small string streams
2022-10-27 10:51:28,043 __main__ INFO --- Sending stream to samplerd
2022-10-27 10:53:29,973 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 10:53:31,158 TADA INFO assertion 11, samplerd receives small string streams: Verify all streams were received correctly, passed
2022-10-27 10:53:31,158 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 10:53:32,336 TADA INFO assertion 12, agg receives small string streams: Verify all streams were received correctly, passed
2022-10-27 10:53:32,337 TADA INFO test ldmsd_stream_test ended
2022-10-27 10:53:46 INFO: ----------------------------------------------
2022-10-27 10:53:47 INFO: ======== maestro_cfg_test ========
2022-10-27 10:53:47 INFO: CMD: python3 maestro_cfg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/maestro_cfg_test
2022-10-27 10:53:48,548 TADA INFO starting test `maestro_cfg_test`
2022-10-27 10:53:48,548 TADA INFO   test-id: a4956b3ec50e74313d8e6e253ad303931a6978652f8adc2ec7eb8849fbe9f1f1
2022-10-27 10:53:48,548 TADA INFO   test-suite: LDMSD
2022-10-27 10:53:48,548 TADA INFO   test-name: maestro_cfg_test
2022-10-27 10:53:48,548 TADA INFO   test-user: narate
2022-10-27 10:53:48,548 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:53:58,557 __main__ INFO -- Get or create cluster --
2022-10-27 10:54:24,410 __main__ INFO -- Start daemons --
2022-10-27 10:54:39,182 __main__ INFO ... make sure ldmsd's are up
2022-10-27 10:54:46,911 TADA INFO assertion 1, load maestro etcd cluster: etcd cluster loaded successfully, passed
2022-10-27 10:55:26,943 TADA INFO assertion 2, config ldmsd cluster with maestro: Maestro ldmsd configuration successful, passed
2022-10-27 10:55:28,499 TADA INFO assertion 3, verify sampler daemons: OK, passed
2022-10-27 10:55:29,078 TADA INFO assertion 4, verify L1 aggregator daemons: OK, passed
2022-10-27 10:55:29,331 TADA INFO assertion 5, verify L2 aggregator daemon: OK, passed
2022-10-27 10:55:29,629 TADA INFO assertion 6, verify data storage: OK, passed
---Wait for config to write to file---
2022-10-27 10:55:29,629 TADA INFO test maestro_cfg_test ended
2022-10-27 10:55:47 INFO: ----------------------------------------------
2022-10-27 10:55:48 INFO: ======== mt-slurm-test ========
2022-10-27 10:55:48 INFO: CMD: python3 mt-slurm-test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/mt-slurm-test
-- Get or create the cluster --
-- Start daemons --
... wait a bit to make sure ldmsd's are up
Every job in input data represented in output: : Passed
['# task_rank,timestamp', '0,1666886188.983948', '1,1666886188.983948', '2,1666886188.983948', '3,1666886188.983948', '4,1666886188.983948', '5,1666886188.983948', '6,1666886188.983948', '7,1666886188.983948', '8,1666886189.949235', '9,1666886190.955085', '10,1666886190.955085', '11,1666886190.955085', '12,1666886190.955085', '13,1666886190.955085', '14,1666886190.955085', '15,1666886191.917581', '16,1666886191.917581', '17,1666886191.917581', '18,1666886192.937345', '19,1666886192.937345', '20,1666886192.937345', '21,1666886192.937345', '22,1666886193.905417', '23,1666886193.905417', '24,1666886193.905417', '25,1666886193.905417', '26,1666886193.905417', '# Records 27/27.', '']
Job 10000 has 27 rank: : Passed
Job 10100 has 64 rank: : Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
Job 10000 has 3 nodes: node count 3 correct: Passed
Job 10100 has 4 nodes: node count 4 correct: Passed
2022-10-27 10:57:07 INFO: ----------------------------------------------
2022-10-27 10:57:08 INFO: ======== ovis_ev_test ========
2022-10-27 10:57:08 INFO: CMD: python3 ovis_ev_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ovis_ev_test
2022-10-27 10:57:08,908 __main__ INFO -- Create the cluster -- 
2022-10-27 10:57:18,168 TADA INFO starting test `ovis_ev_test`
2022-10-27 10:57:18,168 TADA INFO   test-id: d5b0e089bd665c4b446be665174eef37889dbbd957e405e42a00e01df71133ce
2022-10-27 10:57:18,168 TADA INFO   test-suite: test_ovis_ev
2022-10-27 10:57:18,168 TADA INFO   test-name: ovis_ev_test
2022-10-27 10:57:18,169 TADA INFO   test-user: narate
2022-10-27 10:57:18,169 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:57:18,169 TADA INFO assertion 1, Test posting an event without timeout: ovis_ev delivered the expected event., passed
2022-10-27 10:57:18,169 TADA INFO assertion 2, Test posting an event with a current timeout: ovis_ev delivered the expected event., passed
2022-10-27 10:57:18,170 TADA INFO assertion 3, Test posting an event with a future timeout: ovis_ev delivered the expected event., passed
2022-10-27 10:57:18,170 TADA INFO assertion 4, Test reposting a posted event: ev_post returned EBUSY when posted an already posted event, passed
2022-10-27 10:57:18,170 TADA INFO assertion 5, Test canceling a posted event: ovis_ev delivered the expected event., passed
2022-10-27 10:57:18,170 TADA INFO assertion 6, Test rescheduling a posted event: ovis_ev delivered the expected event., passed
2022-10-27 10:57:18,170 TADA INFO assertion 7, Test event deliver order: The event delivery order was correct., passed
2022-10-27 10:57:18,170 TADA INFO assertion 8, Test flushing events: Expected status (1) == delivered status (1), passed
2022-10-27 10:57:18,170 TADA INFO assertion 9, Test posting event on a flushed worker: Expected status (0) == delivered status (0), passed
2022-10-27 10:57:18,171 TADA INFO assertion 10, Test the case that multiple threads post the same event: ev_post returned the expected return code., passed
2022-10-27 10:57:18,171 TADA INFO test ovis_ev_test ended
2022-10-27 10:57:28 INFO: ----------------------------------------------
2022-10-27 10:57:29 INFO: ======== prdcr_subscribe_test ========
2022-10-27 10:57:29 INFO: CMD: python3 prdcr_subscribe_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/prdcr_subscribe_test
2022-10-27 10:57:30,457 TADA INFO starting test `prdcr_subscribe_test`
2022-10-27 10:57:30,457 TADA INFO   test-id: 537512e3f9a37b07001240f255f24833e81c21d24fce5f4c402b8f624703a29a
2022-10-27 10:57:30,457 TADA INFO   test-suite: LDMSD
2022-10-27 10:57:30,457 TADA INFO   test-name: prdcr_subscribe_test
2022-10-27 10:57:30,457 TADA INFO   test-user: narate
2022-10-27 10:57:30,457 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:58:05,901 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-27 10:58:05,902 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-27 10:58:05,902 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-27 10:58:05,902 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-27 10:58:05,903 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verification, passed
2022-10-27 10:58:06,258 TADA INFO assertion 5, Stopping the producers succeeds: , passed
2022-10-27 10:58:06,619 TADA INFO assertion 6, Restarting the producers succeeds: , passed
2022-10-27 10:58:14,600 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-27 10:58:14,601 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-27 10:58:14,601 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-27 10:58:14,601 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-27 10:58:14,602 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verification, passed
2022-10-27 10:58:15,826 TADA INFO assertion 12, stream-sampler-1 is not running: (running == False), passed
2022-10-27 10:58:17,390 TADA INFO assertion 13, stream-sampler-1 has restarted: (running == True), passed
2022-10-27 10:58:24,967 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-27 10:58:24,967 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-27 10:58:24,967 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verification, passed
2022-10-27 10:58:25,333 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: , passed
2022-10-27 10:58:28,641 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-27 10:58:34,456 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-27 10:58:34,457 TADA INFO test prdcr_subscribe_test ended
2022-10-27 10:58:47 INFO: ----------------------------------------------
2022-10-27 10:58:48 INFO: ======== set_array_test ========
2022-10-27 10:58:48 INFO: CMD: python3 set_array_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/set_array_test
2022-10-27 10:58:48,770 TADA INFO starting test `set_array_test`
2022-10-27 10:58:48,771 TADA INFO   test-id: 47e88251aa744cd2448d2869c045d054e9dfcd253d08fe5ae4b89a155210a44f
2022-10-27 10:58:48,771 TADA INFO   test-suite: LDMSD
2022-10-27 10:58:48,771 TADA INFO   test-name: set_array_test
2022-10-27 10:58:48,771 TADA INFO   test-user: narate
2022-10-27 10:58:48,771 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:58:48,772 __main__ INFO -- Get or create the cluster --
2022-10-27 10:58:53,857 __main__ INFO -- Start daemons --
2022-10-27 10:58:55,856 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:59:25,534 TADA INFO assertion 1, 1st update got some callbacks: verified hunk of 1 snapshots, passed
2022-10-27 10:59:25,535 TADA INFO assertion 2, 2nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-27 10:59:25,535 TADA INFO assertion 3, 3nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-27 10:59:25,535 TADA INFO test set_array_test ended
2022-10-27 10:59:36 INFO: ----------------------------------------------
2022-10-27 10:59:37 INFO: ======== setgroup_test ========
2022-10-27 10:59:37 INFO: CMD: python3 setgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/setgroup_test
2022-10-27 10:59:38,466 TADA INFO starting test `setgroup_test`
2022-10-27 10:59:38,467 TADA INFO   test-id: 09681274552eafdbe1d3ab0913c9b82f540ab2988edf8c2e05eb683a2d7b7417
2022-10-27 10:59:38,467 TADA INFO   test-suite: LDMSD
2022-10-27 10:59:38,467 TADA INFO   test-name: setgroup_test
2022-10-27 10:59:38,467 TADA INFO   test-user: narate
2022-10-27 10:59:38,468 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 10:59:38,468 __main__ INFO -- Get or create the cluster --
2022-10-27 10:59:47,766 __main__ INFO -- Start daemons --
2022-10-27 10:59:52,209 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 10:59:57,214 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 10:59:57,329 TADA INFO assertion 1, ldms_ls grp on agg-2: dir result verified, passed
2022-10-27 10:59:59,591 TADA INFO assertion 2, members on agg-2 are being updated: data verified, passed
2022-10-27 10:59:59,591 __main__ INFO -- Removing test_2 from grp --
2022-10-27 11:00:00,062 TADA INFO assertion 3, test_2 is removed fom grp on sampler: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2022-10-27 11:00:04,195 TADA INFO assertion 4, test_2 is removed from grp on agg-1: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2022-10-27 11:00:08,320 TADA INFO assertion 5, test_2 is removed from grp on agg-2: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2022-10-27 11:00:12,325 __main__ INFO -- Adding test_2 back into grp --
2022-10-27 11:00:12,779 TADA INFO assertion 6, test_2 is added back to grp on sampler: expect {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, passed
2022-10-27 11:00:16,912 TADA INFO assertion 7, test_2 is added back to grp on agg-1: expect {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, passed
2022-10-27 11:00:19,052 TADA INFO assertion 8, test_2 is added back to grp on agg-2: expect {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, passed
2022-10-27 11:00:21,054 TADA INFO test setgroup_test ended
2022-10-27 11:00:33 INFO: ----------------------------------------------
2022-10-27 11:00:34 INFO: ======== slurm_stream_test ========
2022-10-27 11:00:34 INFO: CMD: python3 slurm_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/slurm_stream_test
2022-10-27 11:00:35,379 TADA INFO starting test `slurm_stream_test`
2022-10-27 11:00:35,380 TADA INFO   test-id: 7fd3511ebd9a771bd9bb6e76c016300acc795517d03b11ceb3f32aa442ad07ac
2022-10-27 11:00:35,380 TADA INFO   test-suite: LDMSD
2022-10-27 11:00:35,380 TADA INFO   test-name: slurm_stream_test
2022-10-27 11:00:35,380 TADA INFO   test-user: narate
2022-10-27 11:00:35,380 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:00:35,380 __main__ INFO -- Get or create the cluster --
2022-10-27 11:00:42,178 __main__ INFO -- Start daemons --
2022-10-27 11:00:44,815 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 11:01:14,520 TADA INFO assertion 1, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:14,520 __main__ INFO 12345
2022-10-27 11:01:14,520 __main__ INFO 12345
2022-10-27 11:01:14,520 TADA INFO assertion 2, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,520 TADA INFO assertion 3, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-27 11:01:14,520 TADA INFO assertion 4, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,520 TADA INFO assertion 5, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,521 TADA INFO assertion 6, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,521 TADA INFO assertion 7, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,650 TADA INFO assertion 8, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:14,650 __main__ INFO 12345
2022-10-27 11:01:14,651 __main__ INFO 12345
2022-10-27 11:01:14,651 TADA INFO assertion 9, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,651 TADA INFO assertion 10, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-27 11:01:14,651 TADA INFO assertion 11, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,651 TADA INFO assertion 12, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,651 TADA INFO assertion 13, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,651 TADA INFO assertion 14, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 11:01:14,763 TADA INFO assertion 15, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:14,763 __main__ INFO 12346
2022-10-27 11:01:14,763 __main__ INFO 12346
2022-10-27 11:01:14,763 TADA INFO assertion 16, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,763 TADA INFO assertion 17, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-27 11:01:14,764 TADA INFO assertion 18, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,764 TADA INFO assertion 19, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,764 TADA INFO assertion 20, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,764 TADA INFO assertion 21, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,870 TADA INFO assertion 22, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:14,870 __main__ INFO 12346
2022-10-27 11:01:14,870 __main__ INFO 12346
2022-10-27 11:01:14,871 TADA INFO assertion 23, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,871 TADA INFO assertion 24, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-27 11:01:14,871 TADA INFO assertion 25, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,871 TADA INFO assertion 26, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,871 TADA INFO assertion 27, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,871 TADA INFO assertion 28, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 11:01:14,981 TADA INFO assertion 29, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:14,981 __main__ INFO 12347
2022-10-27 11:01:14,981 __main__ INFO 12347
2022-10-27 11:01:14,981 TADA INFO assertion 30, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-27 11:01:14,982 TADA INFO assertion 31, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-27 11:01:14,982 TADA INFO assertion 32, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 11:01:14,982 TADA INFO assertion 33, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 11:01:14,982 TADA INFO assertion 34, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 11:01:14,982 TADA INFO assertion 35, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 11:01:15,092 TADA INFO assertion 36, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,092 __main__ INFO 12347
2022-10-27 11:01:15,092 __main__ INFO 12347
2022-10-27 11:01:15,093 TADA INFO assertion 37, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-27 11:01:15,093 TADA INFO assertion 38, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-27 11:01:15,093 TADA INFO assertion 39, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 11:01:15,093 TADA INFO assertion 40, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 11:01:15,093 TADA INFO assertion 41, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 11:01:15,094 TADA INFO assertion 42, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 11:01:15,205 TADA INFO assertion 43, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,205 __main__ INFO 12348
2022-10-27 11:01:15,205 __main__ INFO 12348
2022-10-27 11:01:15,206 TADA INFO assertion 44, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,206 TADA INFO assertion 45, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-27 11:01:15,206 TADA INFO assertion 46, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,206 TADA INFO assertion 47, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,206 TADA INFO assertion 48, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,206 TADA INFO assertion 49, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,308 TADA INFO assertion 50, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,308 __main__ INFO 12348
2022-10-27 11:01:15,308 __main__ INFO 12348
2022-10-27 11:01:15,308 TADA INFO assertion 51, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,309 TADA INFO assertion 52, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-27 11:01:15,309 TADA INFO assertion 53, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,309 TADA INFO assertion 54, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,309 TADA INFO assertion 55, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,309 TADA INFO assertion 56, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 11:01:15,419 TADA INFO assertion 57, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,419 __main__ INFO 12355
2022-10-27 11:01:15,419 __main__ INFO 12355
2022-10-27 11:01:15,419 TADA INFO assertion 58, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,420 TADA INFO assertion 59, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-27 11:01:15,420 TADA INFO assertion 60, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,420 TADA INFO assertion 61, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,420 TADA INFO assertion 62, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,420 TADA INFO assertion 63, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,420 TADA INFO assertion 64, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,421 TADA INFO assertion 65, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,421 TADA INFO assertion 66, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,421 TADA INFO assertion 67, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,535 TADA INFO assertion 68, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,535 __main__ INFO 12355
2022-10-27 11:01:15,536 __main__ INFO 12355
2022-10-27 11:01:15,536 TADA INFO assertion 69, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,536 TADA INFO assertion 70, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-27 11:01:15,536 TADA INFO assertion 71, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,536 TADA INFO assertion 72, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,536 TADA INFO assertion 73, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,536 TADA INFO assertion 74, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,537 TADA INFO assertion 75, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,537 TADA INFO assertion 76, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,537 TADA INFO assertion 77, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,537 TADA INFO assertion 78, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 11:01:15,653 TADA INFO assertion 79, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,653 __main__ INFO 12356
2022-10-27 11:01:15,653 __main__ INFO 12356
2022-10-27 11:01:15,653 TADA INFO assertion 80, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,653 TADA INFO assertion 81, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-27 11:01:15,654 TADA INFO assertion 82, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,654 TADA INFO assertion 83, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,654 TADA INFO assertion 84, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,654 TADA INFO assertion 85, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,654 TADA INFO assertion 86, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,654 TADA INFO assertion 87, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,654 TADA INFO assertion 88, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,655 TADA INFO assertion 89, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,758 TADA INFO assertion 90, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,758 __main__ INFO 12356
2022-10-27 11:01:15,758 __main__ INFO 12356
2022-10-27 11:01:15,758 TADA INFO assertion 91, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,758 TADA INFO assertion 92, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-27 11:01:15,758 TADA INFO assertion 93, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,758 TADA INFO assertion 94, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,759 TADA INFO assertion 95, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,759 TADA INFO assertion 96, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,759 TADA INFO assertion 97, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,759 TADA INFO assertion 98, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,759 TADA INFO assertion 99, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,759 TADA INFO assertion 100, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 11:01:15,876 TADA INFO assertion 101, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,876 __main__ INFO 12357
2022-10-27 11:01:15,876 __main__ INFO 12357
2022-10-27 11:01:15,876 TADA INFO assertion 102, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,876 TADA INFO assertion 103, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-27 11:01:15,877 TADA INFO assertion 104, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,877 TADA INFO assertion 105, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,877 TADA INFO assertion 106, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,877 TADA INFO assertion 107, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,877 TADA INFO assertion 108, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,877 TADA INFO assertion 109, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,878 TADA INFO assertion 110, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,878 TADA INFO assertion 111, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,983 TADA INFO assertion 112, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:15,983 __main__ INFO 12357
2022-10-27 11:01:15,983 __main__ INFO 12357
2022-10-27 11:01:15,983 TADA INFO assertion 113, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,983 TADA INFO assertion 114, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-27 11:01:15,983 TADA INFO assertion 115, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,984 TADA INFO assertion 116, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,984 TADA INFO assertion 117, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,984 TADA INFO assertion 118, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,984 TADA INFO assertion 119, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,984 TADA INFO assertion 120, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,984 TADA INFO assertion 121, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:15,985 TADA INFO assertion 122, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 11:01:16,094 TADA INFO assertion 123, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:16,094 __main__ INFO 12358
2022-10-27 11:01:16,095 __main__ INFO 12358
2022-10-27 11:01:16,095 TADA INFO assertion 124, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,095 TADA INFO assertion 125, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-27 11:01:16,095 TADA INFO assertion 126, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,095 TADA INFO assertion 127, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,095 TADA INFO assertion 128, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,095 TADA INFO assertion 129, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,096 TADA INFO assertion 130, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,096 TADA INFO assertion 131, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,096 TADA INFO assertion 132, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,096 TADA INFO assertion 133, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,193 TADA INFO assertion 134, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 11:01:16,193 __main__ INFO 12358
2022-10-27 11:01:16,193 __main__ INFO 12358
2022-10-27 11:01:16,193 TADA INFO assertion 135, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,194 TADA INFO assertion 136, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-27 11:01:16,194 TADA INFO assertion 137, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,194 TADA INFO assertion 138, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,194 TADA INFO assertion 139, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,194 TADA INFO assertion 140, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,194 TADA INFO assertion 141, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,194 TADA INFO assertion 142, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,195 TADA INFO assertion 143, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:16,195 TADA INFO assertion 144, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 11:01:18,271 TADA INFO assertion 145, new job correctly replaces oldest slot: correct job_id fills next slot, passed
2022-10-27 11:01:18,272 __main__ INFO 12353
2022-10-27 11:01:18,272 __main__ INFO 12353
2022-10-27 11:01:18,272 TADA INFO assertion 146, new job_start correctly represented in metric set: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,272 TADA INFO assertion 147, new job_end correctly represented in metric set: with mutl jobs running, for Job 12353, passed
2022-10-27 11:01:18,272 TADA INFO assertion 148, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,272 TADA INFO assertion 149, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,272 TADA INFO assertion 150, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,272 TADA INFO assertion 151, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,273 TADA INFO assertion 152, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,273 TADA INFO assertion 153, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,273 TADA INFO assertion 154, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,273 TADA INFO assertion 155, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 11:01:18,273 __main__ INFO -- Test Finished --
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
2022-10-27 11:01:18,274 TADA INFO test slurm_stream_test ended
2022-10-27 11:01:29 INFO: ----------------------------------------------
2022-10-27 11:01:30 INFO: ======== spank_notifier_test ========
2022-10-27 11:01:30 INFO: CMD: python3 spank_notifier_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/spank_notifier_test
2022-10-27 11:01:31,244 TADA INFO starting test `spank_notifier_test`
2022-10-27 11:01:31,244 TADA INFO   test-id: 5ddae419318cc9558b2aa5f8e16c9764acb4790eb465919dd2cee599d36b5810
2022-10-27 11:01:31,244 TADA INFO   test-suite: Slurm_Plugins
2022-10-27 11:01:31,244 TADA INFO   test-name: spank_notifier_test
2022-10-27 11:01:31,244 TADA INFO   test-user: narate
2022-10-27 11:01:31,244 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:01:31,245 __main__ INFO -- Create the cluster --
2022-10-27 11:01:57,138 __main__ INFO -- Cleanup output --
2022-10-27 11:01:57,439 __main__ INFO -- Test bad plugstack config --
2022-10-27 11:01:57,439 __main__ INFO Starting slurm ...
2022-10-27 11:02:11,983 __main__ INFO Starting slurm ... OK
2022-10-27 11:02:32,433 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 11:02:32,551 __main__ INFO   jobid = 1
2022-10-27 11:02:32,739 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 11:02:32,852 __main__ INFO   jobid = 2
2022-10-27 11:02:33,057 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 11:02:33,176 __main__ INFO   jobid = 3
2022-10-27 11:02:33,401 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 11:02:33,519 __main__ INFO   jobid = 4
2022-10-27 11:02:44,215 TADA INFO assertion 60, Bad config does not affect jobs: jobs verified, passed
2022-10-27 11:02:44,215 __main__ INFO Killin slurm ...
2022-10-27 11:02:47,156 __main__ INFO Killin slurm ... OK
2022-10-27 11:03:07,176 __main__ INFO -- Start daemons --
2022-10-27 11:03:17,978 __main__ INFO Starting slurm ... OK
2022-10-27 11:03:38,243 __main__ INFO -- Submitting job with no stream listener --
2022-10-27 11:03:38,465 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-27 11:03:38,576 __main__ INFO   jobid = 5
2022-10-27 11:03:54,554 TADA INFO assertion 0, Missing stream listener on node-1 does not affect job execution: job output file created, passed
2022-10-27 11:03:54,555 TADA INFO assertion 1, Missing stream listener on node-2 does not affect job execution: job output file created, passed
2022-10-27 11:04:00,423 __main__ INFO -- Submitting job with listener --
2022-10-27 11:04:00,642 __main__ INFO -- Submitting job with num_tasks 1 --
2022-10-27 11:04:00,756 __main__ INFO   jobid = 6
2022-10-27 11:04:00,964 __main__ INFO -- Submitting job with num_tasks 2 --
2022-10-27 11:04:01,068 __main__ INFO   jobid = 7
2022-10-27 11:04:01,258 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 11:04:01,368 __main__ INFO   jobid = 8
2022-10-27 11:04:01,565 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-27 11:04:01,693 __main__ INFO   jobid = 9
2022-10-27 11:04:01,893 __main__ INFO -- Submitting job with num_tasks 27 --
2022-10-27 11:04:02,009 __main__ INFO   jobid = 10
2022-10-27 11:04:23,706 __main__ INFO -- Verifying Events --
2022-10-27 11:04:23,706 TADA INFO assertion 2, 1-task job: first event is 'init': `init` verified, passed
2022-10-27 11:04:23,706 TADA INFO assertion 3, 1-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 11:04:23,706 TADA INFO assertion 4, 1-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 11:04:23,707 TADA INFO assertion 5, 1-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 11:04:23,707 TADA INFO assertion 6, 1-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 11:04:23,707 TADA INFO assertion 7, 2-task job: first event is 'init': `init` verified, passed
2022-10-27 11:04:23,707 TADA INFO assertion 8, 2-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 11:04:23,707 TADA INFO assertion 9, 2-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 11:04:23,707 TADA INFO assertion 10, 2-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 11:04:23,708 TADA INFO assertion 11, 2-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 11:04:23,708 TADA INFO assertion 12, 4-task job: first event is 'init': `init` verified, passed
2022-10-27 11:04:23,708 TADA INFO assertion 13, 4-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 11:04:23,708 TADA INFO assertion 14, 4-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 11:04:23,708 TADA INFO assertion 15, 4-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 11:04:23,709 TADA INFO assertion 16, 4-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 11:04:23,709 TADA INFO assertion 17, 8-task job: first event is 'init': `init` verified, passed
2022-10-27 11:04:23,709 TADA INFO assertion 18, 8-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 11:04:23,709 TADA INFO assertion 19, 8-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 11:04:23,709 TADA INFO assertion 20, 8-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 11:04:23,710 TADA INFO assertion 21, 8-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 11:04:23,710 TADA INFO assertion 22, 27-task job: first event is 'init': `init` verified, passed
2022-10-27 11:04:23,710 TADA INFO assertion 23, 27-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 11:04:23,710 TADA INFO assertion 24, 27-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 11:04:23,710 TADA INFO assertion 25, 27-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 11:04:23,711 TADA INFO assertion 26, 27-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 11:04:23,711 __main__ INFO job 6 multi-tenant with dict_keys([7])
2022-10-27 11:04:23,711 __main__ INFO job 10 multi-tenant with dict_keys([7, 6])
2022-10-27 11:04:23,711 __main__ INFO job 10 multi-tenant with dict_keys([8])
2022-10-27 11:04:23,711 __main__ INFO job 10 multi-tenant with dict_keys([9])
2022-10-27 11:04:23,711 __main__ INFO job 10 multi-tenant with dict_keys([9])
2022-10-27 11:04:23,711 TADA INFO assertion 50, Multi-tenant verification: Multi-tenant jobs found, passed
2022-10-27 11:04:23,922 __main__ INFO -- Submitting job that crashes listener --
2022-10-27 11:04:24,039 __main__ INFO   jobid = 11
2022-10-27 11:04:34,256 TADA INFO assertion 51, Killing stream listener does not affect job execution on node-1: job output file created, passed
2022-10-27 11:04:34,360 TADA INFO assertion 52, Killing stream listener does not affect job execution on node-2: job output file created, passed
2022-10-27 11:04:34,361 TADA INFO test spank_notifier_test ended
2022-10-27 11:04:50 INFO: ----------------------------------------------
2022-10-27 11:04:51 INFO: ======== ldms_list_test ========
2022-10-27 11:04:51 INFO: CMD: python3 ldms_list_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldms_list_test
2022-10-27 11:04:52,519 TADA INFO starting test `ldms_list_test`
2022-10-27 11:04:52,519 TADA INFO   test-id: 0400a2919078da2b859306ccc559fcca1b602494ecc85c986532fc43cbc51463
2022-10-27 11:04:52,519 TADA INFO   test-suite: LDMSD
2022-10-27 11:04:52,519 TADA INFO   test-name: ldms_list_test
2022-10-27 11:04:52,519 TADA INFO   test-user: narate
2022-10-27 11:04:52,519 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:04:52,520 __main__ INFO -- Get or create the cluster --
2022-10-27 11:04:55,611 __main__ INFO -- Start daemons --
2022-10-27 11:05:02,013 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 11:05:04,015 __main__ INFO start list_samp.py and list_agg.py interactive sessions
2022-10-27 11:05:10,049 TADA INFO assertion 1, check list_sampler on list_agg.py: OK, passed
2022-10-27 11:05:10,050 TADA INFO assertion 2, (1st update) check set1 on list_samp.py: OK, passed
2022-10-27 11:05:10,050 TADA INFO assertion 3, (1st update) check set3_p on list_samp.py: OK, passed
2022-10-27 11:05:10,050 TADA INFO assertion 4, (1st update)check set3_c on list_samp.py: OK, passed
2022-10-27 11:05:10,051 TADA INFO assertion 5, (1st update)check set1 on list_agg.py: OK, passed
2022-10-27 11:05:10,051 TADA INFO assertion 6, (1st update)check set3_p on list_agg.py: OK, passed
2022-10-27 11:05:10,051 TADA INFO assertion 7, (1st update)check set3_c on list_agg.py: OK, passed
2022-10-27 11:05:10,051 __main__ INFO 2nd sampling on the sampler...
2022-10-27 11:05:17,261 TADA INFO assertion 8, (2nd update) check set1 on list_samp.py: OK, passed
2022-10-27 11:05:17,261 TADA INFO assertion 9, (2nd update) check set3_p on list_samp.py: OK, passed
2022-10-27 11:05:17,261 TADA INFO assertion 10, (2nd update) check set3_c on list_samp.py: OK, passed
2022-10-27 11:05:17,261 __main__ INFO 2nd update on the aggregator...
2022-10-27 11:05:24,471 TADA INFO assertion 11, (2nd update) check set1 on list_agg.py: OK, passed
2022-10-27 11:05:24,471 TADA INFO assertion 12, (2nd update) check set3_p on list_agg.py: OK, passed
2022-10-27 11:05:24,471 TADA INFO assertion 13, (2nd update) check set3_c on list_agg.py: OK, passed
2022-10-27 11:05:24,472 __main__ INFO 3rd sampling on the sampler...
2022-10-27 11:05:31,681 TADA INFO assertion 14, (3rd update) check set1 on list_samp.py: OK, passed
2022-10-27 11:05:31,681 TADA INFO assertion 15, (3rd update) check set3_p on list_samp.py: OK, passed
2022-10-27 11:05:31,682 TADA INFO assertion 16, (3rd update) check set3_c on list_samp.py: OK, passed
2022-10-27 11:05:31,682 __main__ INFO 3rd update on the aggregator...
2022-10-27 11:05:38,891 TADA INFO assertion 17, (3rd update) check set1 on list_agg.py: OK, passed
2022-10-27 11:05:38,892 TADA INFO assertion 18, (3rd update) check set3_p on list_agg.py: OK, passed
2022-10-27 11:05:38,892 TADA INFO assertion 19, (3rd update) check set3_c on list_agg.py: OK, passed
2022-10-27 11:05:38,892 __main__ INFO 4th sampling on the sampler...
2022-10-27 11:05:46,101 TADA INFO assertion 20, (4th update; list uncahnged) check set1 on list_samp.py: OK, passed
2022-10-27 11:05:46,102 TADA INFO assertion 21, (4th update; list uncahnged) check set3_p on list_samp.py: OK, passed
2022-10-27 11:05:46,102 TADA INFO assertion 22, (4th update; list uncahnged) check set3_c on list_samp.py: OK, passed
2022-10-27 11:05:46,102 __main__ INFO 4th update on the aggregator...
2022-10-27 11:05:53,311 TADA INFO assertion 23, (4th update; list uncahnged) check set1 on list_agg.py: OK, passed
2022-10-27 11:05:53,312 TADA INFO assertion 24, (4th update; list uncahnged) check set3_p on list_agg.py: OK, passed
2022-10-27 11:05:53,312 TADA INFO assertion 25, (4th update; list uncahnged) check set3_c on list_agg.py: OK, passed
2022-10-27 11:05:53,312 __main__ INFO 5th sampling on the sampler...
2022-10-27 11:06:00,521 TADA INFO assertion 26, (5th update; list del) check set1 on list_samp.py: OK, passed
2022-10-27 11:06:00,522 TADA INFO assertion 27, (5th update; list del) check set3_p on list_samp.py: OK, passed
2022-10-27 11:06:00,522 TADA INFO assertion 28, (5th update; list del) check set3_c on list_samp.py: OK, passed
2022-10-27 11:06:00,522 __main__ INFO 5th update on the aggregator...
2022-10-27 11:06:07,732 TADA INFO assertion 29, (5th update; list del) check set1 on list_agg.py: OK, passed
2022-10-27 11:06:07,732 TADA INFO assertion 30, (5th update; list del) check set3_p on list_agg.py: OK, passed
2022-10-27 11:06:07,732 TADA INFO assertion 31, (5th update; list del) check set3_c on list_agg.py: OK, passed
2022-10-27 11:06:07,732 __main__ INFO 6th sampling on the sampler...
2022-10-27 11:06:14,942 TADA INFO assertion 32, (6th update; list unchanged) check set1 on list_samp.py: OK, passed
2022-10-27 11:06:14,942 TADA INFO assertion 33, (6th update; list unchanged) check set3_p on list_samp.py: OK, passed
2022-10-27 11:06:14,942 TADA INFO assertion 34, (6th update; list unchanged) check set3_c on list_samp.py: OK, passed
2022-10-27 11:06:14,942 __main__ INFO 6th update on the updator...
2022-10-27 11:06:22,152 TADA INFO assertion 35, (6th update; list unchanged) check set1 on list_agg.py: OK, passed
2022-10-27 11:06:22,152 TADA INFO assertion 36, (6th update; list unchanged) check set3_p on list_agg.py: OK, passed
2022-10-27 11:06:22,152 TADA INFO assertion 37, (6th update; list unchanged) check set3_c on list_agg.py: OK, passed
2022-10-27 11:06:22,153 TADA INFO test ldms_list_test ended
2022-10-27 11:06:32 INFO: ----------------------------------------------
2022-10-27 11:06:33 INFO: ======== quick_set_add_rm_test ========
2022-10-27 11:06:33 INFO: CMD: python3 quick_set_add_rm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/quick_set_add_rm_test
2022-10-27 11:06:34,419 TADA INFO starting test `quick_set_add_rm_test`
2022-10-27 11:06:34,419 TADA INFO   test-id: 9bb6022c9d0b266eea5745773d83d70be6c00461341185cd23b9cec9ecd7ecb0
2022-10-27 11:06:34,419 TADA INFO   test-suite: LDMSD
2022-10-27 11:06:34,419 TADA INFO   test-name: quick_set_add_rm_test
2022-10-27 11:06:34,419 TADA INFO   test-user: narate
2022-10-27 11:06:34,419 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:06:34,420 __main__ INFO -- Get or create the cluster --
2022-10-27 11:06:41,879 __main__ INFO -- Start samp.py --
2022-10-27 11:06:46,995 TADA INFO assertion 1, start samp.py: prompt checked, passed
2022-10-27 11:06:46,995 __main__ INFO -- Start daemons --
2022-10-27 11:06:54,777 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 11:07:00,368 TADA INFO assertion 2, verify data: verified, passed
2022-10-27 11:07:04,942 TADA INFO assertion 3, samp.py adds set1 / verify data: verified, passed
2022-10-27 11:07:09,521 TADA INFO assertion 4, samp.py removes set1 / verify data: verified, passed
2022-10-27 11:07:14,127 TADA INFO assertion 5, samp.py quickly adds and removes set2 / verify data: verified, passed
2022-10-27 11:07:19,240 TADA INFO assertion 6, agg-1 log stays empty: verified, passed
2022-10-27 11:07:19,240 TADA INFO test quick_set_add_rm_test ended
2022-10-27 11:07:31 INFO: ----------------------------------------------
2022-10-27 11:07:32 INFO: ======== set_array_hang_test ========
2022-10-27 11:07:32 INFO: CMD: python3 set_array_hang_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/set_array_hang_test
2022-10-27 11:07:32,890 TADA INFO starting test `set_array_hang_test`
2022-10-27 11:07:32,890 TADA INFO   test-id: 3ee9a6f2e1b2a951ff4e9a0f0a5341b506bf7b515a13e8fcb4b34dc3653c0501
2022-10-27 11:07:32,890 TADA INFO   test-suite: LDMSD
2022-10-27 11:07:32,890 TADA INFO   test-name: set_array_hang_test
2022-10-27 11:07:32,890 TADA INFO   test-user: narate
2022-10-27 11:07:32,890 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:07:32,891 __main__ INFO -- Get or create the cluster --
2022-10-27 11:07:35,997 __main__ INFO -- Start processes --
2022-10-27 11:07:35,997 __main__ INFO starting interactive set_array_samp.py
2022-10-27 11:07:39,012 TADA INFO assertion 1, start set_array_samp.py: data verified, passed
2022-10-27 11:07:42,028 TADA INFO assertion 2, start set_array_agg.py: data verified, passed
2022-10-27 11:07:49,238 TADA INFO assertion 3, agg update before the 1st sample: data verified, passed
2022-10-27 11:07:56,448 TADA INFO assertion 4, sampling 2 times then agg update: data verified, passed
2022-10-27 11:08:00,053 TADA INFO assertion 5, agg update w/o new sampling: data verified, passed
2022-10-27 11:08:07,262 TADA INFO assertion 6, sampling 5 times then agg update: data verified, passed
2022-10-27 11:08:07,263 TADA INFO test set_array_hang_test ended
2022-10-27 11:08:17 INFO: ----------------------------------------------
2022-10-27 11:08:18 INFO: ======== ldmsd_autointerval_test ========
2022-10-27 11:08:18 INFO: CMD: python3 ldmsd_autointerval_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldmsd_autointerval_test
2022-10-27 11:08:19,546 TADA INFO starting test `ldmsd_autointerval_test`
2022-10-27 11:08:19,546 TADA INFO   test-id: d85fef83e44c64ee28a99825021d3529ab3124a024c8eff122d4a1de42716b70
2022-10-27 11:08:19,546 TADA INFO   test-suite: LDMSD
2022-10-27 11:08:19,547 TADA INFO   test-name: ldmsd_autointerval_test
2022-10-27 11:08:19,547 TADA INFO   test-user: narate
2022-10-27 11:08:19,547 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:08:19,547 __main__ INFO -- Get or create the cluster --
2022-10-27 11:08:27,052 __main__ INFO -- Start daemons --
2022-10-27 11:08:30,822 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 11:08:37,341 TADA INFO assertion 1, start all daemons and interactive controller: OK, passed
2022-10-27 11:08:39,563 TADA INFO assertion 2, verify sampling interval and update hints: verified, passed
2022-10-27 11:08:39,563 __main__ INFO Let them run for a while to collect data ...
2022-10-27 11:08:49,574 __main__ INFO Setting sample interval to 1000000 ...
2022-10-27 11:08:57,827 TADA INFO assertion 3, set and verify 2nd sampling interval / update hints: verified, passed
2022-10-27 11:08:57,827 __main__ INFO Let them run for a while to collect data ...
2022-10-27 11:09:07,838 __main__ INFO Setting sample interval to 2000000 ...
2022-10-27 11:09:16,099 TADA INFO assertion 4, set and verify 3rd sampling interval / update hints: verified, passed
2022-10-27 11:09:16,099 __main__ INFO Let them run for a while to collect data ...
2022-10-27 11:09:26,345 TADA INFO assertion 5, verify SOS data: timestamp differences in SOS show all 3 intervals, passed
2022-10-27 11:09:26,477 TADA INFO assertion 6, verify 'oversampled' in the agg2 log: OK, passed
2022-10-27 11:09:26,477 TADA INFO test ldmsd_autointerval_test ended
2022-10-27 11:09:38 INFO: ----------------------------------------------
2022-10-27 11:09:39 INFO: ======== ldms_record_test ========
2022-10-27 11:09:39 INFO: CMD: python3 ldms_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldms_record_test
2022-10-27 11:09:40,119 TADA INFO starting test `ldms_record_test`
2022-10-27 11:09:40,119 TADA INFO   test-id: a07ffd29ca053019baa52538dc33a6f4e99972b1d01710f2afc0afc3cdc31b44
2022-10-27 11:09:40,119 TADA INFO   test-suite: LDMSD
2022-10-27 11:09:40,119 TADA INFO   test-name: ldms_record_test
2022-10-27 11:09:40,119 TADA INFO   test-user: narate
2022-10-27 11:09:40,120 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:09:40,120 __main__ INFO -- Get or create the cluster --
2022-10-27 11:09:43,257 __main__ INFO -- Start daemons --
2022-10-27 11:09:49,632 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 11:09:51,634 __main__ INFO start record_samp.py and record_agg.py interactive sessions
2022-10-27 11:09:57,671 TADA INFO assertion 1, check record_sampler on record_agg.py: OK, passed
2022-10-27 11:09:57,671 TADA INFO assertion 2, (1st update) check set1 on record_samp.py: OK, passed
2022-10-27 11:09:57,671 TADA INFO assertion 3, (1st update) check set3_p on record_samp.py: OK, passed
2022-10-27 11:09:57,672 TADA INFO assertion 4, (1st update) check set3_c on record_samp.py: OK, passed
2022-10-27 11:09:57,672 TADA INFO assertion 5, (1st update) check set1 on record_agg.py: OK, passed
2022-10-27 11:09:57,672 TADA INFO assertion 6, (1st update) check set3_p on record_agg.py: OK, passed
2022-10-27 11:09:57,672 TADA INFO assertion 7, (1st update) check set3_c on record_agg.py: OK, passed
2022-10-27 11:09:57,673 __main__ INFO 2nd sampling on the sampler...
2022-10-27 11:10:04,882 TADA INFO assertion 8, (2nd update) check set1 on record_samp.py: OK, passed
2022-10-27 11:10:04,882 TADA INFO assertion 9, (2nd update) check set3_p on record_samp.py: OK, passed
2022-10-27 11:10:04,883 TADA INFO assertion 10, (2nd update) check set3_c on record_samp.py: OK, passed
2022-10-27 11:10:04,883 __main__ INFO 2nd update on the aggregator...
2022-10-27 11:10:12,092 TADA INFO assertion 11, (2nd update) check set1 on record_agg.py: OK, passed
2022-10-27 11:10:12,093 TADA INFO assertion 12, (2nd update) check set3_p on record_agg.py: OK, passed
2022-10-27 11:10:12,093 TADA INFO assertion 13, (2nd update) check set3_c on record_agg.py: OK, passed
2022-10-27 11:10:12,093 __main__ INFO 3rd sampling on the sampler...
2022-10-27 11:10:19,302 TADA INFO assertion 14, (3rd update) check set1 on record_samp.py: OK, passed
2022-10-27 11:10:19,303 TADA INFO assertion 15, (3rd update) check set3_p on record_samp.py: OK, passed
2022-10-27 11:10:19,303 TADA INFO assertion 16, (3rd update) check set3_c on record_samp.py: OK, passed
2022-10-27 11:10:19,303 __main__ INFO 3rd update on the aggregator...
2022-10-27 11:10:26,513 TADA INFO assertion 17, (3rd update) check set1 on record_agg.py: OK, passed
2022-10-27 11:10:26,513 TADA INFO assertion 18, (3rd update) check set3_p on record_agg.py: OK, passed
2022-10-27 11:10:26,514 TADA INFO assertion 19, (3rd update) check set3_c on record_agg.py: OK, passed
2022-10-27 11:10:26,514 __main__ INFO 4th sampling on the sampler...
2022-10-27 11:10:33,723 TADA INFO assertion 20, (4th update; record uncahnged) check set1 on record_samp.py: OK, passed
2022-10-27 11:10:33,723 TADA INFO assertion 21, (4th update; record uncahnged) check set3_p on record_samp.py: OK, passed
2022-10-27 11:10:33,723 TADA INFO assertion 22, (4th update; record uncahnged) check set3_c on record_samp.py: OK, passed
2022-10-27 11:10:33,723 __main__ INFO 4th update on the aggregator...
2022-10-27 11:10:40,932 TADA INFO assertion 23, (4th update; record uncahnged) check set1 on record_agg.py: OK, passed
2022-10-27 11:10:40,932 TADA INFO assertion 24, (4th update; record uncahnged) check set3_p on record_agg.py: OK, passed
2022-10-27 11:10:40,933 TADA INFO assertion 25, (4th update; record uncahnged) check set3_c on record_agg.py: OK, passed
2022-10-27 11:10:40,933 __main__ INFO 5th sampling on the sampler...
2022-10-27 11:10:48,142 TADA INFO assertion 26, (5th update; record del) check set1 on record_samp.py: OK, passed
2022-10-27 11:10:48,142 TADA INFO assertion 27, (5th update; record del) check set3_p on record_samp.py: OK, passed
2022-10-27 11:10:48,143 TADA INFO assertion 28, (5th update; record del) check set3_c on record_samp.py: OK, passed
2022-10-27 11:10:48,143 __main__ INFO 5th update on the aggregator...
2022-10-27 11:10:55,352 TADA INFO assertion 29, (5th update; record del) check set1 on record_agg.py: OK, passed
2022-10-27 11:10:55,352 TADA INFO assertion 30, (5th update; record del) check set3_p on record_agg.py: OK, passed
2022-10-27 11:10:55,353 TADA INFO assertion 31, (5th update; record del) check set3_c on record_agg.py: OK, passed
2022-10-27 11:10:55,353 __main__ INFO 6th sampling on the sampler...
2022-10-27 11:11:02,562 TADA INFO assertion 32, (6th update; record unchanged) check set1 on record_samp.py: OK, passed
2022-10-27 11:11:02,563 TADA INFO assertion 33, (6th update; record unchanged) check set3_p on record_samp.py: OK, passed
2022-10-27 11:11:02,563 TADA INFO assertion 34, (6th update; record unchanged) check set3_c on record_samp.py: OK, passed
2022-10-27 11:11:02,563 __main__ INFO 6th update on the updator...
2022-10-27 11:11:09,772 TADA INFO assertion 35, (6th update; record unchanged) check set1 on record_agg.py: OK, passed
2022-10-27 11:11:09,773 TADA INFO assertion 36, (6th update; record unchanged) check set3_p on record_agg.py: OK, passed
2022-10-27 11:11:09,773 TADA INFO assertion 37, (6th update; record unchanged) check set3_c on record_agg.py: OK, passed
2022-10-27 11:11:09,773 TADA INFO test ldms_record_test ended
2022-10-27 11:11:20 INFO: ----------------------------------------------
2022-10-27 11:11:21 INFO: ======== ldms_schema_digest_test ========
2022-10-27 11:11:21 INFO: CMD: python3 ldms_schema_digest_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldms_schema_digest_test
2022-10-27 11:11:22,090 TADA INFO starting test `ldms_schema_digest_test`
2022-10-27 11:11:22,090 TADA INFO   test-id: 026504f16a7bb96fc3119796d117e028eb89ad9d9775d46d9f35669afc44305e
2022-10-27 11:11:22,090 TADA INFO   test-suite: LDMSD
2022-10-27 11:11:22,090 TADA INFO   test-name: ldms_schema_digest_test
2022-10-27 11:11:22,090 TADA INFO   test-user: narate
2022-10-27 11:11:22,091 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:11:22,091 __main__ INFO -- Get or create the cluster --
2022-10-27 11:11:29,412 __main__ INFO -- Start daemons --
2022-10-27 11:11:32,576 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 11:11:37,692 TADA INFO assertion 1, No schema digest from ldms_ls -v sampler: verified, passed
2022-10-27 11:11:37,801 TADA INFO assertion 2, Schema digest from ldms_ls -vv sampler is not empty: verified, passed
2022-10-27 11:11:37,925 TADA INFO assertion 3, Schema digest from ldms_ls -vv agg-1 is not empty: verified, passed
2022-10-27 11:11:38,107 TADA INFO assertion 4, Schema digest from Python ldms dir agg-1 is not empty: verified, passed
2022-10-27 11:11:38,107 TADA INFO assertion 5, Schema digest from Python ldms lokoup agg-1 is not empty: verified, passed
2022-10-27 11:11:38,108 TADA INFO assertion 6, All digests of the same set are the same: , passed
2022-10-27 11:11:40,520 TADA INFO assertion 7, Sets of same schema yield the same digest: check, passed
2022-10-27 11:11:40,520 TADA INFO assertion 8, Different schema (1-off metric) yield different digest: check, passed
2022-10-27 11:11:40,520 TADA INFO test ldms_schema_digest_test ended
2022-10-27 11:11:52 INFO: ----------------------------------------------
2022-10-27 11:11:53 INFO: ======== ldmsd_decomp_test ========
2022-10-27 11:11:53 INFO: CMD: python3 ldmsd_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldmsd_decomp_test
2022-10-27 11:11:54,490 TADA INFO starting test `ldmsd_decomp_test`
2022-10-27 11:11:54,491 TADA INFO   test-id: 0e1481546b750f7e5561d5113f50f50c8db91703c51e942b1a03eb41dfb141cf
2022-10-27 11:11:54,491 TADA INFO   test-suite: LDMSD
2022-10-27 11:11:54,491 TADA INFO   test-name: ldmsd_decomp_test
2022-10-27 11:11:54,491 TADA INFO   test-user: narate
2022-10-27 11:11:54,491 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:11:54,492 __main__ INFO -- Get or create the cluster --
2022-10-27 11:12:10,453 __main__ INFO -- Start daemons --
2022-10-27 11:12:20,770 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 11:13:15,554 TADA INFO assertion 1, `as_is` decomposition, test_sampler_8d2b8bd sos schema check: OK, passed
2022-10-27 11:13:15,554 TADA INFO assertion 2, `as_is` decomposition, test_sampler_95772b6 sos schema check: OK, passed
2022-10-27 11:13:15,554 TADA INFO assertion 3, `as_is` decomposition, record_sampler_e1f021f sos schema check: OK, passed
2022-10-27 11:13:15,554 TADA INFO assertion 4, `static` decomposition, fill sos schema check: OK, passed
2022-10-27 11:13:15,555 TADA INFO assertion 5, `static` decomposition, filter sos schema check: OK, passed
2022-10-27 11:13:15,555 TADA INFO assertion 6, `static` decomposition, record sos schema check: OK, passed
2022-10-27 11:13:15,555 TADA INFO assertion 7, `as_is` decomposition, test_sampler_8d2b8bd csv schema check: OK, passed
2022-10-27 11:13:15,555 TADA INFO assertion 8, `as_is` decomposition, test_sampler_95772b6 csv schema check: OK, passed
2022-10-27 11:13:15,555 TADA INFO assertion 9, `as_is` decomposition, record_sampler_e1f021f csv schema check: OK, passed
2022-10-27 11:13:15,555 TADA INFO assertion 10, `static` decomposition, fill csv schema check: OK, passed
2022-10-27 11:13:15,555 TADA INFO assertion 11, `static` decomposition, filter csv schema check: OK, passed
2022-10-27 11:13:15,556 TADA INFO assertion 12, `static` decomposition, record csv schema check: OK, passed
2022-10-27 11:13:15,556 TADA INFO assertion 13, `as_is` decomposition, test_sampler_8d2b8bd kafka schema check: OK, passed
2022-10-27 11:13:15,556 TADA INFO assertion 14, `as_is` decomposition, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-27 11:13:15,556 TADA INFO assertion 15, `as_is` decomposition, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-27 11:13:15,556 TADA INFO assertion 16, `static` decomposition, fill kafka schema check: OK, passed
2022-10-27 11:13:15,556 TADA INFO assertion 17, `static` decomposition, filter kafka schema check: OK, passed
2022-10-27 11:13:15,557 TADA INFO assertion 18, `static` decomposition, record kafka schema check: OK, passed
2022-10-27 11:13:15,558 TADA INFO assertion 19, `as_is` decomposition, test_sampler_8d2b8bd sos data check: OK, passed
2022-10-27 11:13:15,560 TADA INFO assertion 20, `as_is` decomposition, test_sampler_95772b6 sos data check: OK, passed
2022-10-27 11:13:15,633 TADA INFO assertion 21, `as_is` decomposition, record_sampler_e1f021f sos data check: OK, passed
2022-10-27 11:13:15,637 TADA INFO assertion 22, `static` decomposition, fill sos data check: OK, passed
2022-10-27 11:13:15,640 TADA INFO assertion 23, `static` decomposition, filter sos data check: OK, passed
2022-10-27 11:13:15,648 TADA INFO assertion 24, `static` decomposition, record sos data check: OK, passed
2022-10-27 11:13:15,650 TADA INFO assertion 25, `as_is` decomposition, test_sampler_8d2b8bd csv data check: OK, passed
2022-10-27 11:13:15,651 TADA INFO assertion 26, `as_is` decomposition, test_sampler_95772b6 csv data check: OK, passed
2022-10-27 11:13:15,721 TADA INFO assertion 27, `as_is` decomposition, record_sampler_e1f021f csv data check: OK, passed
2022-10-27 11:13:15,725 TADA INFO assertion 28, `static` decomposition, fill csv data check: OK, passed
2022-10-27 11:13:15,728 TADA INFO assertion 29, `static` decomposition, filter csv data check: OK, passed
2022-10-27 11:13:15,735 TADA INFO assertion 30, `static` decomposition, record csv data check: OK, passed
2022-10-27 11:13:15,736 TADA INFO assertion 31, `as_is` decomposition, test_sampler_8d2b8bd kafka data check: OK, passed
2022-10-27 11:13:15,737 TADA INFO assertion 32, `as_is` decomposition, test_sampler_95772b6 kafka data check: OK, passed
2022-10-27 11:13:15,764 TADA INFO assertion 33, `as_is` decomposition, record_sampler_e1f021f kafka data check: OK, passed
2022-10-27 11:13:15,766 TADA INFO assertion 34, `static` decomposition, fill kafka data check: OK, passed
2022-10-27 11:13:15,768 TADA INFO assertion 35, `static` decomposition, filter kafka data check: OK, passed
2022-10-27 11:13:15,772 TADA INFO assertion 36, `static` decomposition, record kafka data check: OK, passed
2022-10-27 11:13:15,772 TADA INFO test ldmsd_decomp_test ended
2022-10-27 11:13:15,772 TADA INFO test ldmsd_decomp_test ended
2022-10-27 11:13:30 INFO: ----------------------------------------------
2022-10-27 11:13:31 INFO: ======== ldmsd_stream_dir_test ========
2022-10-27 11:13:31 INFO: CMD: python3 ldmsd_stream_dir_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldmsd_stream_dir_test
2022-10-27 11:13:32,538 __main__ INFO -- Get or create the cluster --
2022-10-27 11:13:32,538 TADA INFO starting test `ldmsd_stream_dir`
2022-10-27 11:13:32,538 TADA INFO   test-id: afbb5908d1973a09b4c6c299128ff3ab1ed939978b3278a345dc48efa202584c
2022-10-27 11:13:32,538 TADA INFO   test-suite: LDMSD
2022-10-27 11:13:32,538 TADA INFO   test-name: ldmsd_stream_dir
2022-10-27 11:13:32,538 TADA INFO   test-user: narate
2022-10-27 11:13:32,539 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:13:41,161 __main__ INFO -- Start daemons --
2022-10-27 11:13:44,902 __main__ INFO waiting ... for all LDMSDs to start
2022-10-27 11:13:45,222 __main__ INFO All LDMSDs are up.
2022-10-27 11:13:46,465 TADA INFO assertion 1, No Stream data: {} == {}, passed
2022-10-27 11:13:47,815 TADA INFO assertion 2, stream_dir -- one stream message: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666887226, 'last_ts': 1666887226, 'count': 1, 'total_bytes': 6}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666887226, 'last_ts': 1666887226, 'count': 1, 'total_bytes': 6}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1666887226, 'last_ts': 1666887226}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1666887226, 'last_ts': 1666887226}}}, passed
2022-10-27 11:13:50,263 TADA INFO assertion 3, stream_dir --  multiple stream messages: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666887226, 'last_ts': 1666887229, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666887226, 'last_ts': 1666887229, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666887226, 'last_ts': 1666887229, 'bytes/sec': 6.0, 'msg/sec': 1.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666887226, 'last_ts': 1666887229, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, passed
2022-10-27 11:13:51,484 TADA INFO assertion 4, prdcr_stream_dir to agg -- one producer: {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666887229, 'first_ts': 1666887226, 'bytes/sec': 6.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666887229, 'first_ts': 1666887226, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666887226, 'last_ts': 1666887229, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666887226, 'last_ts': 1666887229, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}}, passed
2022-10-27 11:13:55,305 TADA INFO assertion 5, stream_dir -- mulitple streams: {'bar': {'mode': 'not subscribed', 'info': {'first_ts': 1666887232, 'last_ts': 1666887234, 'count': 3, 'total_bytes': 48, 'msg/sec': 1.5, 'bytes/sec': 24.0}, 'publishers': {}}, 'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666887231, 'last_ts': 1666887232, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666887231, 'last_ts': 1666887234, 'count': 5, 'total_bytes': 60, 'msg/sec': 1.666667, 'bytes/sec': 20.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666887231, 'last_ts': 1666887232, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {}}, 'bar': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1666887232, 'last_ts': 1666887234, 'bytes/sec': 24.0, 'msg/sec': 1.5}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1666887231, 'last_ts': 1666887234, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}, passed
2022-10-27 11:13:56,539 TADA INFO assertion 6, prdcr_stream_dir to agg -- two producers: {'foo': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 2.0, 'total_bytes': 12, 'last_ts': 1666887232, 'first_ts': 1666887231, 'bytes/sec': 12.0, 'count': 2}}, 'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666887229, 'first_ts': 1666887226, 'bytes/sec': 6.0, 'count': 3}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 1.5, 'total_bytes': 48, 'last_ts': 1666887234, 'first_ts': 1666887232, 'bytes/sec': 24.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-2': {'info': {'msg/sec': 1.666667, 'total_bytes': 60, 'last_ts': 1666887234, 'first_ts': 1666887231, 'bytes/sec': 20.0, 'count': 5}}, 'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666887229, 'first_ts': 1666887226, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666887226, 'last_ts': 1666887229, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666887231, 'last_ts': 1666887232, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1666887232, 'last_ts': 1666887234, 'bytes/sec': 24.0, 'msg/sec': 1.5}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666887226, 'last_ts': 1666887229, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1666887231, 'last_ts': 1666887234, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}}, passed
2022-10-27 11:14:00,214 TADA INFO assertion 7, stream_dir to agg after one producer republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666887237, 'last_ts': 1666887238, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1666887237, 'last_ts': 1666887238, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}}}, '_AGGREGATED_': {'info': {'first_ts': 1666887237, 'last_ts': 1666887238, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666887237, 'last_ts': 1666887238, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666887237, 'last_ts': 1666887238, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}}, '_AGGREGATED_': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666887237, 'last_ts': 1666887238, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, passed
2022-10-27 11:14:01,787 TADA INFO assertion 8, stream_dir to agg after two producers republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666887237, 'last_ts': 1666887240, 'count': 5, 'total_bytes': 30, 'msg/sec': 1.666667, 'bytes/sec': 10.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1666887237, 'last_ts': 1666887238, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}, 'samplerd-2': {'info': {'first_ts': 1666887240, 'last_ts': 1666887240, 'count': 3, 'total_bytes': 18}}}}, '_AGGREGATED_': {'info': {'first_ts': 1666887237, 'last_ts': 1666887240, 'count': 5, 'total_bytes': 30, 'msg/sec': 1.666667, 'bytes/sec': 10.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1666887237, 'last_ts': 1666887240, 'bytes/sec': 10.0, 'msg/sec': 1.666667}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666887237, 'last_ts': 1666887238, 'bytes/sec': 12.0, 'msg/sec': 2.0}}, 'samplerd-2': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666887240, 'last_ts': 1666887240}}}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1666887237, 'last_ts': 1666887240, 'bytes/sec': 10.0, 'msg/sec': 1.666667}}}, passed
2022-10-27 11:14:01,788 TADA INFO test ldmsd_stream_dir ended
2022-10-27 11:14:13 INFO: ----------------------------------------------
2022-10-27 11:14:14 INFO: ======== store_list_record_test ========
2022-10-27 11:14:14 INFO: CMD: python3 store_list_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/store_list_record_test
2022-10-27 11:14:15,438 __main__ INFO -- Get or create the cluster --
2022-10-27 11:14:15,438 TADA INFO starting test `store_sos_lists_test`
2022-10-27 11:14:15,438 TADA INFO   test-id: a55f28b96711b7508699578010c161087ea6e8293d8b20b9c3dddf6bc680025a
2022-10-27 11:14:15,438 TADA INFO   test-suite: LDMSD
2022-10-27 11:14:15,438 TADA INFO   test-name: store_sos_lists_test
2022-10-27 11:14:15,438 TADA INFO   test-user: narate
2022-10-27 11:14:15,439 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:14:22,886 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:14:26,771 __main__ INFO All sampler daemons are up.
2022-10-27 11:14:26,875 TADA INFO assertion 1, aggregator with store_sos has started properly.: agg_sos.check_ldmsd(), passed
2022-10-27 11:14:26,987 TADA INFO assertion 2, aggregator with store_csv has started properly.: agg_csv.check_ldmsd(), passed
2022-10-27 11:14:39,321 TADA INFO assertion 3, store_sos is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-27 11:14:42,633 TADA INFO assertion 4, store_sos stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-27 11:14:51,469 TADA INFO assertion 5, store_sos stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-27 11:14:52,874 TADA INFO assertion 6, store_csv is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-27 11:15:04,049 TADA INFO assertion 7, store_csv stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-27 11:15:13,721 TADA INFO assertion 8, store_csv stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-27 11:15:13,722 TADA INFO test store_sos_lists_test ended
2022-10-27 11:15:27 INFO: ----------------------------------------------
2022-10-27 11:15:28 INFO: ======== maestro_raft_test ========
2022-10-27 11:15:28 INFO: CMD: python3 maestro_raft_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/maestro_raft_test
2022-10-27 11:15:28,923 TADA INFO starting test `maestro_raft_test`
2022-10-27 11:15:28,923 TADA INFO   test-id: daa684e8247fc4171c4c61812c36771cb9a8340373a5fdf202d48b9b261e1378
2022-10-27 11:15:28,923 TADA INFO   test-suite: LDMSD
2022-10-27 11:15:28,923 TADA INFO   test-name: maestro_raft_test
2022-10-27 11:15:28,924 TADA INFO   test-user: narate
2022-10-27 11:15:28,924 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:15:38,935 __main__ INFO -- Get or create cluster --
2022-10-27 11:16:13,560 __main__ INFO -- Start daemons --
2022-10-27 11:17:24,363 __main__ INFO -- making known hosts (ssh) --
2022-10-27 11:17:31,311 __main__ INFO ... make sure ldmsd's are up
2022-10-27 11:17:47,584 TADA INFO assertion 1, Statuses of maestros, 1 leader + 2 followers: [('FOLLOWER', 2), ('LEADER', 1)], passed
2022-10-27 11:17:59,952 TADA INFO assertion 2, All ldmsds are up and configured: sets verified, passed
2022-10-27 11:18:00,242 TADA INFO assertion 3, Data are being stored: data check, passed
2022-10-27 11:18:05,118 TADA INFO assertion 4, New leader elected: checked, passed
2022-10-27 11:18:16,954 TADA INFO assertion 5, Restarted ldmsd is configured: sets verified, passed
2022-10-27 11:18:17,172 TADA INFO assertion 6, New data are presented in the store: data check, passed
2022-10-27 11:18:28,220 TADA INFO assertion 7, The restarted maestro becomes a follower: checked, passed
---Wait for config to write to file---
2022-10-27 11:18:28,220 TADA INFO test maestro_raft_test ended
2022-10-27 11:18:49 INFO: ----------------------------------------------
2022-10-27 11:18:49 INFO: ======== ovis_json_test ========
2022-10-27 11:18:49 INFO: CMD: python3 ovis_json_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ovis_json_test
2022-10-27 11:18:50,664 __main__ INFO -- Create the cluster -- 
2022-10-27 11:18:56,185 TADA INFO starting test `ovis_json_test`
2022-10-27 11:18:56,185 TADA INFO   test-id: 34502396f51b278618464e06b1433136fc35ace4d7f5c36130e10dd5deb1090b
2022-10-27 11:18:56,186 TADA INFO   test-suite: OVIS-LIB
2022-10-27 11:18:56,186 TADA INFO   test-name: ovis_json_test
2022-10-27 11:18:56,186 TADA INFO   test-user: narate
2022-10-27 11:18:56,186 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:18:56,187 TADA INFO assertion 1, Test creating a JSON integer entity: (type is JSON_INT_VALUE) && (1 == e->value.int_), passed
2022-10-27 11:18:56,187 TADA INFO assertion 2, Test creating a JSON boolean entity: (type is JSON_BOOL_VALUE) && (1 == e->value.bool_), passed
2022-10-27 11:18:56,187 TADA INFO assertion 3, Test creating a JSON float entity: (type is JSON_FLOAT_VALUE) && (1.1 == e->value.double_), passed
2022-10-27 11:18:56,187 TADA INFO assertion 4, Test creating a JSON string entity: (type is JSON_STRING_VALUE) && (foo == e->value.str_->str), passed
2022-10-27 11:18:56,187 TADA INFO assertion 5, Test creating a JSON attribute entity: (type is JSON_ATTR_VALUE) && (name == <attr name>) && (value == <attr value>), passed
2022-10-27 11:18:56,187 TADA INFO assertion 6, Test creating a JSON list entity: (type is JSON_LIST_VALUE) && (0 == Number of elements) && (list is empty), passed
2022-10-27 11:18:56,188 TADA INFO assertion 7, Test creating a JSON dictionary entity: (type is JSON_DICT_VALUE) && (dict table is empty), passed
2022-10-27 11:18:56,188 TADA INFO assertion 8, Test creating a JSON null entity: (type is JSON_NULL_VALUE) && (0 == e->value.int_), passed
2022-10-27 11:18:56,188 TADA INFO assertion 9, Test parsing a JSON integer string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 11:18:56,188 TADA INFO assertion 10, Test parsing a JSON false boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 11:18:56,188 TADA INFO assertion 11, Test parsing a JSON true boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 11:18:56,188 TADA INFO assertion 12, Test parsing a JSON float string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 11:18:56,188 TADA INFO assertion 13, Test parsing a JSON string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 11:18:56,189 TADA INFO assertion 15, Test parsing a JSON dict string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 11:18:56,189 TADA INFO assertion 16, Test parsing a JSON null string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 11:18:56,189 TADA INFO assertion 17, Test parsing an invalid string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 11:18:56,189 TADA INFO assertion 17, Test parsing an invalid string: 0 != json_parse_buffer(), passed
2022-10-27 11:18:56,189 TADA INFO assertion 18, Test dumping a JSON integer entity: 1 == 1, passed
2022-10-27 11:18:56,189 TADA INFO assertion 19, Test dumping a JSON false boolean entity: false == false, passed
2022-10-27 11:18:56,190 TADA INFO assertion 20, Test dumping a JSON true boolean entity: true == true, passed
2022-10-27 11:18:56,190 TADA INFO assertion 21, Test dumping a JSON float entity: 1.100000 == 1.100000, passed
2022-10-27 11:18:56,190 TADA INFO assertion 22, Test dumping a JSON string entity: "foo" == "foo", passed
2022-10-27 11:18:56,190 TADA INFO assertion 23, Test dumping a JSON attr entity: "name":"foo" == jb->buf, passed
2022-10-27 11:18:56,190 TADA INFO assertion 24, Test dumping a JSON list entity: [1,false,1.100000,"foo",[],{},null] == [1,false,1.100000,"foo",[],{},null], passed
2022-10-27 11:18:56,190 TADA INFO assertion 25, Test dumping a JSON dict entity: {"int":1,"bool":true,"float":1.100000,"string":"foo","list":[1,false,1.100000,"foo",[],{},null],"dict":{"attr_1":"value_1"},"null":null} == {"null":null,"list":[1,false,1.100000,"foo",[],{},null],"string":"foo","float":1.100000,"bool":true,"dict":{"attr_1":"value_1"},"int":1}, passed
2022-10-27 11:18:56,190 TADA INFO assertion 26, Test dumping a JSON null entity: null == null, passed
2022-10-27 11:18:56,191 TADA INFO assertion 27, Test dumping a JSON entity to a non-empty jbuf: This is a book."FOO" == This is a book."FOO", passed
2022-10-27 11:18:56,191 TADA INFO assertion 28, Test copying a JSON integer entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,191 TADA INFO assertion 29, Test copying a JSON false boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,191 TADA INFO assertion 30, Test copying a JSON true boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,191 TADA INFO assertion 31, Test copying a JSON float entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,191 TADA INFO assertion 32, Test copying a JSON string entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,191 TADA INFO assertion 33, Test copying a JSON attribute entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,192 TADA INFO assertion 34, Test copying a JSON list entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,192 TADA INFO assertion 35, Test copying a JSON dict entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,192 TADA INFO assertion 36, Test copying a JSON null entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 11:18:56,192 TADA INFO assertion 37, Test obtaining the number of attributes: 7 == json_attr_count(dict), passed
2022-10-27 11:18:56,192 TADA INFO assertion 38, Test finding an existing attribute: 0 != json_attr_find(), passed
2022-10-27 11:18:56,192 TADA INFO assertion 39, Test finding a non-existng attribute: 0 == json_attr_find(), passed
2022-10-27 11:18:56,192 TADA INFO assertion 40, Test finding the value of an existing attribute: 0 != json_value_find(), passed
2022-10-27 11:18:56,193 TADA INFO assertion 41, Test finding the value of a non-existing attribute: 0 == json_value_find(), passed
2022-10-27 11:18:56,193 TADA INFO assertion 42, Test adding a new attribute to a dictionary: (0 == json_attr_add() && (0 != json_attr_find()), passed
2022-10-27 11:18:56,193 TADA INFO assertion 43, Test replacing the value of an existing attribute: (0 == json_attr_add()) && (0 != json_value_find()) && (is_same_entity(old_v, new_v)), passed
2022-10-27 11:18:56,193 TADA INFO assertion 44, Test removing an existing attribute: (0 = json_attr_rem()) && (0 == json_attr_find()), passed
2022-10-27 11:18:56,193 TADA INFO assertion 45, Test removing a non-existing attribute: (ENOENT == json_attr_rem()), passed
2022-10-27 11:18:56,193 TADA INFO assertion 46, Test creating a dictionary by json_dict_build: expected == json_dict_build(...), passed
2022-10-27 11:18:56,194 TADA INFO assertion 47, Test adding attributes and replacing attribute values by json_dict_build: expected == json_dict_build(d, ...), passed
2022-10-27 11:18:56,194 TADA INFO assertion 48, Test json_dict_merge(): The merged dictionary is correct., passed
2022-10-27 11:18:56,194 TADA INFO assertion 49, Test json_list_len(): 7 == json_list_len(), passed
2022-10-27 11:18:56,194 TADA INFO assertion 50, Test adding items to a list: 0 == strcmp(exp_str, json_entity_dump(l)->buf, passed
2022-10-27 11:18:56,194 TADA INFO assertion 51, Test removing an existing item by json_item_rem(): 0 == json_item_rem(), passed
2022-10-27 11:18:56,194 TADA INFO assertion 52, Test removing a non-existing item by json_item_rem(): ENOENT == json_item_rem(), passed
2022-10-27 11:18:56,194 TADA INFO assertion 53, Test popping an existing item from a list by json_item_pop(): NULL == json_item_pop(len + 3), passed
2022-10-27 11:18:56,195 TADA INFO assertion 54, Test popping a non-existing item from a list by json_item_pop(): NULL != json_item_pop(len - 1), passed
2022-10-27 11:18:56,195 TADA INFO test ovis_json_test ended
2022-10-27 11:19:07 INFO: ----------------------------------------------
2022-10-27 11:19:07 INFO: ======== updtr_add_test ========
2022-10-27 11:19:07 INFO: CMD: python3 updtr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/updtr_add_test
2022-10-27 11:19:08,578 __main__ INFO -- Get or create the cluster --
2022-10-27 11:19:08,578 TADA INFO starting test `updtr_add test`
2022-10-27 11:19:08,578 TADA INFO   test-id: 4d57084f99bedb9477a4490abf93c4d79ac2c0d6b80875a278373a9b471d0523
2022-10-27 11:19:08,579 TADA INFO   test-suite: LDMSD
2022-10-27 11:19:08,579 TADA INFO   test-name: updtr_add test
2022-10-27 11:19:08,579 TADA INFO   test-user: narate
2022-10-27 11:19:08,579 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:19:16,366 __main__ INFO -- Start daemons --
2022-10-27 11:19:20,030 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:19:20,363 __main__ INFO All LDMSDs are up.
2022-10-27 11:19:21,588 TADA INFO assertion 1, Add an updater with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:19:22,791 TADA INFO assertion 2, Add an updater with a zero interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:19:24,013 TADA INFO assertion 3, Add an updater with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:19:25,229 TADA INFO assertion 4, Add an updater with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-27 11:19:26,448 TADA INFO assertion 5, Add an updater with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:19:28,886 TADA INFO assertion 6, Add an updater without an offset: report(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 11:19:31,302 TADA INFO assertion 7, Add an updater with a valid offset: report(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 11:19:32,518 TADA INFO assertion 8, Add an updater with an existing name: report(rc = 17) == expect(rc = 17), passed
2022-10-27 11:19:32,519 __main__ INFO --- done ---
2022-10-27 11:19:32,519 TADA INFO test updtr_add test ended
2022-10-27 11:19:44 INFO: ----------------------------------------------
2022-10-27 11:19:45 INFO: ======== updtr_del_test ========
2022-10-27 11:19:45 INFO: CMD: python3 updtr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/updtr_del_test
2022-10-27 11:19:46,205 __main__ INFO -- Get or create the cluster --
2022-10-27 11:19:46,205 TADA INFO starting test `updtr_add test`
2022-10-27 11:19:46,206 TADA INFO   test-id: 35862e2034a02115aa105dccc3c2caa33609f81e22f0f49813192af7b2addc22
2022-10-27 11:19:46,206 TADA INFO   test-suite: LDMSD
2022-10-27 11:19:46,206 TADA INFO   test-name: updtr_add test
2022-10-27 11:19:46,206 TADA INFO   test-user: narate
2022-10-27 11:19:46,206 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:19:54,143 __main__ INFO -- Start daemons --
2022-10-27 11:19:57,840 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:19:58,131 __main__ INFO All LDMSDs are up.
2022-10-27 11:19:59,343 TADA INFO assertion 1, updtr_del a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 11:20:00,574 TADA INFO assertion 2, updtr_del a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 11:20:01,794 TADA INFO assertion 3, updtr_del a stopped updater: report(rc = 0) == expect(rc = 0), passed
2022-10-27 11:20:03,034 TADA INFO assertion 4, updtr_del a just-added updater: report(rc = 0) == expect(rc = 0), passed
2022-10-27 11:20:03,034 __main__ INFO --- done ---
2022-10-27 11:20:03,034 TADA INFO test updtr_add test ended
2022-10-27 11:20:15 INFO: ----------------------------------------------
2022-10-27 11:20:15 INFO: ======== updtr_match_add_test ========
2022-10-27 11:20:16 INFO: CMD: python3 updtr_match_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/updtr_match_add_test
2022-10-27 11:20:16,703 __main__ INFO -- Get or create the cluster --
2022-10-27 11:20:16,703 TADA INFO starting test `updtr_add test`
2022-10-27 11:20:16,703 TADA INFO   test-id: 6fc211f881901ce4f892e11fb57f11d76c793d1feff675c21596989557994c2f
2022-10-27 11:20:16,703 TADA INFO   test-suite: LDMSD
2022-10-27 11:20:16,703 TADA INFO   test-name: updtr_add test
2022-10-27 11:20:16,704 TADA INFO   test-user: narate
2022-10-27 11:20:16,704 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:20:24,537 __main__ INFO -- Start daemons --
2022-10-27 11:20:28,235 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:20:28,528 __main__ INFO All LDMSDs are up.
2022-10-27 11:20:29,738 TADA INFO assertion 1, updtr_match_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:20:30,971 TADA INFO assertion 2, updtr_match_add with an invalid match: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:20:32,186 TADA INFO assertion 3, updtr_match_add of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 11:20:33,398 TADA INFO assertion 4, A success updtr_match_add: report(rc = 0) == expect(rc = 0), passed
2022-10-27 11:20:34,616 TADA INFO assertion 5, updtr_match_add of a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 11:20:34,616 __main__ INFO --- done ---
2022-10-27 11:20:34,617 TADA INFO test updtr_add test ended
2022-10-27 11:20:46 INFO: ----------------------------------------------
2022-10-27 11:20:47 INFO: ======== updtr_match_del_test ========
2022-10-27 11:20:47 INFO: CMD: python3 updtr_match_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/updtr_match_del_test
2022-10-27 11:20:48,307 __main__ INFO -- Get or create the cluster --
2022-10-27 11:20:48,307 TADA INFO starting test `updtr_add test`
2022-10-27 11:20:48,307 TADA INFO   test-id: e0b4925a988d8958eb8d2c34681efc3760f4ec9d8431c597d6f747cb50eff38c
2022-10-27 11:20:48,307 TADA INFO   test-suite: LDMSD
2022-10-27 11:20:48,307 TADA INFO   test-name: updtr_add test
2022-10-27 11:20:48,307 TADA INFO   test-user: narate
2022-10-27 11:20:48,307 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:20:56,268 __main__ INFO -- Start daemons --
2022-10-27 11:20:59,994 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:21:00,314 __main__ INFO All LDMSDs are up.
2022-10-27 11:21:01,532 TADA INFO assertion 1, Send updtr_match_del with an invalid regex: report(rc = 2) == expect(rc = 22), passed
2022-10-27 11:21:02,736 TADA INFO assertion 2, Send updtr_match_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 11:21:03,955 TADA INFO assertion 3, Send updtr_match_del with a non-existing inst match: report(rc = 2) == expect(rc = 2), passed
2022-10-27 11:21:05,170 TADA INFO assertion 4, Send updtr_match_del with a non-existing schema match: report(rc = 2) == expect(rc = 2), passed
2022-10-27 11:21:06,381 TADA INFO assertion 5, Send updater_match_del with an invalid match type: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:21:07,594 TADA INFO assertion 6, Send updater_match_del with a valid regex of the inst type: report(rc = 0) == expect(rc = 0), passed
2022-10-27 11:21:08,806 TADA INFO assertion 7, Send updater_match_del with a valid regex of the schema type: report(rc = 0) == expect(rc = 0), passed
2022-10-27 11:21:08,806 __main__ INFO --- done ---
2022-10-27 11:21:08,806 TADA INFO test updtr_add test ended
2022-10-27 11:21:20 INFO: ----------------------------------------------
2022-10-27 11:21:21 INFO: ======== updtr_prdcr_add_test ========
2022-10-27 11:21:21 INFO: CMD: python3 updtr_prdcr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/updtr_prdcr_add_test
2022-10-27 11:21:22,459 __main__ INFO -- Get or create the cluster --
2022-10-27 11:21:22,459 TADA INFO starting test `updtr_add test`
2022-10-27 11:21:22,459 TADA INFO   test-id: aa8dbd5e4e1638a0d0924955a32868396bc23b011b592dd8981b5e2b8e894045
2022-10-27 11:21:22,459 TADA INFO   test-suite: LDMSD
2022-10-27 11:21:22,459 TADA INFO   test-name: updtr_add test
2022-10-27 11:21:22,459 TADA INFO   test-user: narate
2022-10-27 11:21:22,459 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:21:30,415 __main__ INFO -- Start daemons --
2022-10-27 11:21:34,034 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:21:34,343 __main__ INFO All LDMSDs are up.
2022-10-27 11:21:35,566 TADA INFO assertion 1, Send updtr_prdcr_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:21:37,990 TADA INFO assertion 2, Send updtr_prdcr_add with a regex matching no prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 11:21:40,413 TADA INFO assertion 3, Send updtr_prdcdr_add with a regex matching some prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 11:21:41,633 TADA INFO assertion 4, Send updtr_prdcdr_add to a running updtr: report(rc = 16) == expect(rc = 16), passed
2022-10-27 11:21:42,828 TADA INFO assertion 5, Send updtr_prdcr_add to a not-existing updtr: report(rc = 2) == expect(rc = 2), passed
2022-10-27 11:21:42,828 __main__ INFO --- done ---
2022-10-27 11:21:42,829 TADA INFO test updtr_add test ended
2022-10-27 11:21:54 INFO: ----------------------------------------------
2022-10-27 11:21:55 INFO: ======== updtr_prdcr_del_test ========
2022-10-27 11:21:55 INFO: CMD: python3 updtr_prdcr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/updtr_prdcr_del_test
2022-10-27 11:21:56,488 __main__ INFO -- Get or create the cluster --
2022-10-27 11:21:56,488 TADA INFO starting test `updtr_add test`
2022-10-27 11:21:56,488 TADA INFO   test-id: 422e6d13520de96363a7fa3fd8c6c3aee943fb152e987ac0bed49f4978a4cddd
2022-10-27 11:21:56,488 TADA INFO   test-suite: LDMSD
2022-10-27 11:21:56,488 TADA INFO   test-name: updtr_add test
2022-10-27 11:21:56,488 TADA INFO   test-user: narate
2022-10-27 11:21:56,488 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:22:04,204 __main__ INFO -- Start daemons --
2022-10-27 11:22:07,864 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:22:08,198 __main__ INFO All LDMSDs are up.
2022-10-27 11:22:09,417 TADA INFO assertion 1, Send updtr_prdcr_del with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:22:10,631 TADA INFO assertion 2, Send updtr_prdcr_del to a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 11:22:11,850 TADA INFO assertion 3, Send updtr_prdcr_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 11:22:14,245 TADA INFO assertion 4, Send updtr_prdcr_del successfully: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}], passed
2022-10-27 11:22:14,245 __main__ INFO --- done ---
2022-10-27 11:22:14,245 TADA INFO test updtr_add test ended
2022-10-27 11:22:26 INFO: ----------------------------------------------
2022-10-27 11:22:27 INFO: ======== updtr_start_test ========
2022-10-27 11:22:27 INFO: CMD: python3 updtr_start_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/updtr_start_test
2022-10-27 11:22:27,973 __main__ INFO -- Get or create the cluster --
2022-10-27 11:22:27,973 TADA INFO starting test `updtr_add test`
2022-10-27 11:22:27,973 TADA INFO   test-id: 6fe1909ae83eda9a225f9e6e6bf8d98e6e5ad732ab1939bc826f157403e7e13d
2022-10-27 11:22:27,973 TADA INFO   test-suite: LDMSD
2022-10-27 11:22:27,973 TADA INFO   test-name: updtr_add test
2022-10-27 11:22:27,973 TADA INFO   test-user: narate
2022-10-27 11:22:27,974 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:22:35,728 __main__ INFO -- Start daemons --
2022-10-27 11:22:39,442 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:22:39,773 __main__ INFO All LDMSDs are up.
2022-10-27 11:22:40,993 TADA INFO assertion 1, updtr_start with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:22:42,215 TADA INFO assertion 2, updtr_start with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:22:43,426 TADA INFO assertion 3, updtr_start with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-27 11:22:44,645 TADA INFO assertion 4, updtr_start with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:22:45,857 TADA INFO assertion 5, updtr_start without an offset larger than interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 11:22:48,292 TADA INFO assertion 6, updtr_start that changes offset to no offset: report(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 11:22:49,499 TADA INFO assertion 7, updtr_start of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 11:22:51,932 TADA INFO assertion 8, updtr_start with a valid interval: report(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 11:22:54,363 TADA INFO assertion 9, updtr_start with a valid offset: report(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 11:22:56,800 TADA INFO assertion 10, updtr_start without giving interval and offset: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 11:22:58,026 TADA INFO assertion 11, updtr_start a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 11:22:58,026 __main__ INFO --- done ---
2022-10-27 11:22:58,026 TADA INFO test updtr_add test ended
2022-10-27 11:23:10 INFO: ----------------------------------------------
2022-10-27 11:23:10 INFO: ======== updtr_status_test ========
2022-10-27 11:23:10 INFO: CMD: python3 updtr_status_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/updtr_status_test
2022-10-27 11:23:11,694 __main__ INFO -- Get or create the cluster --
2022-10-27 11:23:11,695 TADA INFO starting test `updtr_status test`
2022-10-27 11:23:11,695 TADA INFO   test-id: 2a5cf85400b42f6a7a315429671b8e353e2deb0bfd64fde3409e4774b4f390fb
2022-10-27 11:23:11,695 TADA INFO   test-suite: LDMSD
2022-10-27 11:23:11,695 TADA INFO   test-name: updtr_status test
2022-10-27 11:23:11,695 TADA INFO   test-user: narate
2022-10-27 11:23:11,695 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:23:21,784 __main__ INFO -- Start daemons --
2022-10-27 11:23:26,687 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 11:23:27,115 __main__ INFO All LDMSDs are up.
2022-10-27 11:23:28,333 TADA INFO assertion 1, Send 'updtr_status' to an LDMSD without any Updaters: [], passed
2022-10-27 11:23:29,561 TADA INFO assertion 2, Send 'updtr_status name=foo', where updtr 'foo' doesn't exist.: report(updtr 'foo' doesn't exist.) == expect(updtr 'foo' doesn't exist.), passed
2022-10-27 11:23:30,779 TADA INFO assertion 3, Send 'updtr_status name=all', where 'all' exists.: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 11:23:31,979 TADA INFO assertion 4, Send 'updtr_status' to an LDMSD with a single Updater: report([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 11:23:33,202 TADA INFO assertion 5, Send 'updtr_status' to an LDMSD with 2 updaters: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 11:23:33,202 __main__ INFO --- done ---
2022-10-27 11:23:33,202 TADA INFO test updtr_status test ended
2022-10-27 11:23:45 INFO: ----------------------------------------------
2022-10-27 11:23:46 INFO: ======== ldmsd_flex_decomp_test ========
2022-10-27 11:23:46 INFO: CMD: python3 ldmsd_flex_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldmsd_flex_decomp_test
2022-10-27 11:23:47,464 TADA INFO starting test `ldmsd_flex_decomp_test`
2022-10-27 11:23:47,464 TADA INFO   test-id: 6a047a431c9e1bd09a6022d4e8a42c626237cebc1d43765e3595eb333eb5ae67
2022-10-27 11:23:47,464 TADA INFO   test-suite: LDMSD
2022-10-27 11:23:47,464 TADA INFO   test-name: ldmsd_flex_decomp_test
2022-10-27 11:23:47,464 TADA INFO   test-user: narate
2022-10-27 11:23:47,464 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:23:47,465 __main__ INFO -- Get or create the cluster --
2022-10-27 11:24:03,134 __main__ INFO -- Start daemons --
2022-10-27 11:24:13,278 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 11:25:02,622 TADA INFO assertion 1, test_sampler_95772b6 sos schema check: OK, passed
2022-10-27 11:25:02,622 TADA INFO assertion 2, record_sampler_e1f021f sos schema check: OK, passed
2022-10-27 11:25:02,622 TADA INFO assertion 3, fill sos schema check: OK, passed
2022-10-27 11:25:02,622 TADA INFO assertion 4, filter sos schema check: OK, passed
2022-10-27 11:25:02,622 TADA INFO assertion 5, record sos schema check: OK, passed
2022-10-27 11:25:02,622 TADA INFO assertion 6, test_sampler_95772b6 csv schema check: OK, passed
2022-10-27 11:25:02,623 TADA INFO assertion 7, record_sampler_e1f021f csv schema check: OK, passed
2022-10-27 11:25:02,623 TADA INFO assertion 8, fill csv schema check: OK, passed
2022-10-27 11:25:02,623 TADA INFO assertion 9, filter csv schema check: OK, passed
2022-10-27 11:25:02,623 TADA INFO assertion 10, record csv schema check: OK, passed
2022-10-27 11:25:02,623 TADA INFO assertion 11, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-27 11:25:02,623 TADA INFO assertion 12, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-27 11:25:02,624 TADA INFO assertion 13, fill kafka schema check: OK, passed
2022-10-27 11:25:02,624 TADA INFO assertion 14, filter kafka schema check: OK, passed
2022-10-27 11:25:02,624 TADA INFO assertion 15, record kafka schema check: OK, passed
2022-10-27 11:25:02,625 TADA INFO assertion 16, test_sampler_95772b6 sos data check: OK, passed
2022-10-27 11:25:02,689 TADA INFO assertion 17, record_sampler_e1f021f sos data check: OK, passed
2022-10-27 11:25:02,692 TADA INFO assertion 18, fill sos data check: OK, passed
2022-10-27 11:25:02,694 TADA INFO assertion 19, filter sos data check: OK, passed
2022-10-27 11:25:02,702 TADA INFO assertion 20, record sos data check: OK, passed
2022-10-27 11:25:02,703 TADA INFO assertion 21, test_sampler_95772b6 csv data check: OK, passed
2022-10-27 11:25:02,764 TADA INFO assertion 22, record_sampler_e1f021f csv data check: OK, passed
2022-10-27 11:25:02,767 TADA INFO assertion 23, fill csv data check: OK, passed
2022-10-27 11:25:02,768 TADA INFO assertion 24, filter csv data check: OK, passed
2022-10-27 11:25:02,776 TADA INFO assertion 25, record csv data check: OK, passed
2022-10-27 11:25:02,777 TADA INFO assertion 26, test_sampler_95772b6 kafka data check: OK, passed
2022-10-27 11:25:02,799 TADA INFO assertion 27, record_sampler_e1f021f kafka data check: OK, passed
2022-10-27 11:25:02,800 TADA INFO assertion 28, fill kafka data check: OK, passed
2022-10-27 11:25:02,801 TADA INFO assertion 29, filter kafka data check: OK, passed
2022-10-27 11:25:02,805 TADA INFO assertion 30, record kafka data check: OK, passed
2022-10-27 11:25:02,805 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-27 11:25:02,805 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-27 11:25:17 INFO: ----------------------------------------------
2022-10-27 11:25:18 INFO: ======== ldms_set_info_test ========
2022-10-27 11:25:18 INFO: CMD: python3 ldms_set_info_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/ldms_set_info_test
2022-10-27 11:25:29,245 TADA INFO starting test `ldms_set_info_test`
2022-10-27 11:25:29,245 TADA INFO   test-id: dc9515176b02d0b0297628c223cb151e005b22f3cf5229c1c0f8cecc49255661
2022-10-27 11:25:29,245 TADA INFO   test-suite: LDMSD
2022-10-27 11:25:29,245 TADA INFO   test-name: ldms_set_info_test
2022-10-27 11:25:29,245 TADA INFO   test-user: narate
2022-10-27 11:25:29,245 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:25:29,246 TADA INFO assertion 1, Adding set info key value pairs : -, passed
2022-10-27 11:25:29,246 TADA INFO assertion 2, Reset value of an existing pair : -, passed
2022-10-27 11:25:29,246 TADA INFO assertion 3, Get a value : -, passed
2022-10-27 11:25:29,246 TADA INFO assertion 4, Unset a pair : -, passed
2022-10-27 11:25:29,246 TADA INFO assertion 5, Traverse the local set info : -, passed
2022-10-27 11:25:29,247 TADA INFO assertion 6, Verifying the set info at the 1st level : -, passed
2022-10-27 11:25:29,247 TADA INFO assertion 7, Server resetting a key : -, passed
2022-10-27 11:25:29,247 TADA INFO assertion 8, Server unset a key : -, passed
2022-10-27 11:25:29,247 TADA INFO assertion 9, Server add a key : -, passed
2022-10-27 11:25:29,247 TADA INFO assertion 10, Adding a key : -, passed
2022-10-27 11:25:29,247 TADA INFO assertion 11, Add a key that is already in the remote list : -, passed
2022-10-27 11:25:29,247 TADA INFO assertion 12, Unset a key that appears in both local and remote list : -, passed
2022-10-27 11:25:29,248 TADA INFO assertion 13, Verifying the set_info at the 2nd level : -, passed
2022-10-27 11:25:29,248 TADA INFO assertion 14, Test set info propagation: resetting a key on the set origin : -, passed
2022-10-27 11:25:29,248 TADA INFO assertion 15, Test set info propagation: unsetting a key on the set origin : -, passed
2022-10-27 11:25:29,248 TADA INFO assertion 16, Test set info propagation: adding a key on the set origin : -, passed
2022-10-27 11:25:29,248 TADA INFO test ldms_set_info_test ended
2022-10-27 11:25:39 INFO: ----------------------------------------------
2022-10-27 11:25:40 INFO: ======== slurm_sampler2_test ========
2022-10-27 11:25:40 INFO: CMD: python3 slurm_sampler2_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-102619/data/slurm_sampler2_test
2022-10-27 11:25:41,508 TADA INFO starting test `slurm_sampler2_test`
2022-10-27 11:25:41,508 TADA INFO   test-id: 1736901c04db1afe5dc1b2098fc555f1ad88b2d5ff47b5443a0685aa6b2bd51d
2022-10-27 11:25:41,508 TADA INFO   test-suite: LDMSD
2022-10-27 11:25:41,508 TADA INFO   test-name: slurm_sampler2_test
2022-10-27 11:25:41,508 TADA INFO   test-user: narate
2022-10-27 11:25:41,508 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 11:25:41,509 __main__ INFO -- Get or create the cluster --
2022-10-27 11:25:55,135 __main__ INFO -- Add users --
2022-10-27 11:26:00,399 __main__ INFO -- Preparing job script & programs --
2022-10-27 11:26:01,058 __main__ INFO -- Start daemons --
2022-10-27 11:26:20,941 TADA INFO assertion 1, Correctly collect the data of a job running on multiple nodes: The collected job data is correct., passed
2022-10-27 11:26:20,942 TADA INFO assertion 2, Correctly collect the data of a job running on N tasks of multiple nodes: skipped
2022-10-27 11:26:20,942 TADA INFO assertion 3, Correctly fill the metric values after expanding the set heap: skipped
2022-10-27 11:26:20,942 TADA INFO assertion 4, Correctly collect the data of a job submitted as a user: skipped
2022-10-27 11:26:20,942 TADA INFO assertion 5, Correctly collect the data in the multi-tenant case: skipped
2022-10-27 11:26:20,942 TADA INFO test slurm_sampler2_test ended
2022-10-27 11:26:34 INFO: ----------------------------------------------
2022-10-27 11:26:35 INFO: ======== test-ldms ========
2022-10-27 11:26:35 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-ldms/test.sh
2022-10-27T11:26:35-05:00 INFO: starting test-samp-1
aa87643d4a39e6f2e9e7fa55c632a8da8638a81d82b92ef4d5c400c1f2d1a8f7
2022-10-27T11:26:38-05:00 INFO: starting test-samp-2
7d842f757726c490873bb1bf6d399b305229ebdd412c5ae174127f76a6cf9224
2022-10-27T11:26:40-05:00 INFO: starting test-samp-3
9f439bb1d1ec9edac01f0a13b7dff2b939f909e2074361a652ef1c58c5adfa72
2022-10-27T11:26:41-05:00 INFO: starting test-samp-4
c0de913b6866071340501f1f046758b1b9212ccc485776f9de4bb28b2e8a92b2
2022-10-27T11:26:43-05:00 INFO: test-samp-1 is running
2022-10-27T11:26:43-05:00 INFO: test-samp-2 is running
2022-10-27T11:26:43-05:00 INFO: test-samp-3 is running
2022-10-27T11:26:44-05:00 INFO: test-samp-4 is running
2022-10-27T11:26:44-05:00 INFO: starting test-agg-11
c17e78244fc1e4bb6af8e73791ebd80e2911d37c1fb2214e4fb4d4477163ec0e
2022-10-27T11:26:45-05:00 INFO: starting test-agg-12
c0f8dea2a4ebcf7a9d81467574dbc7c491c5eda5ab03ea539964a0869ae46441
2022-10-27T11:26:47-05:00 INFO: test-agg-11 is running
2022-10-27T11:26:47-05:00 INFO: test-agg-12 is running
2022-10-27T11:26:47-05:00 INFO: starting test-agg-2
c5c1b006c40afa8dd782f6e6bd92ad06d897f3515aa1798ddf2cf605e649c139
2022-10-27T11:26:49-05:00 INFO: test-agg-2 is running
2022-10-27T11:26:49-05:00 INFO: Collecting data (into SOS)
2022-10-27T11:26:59-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T11:27:01-05:00 INFO: check rc: 0
2022-10-27T11:27:01-05:00 INFO: Cleaning up ...
test-samp-1
test-samp-2
test-samp-3
test-samp-4
test-agg-11
test-agg-12
test-agg-2
2022-10-27T11:27:06-05:00 INFO: DONE
2022-10-27 11:27:16 INFO: ----------------------------------------------
2022-10-27 11:27:16 INFO: ======== test-maestro ========
2022-10-27 11:27:16 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro/test.sh
2022-10-27T11:27:16-05:00 INFO: starting mtest-maestro
787d5651e5112fea5d2be704e2f5d1d5e4c709dc56b2702641cec07ac4ae46ca
2022-10-27T11:27:18-05:00 INFO: starting mtest-samp-1
64f6640febc5b3ab84ff52bd3942c332f440dfb1e8fbc1710b18a6d3c57a4752
2022-10-27T11:27:20-05:00 INFO: starting mtest-samp-2
97ba6a461c152aeb5582b217227b85e18ac15bad60e004f40589e37bf412605e
2022-10-27T11:27:22-05:00 INFO: starting mtest-samp-3
470e378021fe941ce506a2cae2bba1440fc6dd51a272022f79e6274ad14bc2bb
2022-10-27T11:27:23-05:00 INFO: starting mtest-samp-4
0a1e5b2e95cd310c290a28c87f4a4486bc2c83cbfd337405c62cf459c59477f3
2022-10-27T11:27:25-05:00 INFO: mtest-samp-1 is running
2022-10-27T11:27:25-05:00 INFO: mtest-samp-2 is running
2022-10-27T11:27:25-05:00 INFO: mtest-samp-3 is running
2022-10-27T11:27:25-05:00 INFO: mtest-samp-4 is running
2022-10-27T11:27:25-05:00 INFO: starting mtest-agg-11
b2a8e1ed24c397c1c5df969fdb320d98c6bf05b3ecfc6c5b409ebb8de7366fe2
2022-10-27T11:27:26-05:00 INFO: starting mtest-agg-12
7132287d464ada15e3e2a101c16820e068b71eec6bbfb5fafea90756e87dc447
2022-10-27T11:27:28-05:00 INFO: mtest-agg-11 is running
2022-10-27T11:27:28-05:00 INFO: mtest-agg-12 is running
2022-10-27T11:27:28-05:00 INFO: starting mtest-agg-2
62c33727b5640fecec9e40d464b7ce70ac1caa4c9c62ef7cf5ccdb88b0a7c0e4
2022-10-27T11:27:29-05:00 INFO: mtest-agg-2 is running
2022-10-27T11:27:29-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T11:27:41-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T11:27:43-05:00 INFO: sos check rc: 0
2022-10-27T11:27:44-05:00 INFO: starting mtest-ui
e88e1b5b3d2a31e4f7cf17928f5c326ab1e066a95f745af9210cf96e9b1fa753
2022-10-27T11:27:51-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4345388, 1666888053000.599], [4345388, 1666888053001.506], [4345388, 1666888053001.909], [4345388, 1666888053002.108], [4345744, 1666888054000.59], [4345744, 1666888054001.143], [4345744, 1666888054001.621], [4345744, 1666888054001.7358], [4345744, 1666888055001.034], [4345744, 1666888055001.312], [4345744, 1666888055001.75], [4345744, 1666888055001.755], [4345744, 1666888056000.628], [4345744, 1666888056001.454], [4345744, 1666888056001.8591], [4345744, 1666888056001.8828], [4345744, 1666888057001.3179], [4345744, 1666888057001.593], [4345744, 1666888057001.612], [4345744, 1666888057001.77], [4345744, 1666888058001.3271], [4345744, 1666888058001.354], [4345744, 1666888058001.737], [4345744, 1666888058001.92], [4345744, 1666888059001.3], [4345744, 1666888059001.42], [4345744, 1666888059001.428], [4345744, 1666888059001.4668]]}, {"target": "component_id", "datapoints": [[3, 1666888053000.599], [1, 1666888053001.506], [2, 1666888053001.909], [4, 1666888053002.108], [4, 1666888054000.59], [2, 1666888054001.143], [1, 1666888054001.621], [3, 1666888054001.7358], [2, 1666888055001.034], [3, 1666888055001.312], [1, 1666888055001.75], [4, 1666888055001.755], [2, 1666888056000.628], [3, 1666888056001.454], [1, 1666888056001.8591], [4, 1666888056001.8828], [1, 1666888057001.3179], [4, 1666888057001.593], [3, 1666888057001.612], [2, 1666888057001.77], [4, 1666888058001.3271], [1, 1666888058001.354], [3, 1666888058001.737], [2, 1666888058001.92], [2, 1666888059001.3], [4, 1666888059001.42], [3, 1666888059001.428], [1, 1666888059001.4668]]}, {"target": "job_id", "datapoints": [[0, 1666888053000.599], [0, 1666888053001.506], [0, 1666888053001.909], [0, 1666888053002.108], [0, 1666888054000.59], [0, 1666888054001.143], [0, 1666888054001.621], [0, 1666888054001.7358], [0, 1666888055001.034], [0, 1666888055001.312], [0, 1666888055001.75], [0, 1666888055001.755], [0, 1666888056000.628], [0, 1666888056001.454], [0, 1666888056001.8591], [0, 1666888056001.8828], [0, 1666888057001.3179], [0, 1666888057001.593], [0, 1666888057001.612], [0, 1666888057001.77], [0, 1666888058001.3271], [0, 1666888058001.354], [0, 1666888058001.737], [0, 1666888058001.92], [0, 1666888059001.3], [0, 1666888059001.42], [0, 1666888059001.428], [0, 1666888059001.4668]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T11:27:53-05:00 INFO: query check RC: 0
db2baf7211271860c7f8a770bbdae79b1d02bb1843bdbb3398c025d4c9cf6071
2022-10-27T11:28:24-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2617    808 --:--:-- --:--:-- --:--:--  3446
{"datasource":{"id":1,"uid":"2jSBroNVz","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T11:28:25-05:00 INFO: Checking grafana data
2022-10-27T11:28:26-05:00 INFO: Grafana data check, rc: 0
2022-10-27T11:28:26-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T11:28:31-05:00 INFO: DONE
2022-10-27 11:28:41 INFO: ----------------------------------------------
2022-10-27 11:28:41 INFO: ======== test-maestro-hostmunge ========
2022-10-27 11:28:41 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-hostmunge/test.sh
2022-10-27T11:28:41-05:00 INFO: Checking munge on localhost
2022-10-27T11:28:41-05:00 INFO: munge encode/decode successfully
2022-10-27T11:28:41-05:00 INFO: starting mtest-maestro
4a643c13f66f0636188b0834b6bb5d9bf0ebcb15d11276dca9db4ae20a5e4404
2022-10-27T11:28:43-05:00 INFO: starting mtest-samp-1
17ce5bbfd61d03df9e42a4907a996abda4f2677c83c51fb91c5963e4ca6d85fa
2022-10-27T11:28:45-05:00 INFO: starting mtest-samp-2
64741b28c519a101e2b787ed3485e15f653502cecd5340e63fdc224facc7b62b
2022-10-27T11:28:47-05:00 INFO: starting mtest-samp-3
017f9e156e2170280c625457a70d85f1ced5cc4528897633a149195b3e2de4e1
2022-10-27T11:28:48-05:00 INFO: starting mtest-samp-4
ccb58dac8081e4e36c8adeda982f259a81b2887e30ac93fd350a81f2064f5f6a
2022-10-27T11:28:50-05:00 INFO: mtest-samp-1 is running
2022-10-27T11:28:50-05:00 INFO: mtest-samp-2 is running
2022-10-27T11:28:50-05:00 INFO: mtest-samp-3 is running
2022-10-27T11:28:50-05:00 INFO: mtest-samp-4 is running
2022-10-27T11:28:50-05:00 INFO: starting mtest-agg-11
7e1074d3bf7201b0da2536dfc5df3a69a79ccc33ea2c38ae7574c4bbac30d8ac
2022-10-27T11:28:51-05:00 INFO: starting mtest-agg-12
343a7e5903d858cff0432db2a725c5aa86cc14de97f21cc6aa8a88dc04b3dcdf
2022-10-27T11:28:53-05:00 INFO: mtest-agg-11 is running
2022-10-27T11:28:53-05:00 INFO: mtest-agg-12 is running
2022-10-27T11:28:53-05:00 INFO: starting mtest-agg-2
3ccf11021017ce0d921e15c69bd742128826f700ab8232cd5447f6de7c5b5b55
2022-10-27T11:28:54-05:00 INFO: mtest-agg-2 is running
2022-10-27T11:28:54-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T11:29:05-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T11:29:08-05:00 INFO: sos check rc: 0
2022-10-27T11:29:09-05:00 INFO: starting mtest-ui
bbdac76fd9b76608b9e3161929230a17fc9c80d3a1d0f82a33c114e65ddee145
2022-10-27T11:29:11-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4345676, 1666888138001.8198], [4345676, 1666888138001.823], [4345676, 1666888138002.098], [4345676, 1666888138002.124], [4345920, 1666888139001.2732], [4345920, 1666888139001.29], [4345920, 1666888139001.29], [4345920, 1666888139001.794], [4346048, 1666888140000.9028], [4346048, 1666888140001.405], [4346048, 1666888140001.433], [4346048, 1666888140001.4358], [4346048, 1666888141001.3262], [4346048, 1666888141001.342], [4346048, 1666888141001.3481], [4346048, 1666888141001.5842], [4346048, 1666888142000.754], [4346048, 1666888142001.038], [4346048, 1666888142001.375], [4346048, 1666888142001.737], [4346048, 1666888143001.203], [4346048, 1666888143001.533], [4346048, 1666888143001.589], [4346048, 1666888143001.8071], [4346048, 1666888144001.334], [4346048, 1666888144001.346], [4346048, 1666888144001.451], [4346048, 1666888144001.468]]}, {"target": "component_id", "datapoints": [[2, 1666888138001.8198], [4, 1666888138001.823], [3, 1666888138002.098], [1, 1666888138002.124], [3, 1666888139001.2732], [1, 1666888139001.29], [2, 1666888139001.29], [4, 1666888139001.794], [2, 1666888140000.9028], [3, 1666888140001.405], [4, 1666888140001.433], [1, 1666888140001.4358], [2, 1666888141001.3262], [4, 1666888141001.342], [3, 1666888141001.3481], [1, 1666888141001.5842], [4, 1666888142000.754], [2, 1666888142001.038], [3, 1666888142001.375], [1, 1666888142001.737], [2, 1666888143001.203], [3, 1666888143001.533], [4, 1666888143001.589], [1, 1666888143001.8071], [4, 1666888144001.334], [3, 1666888144001.346], [2, 1666888144001.451], [1, 1666888144001.468]]}, {"target": "job_id", "datapoints": [[0, 1666888138001.8198], [0, 1666888138001.823], [0, 1666888138002.098], [0, 1666888138002.124], [0, 1666888139001.2732], [0, 1666888139001.29], [0, 1666888139001.29], [0, 1666888139001.794], [0, 1666888140000.9028], [0, 1666888140001.405], [0, 1666888140001.433], [0, 1666888140001.4358], [0, 1666888141001.3262], [0, 1666888141001.342], [0, 1666888141001.3481], [0, 1666888141001.5842], [0, 1666888142000.754], [0, 1666888142001.038], [0, 1666888142001.375], [0, 1666888142001.737], [0, 1666888143001.203], [0, 1666888143001.533], [0, 1666888143001.589], [0, 1666888143001.8071], [0, 1666888144001.334], [0, 1666888144001.346], [0, 1666888144001.451], [0, 1666888144001.468]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T11:29:13-05:00 INFO: query check RC: 0
00345a82c10ce09936a32eb21e53167ef55ba7f2211677c324a524194f27d7c9
2022-10-27T11:29:44-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2404    742 --:--:-- --:--:-- --:--:--  3172
{"datasource":{"id":1,"uid":"VkPP9oH4z","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T11:29:45-05:00 INFO: Checking grafana data
2022-10-27T11:29:46-05:00 INFO: Grafana data check, rc: 0
2022-10-27T11:29:46-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T11:29:50-05:00 INFO: DONE
2022-10-27 11:30:00 INFO: ----------------------------------------------
2022-10-27 11:30:00 INFO: ======== test-maestro-munge ========
2022-10-27 11:30:00 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-munge/test.sh
1+0 records in
1+0 records out
4096 bytes (4.1 kB, 4.0 KiB) copied, 0.000227553 s, 18.0 MB/s
2022-10-27T11:30:02-05:00 INFO: starting mtest-maestro
71f653685ce58a334966af1e52206dbdfe9edf3e60daaad30a1a991dd3cb5d01
2022-10-27T11:30:04-05:00 INFO: starting mtest-samp-1
f2211db7763a6e63e8d522d2eec50835cdb5ede94484177839f84c87912d13ef
2022-10-27T11:30:06-05:00 INFO: starting mtest-samp-2
f9cd7700f8f0d15fdddb302842b3b9ef4157d7b8dbc35ed51257ea7a403a4c83
2022-10-27T11:30:07-05:00 INFO: starting mtest-samp-3
4d7dbbba5cc1edfad98a285db85e1537fdd8f1fedbbe7c3f28bbf12566f5552d
2022-10-27T11:30:10-05:00 INFO: starting mtest-samp-4
f6b14cde6b8a921514930289afaba6d64440cb66f2bb13e6201e3f5a468af472
2022-10-27T11:30:11-05:00 INFO: mtest-samp-1 is running
2022-10-27T11:30:11-05:00 INFO: mtest-samp-2 is running
2022-10-27T11:30:11-05:00 INFO: mtest-samp-3 is running
2022-10-27T11:30:11-05:00 INFO: mtest-samp-4 is running
2022-10-27T11:30:11-05:00 INFO: starting mtest-agg-11
e45d0269f78342313a4db1d1962461874b3c0e6752c5220d56992e022d1c0c09
2022-10-27T11:30:13-05:00 INFO: starting mtest-agg-12
b700e4feb78e39eba259e08b2db871ce0450cbeae85a77de8b22b3fd6f9ddfaf
2022-10-27T11:30:14-05:00 INFO: mtest-agg-11 is running
2022-10-27T11:30:14-05:00 INFO: mtest-agg-12 is running
2022-10-27T11:30:14-05:00 INFO: starting mtest-agg-2
4f9f5e1fb34510c158ee94787d04b1748c770c8cf451f6c73767ce1af706ea9a
2022-10-27T11:30:16-05:00 INFO: mtest-agg-2 is running
2022-10-27T11:30:16-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T11:30:27-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T11:30:29-05:00 INFO: sos check rc: 0
2022-10-27T11:30:30-05:00 INFO: starting mtest-ui
839436df32fcaed5407245840c9e5c0d14671eec73c978284bb920692322304f
2022-10-27T11:30:32-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4346532, 1666888222000.733], [4346532, 1666888222001.543], [4346532, 1666888222001.619], [4346532, 1666888222001.674], [4346904, 1666888223001.2732], [4346904, 1666888223001.677], [4346904, 1666888223001.7148], [4346904, 1666888223001.755], [4346904, 1666888224001.413], [4346904, 1666888224001.4312], [4346904, 1666888224001.8162], [4346904, 1666888224001.9358], [4346904, 1666888225001.545], [4346904, 1666888225001.574], [4346904, 1666888225001.6482], [4346904, 1666888225002.093], [4346904, 1666888226001.2769], [4346904, 1666888226001.688], [4346904, 1666888226001.705], [4346904, 1666888226001.71]]}, {"target": "component_id", "datapoints": [[3, 1666888222000.733], [1, 1666888222001.543], [4, 1666888222001.619], [2, 1666888222001.674], [2, 1666888223001.2732], [3, 1666888223001.677], [1, 1666888223001.7148], [4, 1666888223001.755], [3, 1666888224001.413], [2, 1666888224001.4312], [1, 1666888224001.8162], [4, 1666888224001.9358], [3, 1666888225001.545], [1, 1666888225001.574], [2, 1666888225001.6482], [4, 1666888225002.093], [4, 1666888226001.2769], [3, 1666888226001.688], [2, 1666888226001.705], [1, 1666888226001.71]]}, {"target": "job_id", "datapoints": [[0, 1666888222000.733], [0, 1666888222001.543], [0, 1666888222001.619], [0, 1666888222001.674], [0, 1666888223001.2732], [0, 1666888223001.677], [0, 1666888223001.7148], [0, 1666888223001.755], [0, 1666888224001.413], [0, 1666888224001.4312], [0, 1666888224001.8162], [0, 1666888224001.9358], [0, 1666888225001.545], [0, 1666888225001.574], [0, 1666888225001.6482], [0, 1666888225002.093], [0, 1666888226001.2769], [0, 1666888226001.688], [0, 1666888226001.705], [0, 1666888226001.71]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T11:30:34-05:00 INFO: query check RC: 0
8a68150573f61926ebddf4c83ff7ac5c070cf25aae845496871ed607e448ad1e
2022-10-27T11:31:05-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2835    875 --:--:-- --:--:-- --:--:--  3742
{"datasource":{"id":1,"uid":"5SnQ9TH4k","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T11:31:07-05:00 INFO: Checking grafana data
2022-10-27T11:31:07-05:00 INFO: Grafana data check, rc: 0
2022-10-27T11:31:07-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T11:31:12-05:00 INFO: DONE
2022-10-27 11:31:22 INFO: ----------------------------------------------
2022-10-27 11:31:22 INFO: ==== Summary ====
ldmsd_ctrl_test: [01;32mPASSED[0m
papi_store_test: [01;32mPASSED[0m
updtr_status_test: [01;32mPASSED[0m
ldmsd_auth_ovis_test: [01;32mPASSED[0m
store_app_test: [01;32mPASSED[0m
store_list_record_test: [01;32mPASSED[0m
set_array_test: [01;32mPASSED[0m
ovis_ev_test: [01;32mPASSED[0m
setgroup_test: [01;32mPASSED[0m
ldms_list_test: [01;32mPASSED[0m
slurm_stream_test: [01;32mPASSED[0m
maestro_cfg_test: [01;32mPASSED[0m
ldms_set_info_test: [01;32mPASSED[0m
spank_notifier_test: [01;32mPASSED[0m
agg_slurm_test: [01;31mFAILED[0m
updtr_match_add_test: [01;32mPASSED[0m
updtr_match_del_test: [01;32mPASSED[0m
ldmsd_stream_dir_test: [01;32mPASSED[0m
direct_prdcr_subscribe_test: [01;32mPASSED[0m
ldmsd_auth_test: [01;32mPASSED[0m
cont-test-maestro-munge: [01;32mPASSED[0m
cont-test-ldms: [01;32mPASSED[0m
prdcr_subscribe_test: [01;32mPASSED[0m
cont-test-maestro-hostmunge: [01;32mPASSED[0m
maestro_raft_test: [01;32mPASSED[0m
updtr_start_test: [01;32mPASSED[0m
failover_test: [01;32mPASSED[0m
ldms_record_test: [01;32mPASSED[0m
cont-test-maestro: [01;32mPASSED[0m
ldmsd_decomp_test: [01;32mPASSED[0m
ldmsd_flex_decomp_test: [01;32mPASSED[0m
quick_set_add_rm_test: [01;32mPASSED[0m
updtr_prdcr_del_test: [01;32mPASSED[0m
updtr_prdcr_add_test: [01;32mPASSED[0m
mt-slurm-test: [01;32mPASSED[0m
ovis_json_test: [01;32mPASSED[0m
papi_sampler_test: [01;32mPASSED[0m
syspapi_test: [01;32mPASSED[0m
updtr_del_test: [01;32mPASSED[0m
ldmsd_autointerval_test: [01;32mPASSED[0m
updtr_add_test: [01;32mPASSED[0m
ldmsd_stream_test: [01;32mPASSED[0m
direct_ldms_ls_conn_test: [01;32mPASSED[0m
set_array_hang_test: [01;32mPASSED[0m
slurm_sampler2_test: [01;32mPASSED[0m
ldms_schema_digest_test: [01;32mPASSED[0m
agg_test: [01;32mPASSED[0m
------------------------------------------
Total tests passed: 46/47
------------------------------------------
