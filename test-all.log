2022-10-31 08:36:43 INFO: WORK_DIR: /mnt/300G/data/2022-10-31-083642
2022-10-31 08:36:43 INFO: LOG: /mnt/300G/data/2022-10-31-083642/cygnus-weekly.log
~/cron/ldms-test ~/cron/ldms-test
/mnt/300G/data/2022-10-31-083642 ~/cron/ldms-test ~/cron/ldms-test
2022-10-31 08:36:44 INFO: Skip building on host because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:36:44 INFO: Skip building containerized binary because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:36:44 INFO: -- Installation process succeeded --
2022-10-31 08:36:44 INFO: ---------------------------------------------------------------
~/cron/ldms-test /mnt/300G/data/2022-10-31-083642
~/cron/ldms-test/weekly-report ~/cron/ldms-test /mnt/300G/data/2022-10-31-083642
HEAD is now at fdb722b 2022-10-27-221905
[master 1d6ccf1] 2022-10-31-083642
 2 files changed, 14 insertions(+), 2036 deletions(-)
 rewrite test-all.log (99%)
To github.com:ldms-test/weekly-report
   fdb722b..1d6ccf1  master -> master
~/cron/ldms-test /mnt/300G/data/2022-10-31-083642
2022-10-31 08:36:45 INFO: ==== OVIS+SOS Installation Completed ====
2022-10-31 08:36:45 INFO: ==== Start batch testing ====
~/cron/ldms-test /mnt/300G/data/2022-10-31-083642 ~/cron/ldms-test ~/cron/ldms-test
2022-10-31 08:36:45 INFO: ======== direct_ldms_ls_conn_test ========
2022-10-31 08:36:45 INFO: CMD: python3 direct_ldms_ls_conn_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/direct_ldms_ls_conn_test
2022-10-31 08:36:46,512 TADA INFO starting test `direct_ldms_ls_conn_test`
2022-10-31 08:36:46,513 TADA INFO   test-id: 7d417f0a7e9897ff63f905198c67148c015549266dbfe358cb41a4974c256e78
2022-10-31 08:36:46,513 TADA INFO   test-suite: LDMSD
2022-10-31 08:36:46,513 TADA INFO   test-name: direct_ldms_ls_conn_test
2022-10-31 08:36:46,513 TADA INFO   test-user: narate
2022-10-31 08:36:46,513 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:36:46,967 __main__ INFO starting munged on cygnus-01-iw
2022-10-31 08:36:47,321 __main__ INFO starting munged on localhost
2022-10-31 08:36:47,552 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-31 08:36:47,855 TADA INFO assertion 0, Start ldmsd sampler and munged: OK, passed
2022-10-31 08:36:53,041 TADA INFO assertion 1, ldms_ls to the sampler: OK, passed
2022-10-31 08:36:53,042 __main__ INFO Stopping sampler daemon ...
2022-10-31 08:36:58,464 TADA INFO assertion 2, Kill the sampler: OK, passed
2022-10-31 08:36:58,503 TADA INFO assertion 3, ldms_ls to the dead sampler: got expected output, passed
2022-10-31 08:36:58,541 TADA INFO assertion 4, ldms_ls to a dead host: got expected output, passed
2022-10-31 08:36:58,542 TADA INFO test direct_ldms_ls_conn_test ended
2022-10-31 08:36:58,758 __main__ INFO stopping munged on cygnus-01-iw
2022-10-31 08:36:59,169 __main__ INFO stopping munged on localhost
2022-10-31 08:36:59 INFO: ----------------------------------------------
2022-10-31 08:36:59 INFO: ======== direct_prdcr_subscribe_test ========
2022-10-31 08:36:59 INFO: CMD: python3 direct_prdcr_subscribe_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/direct_prdcr_subscribe_test
2022-10-31 08:36:59,999 TADA INFO starting test `direct_prdcr_subscribe_test`
2022-10-31 08:36:59,999 TADA INFO   test-id: f8400f337ee51361fa9ee40fa49ef44170d9fd45d81da2e576a7738f9d2d956d
2022-10-31 08:36:59,999 TADA INFO   test-suite: LDMSD
2022-10-31 08:36:59,999 TADA INFO   test-name: direct_prdcr_subscribe_test
2022-10-31 08:36:59,999 TADA INFO   test-user: narate
2022-10-31 08:37:00,000 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:37:01,916 __main__ INFO starting munged on cygnus-01-iw
2022-10-31 08:37:02,711 __main__ INFO starting munged on cygnus-02-iw
2022-10-31 08:37:03,439 __main__ INFO starting munged on cygnus-03-iw
2022-10-31 08:37:04,267 __main__ INFO starting munged on cygnus-04-iw
2022-10-31 08:37:04,778 __main__ INFO starting munged on localhost
2022-10-31 08:37:05,004 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-31 08:37:05,501 __main__ INFO starting ldmsd on cygnus-02-iw
2022-10-31 08:37:06,025 __main__ INFO starting ldmsd on cygnus-03-iw
2022-10-31 08:37:06,524 __main__ INFO starting ldmsd on cygnus-04-iw
2022-10-31 08:37:13,372 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-31 08:37:13,373 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-31 08:37:13,373 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-31 08:37:13,374 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-31 08:37:13,375 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verified, passed
2022-10-31 08:37:13,410 TADA INFO assertion 5, Stopping the producers succeeds: agg-1 producers stopped, passed
2022-10-31 08:37:14,412 TADA INFO assertion 6, Restarting the producers succeeds: agg-1 producers started, passed
2022-10-31 08:37:20,956 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-31 08:37:20,957 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-31 08:37:20,957 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-31 08:37:20,958 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-31 08:37:20,959 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verified, passed
2022-10-31 08:37:20,959 __main__ INFO stopping sampler-1
2022-10-31 08:37:22,368 TADA INFO assertion 12, stream-sampler-1 is not running: sampler-1 stopped, passed
2022-10-31 08:37:22,369 __main__ INFO starting sampler-1
2022-10-31 08:37:23,626 TADA INFO assertion 13, stream-sampler-1 has restarted: sampler-1 running, passed
2022-10-31 08:37:23,626 __main__ INFO allow some time for prdcr to reconnect ...
2022-10-31 08:37:29,537 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-31 08:37:29,538 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-31 08:37:29,539 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verified, passed
2022-10-31 08:37:29,540 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: unsubscribed, passed
2022-10-31 08:37:31,716 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-31 08:37:31,721 __main__ INFO stopping agg-1
2022-10-31 08:37:36,934 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-31 08:37:36,935 TADA INFO test direct_prdcr_subscribe_test ended
2022-10-31 08:37:37,146 __main__ INFO stopping munged on cygnus-01-iw
2022-10-31 08:37:37,565 __main__ INFO stopping ldmsd on cygnus-01-iw
2022-10-31 08:37:37,971 __main__ INFO stopping munged on cygnus-02-iw
2022-10-31 08:37:38,378 __main__ INFO stopping ldmsd on cygnus-02-iw
2022-10-31 08:37:38,840 __main__ INFO stopping munged on cygnus-03-iw
2022-10-31 08:37:39,462 __main__ INFO stopping munged on cygnus-04-iw
2022-10-31 08:37:39,886 __main__ INFO stopping ldmsd on cygnus-04-iw
2022-10-31 08:37:40,091 __main__ INFO stopping munged on localhost
2022-10-31 08:37:40 INFO: ----------------------------------------------
2022-10-31 08:37:40 INFO: ======== agg_slurm_test ========
2022-10-31 08:37:40 INFO: CMD: python3 agg_slurm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/agg_slurm_test
2022-10-31 08:37:40,961 TADA INFO starting test `agg_slurm_test`
2022-10-31 08:37:40,961 TADA INFO   test-id: d5f445cc1e290d8acdaef9b9bfeb6731bfb93b317d84e9e5f51f1bfd44127f6f
2022-10-31 08:37:40,961 TADA INFO   test-suite: LDMSD
2022-10-31 08:37:40,961 TADA INFO   test-name: agg_slurm_test
2022-10-31 08:37:40,961 TADA INFO   test-user: narate
2022-10-31 08:37:40,961 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:37:40,962 __main__ INFO -- Get or create the cluster --
2022-10-31 08:37:54,785 __main__ INFO -- Preparing syspapi JSON file --
2022-10-31 08:37:54,884 __main__ INFO -- Preparing jobpapi JSON file --
2022-10-31 08:37:55,002 __main__ INFO -- Preparing job script & programs --
2022-10-31 08:37:56,376 __main__ INFO -- Start daemons --
2022-10-31 08:38:08,465 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 08:38:13,467 __main__ INFO -- ldms_ls to agg-2 --
2022-10-31 08:38:13,588 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-31 08:38:13,706 __main__ INFO -- Give syspapi some time to work before submitting job --
2022-10-31 08:38:18,710 __main__ INFO -- Submitting jobs --
2022-10-31 08:38:18,829 __main__ INFO job_one: 1
2022-10-31 08:38:18,960 __main__ INFO job_two: 2
2022-10-31 08:38:28,970 __main__ INFO -- Cancelling jobs --
2022-10-31 08:38:28,971 __main__ INFO job_one: 1
2022-10-31 08:38:29,098 __main__ INFO job_two: 2
2022-10-31 08:39:40,930 TADA INFO assertion 2, slurm data verification: get expected data from store, passed
2022-10-31 08:39:40,930 TADA INFO assertion 3, meminfo data verification: No data missing, failed
Traceback (most recent call last):
  File "agg_slurm_test", line 592, in <module>
    test.assert_test(3, len(meminfo) > 5 and missing_counts == 0, "No data missing")
  File "/home/narate/cron/ldms-test/TADA.py", line 157, in assert_test
    raise AssertionException(self.test_desc + ", " + cond_str + ": FAILED")
TADA.AssertionException: LDMSD 2-level agg with slurm, No data missing: FAILED
2022-10-31 08:39:40,931 TADA INFO assertion 4, (SYS/JOB) PAPI data verification: skipped
2022-10-31 08:39:40,932 TADA INFO test agg_slurm_test ended
2022-10-31 08:39:55 INFO: ----------------------------------------------
2022-10-31 08:39:55 INFO: ======== papi_sampler_test ========
2022-10-31 08:39:55 INFO: CMD: python3 papi_sampler_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/papi_sampler_test
2022-10-31 08:39:56,686 TADA INFO starting test `papi_sampler_test`
2022-10-31 08:39:56,686 TADA INFO   test-id: 393e762811817c1b9cc7e3a1a2d1e80a7a3ea07f12ee47d8e9fb80cd07942516
2022-10-31 08:39:56,686 TADA INFO   test-suite: LDMSD
2022-10-31 08:39:56,686 TADA INFO   test-name: papi_sampler_test
2022-10-31 08:39:56,686 TADA INFO   test-user: narate
2022-10-31 08:39:56,686 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:39:56,687 __main__ INFO -- Get or create the cluster --
2022-10-31 08:40:01,921 __main__ INFO -- Start daemons --
2022-10-31 08:40:11,952 TADA INFO assertion 0, ldmsd has started: verified, passed
2022-10-31 08:40:12,174 TADA INFO assertion 1.1, Non-papi job is submitted: jobid(1) > 0, passed
2022-10-31 08:40:17,300 TADA INFO assertion 1.2, Non-papi job is running before ldms_ls: STATE = RUNNING, passed
2022-10-31 08:40:17,467 TADA INFO assertion 1.3, Non-papi job is running after ldms_ls: STATE = RUNNING, passed
2022-10-31 08:40:17,468 TADA INFO assertion 1, Non-papi job does not create set: verified, passed
2022-10-31 08:40:31,292 TADA INFO assertion 2, papi job creates set: PAPI set created, passed
2022-10-31 08:40:31,292 TADA INFO assertion 2.2, Schema name is set accordingly: schema name == papi0, passed
2022-10-31 08:40:31,293 TADA INFO assertion 2.1, Events in papi job set created according to config file: {'PAPI_TOT_INS'} == {'PAPI_TOT_INS'}, passed
2022-10-31 08:40:31,293 TADA INFO assertion 2.3, PAPI set has correct job_id: 2 == 2, passed
2022-10-31 08:40:31,511 TADA INFO assertion 2.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-31 08:40:37,329 TADA INFO assertion 3, papi job creates set: PAPI set created, passed
2022-10-31 08:40:37,329 TADA INFO assertion 3.2, Schema name is set accordingly: schema name == papi1, passed
2022-10-31 08:40:37,330 TADA INFO assertion 3.1, Events in papi job set created according to config file: {'PAPI_TOT_INS', 'PAPI_BR_MSP'} == {'PAPI_TOT_INS', 'PAPI_BR_MSP'}, passed
2022-10-31 08:40:37,330 TADA INFO assertion 3.3, PAPI set has correct job_id: 3 == 3, passed
2022-10-31 08:40:37,535 TADA INFO assertion 3.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-31 08:40:37,535 TADA INFO assertion 4, Multiple, concurrent jobs results in concurrent, multiple sets: LDMS sets ({'node-1/papi1/3.0', 'node-1/meminfo', 'node-1/papi0/2.0'}), passed
2022-10-31 08:40:48,095 TADA INFO assertion 6, PAPI set persists within `job_expiry` after job exited: verified, passed
2022-10-31 08:41:28,439 TADA INFO assertion 7, PAPI set is deleted after `2.2 x job_expiry` since job exited: node-1/meminfo deleted, passed
2022-10-31 08:41:30,799 TADA INFO assertion 8, Missing config file attribute is logged: : papi_sampler[519]: papi_config object must contain either the 'file' or 'config' attribute., passed
2022-10-31 08:41:36,244 TADA INFO assertion 9, Bad config file is logged: : papi_sampler: configuration file syntax error., passed
2022-10-31 08:41:41,691 TADA INFO assertion 10, Unsupported events are logged: : papi_sampler: PAPI error 'Event does not exist' translating event code 'FOO', passed
2022-10-31 08:41:41,692 __main__ INFO -- Finishing Test --
2022-10-31 08:41:41,692 TADA INFO test papi_sampler_test ended
2022-10-31 08:41:41,692 __main__ INFO -- Cleaning up files --
2022-10-31 08:41:41,693 __main__ INFO -- Removing the virtual cluster --
2022-10-31 08:41:53 INFO: ----------------------------------------------
2022-10-31 08:41:53 INFO: ======== papi_store_test ========
2022-10-31 08:41:53 INFO: CMD: python3 papi_store_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/papi_store_test
2022-10-31 08:41:54,681 TADA INFO starting test `papi_store_test`
2022-10-31 08:41:54,682 TADA INFO   test-id: 3510b5627232b72fc69d1144d6da44c047bf974f40bdb6c4094b5327d3eec0e0
2022-10-31 08:41:54,682 TADA INFO   test-suite: LDMSD
2022-10-31 08:41:54,682 TADA INFO   test-name: papi_store_test
2022-10-31 08:41:54,682 TADA INFO   test-user: narate
2022-10-31 08:41:54,683 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:41:54,684 __main__ INFO -- Get or create the cluster --
2022-10-31 08:42:02,241 __main__ INFO -- Start daemons --
2022-10-31 08:42:34,865 TADA INFO assertion 1, Every job in the input data is represented in the output: {1, 2, 3, 4} = {1, 2, 3, 4}, passed
2022-10-31 08:42:34,865 TADA INFO assertion 2, Every event in every job results in a separate row in the output: verified, passed
2022-10-31 08:42:34,866 TADA INFO assertion 3, The schema name in the output matches the event name: verified, passed
2022-10-31 08:42:34,866 TADA INFO assertion 4, Each rank in the job results in a row per event in the output: verified, passed
2022-10-31 08:42:34,866 TADA INFO test papi_store_test ended
2022-10-31 08:42:47 INFO: ----------------------------------------------
2022-10-31 08:42:47 INFO: ======== store_app_test ========
2022-10-31 08:42:47 INFO: CMD: python3 store_app_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/store_app_test
2022-10-31 08:42:48,672 TADA INFO starting test `store_app_test`
2022-10-31 08:42:48,672 TADA INFO   test-id: 8addc06b20bdbabe1d0f74557dc82bfed7d4fb40817c2c605239196918ead2d7
2022-10-31 08:42:48,673 TADA INFO   test-suite: LDMSD
2022-10-31 08:42:48,673 TADA INFO   test-name: store_app_test
2022-10-31 08:42:48,673 TADA INFO   test-user: narate
2022-10-31 08:42:48,673 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:42:48,674 __main__ INFO -- Get or create the cluster --
2022-10-31 08:43:02,986 __main__ INFO -- Preparing job script & programs --
2022-10-31 08:43:03,389 __main__ INFO -- Start daemons --
2022-10-31 08:43:15,765 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 08:43:20,767 __main__ INFO -- Submitting jobs --
2022-10-31 08:43:20,959 __main__ INFO job_one: 1
2022-10-31 08:43:26,183 __main__ INFO job_two: 2
2022-10-31 08:43:35,368 __main__ INFO Verifying data ...
2022-10-31 08:45:32,138 TADA INFO assertion 1, Verify data: sos data is not empty and sos data < ldms_ls data, passed
2022-10-31 08:45:32,138 TADA INFO test store_app_test ended
2022-10-31 08:45:46 INFO: ----------------------------------------------
2022-10-31 08:45:46 INFO: ======== syspapi_test ========
2022-10-31 08:45:46 INFO: CMD: python3 syspapi_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/syspapi_test
2022-10-31 08:45:47,695 TADA INFO starting test `syspapi_test`
2022-10-31 08:45:47,695 TADA INFO   test-id: fd5601d79e8c8f1d257f034378effa1243b04cf877f1304c325981c61866d7da
2022-10-31 08:45:47,695 TADA INFO   test-suite: LDMSD
2022-10-31 08:45:47,695 TADA INFO   test-name: syspapi_test
2022-10-31 08:45:47,696 TADA INFO   test-user: narate
2022-10-31 08:45:47,696 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:45:47,696 __main__ INFO -- Get or create the cluster --
2022-10-31 08:45:58,927 __main__ INFO -- Write syspapi JSON config files --
2022-10-31 08:45:58,927 __main__ INFO    - db/syspapi-1.json
2022-10-31 08:45:58,927 __main__ INFO    - db/syspapi-bad.json
2022-10-31 08:45:58,928 __main__ INFO -- Start daemons --
2022-10-31 08:46:07,311 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 08:46:12,314 __main__ INFO -- Verifying --
2022-10-31 08:46:12,446 TADA INFO assertion 1, verify set creation by cfg_file: set existed (with correct instance name), passed
2022-10-31 08:46:12,446 TADA INFO assertion 2, verify schema name by cfg_file: verify schema name, passed
2022-10-31 08:46:12,559 TADA INFO assertion 3, verify metrics (events) by cfg_file: verify events (metrics), passed
2022-10-31 08:46:14,678 TADA INFO assertion 4, verify increment counters: verify increment of supported counters, passed
2022-10-31 08:46:14,800 TADA INFO assertion 5, verify cfg_file syntax error report: verify JSON parse error, passed
2022-10-31 08:46:14,915 TADA INFO assertion 6, verify cfg_file unsupported events report: verify unsupported event report, passed
2022-10-31 08:46:36,124 TADA INFO assertion 7, verify cfg_file for many events: each event has either 'sucees' or 'failed' report, passed
2022-10-31 08:46:36,124 __main__ INFO  events succeeded: 77
2022-10-31 08:46:36,124 __main__ INFO  events failed: 114
2022-10-31 08:46:36,124 TADA INFO test syspapi_test ended
2022-10-31 08:46:49 INFO: ----------------------------------------------
2022-10-31 08:46:50 INFO: ======== agg_test ========
2022-10-31 08:46:50 INFO: CMD: python3 agg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/agg_test
2022-10-31 08:46:51,044 TADA INFO starting test `agg_test`
2022-10-31 08:46:51,045 TADA INFO   test-id: 58f20ac9e9c66d73828600b8987c57270c67e58e8103ff3216316ec54926fb15
2022-10-31 08:46:51,045 TADA INFO   test-suite: LDMSD
2022-10-31 08:46:51,045 TADA INFO   test-name: agg_test
2022-10-31 08:46:51,045 TADA INFO   test-user: narate
2022-10-31 08:46:51,045 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:46:51,046 __main__ INFO -- Get or create the cluster --
2022-10-31 08:47:08,476 __main__ INFO -- Start daemons --
2022-10-31 08:47:17,737 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 08:47:22,742 __main__ INFO -- ldms_ls to agg-2 --
2022-10-31 08:47:22,858 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-31 08:47:23,614 TADA INFO assertion 2, meminfo data verification: data verified, passed
2022-10-31 08:47:23,614 __main__ INFO -- Terminating ldmsd on node-1 --
2022-10-31 08:47:25,964 TADA INFO assertion 3, node-1 ldmsd terminated, sets removed from agg-11: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-31 08:47:26,203 TADA INFO assertion 4, node-1 ldmsd terminated, sets removed from agg-2: list({'node-3/meminfo', 'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:47:26,203 __main__ INFO -- Resurrecting ldmsd on node-1 --
2022-10-31 08:47:31,866 TADA INFO assertion 5, node-1 ldmsd revived, sets added to agg-11: list({'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-31 08:47:31,979 TADA INFO assertion 6, node-1 ldmsd revived, sets added to agg-2: list({'node-3/meminfo', 'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo', 'node-1/meminfo'}), passed
2022-10-31 08:47:31,979 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-31 08:47:34,323 TADA INFO assertion 7, agg-11 ldmsd terminated, sets removed from agg-2: list({'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:47:34,451 TADA INFO assertion 8, agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-31 08:47:34,558 TADA INFO assertion 9, agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-31 08:47:34,558 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-31 08:47:40,239 TADA INFO assertion 10, agg-11 ldmsd revived, sets added to agg-2: list({'node-3/meminfo', 'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo', 'node-1/meminfo'}), passed
2022-10-31 08:47:40,239 TADA INFO test agg_test ended
2022-10-31 08:47:55 INFO: ----------------------------------------------
2022-10-31 08:47:56 INFO: ======== failover_test ========
2022-10-31 08:47:56 INFO: CMD: python3 failover_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/failover_test
2022-10-31 08:47:57,165 TADA INFO starting test `failover_test`
2022-10-31 08:47:57,165 TADA INFO   test-id: 4dd27fc95303436b8b68d13b02336281d5c292ffaacb7c61c83e29134930dd6a
2022-10-31 08:47:57,165 TADA INFO   test-suite: LDMSD
2022-10-31 08:47:57,165 TADA INFO   test-name: failover_test
2022-10-31 08:47:57,165 TADA INFO   test-user: narate
2022-10-31 08:47:57,165 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:47:57,166 __main__ INFO -- Get or create the cluster --
2022-10-31 08:48:14,540 __main__ INFO -- Start daemons --
2022-10-31 08:48:23,841 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 08:48:38,853 __main__ INFO -- ldms_ls to agg-2 --
2022-10-31 08:48:38,972 TADA INFO assertion 1, 
ldms_ls agg-2: dir result verified, passed
2022-10-31 08:48:39,774 TADA INFO assertion 2, 
meminfo data verification: data verified, passed
2022-10-31 08:48:39,775 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-31 08:48:45,126 TADA INFO assertion 3, 
agg-11 ldmsd terminated, sets added to agg-12: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:48:45,248 TADA INFO assertion 4, 
agg-11 ldmsd terminated, all sets running on agg-2: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:48:45,365 TADA INFO assertion 5, 
agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-31 08:48:45,478 TADA INFO assertion 6, 
agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-31 08:48:45,478 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-31 08:49:06,148 TADA INFO assertion 7, 
agg-11 ldmsd revived, sets removed from agg-12: list({'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:49:06,260 TADA INFO assertion 8, 
agg-11 ldmsd revived, all sets running on agg-2: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:49:06,260 __main__ INFO -- Terminating ldmsd on agg-12 --
2022-10-31 08:49:11,598 TADA INFO assertion 9, 
agg-12 ldmsd terminated, sets added to agg-11: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:49:11,724 TADA INFO assertion 10, 
agg-12 ldmsd terminated, all sets running on agg-2: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:49:11,827 TADA INFO assertion 11, 
agg-12 ldmsd terminated, node-2 ldmsd is still running: list({'node-2/meminfo'}) == expect({'node-2/meminfo'}), passed
2022-10-31 08:49:11,939 TADA INFO assertion 12, 
agg-12 ldmsd terminated, node-4 ldmsd is still running: list({'node-4/meminfo'}) == expect({'node-4/meminfo'}), passed
2022-10-31 08:49:11,939 __main__ INFO -- Resurrecting ldmsd on agg-12 --
2022-10-31 08:49:32,629 TADA INFO assertion 13, 
agg-12 ldmsd revived, sets removed from agg-11: list({'node-1/meminfo', 'node-3/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo'}), passed
2022-10-31 08:49:32,747 TADA INFO assertion 14, 
agg-12 ldmsd revived, all sets running on agg-2: list({'node-2/meminfo', 'node-1/meminfo', 'node-3/meminfo', 'node-4/meminfo'}) == expect({'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-31 08:49:32,747 TADA INFO test failover_test ended
2022-10-31 08:49:48 INFO: ----------------------------------------------
2022-10-31 08:49:49 INFO: ======== ldmsd_auth_ovis_test ========
2022-10-31 08:49:49 INFO: CMD: python3 ldmsd_auth_ovis_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldmsd_auth_ovis_test
2022-10-31 08:49:49,741 TADA INFO starting test `ldmsd_auth_ovis_test`
2022-10-31 08:49:49,741 TADA INFO   test-id: a9d281653104f8736b4c2476ffffa8d016c9e21c8a367c60fc64185f0acff8c5
2022-10-31 08:49:49,741 TADA INFO   test-suite: LDMSD
2022-10-31 08:49:49,741 TADA INFO   test-name: ldmsd_auth_ovis_test
2022-10-31 08:49:49,741 TADA INFO   test-user: narate
2022-10-31 08:49:49,741 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:49:49,742 __main__ INFO -- Get or create the cluster --
2022-10-31 08:49:55,305 __main__ INFO -- Start daemons --
2022-10-31 08:49:57,296 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 08:50:02,432 TADA INFO assertion 1, ldms_ls with auth none: verified, passed
2022-10-31 08:50:02,562 TADA INFO assertion 2, ldms_ls with wrong secret: verified, passed
2022-10-31 08:50:02,683 TADA INFO assertion 3, ldms_ls 'dir' with right secret: verified, passed
2022-10-31 08:50:02,967 TADA INFO assertion 4, ldms_ls 'read' with right secret: verified, passed
2022-10-31 08:50:02,967 TADA INFO test ldmsd_auth_ovis_test ended
2022-10-31 08:50:14 INFO: ----------------------------------------------
2022-10-31 08:50:15 INFO: ======== ldmsd_auth_test ========
2022-10-31 08:50:15 INFO: CMD: python3 ldmsd_auth_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldmsd_auth_test
2022-10-31 08:50:15,963 TADA INFO starting test `ldmsd_auth_test`
2022-10-31 08:50:15,963 TADA INFO   test-id: 43de03a78a3b37a06486a3edde979c7c79c01d5cfd9aee9c6b72e52f43119761
2022-10-31 08:50:15,963 TADA INFO   test-suite: LDMSD
2022-10-31 08:50:15,963 TADA INFO   test-name: ldmsd_auth_test
2022-10-31 08:50:15,963 TADA INFO   test-user: narate
2022-10-31 08:50:15,963 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:50:15,964 __main__ INFO -- Get or create the cluster --
2022-10-31 08:50:33,850 __main__ INFO -- Start daemons --
2022-10-31 08:50:52,576 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 08:50:57,707 TADA INFO assertion 1, root@agg-2(dom3) ldms_ls to agg-2:10000: see all sets, passed
2022-10-31 08:50:57,831 TADA INFO assertion 2, user@agg-2(dom3) ldms_ls to agg-2:10000: see only meminfo, passed
2022-10-31 08:50:57,954 TADA INFO assertion 3, root@headnode(dom4) ldms_ls to agg-2:10001: see all sets, passed
2022-10-31 08:50:58,076 TADA INFO assertion 4, user@headnode(dom4) ldms_ls to agg-2:10001: see only meminfo, passed
2022-10-31 08:50:58,190 TADA INFO assertion 5, root@headnode(dom4) ldms_ls to agg-11:10000: connection rejected, passed
2022-10-31 08:50:58,191 TADA INFO test ldmsd_auth_test ended
2022-10-31 08:51:13 INFO: ----------------------------------------------
2022-10-31 08:51:14 INFO: ======== ldmsd_ctrl_test ========
2022-10-31 08:51:14 INFO: CMD: python3 ldmsd_ctrl_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldmsd_ctrl_test
2022-10-31 08:51:15,355 TADA INFO starting test `ldmsd_ctrl_test`
2022-10-31 08:51:15,355 TADA INFO   test-id: f2fc10cf730cd73c3db621f08e7da1b3f6e9d3f1ab87c6960478af0be3df836e
2022-10-31 08:51:15,355 TADA INFO   test-suite: LDMSD
2022-10-31 08:51:15,355 TADA INFO   test-name: ldmsd_ctrl_test
2022-10-31 08:51:15,355 TADA INFO   test-user: narate
2022-10-31 08:51:15,355 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:51:15,356 __main__ INFO -- Get or create the cluster --
2022-10-31 08:51:24,612 __main__ INFO -- Start daemons --
2022-10-31 08:51:29,023 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 08:51:35,146 TADA INFO assertion 1, ldmsd_controller interactive session: connected, passed
2022-10-31 08:51:36,262 TADA INFO assertion 2, ldmsctl interactive session: connected, passed
2022-10-31 08:51:36,864 TADA INFO assertion 3, ldmsd_controller start bogus producer: expected output verified, passed
2022-10-31 08:51:37,465 TADA INFO assertion 4, ldmsctl start bogus producer: expected output verified, passed
2022-10-31 08:51:38,067 TADA INFO assertion 5, ldmsd_controller bogus command: expected output verified, passed
2022-10-31 08:51:38,668 TADA INFO assertion 6, ldmsctl bogus command: expected output verified, passed
2022-10-31 08:51:39,270 TADA INFO assertion 7, ldmsd_controller load bogus plugin: expected output verified, passed
2022-10-31 08:51:39,871 TADA INFO assertion 8, ldmsctl load bogus plugin: expected output verified, passed
2022-10-31 08:51:57,074 TADA INFO assertion 9, ldmsd_controller prdcr/updtr: verified, passed
2022-10-31 08:52:14,259 TADA INFO assertion 10, ldmsctl prdcr/updtr: verified, passed
2022-10-31 08:52:14,259 TADA INFO test ldmsd_ctrl_test ended
2022-10-31 08:52:26 INFO: ----------------------------------------------
2022-10-31 08:52:27 INFO: ======== ldmsd_stream_test ========
2022-10-31 08:52:27 INFO: CMD: python3 ldmsd_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldmsd_stream_test
2022-10-31 08:52:28,434 TADA INFO starting test `ldmsd_stream_test`
2022-10-31 08:52:28,434 TADA INFO   test-id: fcfad53359c442e1eb04352d6ae45f503c8db282877028e715e6bee010013d88
2022-10-31 08:52:28,434 TADA INFO   test-suite: LDMSD
2022-10-31 08:52:28,434 TADA INFO   test-name: ldmsd_stream_test
2022-10-31 08:52:28,434 TADA INFO   test-user: narate
2022-10-31 08:52:28,434 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 08:52:39,584 __main__ INFO waiting for libraries to be available across all containers...
2022-10-31 08:52:40,439 __main__ INFO _lib_avail: True
2022-10-31 08:53:47,779 __main__ INFO test ldmsd_stream_subscribe with large json streams
2022-10-31 08:53:53,918 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-31 08:54:07,292 __main__ INFO --- Verifying the received streams
2022-10-31 08:54:08,922 TADA INFO assertion 1, ldmsd_stream_subscribe receives large json streams: Verify all streams were received correctly, passed
2022-10-31 08:54:09,130 __main__ INFO test LDMSD with large json streams
2022-10-31 08:54:15,188 __main__ INFO --- Sending stream to samplerd
2022-10-31 08:54:34,049 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 08:54:36,449 TADA INFO assertion 2, samplerd receives large json streams: Verify all streams were received correctly, passed
2022-10-31 08:54:36,449 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 08:54:38,847 TADA INFO assertion 3, agg receives large json streams: Verify all streams were received correctly, passed
2022-10-31 08:54:38,847 __main__ INFO test ldmsd_stream_subscribe with small json streams
2022-10-31 08:54:44,975 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-31 08:56:40,571 __main__ INFO --- Verifying the received streams
2022-10-31 08:56:42,469 TADA INFO assertion 4, ldmsd_stream_subscribe receives small json streams: Verify all streams were received correctly, passed
2022-10-31 08:56:42,688 __main__ INFO test LDMSD with small json streams
2022-10-31 08:56:48,695 __main__ INFO --- Sending stream to samplerd
2022-10-31 08:58:49,630 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 08:58:52,479 TADA INFO assertion 5, samplerd receives small json streams: Verify all streams were received correctly, passed
2022-10-31 08:58:52,479 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 08:58:55,301 TADA INFO assertion 6, agg receives small json streams: Verify all streams were received correctly, passed
2022-10-31 08:58:55,302 __main__ INFO test ldmsd_stream_subscribe with large string streams
2022-10-31 08:59:01,428 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-31 08:59:14,590 __main__ INFO --- Verifying the received streams
2022-10-31 08:59:16,163 TADA INFO assertion 7, ldmsd_stream_subscribe receives large string streams: Verify all streams were received correctly, passed
2022-10-31 08:59:16,376 __main__ INFO test LDMSD with large string streams
2022-10-31 08:59:22,391 __main__ INFO --- Sending stream to samplerd
2022-10-31 08:59:41,244 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 08:59:42,411 TADA INFO assertion 8, samplerd receives large string streams: Verify all streams were received correctly, passed
2022-10-31 08:59:42,412 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 08:59:43,552 TADA INFO assertion 9, agg receives large string streams: Verify all streams were received correctly, passed
2022-10-31 08:59:43,553 __main__ INFO test ldmsd_stream_subscribe with small string streams
2022-10-31 08:59:49,671 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-31 09:01:45,117 __main__ INFO --- Verifying the received streams
2022-10-31 09:01:47,065 TADA INFO assertion 10, ldmsd_stream_subscribe receives small string streams: Verify all streams were received correctly, passed
2022-10-31 09:01:47,272 __main__ INFO test LDMSD with small string streams
2022-10-31 09:01:53,292 __main__ INFO --- Sending stream to samplerd
2022-10-31 09:03:54,473 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 09:03:55,684 TADA INFO assertion 11, samplerd receives small string streams: Verify all streams were received correctly, passed
2022-10-31 09:03:55,684 __main__ INFO --- Verifying the streams received by samplerd
2022-10-31 09:03:56,895 TADA INFO assertion 12, agg receives small string streams: Verify all streams were received correctly, passed
2022-10-31 09:03:56,895 TADA INFO test ldmsd_stream_test ended
2022-10-31 09:04:09 INFO: ----------------------------------------------
2022-10-31 09:04:11 INFO: ======== maestro_cfg_test ========
2022-10-31 09:04:11 INFO: CMD: python3 maestro_cfg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/maestro_cfg_test
2022-10-31 09:04:12,007 TADA INFO starting test `maestro_cfg_test`
2022-10-31 09:04:12,008 TADA INFO   test-id: 99fe83abab97ffc4a6e6bf9d7978e463c5a8d97a076a381268c3bcf52e39c38e
2022-10-31 09:04:12,008 TADA INFO   test-suite: LDMSD
2022-10-31 09:04:12,008 TADA INFO   test-name: maestro_cfg_test
2022-10-31 09:04:12,008 TADA INFO   test-user: narate
2022-10-31 09:04:12,008 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:04:22,009 __main__ INFO -- Get or create cluster --
2022-10-31 09:04:48,233 __main__ INFO -- Start daemons --
2022-10-31 09:05:03,009 __main__ INFO ... make sure ldmsd's are up
2022-10-31 09:05:10,728 TADA INFO assertion 1, load maestro etcd cluster: etcd cluster loaded successfully, passed
2022-10-31 09:05:50,770 TADA INFO assertion 2, config ldmsd cluster with maestro: Maestro ldmsd configuration successful, passed
2022-10-31 09:05:52,369 TADA INFO assertion 3, verify sampler daemons: OK, passed
2022-10-31 09:05:52,964 TADA INFO assertion 4, verify L1 aggregator daemons: OK, passed
2022-10-31 09:05:53,207 TADA INFO assertion 5, verify L2 aggregator daemon: OK, passed
2022-10-31 09:05:53,533 TADA INFO assertion 6, verify data storage: OK, passed
---Wait for config to write to file---
2022-10-31 09:05:53,533 TADA INFO test maestro_cfg_test ended
2022-10-31 09:06:11 INFO: ----------------------------------------------
2022-10-31 09:06:12 INFO: ======== mt-slurm-test ========
2022-10-31 09:06:12 INFO: CMD: python3 mt-slurm-test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/mt-slurm-test
-- Get or create the cluster --
-- Start daemons --
... wait a bit to make sure ldmsd's are up
Every job in input data represented in output: : Passed
['# task_rank,timestamp', '0,1667225212.993633', '1,1667225212.993633', '2,1667225212.993633', '3,1667225212.993633', '4,1667225212.993633', '5,1667225212.993633', '6,1667225212.993633', '7,1667225212.993633', '8,1667225213.931479', '9,1667225214.904530', '10,1667225214.904530', '11,1667225214.904530', '12,1667225214.904530', '13,1667225214.904530', '14,1667225214.904530', '15,1667225215.904764', '16,1667225215.904764', '17,1667225215.904764', '18,1667225216.996661', '19,1667225216.996661', '20,1667225216.996661', '21,1667225216.996661', '22,1667225216.996661', '23,1667225217.987348', '24,1667225217.987348', '25,1667225217.987348', '26,1667225217.987348', '# Records 27/27.', '']
Job 10000 has 27 rank: : Passed
Job 10100 has 64 rank: : Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
Job 10000 has 3 nodes: node count 3 correct: Passed
Job 10100 has 4 nodes: node count 4 correct: Passed
2022-10-31 09:07:31 INFO: ----------------------------------------------
2022-10-31 09:07:32 INFO: ======== ovis_ev_test ========
2022-10-31 09:07:32 INFO: CMD: python3 ovis_ev_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ovis_ev_test
2022-10-31 09:07:33,049 __main__ INFO -- Create the cluster -- 
2022-10-31 09:07:42,307 TADA INFO starting test `ovis_ev_test`
2022-10-31 09:07:42,307 TADA INFO   test-id: 10f0196ed11e7d8493c564d7967862a17e4dc6a6e136e17db5aa7933d9833461
2022-10-31 09:07:42,307 TADA INFO   test-suite: test_ovis_ev
2022-10-31 09:07:42,307 TADA INFO   test-name: ovis_ev_test
2022-10-31 09:07:42,307 TADA INFO   test-user: narate
2022-10-31 09:07:42,307 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:07:42,308 TADA INFO assertion 1, Test posting an event without timeout: ovis_ev delivered the expected event., passed
2022-10-31 09:07:42,308 TADA INFO assertion 2, Test posting an event with a current timeout: ovis_ev delivered the expected event., passed
2022-10-31 09:07:42,309 TADA INFO assertion 3, Test posting an event with a future timeout: ovis_ev delivered the expected event., passed
2022-10-31 09:07:42,309 TADA INFO assertion 4, Test reposting a posted event: ev_post returned EBUSY when posted an already posted event, passed
2022-10-31 09:07:42,309 TADA INFO assertion 5, Test canceling a posted event: ovis_ev delivered the expected event., passed
2022-10-31 09:07:42,309 TADA INFO assertion 6, Test rescheduling a posted event: ovis_ev delivered the expected event., passed
2022-10-31 09:07:42,309 TADA INFO assertion 7, Test event deliver order: The event delivery order was correct., passed
2022-10-31 09:07:42,309 TADA INFO assertion 8, Test flushing events: Expected status (1) == delivered status (1), passed
2022-10-31 09:07:42,309 TADA INFO assertion 9, Test posting event on a flushed worker: Expected status (0) == delivered status (0), passed
2022-10-31 09:07:42,310 TADA INFO assertion 10, Test the case that multiple threads post the same event: ev_post returned the expected return code., passed
2022-10-31 09:07:42,310 TADA INFO test ovis_ev_test ended
2022-10-31 09:07:53 INFO: ----------------------------------------------
2022-10-31 09:07:53 INFO: ======== prdcr_subscribe_test ========
2022-10-31 09:07:53 INFO: CMD: python3 prdcr_subscribe_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/prdcr_subscribe_test
2022-10-31 09:07:54,673 TADA INFO starting test `prdcr_subscribe_test`
2022-10-31 09:07:54,674 TADA INFO   test-id: 8995e0df26fe1f7bb78cc5ec46c463746e2c08f1d20f9365d99d503714828f47
2022-10-31 09:07:54,674 TADA INFO   test-suite: LDMSD
2022-10-31 09:07:54,674 TADA INFO   test-name: prdcr_subscribe_test
2022-10-31 09:07:54,674 TADA INFO   test-user: narate
2022-10-31 09:07:54,674 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:08:30,198 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-31 09:08:30,199 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-31 09:08:30,199 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-31 09:08:30,199 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-31 09:08:30,200 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verification, passed
2022-10-31 09:08:30,548 TADA INFO assertion 5, Stopping the producers succeeds: , passed
2022-10-31 09:08:30,906 TADA INFO assertion 6, Restarting the producers succeeds: , passed
2022-10-31 09:08:38,904 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-31 09:08:38,904 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-31 09:08:38,905 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-31 09:08:38,905 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-31 09:08:38,905 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verification, passed
2022-10-31 09:08:40,130 TADA INFO assertion 12, stream-sampler-1 is not running: (running == False), passed
2022-10-31 09:08:41,677 TADA INFO assertion 13, stream-sampler-1 has restarted: (running == True), passed
2022-10-31 09:08:49,251 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-31 09:08:49,251 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-31 09:08:49,252 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verification, passed
2022-10-31 09:08:49,601 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: , passed
2022-10-31 09:08:52,928 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-31 09:08:58,694 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-31 09:08:58,695 TADA INFO test prdcr_subscribe_test ended
2022-10-31 09:09:11 INFO: ----------------------------------------------
2022-10-31 09:09:12 INFO: ======== set_array_test ========
2022-10-31 09:09:12 INFO: CMD: python3 set_array_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/set_array_test
2022-10-31 09:09:12,954 TADA INFO starting test `set_array_test`
2022-10-31 09:09:12,954 TADA INFO   test-id: 6e5887cc7245e8c2456158734ac49a8ccc246113f89cdd375a05d651d7ec6d75
2022-10-31 09:09:12,955 TADA INFO   test-suite: LDMSD
2022-10-31 09:09:12,955 TADA INFO   test-name: set_array_test
2022-10-31 09:09:12,955 TADA INFO   test-user: narate
2022-10-31 09:09:12,955 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:09:12,956 __main__ INFO -- Get or create the cluster --
2022-10-31 09:09:18,027 __main__ INFO -- Start daemons --
2022-10-31 09:09:19,978 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:09:50,535 TADA INFO assertion 1, 1st update got some callbacks: verified hunk of 2 snapshots, passed
2022-10-31 09:09:50,535 TADA INFO assertion 2, 2nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-31 09:09:50,535 TADA INFO assertion 3, 3nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-31 09:09:50,536 TADA INFO test set_array_test ended
2022-10-31 09:10:01 INFO: ----------------------------------------------
2022-10-31 09:10:02 INFO: ======== setgroup_test ========
2022-10-31 09:10:02 INFO: CMD: python3 setgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/setgroup_test
2022-10-31 09:10:03,562 TADA INFO starting test `setgroup_test`
2022-10-31 09:10:03,563 TADA INFO   test-id: 2e608f5b41caf728c3955059e422f1e5bc5e0f695817dba3b8ac4aa00bdcd7d3
2022-10-31 09:10:03,563 TADA INFO   test-suite: LDMSD
2022-10-31 09:10:03,563 TADA INFO   test-name: setgroup_test
2022-10-31 09:10:03,563 TADA INFO   test-user: narate
2022-10-31 09:10:03,563 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:10:03,564 __main__ INFO -- Get or create the cluster --
2022-10-31 09:10:12,823 __main__ INFO -- Start daemons --
2022-10-31 09:10:17,153 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:10:22,157 __main__ INFO -- ldms_ls to agg-2 --
2022-10-31 09:10:22,270 TADA INFO assertion 1, ldms_ls grp on agg-2: dir result verified, passed
2022-10-31 09:10:24,529 TADA INFO assertion 2, members on agg-2 are being updated: data verified, passed
2022-10-31 09:10:24,530 __main__ INFO -- Removing test_2 from grp --
2022-10-31 09:10:25,012 TADA INFO assertion 3, test_2 is removed fom grp on sampler: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-31 09:10:29,136 TADA INFO assertion 4, test_2 is removed from grp on agg-1: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-31 09:10:33,269 TADA INFO assertion 5, test_2 is removed from grp on agg-2: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-31 09:10:37,274 __main__ INFO -- Adding test_2 back into grp --
2022-10-31 09:10:37,759 TADA INFO assertion 6, test_2 is added back to grp on sampler: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-31 09:10:41,880 TADA INFO assertion 7, test_2 is added back to grp on agg-1: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-31 09:10:44,011 TADA INFO assertion 8, test_2 is added back to grp on agg-2: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-31 09:10:46,014 TADA INFO test setgroup_test ended
2022-10-31 09:10:58 INFO: ----------------------------------------------
2022-10-31 09:10:59 INFO: ======== slurm_stream_test ========
2022-10-31 09:10:59 INFO: CMD: python3 slurm_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/slurm_stream_test
2022-10-31 09:11:00,191 TADA INFO starting test `slurm_stream_test`
2022-10-31 09:11:00,192 TADA INFO   test-id: 99b5cab896752ed01db72f17e42adb663a8f9ede9addb4fc3aac4e1cb6c519b5
2022-10-31 09:11:00,192 TADA INFO   test-suite: LDMSD
2022-10-31 09:11:00,192 TADA INFO   test-name: slurm_stream_test
2022-10-31 09:11:00,192 TADA INFO   test-user: narate
2022-10-31 09:11:00,192 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:11:00,193 __main__ INFO -- Get or create the cluster --
2022-10-31 09:11:07,091 __main__ INFO -- Start daemons --
2022-10-31 09:11:09,661 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:11:39,379 TADA INFO assertion 1, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:39,379 __main__ INFO 12345
2022-10-31 09:11:39,379 __main__ INFO 12345
2022-10-31 09:11:39,380 TADA INFO assertion 2, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,380 TADA INFO assertion 3, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-31 09:11:39,380 TADA INFO assertion 4, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,380 TADA INFO assertion 5, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,380 TADA INFO assertion 6, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,380 TADA INFO assertion 7, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,493 TADA INFO assertion 8, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:39,493 __main__ INFO 12345
2022-10-31 09:11:39,493 __main__ INFO 12345
2022-10-31 09:11:39,493 TADA INFO assertion 9, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,493 TADA INFO assertion 10, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-31 09:11:39,493 TADA INFO assertion 11, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,494 TADA INFO assertion 12, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,494 TADA INFO assertion 13, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,494 TADA INFO assertion 14, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-31 09:11:39,595 TADA INFO assertion 15, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:39,596 __main__ INFO 12346
2022-10-31 09:11:39,596 __main__ INFO 12346
2022-10-31 09:11:39,596 TADA INFO assertion 16, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,596 TADA INFO assertion 17, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-31 09:11:39,596 TADA INFO assertion 18, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,596 TADA INFO assertion 19, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,596 TADA INFO assertion 20, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,597 TADA INFO assertion 21, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,702 TADA INFO assertion 22, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:39,702 __main__ INFO 12346
2022-10-31 09:11:39,702 __main__ INFO 12346
2022-10-31 09:11:39,702 TADA INFO assertion 23, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,702 TADA INFO assertion 24, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-31 09:11:39,703 TADA INFO assertion 25, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,703 TADA INFO assertion 26, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,703 TADA INFO assertion 27, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,703 TADA INFO assertion 28, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-31 09:11:39,829 TADA INFO assertion 29, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:39,829 __main__ INFO 12347
2022-10-31 09:11:39,829 __main__ INFO 12347
2022-10-31 09:11:39,829 TADA INFO assertion 30, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,830 TADA INFO assertion 31, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-31 09:11:39,830 TADA INFO assertion 32, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,830 TADA INFO assertion 33, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,830 TADA INFO assertion 34, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,830 TADA INFO assertion 35, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,935 TADA INFO assertion 36, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:39,935 __main__ INFO 12347
2022-10-31 09:11:39,935 __main__ INFO 12347
2022-10-31 09:11:39,935 TADA INFO assertion 37, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,936 TADA INFO assertion 38, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-31 09:11:39,936 TADA INFO assertion 39, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,936 TADA INFO assertion 40, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,936 TADA INFO assertion 41, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 09:11:39,936 TADA INFO assertion 42, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-31 09:11:40,041 TADA INFO assertion 43, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,041 __main__ INFO 12348
2022-10-31 09:11:40,041 __main__ INFO 12348
2022-10-31 09:11:40,041 TADA INFO assertion 44, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,041 TADA INFO assertion 45, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-31 09:11:40,042 TADA INFO assertion 46, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,042 TADA INFO assertion 47, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,042 TADA INFO assertion 48, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,042 TADA INFO assertion 49, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,146 TADA INFO assertion 50, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,146 __main__ INFO 12348
2022-10-31 09:11:40,146 __main__ INFO 12348
2022-10-31 09:11:40,146 TADA INFO assertion 51, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,146 TADA INFO assertion 52, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-31 09:11:40,146 TADA INFO assertion 53, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,146 TADA INFO assertion 54, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,147 TADA INFO assertion 55, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,147 TADA INFO assertion 56, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-31 09:11:40,257 TADA INFO assertion 57, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,257 __main__ INFO 12355
2022-10-31 09:11:40,257 __main__ INFO 12355
2022-10-31 09:11:40,257 TADA INFO assertion 58, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,258 TADA INFO assertion 59, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-31 09:11:40,258 TADA INFO assertion 60, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,258 TADA INFO assertion 61, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,258 TADA INFO assertion 62, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,258 TADA INFO assertion 63, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,258 TADA INFO assertion 64, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,259 TADA INFO assertion 65, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,259 TADA INFO assertion 66, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,259 TADA INFO assertion 67, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,386 TADA INFO assertion 68, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,386 __main__ INFO 12355
2022-10-31 09:11:40,387 __main__ INFO 12355
2022-10-31 09:11:40,387 TADA INFO assertion 69, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,387 TADA INFO assertion 70, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-31 09:11:40,387 TADA INFO assertion 71, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,387 TADA INFO assertion 72, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,387 TADA INFO assertion 73, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,387 TADA INFO assertion 74, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,388 TADA INFO assertion 75, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,388 TADA INFO assertion 76, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,388 TADA INFO assertion 77, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,388 TADA INFO assertion 78, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-31 09:11:40,492 TADA INFO assertion 79, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,492 __main__ INFO 12356
2022-10-31 09:11:40,492 __main__ INFO 12356
2022-10-31 09:11:40,492 TADA INFO assertion 80, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,493 TADA INFO assertion 81, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-31 09:11:40,493 TADA INFO assertion 82, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,493 TADA INFO assertion 83, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,493 TADA INFO assertion 84, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,493 TADA INFO assertion 85, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,493 TADA INFO assertion 86, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,494 TADA INFO assertion 87, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,494 TADA INFO assertion 88, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,494 TADA INFO assertion 89, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,601 TADA INFO assertion 90, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,601 __main__ INFO 12356
2022-10-31 09:11:40,601 __main__ INFO 12356
2022-10-31 09:11:40,602 TADA INFO assertion 91, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,602 TADA INFO assertion 92, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-31 09:11:40,602 TADA INFO assertion 93, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,602 TADA INFO assertion 94, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,602 TADA INFO assertion 95, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,602 TADA INFO assertion 96, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,603 TADA INFO assertion 97, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,603 TADA INFO assertion 98, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,603 TADA INFO assertion 99, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,603 TADA INFO assertion 100, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-31 09:11:40,724 TADA INFO assertion 101, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,724 __main__ INFO 12357
2022-10-31 09:11:40,724 __main__ INFO 12357
2022-10-31 09:11:40,724 TADA INFO assertion 102, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,724 TADA INFO assertion 103, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-31 09:11:40,725 TADA INFO assertion 104, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,725 TADA INFO assertion 105, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,725 TADA INFO assertion 106, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,725 TADA INFO assertion 107, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,725 TADA INFO assertion 108, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,725 TADA INFO assertion 109, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,725 TADA INFO assertion 110, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,726 TADA INFO assertion 111, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,843 TADA INFO assertion 112, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,843 __main__ INFO 12357
2022-10-31 09:11:40,843 __main__ INFO 12357
2022-10-31 09:11:40,843 TADA INFO assertion 113, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,843 TADA INFO assertion 114, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-31 09:11:40,843 TADA INFO assertion 115, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,844 TADA INFO assertion 116, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,844 TADA INFO assertion 117, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,844 TADA INFO assertion 118, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,844 TADA INFO assertion 119, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,844 TADA INFO assertion 120, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,844 TADA INFO assertion 121, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,844 TADA INFO assertion 122, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-31 09:11:40,945 TADA INFO assertion 123, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:40,945 __main__ INFO 12358
2022-10-31 09:11:40,945 __main__ INFO 12358
2022-10-31 09:11:40,945 TADA INFO assertion 124, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-31 09:11:40,946 TADA INFO assertion 125, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-31 09:11:40,946 TADA INFO assertion 126, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:40,946 TADA INFO assertion 127, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:40,946 TADA INFO assertion 128, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:40,946 TADA INFO assertion 129, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:40,946 TADA INFO assertion 130, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:40,947 TADA INFO assertion 131, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:40,947 TADA INFO assertion 132, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:40,947 TADA INFO assertion 133, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,055 TADA INFO assertion 134, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-31 09:11:41,055 __main__ INFO 12358
2022-10-31 09:11:41,055 __main__ INFO 12358
2022-10-31 09:11:41,056 TADA INFO assertion 135, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,056 TADA INFO assertion 136, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-31 09:11:41,056 TADA INFO assertion 137, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,056 TADA INFO assertion 138, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,056 TADA INFO assertion 139, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,056 TADA INFO assertion 140, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,057 TADA INFO assertion 141, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,057 TADA INFO assertion 142, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,057 TADA INFO assertion 143, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:41,057 TADA INFO assertion 144, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-31 09:11:43,157 TADA INFO assertion 145, new job correctly replaces oldest slot: correct job_id fills next slot, passed
2022-10-31 09:11:43,157 __main__ INFO 12353
2022-10-31 09:11:43,157 __main__ INFO 12353
2022-10-31 09:11:43,157 TADA INFO assertion 146, new job_start correctly represented in metric set: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,157 TADA INFO assertion 147, new job_end correctly represented in metric set: with mutl jobs running, for Job 12353, passed
2022-10-31 09:11:43,157 TADA INFO assertion 148, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,157 TADA INFO assertion 149, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,158 TADA INFO assertion 150, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,158 TADA INFO assertion 151, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,158 TADA INFO assertion 152, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,158 TADA INFO assertion 153, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,158 TADA INFO assertion 154, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,158 TADA INFO assertion 155, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-31 09:11:43,158 __main__ INFO -- Test Finished --
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
2022-10-31 09:11:43,159 TADA INFO test slurm_stream_test ended
2022-10-31 09:11:54 INFO: ----------------------------------------------
2022-10-31 09:11:55 INFO: ======== spank_notifier_test ========
2022-10-31 09:11:55 INFO: CMD: python3 spank_notifier_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/spank_notifier_test
2022-10-31 09:11:56,168 TADA INFO starting test `spank_notifier_test`
2022-10-31 09:11:56,168 TADA INFO   test-id: a84070ac89e45147897b15391efa329ed362a9d254ecc48f15b4226c3a672e69
2022-10-31 09:11:56,169 TADA INFO   test-suite: Slurm_Plugins
2022-10-31 09:11:56,169 TADA INFO   test-name: spank_notifier_test
2022-10-31 09:11:56,169 TADA INFO   test-user: narate
2022-10-31 09:11:56,169 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:11:56,169 __main__ INFO -- Create the cluster --
2022-10-31 09:12:21,655 __main__ INFO -- Cleanup output --
2022-10-31 09:12:21,972 __main__ INFO -- Test bad plugstack config --
2022-10-31 09:12:21,972 __main__ INFO Starting slurm ...
2022-10-31 09:12:36,507 __main__ INFO Starting slurm ... OK
2022-10-31 09:12:56,969 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 09:12:57,088 __main__ INFO   jobid = 1
2022-10-31 09:12:57,286 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 09:12:57,400 __main__ INFO   jobid = 2
2022-10-31 09:12:57,599 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 09:12:57,717 __main__ INFO   jobid = 3
2022-10-31 09:12:57,954 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 09:12:58,072 __main__ INFO   jobid = 4
2022-10-31 09:13:07,679 TADA INFO assertion 60, Bad config does not affect jobs: jobs verified, passed
2022-10-31 09:13:07,679 __main__ INFO Killin slurm ...
2022-10-31 09:13:10,579 __main__ INFO Killin slurm ... OK
2022-10-31 09:13:30,600 __main__ INFO -- Start daemons --
2022-10-31 09:13:41,422 __main__ INFO Starting slurm ... OK
2022-10-31 09:14:01,645 __main__ INFO -- Submitting job with no stream listener --
2022-10-31 09:14:01,870 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-31 09:14:01,992 __main__ INFO   jobid = 5
2022-10-31 09:14:17,958 TADA INFO assertion 0, Missing stream listener on node-1 does not affect job execution: job output file created, passed
2022-10-31 09:14:17,958 TADA INFO assertion 1, Missing stream listener on node-2 does not affect job execution: job output file created, passed
2022-10-31 09:14:23,821 __main__ INFO -- Submitting job with listener --
2022-10-31 09:14:24,038 __main__ INFO -- Submitting job with num_tasks 1 --
2022-10-31 09:14:24,154 __main__ INFO   jobid = 6
2022-10-31 09:14:24,371 __main__ INFO -- Submitting job with num_tasks 2 --
2022-10-31 09:14:24,483 __main__ INFO   jobid = 7
2022-10-31 09:14:24,678 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-31 09:14:24,804 __main__ INFO   jobid = 8
2022-10-31 09:14:25,003 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-31 09:14:25,117 __main__ INFO   jobid = 9
2022-10-31 09:14:25,326 __main__ INFO -- Submitting job with num_tasks 27 --
2022-10-31 09:14:25,433 __main__ INFO   jobid = 10
2022-10-31 09:14:47,145 __main__ INFO -- Verifying Events --
2022-10-31 09:14:47,146 TADA INFO assertion 2, 1-task job: first event is 'init': `init` verified, passed
2022-10-31 09:14:47,146 TADA INFO assertion 3, 1-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 09:14:47,146 TADA INFO assertion 4, 1-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 09:14:47,146 TADA INFO assertion 5, 1-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 09:14:47,147 TADA INFO assertion 6, 1-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 09:14:47,147 TADA INFO assertion 7, 2-task job: first event is 'init': `init` verified, passed
2022-10-31 09:14:47,147 TADA INFO assertion 8, 2-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 09:14:47,148 TADA INFO assertion 9, 2-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 09:14:47,148 TADA INFO assertion 10, 2-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 09:14:47,148 TADA INFO assertion 11, 2-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 09:14:47,148 TADA INFO assertion 12, 4-task job: first event is 'init': `init` verified, passed
2022-10-31 09:14:47,149 TADA INFO assertion 13, 4-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 09:14:47,149 TADA INFO assertion 14, 4-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 09:14:47,149 TADA INFO assertion 15, 4-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 09:14:47,149 TADA INFO assertion 16, 4-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 09:14:47,150 TADA INFO assertion 17, 8-task job: first event is 'init': `init` verified, passed
2022-10-31 09:14:47,150 TADA INFO assertion 18, 8-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 09:14:47,150 TADA INFO assertion 19, 8-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 09:14:47,150 TADA INFO assertion 20, 8-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 09:14:47,150 TADA INFO assertion 21, 8-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 09:14:47,151 TADA INFO assertion 22, 27-task job: first event is 'init': `init` verified, passed
2022-10-31 09:14:47,151 TADA INFO assertion 23, 27-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-31 09:14:47,151 TADA INFO assertion 24, 27-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-31 09:14:47,151 TADA INFO assertion 25, 27-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-31 09:14:47,151 TADA INFO assertion 26, 27-task job: fourth event is 'exit': `exit` verified, passed
2022-10-31 09:14:47,151 __main__ INFO job 6 multi-tenant with dict_keys([7])
2022-10-31 09:14:47,152 __main__ INFO job 10 multi-tenant with dict_keys([7, 6])
2022-10-31 09:14:47,152 __main__ INFO job 10 multi-tenant with dict_keys([8])
2022-10-31 09:14:47,152 __main__ INFO job 10 multi-tenant with dict_keys([9])
2022-10-31 09:14:47,152 __main__ INFO job 9 multi-tenant with dict_keys([10])
2022-10-31 09:14:47,152 TADA INFO assertion 50, Multi-tenant verification: Multi-tenant jobs found, passed
2022-10-31 09:14:47,363 __main__ INFO -- Submitting job that crashes listener --
2022-10-31 09:14:47,482 __main__ INFO   jobid = 11
2022-10-31 09:14:57,717 TADA INFO assertion 51, Killing stream listener does not affect job execution on node-1: job output file created, passed
2022-10-31 09:14:57,825 TADA INFO assertion 52, Killing stream listener does not affect job execution on node-2: job output file created, passed
2022-10-31 09:14:57,825 TADA INFO test spank_notifier_test ended
2022-10-31 09:15:14 INFO: ----------------------------------------------
2022-10-31 09:15:14 INFO: ======== ldms_list_test ========
2022-10-31 09:15:14 INFO: CMD: python3 ldms_list_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldms_list_test
2022-10-31 09:15:15,594 TADA INFO starting test `ldms_list_test`
2022-10-31 09:15:15,594 TADA INFO   test-id: ea0eb76fbf2f7a29dd10e89a94ab380936ca3c07e642bc18438e338f9b79e8b3
2022-10-31 09:15:15,594 TADA INFO   test-suite: LDMSD
2022-10-31 09:15:15,594 TADA INFO   test-name: ldms_list_test
2022-10-31 09:15:15,595 TADA INFO   test-user: narate
2022-10-31 09:15:15,595 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:15:15,595 __main__ INFO -- Get or create the cluster --
2022-10-31 09:15:18,636 __main__ INFO -- Start daemons --
2022-10-31 09:15:24,928 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:15:26,930 __main__ INFO start list_samp.py and list_agg.py interactive sessions
2022-10-31 09:15:32,966 TADA INFO assertion 1, check list_sampler on list_agg.py: OK, passed
2022-10-31 09:15:32,967 TADA INFO assertion 2, (1st update) check set1 on list_samp.py: OK, passed
2022-10-31 09:15:32,967 TADA INFO assertion 3, (1st update) check set3_p on list_samp.py: OK, passed
2022-10-31 09:15:32,967 TADA INFO assertion 4, (1st update)check set3_c on list_samp.py: OK, passed
2022-10-31 09:15:32,967 TADA INFO assertion 5, (1st update)check set1 on list_agg.py: OK, passed
2022-10-31 09:15:32,968 TADA INFO assertion 6, (1st update)check set3_p on list_agg.py: OK, passed
2022-10-31 09:15:32,968 TADA INFO assertion 7, (1st update)check set3_c on list_agg.py: OK, passed
2022-10-31 09:15:32,968 __main__ INFO 2nd sampling on the sampler...
2022-10-31 09:15:40,178 TADA INFO assertion 8, (2nd update) check set1 on list_samp.py: OK, passed
2022-10-31 09:15:40,178 TADA INFO assertion 9, (2nd update) check set3_p on list_samp.py: OK, passed
2022-10-31 09:15:40,178 TADA INFO assertion 10, (2nd update) check set3_c on list_samp.py: OK, passed
2022-10-31 09:15:40,178 __main__ INFO 2nd update on the aggregator...
2022-10-31 09:15:47,388 TADA INFO assertion 11, (2nd update) check set1 on list_agg.py: OK, passed
2022-10-31 09:15:47,388 TADA INFO assertion 12, (2nd update) check set3_p on list_agg.py: OK, passed
2022-10-31 09:15:47,389 TADA INFO assertion 13, (2nd update) check set3_c on list_agg.py: OK, passed
2022-10-31 09:15:47,389 __main__ INFO 3rd sampling on the sampler...
2022-10-31 09:15:54,598 TADA INFO assertion 14, (3rd update) check set1 on list_samp.py: OK, passed
2022-10-31 09:15:54,599 TADA INFO assertion 15, (3rd update) check set3_p on list_samp.py: OK, passed
2022-10-31 09:15:54,599 TADA INFO assertion 16, (3rd update) check set3_c on list_samp.py: OK, passed
2022-10-31 09:15:54,599 __main__ INFO 3rd update on the aggregator...
2022-10-31 09:16:01,808 TADA INFO assertion 17, (3rd update) check set1 on list_agg.py: OK, passed
2022-10-31 09:16:01,809 TADA INFO assertion 18, (3rd update) check set3_p on list_agg.py: OK, passed
2022-10-31 09:16:01,809 TADA INFO assertion 19, (3rd update) check set3_c on list_agg.py: OK, passed
2022-10-31 09:16:01,809 __main__ INFO 4th sampling on the sampler...
2022-10-31 09:16:09,018 TADA INFO assertion 20, (4th update; list uncahnged) check set1 on list_samp.py: OK, passed
2022-10-31 09:16:09,019 TADA INFO assertion 21, (4th update; list uncahnged) check set3_p on list_samp.py: OK, passed
2022-10-31 09:16:09,019 TADA INFO assertion 22, (4th update; list uncahnged) check set3_c on list_samp.py: OK, passed
2022-10-31 09:16:09,019 __main__ INFO 4th update on the aggregator...
2022-10-31 09:16:16,229 TADA INFO assertion 23, (4th update; list uncahnged) check set1 on list_agg.py: OK, passed
2022-10-31 09:16:16,229 TADA INFO assertion 24, (4th update; list uncahnged) check set3_p on list_agg.py: OK, passed
2022-10-31 09:16:16,229 TADA INFO assertion 25, (4th update; list uncahnged) check set3_c on list_agg.py: OK, passed
2022-10-31 09:16:16,229 __main__ INFO 5th sampling on the sampler...
2022-10-31 09:16:23,439 TADA INFO assertion 26, (5th update; list del) check set1 on list_samp.py: OK, passed
2022-10-31 09:16:23,439 TADA INFO assertion 27, (5th update; list del) check set3_p on list_samp.py: OK, passed
2022-10-31 09:16:23,439 TADA INFO assertion 28, (5th update; list del) check set3_c on list_samp.py: OK, passed
2022-10-31 09:16:23,440 __main__ INFO 5th update on the aggregator...
2022-10-31 09:16:30,649 TADA INFO assertion 29, (5th update; list del) check set1 on list_agg.py: OK, passed
2022-10-31 09:16:30,650 TADA INFO assertion 30, (5th update; list del) check set3_p on list_agg.py: OK, passed
2022-10-31 09:16:30,650 TADA INFO assertion 31, (5th update; list del) check set3_c on list_agg.py: OK, passed
2022-10-31 09:16:30,650 __main__ INFO 6th sampling on the sampler...
2022-10-31 09:16:37,859 TADA INFO assertion 32, (6th update; list unchanged) check set1 on list_samp.py: OK, passed
2022-10-31 09:16:37,860 TADA INFO assertion 33, (6th update; list unchanged) check set3_p on list_samp.py: OK, passed
2022-10-31 09:16:37,860 TADA INFO assertion 34, (6th update; list unchanged) check set3_c on list_samp.py: OK, passed
2022-10-31 09:16:37,860 __main__ INFO 6th update on the updator...
2022-10-31 09:16:45,069 TADA INFO assertion 35, (6th update; list unchanged) check set1 on list_agg.py: OK, passed
2022-10-31 09:16:45,069 TADA INFO assertion 36, (6th update; list unchanged) check set3_p on list_agg.py: OK, passed
2022-10-31 09:16:45,070 TADA INFO assertion 37, (6th update; list unchanged) check set3_c on list_agg.py: OK, passed
2022-10-31 09:16:45,070 TADA INFO test ldms_list_test ended
2022-10-31 09:16:55 INFO: ----------------------------------------------
2022-10-31 09:16:56 INFO: ======== quick_set_add_rm_test ========
2022-10-31 09:16:56 INFO: CMD: python3 quick_set_add_rm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/quick_set_add_rm_test
2022-10-31 09:16:57,326 TADA INFO starting test `quick_set_add_rm_test`
2022-10-31 09:16:57,327 TADA INFO   test-id: 95a432201ebcc034a4497734a01d7d52b0e910623fea22ae4212466aff78b677
2022-10-31 09:16:57,327 TADA INFO   test-suite: LDMSD
2022-10-31 09:16:57,327 TADA INFO   test-name: quick_set_add_rm_test
2022-10-31 09:16:57,327 TADA INFO   test-user: narate
2022-10-31 09:16:57,327 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:16:57,327 __main__ INFO -- Get or create the cluster --
2022-10-31 09:17:04,709 __main__ INFO -- Start samp.py --
2022-10-31 09:17:09,824 TADA INFO assertion 1, start samp.py: prompt checked, passed
2022-10-31 09:17:09,825 __main__ INFO -- Start daemons --
2022-10-31 09:17:17,520 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:17:23,116 TADA INFO assertion 2, verify data: verified, passed
2022-10-31 09:17:27,700 TADA INFO assertion 3, samp.py adds set1 / verify data: verified, passed
2022-10-31 09:17:32,288 TADA INFO assertion 4, samp.py removes set1 / verify data: verified, passed
2022-10-31 09:17:36,884 TADA INFO assertion 5, samp.py quickly adds and removes set2 / verify data: verified, passed
2022-10-31 09:17:42,017 TADA INFO assertion 6, agg-1 log stays empty: verified, passed
2022-10-31 09:17:42,018 TADA INFO test quick_set_add_rm_test ended
2022-10-31 09:17:53 INFO: ----------------------------------------------
2022-10-31 09:17:54 INFO: ======== set_array_hang_test ========
2022-10-31 09:17:54 INFO: CMD: python3 set_array_hang_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/set_array_hang_test
2022-10-31 09:17:55,548 TADA INFO starting test `set_array_hang_test`
2022-10-31 09:17:55,548 TADA INFO   test-id: e7cdcb562208db8f95e05abbe3f629f11c29ae14c3876b34fedf35d249433c37
2022-10-31 09:17:55,548 TADA INFO   test-suite: LDMSD
2022-10-31 09:17:55,548 TADA INFO   test-name: set_array_hang_test
2022-10-31 09:17:55,548 TADA INFO   test-user: narate
2022-10-31 09:17:55,548 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:17:55,549 __main__ INFO -- Get or create the cluster --
2022-10-31 09:17:58,696 __main__ INFO -- Start processes --
2022-10-31 09:17:58,696 __main__ INFO starting interactive set_array_samp.py
2022-10-31 09:18:01,712 TADA INFO assertion 1, start set_array_samp.py: data verified, passed
2022-10-31 09:18:04,729 TADA INFO assertion 2, start set_array_agg.py: data verified, passed
2022-10-31 09:18:11,938 TADA INFO assertion 3, agg update before the 1st sample: data verified, passed
2022-10-31 09:18:19,148 TADA INFO assertion 4, sampling 2 times then agg update: data verified, passed
2022-10-31 09:18:22,753 TADA INFO assertion 5, agg update w/o new sampling: data verified, passed
2022-10-31 09:18:29,963 TADA INFO assertion 6, sampling 5 times then agg update: data verified, passed
2022-10-31 09:18:29,964 TADA INFO test set_array_hang_test ended
2022-10-31 09:18:40 INFO: ----------------------------------------------
2022-10-31 09:18:41 INFO: ======== ldmsd_autointerval_test ========
2022-10-31 09:18:41 INFO: CMD: python3 ldmsd_autointerval_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldmsd_autointerval_test
2022-10-31 09:18:42,261 TADA INFO starting test `ldmsd_autointerval_test`
2022-10-31 09:18:42,261 TADA INFO   test-id: 6db8d0e34072b3b64ee6bea87d908e391e2bc995a21eeca921d855649d0044fe
2022-10-31 09:18:42,261 TADA INFO   test-suite: LDMSD
2022-10-31 09:18:42,261 TADA INFO   test-name: ldmsd_autointerval_test
2022-10-31 09:18:42,261 TADA INFO   test-user: narate
2022-10-31 09:18:42,261 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:18:42,262 __main__ INFO -- Get or create the cluster --
2022-10-31 09:18:49,712 __main__ INFO -- Start daemons --
2022-10-31 09:18:53,476 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:18:59,994 TADA INFO assertion 1, start all daemons and interactive controller: OK, passed
2022-10-31 09:19:02,220 TADA INFO assertion 2, verify sampling interval and update hints: verified, passed
2022-10-31 09:19:02,220 __main__ INFO Let them run for a while to collect data ...
2022-10-31 09:19:12,230 __main__ INFO Setting sample interval to 1000000 ...
2022-10-31 09:19:20,458 TADA INFO assertion 3, set and verify 2nd sampling interval / update hints: verified, passed
2022-10-31 09:19:20,459 __main__ INFO Let them run for a while to collect data ...
2022-10-31 09:19:30,469 __main__ INFO Setting sample interval to 2000000 ...
2022-10-31 09:19:38,692 TADA INFO assertion 4, set and verify 3rd sampling interval / update hints: verified, passed
2022-10-31 09:19:38,692 __main__ INFO Let them run for a while to collect data ...
2022-10-31 09:19:48,898 TADA INFO assertion 5, verify SOS data: timestamp differences in SOS show all 3 intervals, passed
2022-10-31 09:19:49,028 TADA INFO assertion 6, verify 'oversampled' in the agg2 log: OK, passed
2022-10-31 09:19:49,028 TADA INFO test ldmsd_autointerval_test ended
2022-10-31 09:20:01 INFO: ----------------------------------------------
2022-10-31 09:20:01 INFO: ======== ldms_record_test ========
2022-10-31 09:20:01 INFO: CMD: python3 ldms_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldms_record_test
2022-10-31 09:20:02,690 TADA INFO starting test `ldms_record_test`
2022-10-31 09:20:02,690 TADA INFO   test-id: b00762e0e300d2f275158c7f8d390ea7b0a479566d8d76e1fc301b323dc4055e
2022-10-31 09:20:02,690 TADA INFO   test-suite: LDMSD
2022-10-31 09:20:02,690 TADA INFO   test-name: ldms_record_test
2022-10-31 09:20:02,690 TADA INFO   test-user: narate
2022-10-31 09:20:02,690 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:20:02,691 __main__ INFO -- Get or create the cluster --
2022-10-31 09:20:05,931 __main__ INFO -- Start daemons --
2022-10-31 09:20:12,294 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:20:14,296 __main__ INFO start record_samp.py and record_agg.py interactive sessions
2022-10-31 09:20:20,331 TADA INFO assertion 1, check record_sampler on record_agg.py: OK, passed
2022-10-31 09:20:20,331 TADA INFO assertion 2, (1st update) check set1 on record_samp.py: OK, passed
2022-10-31 09:20:20,332 TADA INFO assertion 3, (1st update) check set3_p on record_samp.py: OK, passed
2022-10-31 09:20:20,332 TADA INFO assertion 4, (1st update) check set3_c on record_samp.py: OK, passed
2022-10-31 09:20:20,332 TADA INFO assertion 5, (1st update) check set1 on record_agg.py: OK, passed
2022-10-31 09:20:20,332 TADA INFO assertion 6, (1st update) check set3_p on record_agg.py: OK, passed
2022-10-31 09:20:20,333 TADA INFO assertion 7, (1st update) check set3_c on record_agg.py: OK, passed
2022-10-31 09:20:20,333 __main__ INFO 2nd sampling on the sampler...
2022-10-31 09:20:27,540 TADA INFO assertion 8, (2nd update) check set1 on record_samp.py: OK, passed
2022-10-31 09:20:27,541 TADA INFO assertion 9, (2nd update) check set3_p on record_samp.py: OK, passed
2022-10-31 09:20:27,541 TADA INFO assertion 10, (2nd update) check set3_c on record_samp.py: OK, passed
2022-10-31 09:20:27,541 __main__ INFO 2nd update on the aggregator...
2022-10-31 09:20:34,749 TADA INFO assertion 11, (2nd update) check set1 on record_agg.py: OK, passed
2022-10-31 09:20:34,750 TADA INFO assertion 12, (2nd update) check set3_p on record_agg.py: OK, passed
2022-10-31 09:20:34,750 TADA INFO assertion 13, (2nd update) check set3_c on record_agg.py: OK, passed
2022-10-31 09:20:34,750 __main__ INFO 3rd sampling on the sampler...
2022-10-31 09:20:41,960 TADA INFO assertion 14, (3rd update) check set1 on record_samp.py: OK, passed
2022-10-31 09:20:41,960 TADA INFO assertion 15, (3rd update) check set3_p on record_samp.py: OK, passed
2022-10-31 09:20:41,960 TADA INFO assertion 16, (3rd update) check set3_c on record_samp.py: OK, passed
2022-10-31 09:20:41,961 __main__ INFO 3rd update on the aggregator...
2022-10-31 09:20:49,170 TADA INFO assertion 17, (3rd update) check set1 on record_agg.py: OK, passed
2022-10-31 09:20:49,170 TADA INFO assertion 18, (3rd update) check set3_p on record_agg.py: OK, passed
2022-10-31 09:20:49,171 TADA INFO assertion 19, (3rd update) check set3_c on record_agg.py: OK, passed
2022-10-31 09:20:49,171 __main__ INFO 4th sampling on the sampler...
2022-10-31 09:20:56,380 TADA INFO assertion 20, (4th update; record uncahnged) check set1 on record_samp.py: OK, passed
2022-10-31 09:20:56,380 TADA INFO assertion 21, (4th update; record uncahnged) check set3_p on record_samp.py: OK, passed
2022-10-31 09:20:56,381 TADA INFO assertion 22, (4th update; record uncahnged) check set3_c on record_samp.py: OK, passed
2022-10-31 09:20:56,381 __main__ INFO 4th update on the aggregator...
2022-10-31 09:21:03,589 TADA INFO assertion 23, (4th update; record uncahnged) check set1 on record_agg.py: OK, passed
2022-10-31 09:21:03,590 TADA INFO assertion 24, (4th update; record uncahnged) check set3_p on record_agg.py: OK, passed
2022-10-31 09:21:03,590 TADA INFO assertion 25, (4th update; record uncahnged) check set3_c on record_agg.py: OK, passed
2022-10-31 09:21:03,590 __main__ INFO 5th sampling on the sampler...
2022-10-31 09:21:10,799 TADA INFO assertion 26, (5th update; record del) check set1 on record_samp.py: OK, passed
2022-10-31 09:21:10,800 TADA INFO assertion 27, (5th update; record del) check set3_p on record_samp.py: OK, passed
2022-10-31 09:21:10,800 TADA INFO assertion 28, (5th update; record del) check set3_c on record_samp.py: OK, passed
2022-10-31 09:21:10,800 __main__ INFO 5th update on the aggregator...
2022-10-31 09:21:18,010 TADA INFO assertion 29, (5th update; record del) check set1 on record_agg.py: OK, passed
2022-10-31 09:21:18,010 TADA INFO assertion 30, (5th update; record del) check set3_p on record_agg.py: OK, passed
2022-10-31 09:21:18,010 TADA INFO assertion 31, (5th update; record del) check set3_c on record_agg.py: OK, passed
2022-10-31 09:21:18,010 __main__ INFO 6th sampling on the sampler...
2022-10-31 09:21:25,219 TADA INFO assertion 32, (6th update; record unchanged) check set1 on record_samp.py: OK, passed
2022-10-31 09:21:25,220 TADA INFO assertion 33, (6th update; record unchanged) check set3_p on record_samp.py: OK, passed
2022-10-31 09:21:25,220 TADA INFO assertion 34, (6th update; record unchanged) check set3_c on record_samp.py: OK, passed
2022-10-31 09:21:25,220 __main__ INFO 6th update on the updator...
2022-10-31 09:21:32,429 TADA INFO assertion 35, (6th update; record unchanged) check set1 on record_agg.py: OK, passed
2022-10-31 09:21:32,429 TADA INFO assertion 36, (6th update; record unchanged) check set3_p on record_agg.py: OK, passed
2022-10-31 09:21:32,430 TADA INFO assertion 37, (6th update; record unchanged) check set3_c on record_agg.py: OK, passed
2022-10-31 09:21:32,430 TADA INFO test ldms_record_test ended
2022-10-31 09:21:43 INFO: ----------------------------------------------
2022-10-31 09:21:43 INFO: ======== ldms_schema_digest_test ========
2022-10-31 09:21:43 INFO: CMD: python3 ldms_schema_digest_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldms_schema_digest_test
2022-10-31 09:21:44,667 TADA INFO starting test `ldms_schema_digest_test`
2022-10-31 09:21:44,668 TADA INFO   test-id: 9b2a158a545f8e15a3271b7d4a9da79a56c3f1f3406eb5237ee1d519db5a2dd5
2022-10-31 09:21:44,668 TADA INFO   test-suite: LDMSD
2022-10-31 09:21:44,668 TADA INFO   test-name: ldms_schema_digest_test
2022-10-31 09:21:44,668 TADA INFO   test-user: narate
2022-10-31 09:21:44,668 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:21:44,669 __main__ INFO -- Get or create the cluster --
2022-10-31 09:21:51,877 __main__ INFO -- Start daemons --
2022-10-31 09:21:55,073 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:22:00,204 TADA INFO assertion 1, No schema digest from ldms_ls -v sampler: verified, passed
2022-10-31 09:22:00,320 TADA INFO assertion 2, Schema digest from ldms_ls -vv sampler is not empty: verified, passed
2022-10-31 09:22:00,439 TADA INFO assertion 3, Schema digest from ldms_ls -vv agg-1 is not empty: verified, passed
2022-10-31 09:22:00,620 TADA INFO assertion 4, Schema digest from Python ldms dir agg-1 is not empty: verified, passed
2022-10-31 09:22:00,621 TADA INFO assertion 5, Schema digest from Python ldms lokoup agg-1 is not empty: verified, passed
2022-10-31 09:22:00,621 TADA INFO assertion 6, All digests of the same set are the same: , passed
2022-10-31 09:22:03,041 TADA INFO assertion 7, Sets of same schema yield the same digest: check, passed
2022-10-31 09:22:03,042 TADA INFO assertion 8, Different schema (1-off metric) yield different digest: check, passed
2022-10-31 09:22:03,042 TADA INFO test ldms_schema_digest_test ended
2022-10-31 09:22:15 INFO: ----------------------------------------------
2022-10-31 09:22:16 INFO: ======== ldmsd_decomp_test ========
2022-10-31 09:22:16 INFO: CMD: python3 ldmsd_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldmsd_decomp_test
2022-10-31 09:22:16,736 TADA INFO starting test `ldmsd_decomp_test`
2022-10-31 09:22:16,737 TADA INFO   test-id: bd8219d70b5722df6db13d92217aeeb79202ba4cb363a84a8bce9ef1fc063926
2022-10-31 09:22:16,737 TADA INFO   test-suite: LDMSD
2022-10-31 09:22:16,737 TADA INFO   test-name: ldmsd_decomp_test
2022-10-31 09:22:16,737 TADA INFO   test-user: narate
2022-10-31 09:22:16,737 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:22:16,738 __main__ INFO -- Get or create the cluster --
2022-10-31 09:22:32,306 __main__ INFO -- Start daemons --
2022-10-31 09:22:42,791 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:23:37,387 TADA INFO assertion 1, `as_is` decomposition, test_sampler_8d2b8bd sos schema check: OK, passed
2022-10-31 09:23:37,388 TADA INFO assertion 2, `as_is` decomposition, test_sampler_95772b6 sos schema check: OK, passed
2022-10-31 09:23:37,388 TADA INFO assertion 3, `as_is` decomposition, record_sampler_e1f021f sos schema check: OK, passed
2022-10-31 09:23:37,388 TADA INFO assertion 4, `static` decomposition, fill sos schema check: OK, passed
2022-10-31 09:23:37,388 TADA INFO assertion 5, `static` decomposition, filter sos schema check: OK, passed
2022-10-31 09:23:37,388 TADA INFO assertion 6, `static` decomposition, record sos schema check: OK, passed
2022-10-31 09:23:37,388 TADA INFO assertion 7, `as_is` decomposition, test_sampler_8d2b8bd csv schema check: OK, passed
2022-10-31 09:23:37,389 TADA INFO assertion 8, `as_is` decomposition, test_sampler_95772b6 csv schema check: OK, passed
2022-10-31 09:23:37,389 TADA INFO assertion 9, `as_is` decomposition, record_sampler_e1f021f csv schema check: OK, passed
2022-10-31 09:23:37,389 TADA INFO assertion 10, `static` decomposition, fill csv schema check: OK, passed
2022-10-31 09:23:37,389 TADA INFO assertion 11, `static` decomposition, filter csv schema check: OK, passed
2022-10-31 09:23:37,389 TADA INFO assertion 12, `static` decomposition, record csv schema check: OK, passed
2022-10-31 09:23:37,389 TADA INFO assertion 13, `as_is` decomposition, test_sampler_8d2b8bd kafka schema check: OK, passed
2022-10-31 09:23:37,390 TADA INFO assertion 14, `as_is` decomposition, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-31 09:23:37,390 TADA INFO assertion 15, `as_is` decomposition, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-31 09:23:37,390 TADA INFO assertion 16, `static` decomposition, fill kafka schema check: OK, passed
2022-10-31 09:23:37,390 TADA INFO assertion 17, `static` decomposition, filter kafka schema check: OK, passed
2022-10-31 09:23:37,390 TADA INFO assertion 18, `static` decomposition, record kafka schema check: OK, passed
2022-10-31 09:23:37,392 TADA INFO assertion 19, `as_is` decomposition, test_sampler_8d2b8bd sos data check: OK, passed
2022-10-31 09:23:37,393 TADA INFO assertion 20, `as_is` decomposition, test_sampler_95772b6 sos data check: OK, passed
2022-10-31 09:23:37,470 TADA INFO assertion 21, `as_is` decomposition, record_sampler_e1f021f sos data check: OK, passed
2022-10-31 09:23:37,474 TADA INFO assertion 22, `static` decomposition, fill sos data check: OK, passed
2022-10-31 09:23:37,477 TADA INFO assertion 23, `static` decomposition, filter sos data check: OK, passed
2022-10-31 09:23:37,486 TADA INFO assertion 24, `static` decomposition, record sos data check: OK, passed
2022-10-31 09:23:37,488 TADA INFO assertion 25, `as_is` decomposition, test_sampler_8d2b8bd csv data check: OK, passed
2022-10-31 09:23:37,489 TADA INFO assertion 26, `as_is` decomposition, test_sampler_95772b6 csv data check: OK, passed
2022-10-31 09:23:37,563 TADA INFO assertion 27, `as_is` decomposition, record_sampler_e1f021f csv data check: OK, passed
2022-10-31 09:23:37,567 TADA INFO assertion 28, `static` decomposition, fill csv data check: OK, passed
2022-10-31 09:23:37,570 TADA INFO assertion 29, `static` decomposition, filter csv data check: OK, passed
2022-10-31 09:23:37,579 TADA INFO assertion 30, `static` decomposition, record csv data check: OK, passed
2022-10-31 09:23:37,580 TADA INFO assertion 31, `as_is` decomposition, test_sampler_8d2b8bd kafka data check: OK, passed
2022-10-31 09:23:37,580 TADA INFO assertion 32, `as_is` decomposition, test_sampler_95772b6 kafka data check: OK, passed
2022-10-31 09:23:37,610 TADA INFO assertion 33, `as_is` decomposition, record_sampler_e1f021f kafka data check: OK, passed
2022-10-31 09:23:37,612 TADA INFO assertion 34, `static` decomposition, fill kafka data check: OK, passed
2022-10-31 09:23:37,614 TADA INFO assertion 35, `static` decomposition, filter kafka data check: OK, passed
2022-10-31 09:23:37,618 TADA INFO assertion 36, `static` decomposition, record kafka data check: OK, passed
2022-10-31 09:23:37,618 TADA INFO test ldmsd_decomp_test ended
2022-10-31 09:23:37,619 TADA INFO test ldmsd_decomp_test ended
2022-10-31 09:23:53 INFO: ----------------------------------------------
2022-10-31 09:23:54 INFO: ======== ldmsd_stream_dir_test ========
2022-10-31 09:23:54 INFO: CMD: python3 ldmsd_stream_dir_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldmsd_stream_dir_test
2022-10-31 09:23:54,844 __main__ INFO -- Get or create the cluster --
2022-10-31 09:23:54,845 TADA INFO starting test `ldmsd_stream_dir`
2022-10-31 09:23:54,845 TADA INFO   test-id: 4bbfa6a535b5bfe5e191f6635ddc99484892246813222f075d2fa1cd3635480a
2022-10-31 09:23:54,845 TADA INFO   test-suite: LDMSD
2022-10-31 09:23:54,845 TADA INFO   test-name: ldmsd_stream_dir
2022-10-31 09:23:54,845 TADA INFO   test-user: narate
2022-10-31 09:23:54,845 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:24:03,245 __main__ INFO -- Start daemons --
2022-10-31 09:24:07,012 __main__ INFO waiting ... for all LDMSDs to start
2022-10-31 09:24:07,334 __main__ INFO All LDMSDs are up.
2022-10-31 09:24:08,562 TADA INFO assertion 1, No Stream data: {} == {}, passed
2022-10-31 09:24:09,896 TADA INFO assertion 2, stream_dir -- one stream message: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667226248, 'last_ts': 1667226248, 'count': 1, 'total_bytes': 6}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1667226248, 'last_ts': 1667226248, 'count': 1, 'total_bytes': 6}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1667226248, 'last_ts': 1667226248}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1667226248, 'last_ts': 1667226248}}}, passed
2022-10-31 09:24:12,343 TADA INFO assertion 3, stream_dir --  multiple stream messages: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667226248, 'last_ts': 1667226251, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1667226248, 'last_ts': 1667226251, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667226248, 'last_ts': 1667226251, 'bytes/sec': 6.0, 'msg/sec': 1.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667226248, 'last_ts': 1667226251, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, passed
2022-10-31 09:24:13,556 TADA INFO assertion 4, prdcr_stream_dir to agg -- one producer: {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1667226251, 'first_ts': 1667226248, 'bytes/sec': 6.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1667226251, 'first_ts': 1667226248, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667226248, 'last_ts': 1667226251, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667226248, 'last_ts': 1667226251, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}}, passed
2022-10-31 09:24:17,365 TADA INFO assertion 5, stream_dir -- mulitple streams: {'bar': {'mode': 'not subscribed', 'info': {'first_ts': 1667226254, 'last_ts': 1667226256, 'count': 3, 'total_bytes': 48, 'msg/sec': 1.5, 'bytes/sec': 24.0}, 'publishers': {}}, 'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667226253, 'last_ts': 1667226254, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1667226253, 'last_ts': 1667226256, 'count': 5, 'total_bytes': 60, 'msg/sec': 1.666667, 'bytes/sec': 20.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667226253, 'last_ts': 1667226254, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {}}, 'bar': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1667226254, 'last_ts': 1667226256, 'bytes/sec': 24.0, 'msg/sec': 1.5}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1667226253, 'last_ts': 1667226256, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}, passed
2022-10-31 09:24:18,603 TADA INFO assertion 6, prdcr_stream_dir to agg -- two producers: {'foo': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 2.0, 'total_bytes': 12, 'last_ts': 1667226254, 'first_ts': 1667226253, 'bytes/sec': 12.0, 'count': 2}}, 'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1667226251, 'first_ts': 1667226248, 'bytes/sec': 6.0, 'count': 3}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 1.5, 'total_bytes': 48, 'last_ts': 1667226256, 'first_ts': 1667226254, 'bytes/sec': 24.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-2': {'info': {'msg/sec': 1.666667, 'total_bytes': 60, 'last_ts': 1667226256, 'first_ts': 1667226253, 'bytes/sec': 20.0, 'count': 5}}, 'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1667226251, 'first_ts': 1667226248, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667226248, 'last_ts': 1667226251, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667226253, 'last_ts': 1667226254, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1667226254, 'last_ts': 1667226256, 'bytes/sec': 24.0, 'msg/sec': 1.5}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667226248, 'last_ts': 1667226251, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1667226253, 'last_ts': 1667226256, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}}, passed
2022-10-31 09:24:22,270 TADA INFO assertion 7, stream_dir to agg after one producer republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667226259, 'last_ts': 1667226261, 'count': 2, 'total_bytes': 12, 'msg/sec': 1.0, 'bytes/sec': 6.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1667226259, 'last_ts': 1667226261, 'count': 2, 'total_bytes': 12, 'msg/sec': 1.0, 'bytes/sec': 6.0}}}}, '_AGGREGATED_': {'info': {'first_ts': 1667226259, 'last_ts': 1667226261, 'count': 2, 'total_bytes': 12, 'msg/sec': 1.0, 'bytes/sec': 6.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667226259, 'last_ts': 1667226261, 'bytes/sec': 6.0, 'msg/sec': 1.0}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667226259, 'last_ts': 1667226261, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}}, '_AGGREGATED_': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667226259, 'last_ts': 1667226261, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, passed
2022-10-31 09:24:23,813 TADA INFO assertion 8, stream_dir to agg after two producers republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1667226259, 'last_ts': 1667226262, 'count': 5, 'total_bytes': 30, 'msg/sec': 1.666667, 'bytes/sec': 10.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1667226259, 'last_ts': 1667226261, 'count': 2, 'total_bytes': 12, 'msg/sec': 1.0, 'bytes/sec': 6.0}}, 'samplerd-2': {'info': {'first_ts': 1667226262, 'last_ts': 1667226262, 'count': 3, 'total_bytes': 18}}}}, '_AGGREGATED_': {'info': {'first_ts': 1667226259, 'last_ts': 1667226262, 'count': 5, 'total_bytes': 30, 'msg/sec': 1.666667, 'bytes/sec': 10.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1667226259, 'last_ts': 1667226262, 'bytes/sec': 10.0, 'msg/sec': 1.666667}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1667226259, 'last_ts': 1667226261, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1667226262, 'last_ts': 1667226262}}}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1667226259, 'last_ts': 1667226262, 'bytes/sec': 10.0, 'msg/sec': 1.666667}}}, passed
2022-10-31 09:24:23,814 TADA INFO test ldmsd_stream_dir ended
2022-10-31 09:24:35 INFO: ----------------------------------------------
2022-10-31 09:24:36 INFO: ======== store_list_record_test ========
2022-10-31 09:24:36 INFO: CMD: python3 store_list_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/store_list_record_test
2022-10-31 09:24:37,508 __main__ INFO -- Get or create the cluster --
2022-10-31 09:24:37,508 TADA INFO starting test `store_sos_lists_test`
2022-10-31 09:24:37,508 TADA INFO   test-id: 3ca4c03655254768325b9d97b3663f1291cf42e026043595a1f545b72fdda02b
2022-10-31 09:24:37,508 TADA INFO   test-suite: LDMSD
2022-10-31 09:24:37,508 TADA INFO   test-name: store_sos_lists_test
2022-10-31 09:24:37,509 TADA INFO   test-user: narate
2022-10-31 09:24:37,509 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:24:45,064 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:24:48,824 __main__ INFO All sampler daemons are up.
2022-10-31 09:24:48,918 TADA INFO assertion 1, aggregator with store_sos has started properly.: agg_sos.check_ldmsd(), passed
2022-10-31 09:24:49,030 TADA INFO assertion 2, aggregator with store_csv has started properly.: agg_csv.check_ldmsd(), passed
2022-10-31 09:25:01,336 TADA INFO assertion 3, store_sos is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-31 09:25:04,648 TADA INFO assertion 4, store_sos stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-31 09:25:13,455 TADA INFO assertion 5, store_sos stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-31 09:25:14,831 TADA INFO assertion 6, store_csv is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-31 09:25:25,957 TADA INFO assertion 7, store_csv stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-31 09:25:35,574 TADA INFO assertion 8, store_csv stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-31 09:25:35,574 TADA INFO test store_sos_lists_test ended
2022-10-31 09:25:49 INFO: ----------------------------------------------
2022-10-31 09:25:49 INFO: ======== maestro_raft_test ========
2022-10-31 09:25:49 INFO: CMD: python3 maestro_raft_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/maestro_raft_test
2022-10-31 09:25:50,608 TADA INFO starting test `maestro_raft_test`
2022-10-31 09:25:50,609 TADA INFO   test-id: c0b26ef4d8b69b720f0cec1bbfed79fe0e92088b720ce62f945b6522070d40db
2022-10-31 09:25:50,609 TADA INFO   test-suite: LDMSD
2022-10-31 09:25:50,609 TADA INFO   test-name: maestro_raft_test
2022-10-31 09:25:50,609 TADA INFO   test-user: narate
2022-10-31 09:25:50,609 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:26:00,612 __main__ INFO -- Get or create cluster --
2022-10-31 09:26:35,075 __main__ INFO -- Start daemons --
2022-10-31 09:27:45,881 __main__ INFO -- making known hosts (ssh) --
2022-10-31 09:27:52,871 __main__ INFO ... make sure ldmsd's are up
2022-10-31 09:28:07,598 TADA INFO assertion 1, Statuses of maestros, 1 leader + 2 followers: [('FOLLOWER', 2), ('LEADER', 1)], passed
2022-10-31 09:28:20,001 TADA INFO assertion 2, All ldmsds are up and configured: sets verified, passed
2022-10-31 09:28:20,277 TADA INFO assertion 3, Data are being stored: data check, passed
2022-10-31 09:28:25,160 TADA INFO assertion 4, New leader elected: checked, passed
2022-10-31 09:28:36,961 TADA INFO assertion 5, Restarted ldmsd is configured: sets verified, passed
2022-10-31 09:28:37,244 TADA INFO assertion 6, New data are presented in the store: data check, passed
2022-10-31 09:28:48,262 TADA INFO assertion 7, The restarted maestro becomes a follower: checked, passed
---Wait for config to write to file---
2022-10-31 09:28:48,262 TADA INFO test maestro_raft_test ended
2022-10-31 09:29:09 INFO: ----------------------------------------------
2022-10-31 09:29:10 INFO: ======== ovis_json_test ========
2022-10-31 09:29:10 INFO: CMD: python3 ovis_json_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ovis_json_test
2022-10-31 09:29:10,782 __main__ INFO -- Create the cluster -- 
2022-10-31 09:29:16,027 TADA INFO starting test `ovis_json_test`
2022-10-31 09:29:16,027 TADA INFO   test-id: 3910705386d089e464a12acba17ed721c1cc16d0ffd36f2842dea2fddf5d6c22
2022-10-31 09:29:16,028 TADA INFO   test-suite: OVIS-LIB
2022-10-31 09:29:16,028 TADA INFO   test-name: ovis_json_test
2022-10-31 09:29:16,028 TADA INFO   test-user: narate
2022-10-31 09:29:16,028 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:29:16,028 TADA INFO assertion 1, Test creating a JSON integer entity: (type is JSON_INT_VALUE) && (1 == e->value.int_), passed
2022-10-31 09:29:16,029 TADA INFO assertion 2, Test creating a JSON boolean entity: (type is JSON_BOOL_VALUE) && (1 == e->value.bool_), passed
2022-10-31 09:29:16,029 TADA INFO assertion 3, Test creating a JSON float entity: (type is JSON_FLOAT_VALUE) && (1.1 == e->value.double_), passed
2022-10-31 09:29:16,029 TADA INFO assertion 4, Test creating a JSON string entity: (type is JSON_STRING_VALUE) && (foo == e->value.str_->str), passed
2022-10-31 09:29:16,029 TADA INFO assertion 5, Test creating a JSON attribute entity: (type is JSON_ATTR_VALUE) && (name == <attr name>) && (value == <attr value>), passed
2022-10-31 09:29:16,029 TADA INFO assertion 6, Test creating a JSON list entity: (type is JSON_LIST_VALUE) && (0 == Number of elements) && (list is empty), passed
2022-10-31 09:29:16,029 TADA INFO assertion 7, Test creating a JSON dictionary entity: (type is JSON_DICT_VALUE) && (dict table is empty), passed
2022-10-31 09:29:16,030 TADA INFO assertion 8, Test creating a JSON null entity: (type is JSON_NULL_VALUE) && (0 == e->value.int_), passed
2022-10-31 09:29:16,030 TADA INFO assertion 9, Test parsing a JSON integer string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 09:29:16,030 TADA INFO assertion 10, Test parsing a JSON false boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 09:29:16,030 TADA INFO assertion 11, Test parsing a JSON true boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 09:29:16,030 TADA INFO assertion 12, Test parsing a JSON float string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 09:29:16,030 TADA INFO assertion 13, Test parsing a JSON string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 09:29:16,031 TADA INFO assertion 15, Test parsing a JSON dict string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 09:29:16,031 TADA INFO assertion 16, Test parsing a JSON null string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 09:29:16,031 TADA INFO assertion 17, Test parsing an invalid string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-31 09:29:16,031 TADA INFO assertion 17, Test parsing an invalid string: 0 != json_parse_buffer(), passed
2022-10-31 09:29:16,031 TADA INFO assertion 18, Test dumping a JSON integer entity: 1 == 1, passed
2022-10-31 09:29:16,031 TADA INFO assertion 19, Test dumping a JSON false boolean entity: false == false, passed
2022-10-31 09:29:16,031 TADA INFO assertion 20, Test dumping a JSON true boolean entity: true == true, passed
2022-10-31 09:29:16,032 TADA INFO assertion 21, Test dumping a JSON float entity: 1.100000 == 1.100000, passed
2022-10-31 09:29:16,032 TADA INFO assertion 22, Test dumping a JSON string entity: "foo" == "foo", passed
2022-10-31 09:29:16,032 TADA INFO assertion 23, Test dumping a JSON attr entity: "name":"foo" == jb->buf, passed
2022-10-31 09:29:16,032 TADA INFO assertion 24, Test dumping a JSON list entity: [1,false,1.100000,"foo",[],{},null] == [1,false,1.100000,"foo",[],{},null], passed
2022-10-31 09:29:16,032 TADA INFO assertion 25, Test dumping a JSON dict entity: {"int":1,"bool":true,"float":1.100000,"string":"foo","list":[1,false,1.100000,"foo",[],{},null],"dict":{"attr_1":"value_1"},"null":null} == {"null":null,"list":[1,false,1.100000,"foo",[],{},null],"string":"foo","float":1.100000,"bool":true,"dict":{"attr_1":"value_1"},"int":1}, passed
2022-10-31 09:29:16,032 TADA INFO assertion 26, Test dumping a JSON null entity: null == null, passed
2022-10-31 09:29:16,033 TADA INFO assertion 27, Test dumping a JSON entity to a non-empty jbuf: This is a book."FOO" == This is a book."FOO", passed
2022-10-31 09:29:16,033 TADA INFO assertion 28, Test copying a JSON integer entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,033 TADA INFO assertion 29, Test copying a JSON false boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,033 TADA INFO assertion 30, Test copying a JSON true boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,033 TADA INFO assertion 31, Test copying a JSON float entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,033 TADA INFO assertion 32, Test copying a JSON string entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,033 TADA INFO assertion 33, Test copying a JSON attribute entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,034 TADA INFO assertion 34, Test copying a JSON list entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,034 TADA INFO assertion 35, Test copying a JSON dict entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,034 TADA INFO assertion 36, Test copying a JSON null entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-31 09:29:16,034 TADA INFO assertion 37, Test obtaining the number of attributes: 7 == json_attr_count(dict), passed
2022-10-31 09:29:16,034 TADA INFO assertion 38, Test finding an existing attribute: 0 != json_attr_find(), passed
2022-10-31 09:29:16,034 TADA INFO assertion 39, Test finding a non-existng attribute: 0 == json_attr_find(), passed
2022-10-31 09:29:16,034 TADA INFO assertion 40, Test finding the value of an existing attribute: 0 != json_value_find(), passed
2022-10-31 09:29:16,035 TADA INFO assertion 41, Test finding the value of a non-existing attribute: 0 == json_value_find(), passed
2022-10-31 09:29:16,035 TADA INFO assertion 42, Test adding a new attribute to a dictionary: (0 == json_attr_add() && (0 != json_attr_find()), passed
2022-10-31 09:29:16,035 TADA INFO assertion 43, Test replacing the value of an existing attribute: (0 == json_attr_add()) && (0 != json_value_find()) && (is_same_entity(old_v, new_v)), passed
2022-10-31 09:29:16,035 TADA INFO assertion 44, Test removing an existing attribute: (0 = json_attr_rem()) && (0 == json_attr_find()), passed
2022-10-31 09:29:16,035 TADA INFO assertion 45, Test removing a non-existing attribute: (ENOENT == json_attr_rem()), passed
2022-10-31 09:29:16,035 TADA INFO assertion 46, Test creating a dictionary by json_dict_build: expected == json_dict_build(...), passed
2022-10-31 09:29:16,036 TADA INFO assertion 47, Test adding attributes and replacing attribute values by json_dict_build: expected == json_dict_build(d, ...), passed
2022-10-31 09:29:16,036 TADA INFO assertion 48, Test json_dict_merge(): The merged dictionary is correct., passed
2022-10-31 09:29:16,036 TADA INFO assertion 49, Test json_list_len(): 7 == json_list_len(), passed
2022-10-31 09:29:16,036 TADA INFO assertion 50, Test adding items to a list: 0 == strcmp(exp_str, json_entity_dump(l)->buf, passed
2022-10-31 09:29:16,036 TADA INFO assertion 51, Test removing an existing item by json_item_rem(): 0 == json_item_rem(), passed
2022-10-31 09:29:16,036 TADA INFO assertion 52, Test removing a non-existing item by json_item_rem(): ENOENT == json_item_rem(), passed
2022-10-31 09:29:16,036 TADA INFO assertion 53, Test popping an existing item from a list by json_item_pop(): NULL == json_item_pop(len + 3), passed
2022-10-31 09:29:16,036 TADA INFO assertion 54, Test popping a non-existing item from a list by json_item_pop(): NULL != json_item_pop(len - 1), passed
2022-10-31 09:29:16,037 TADA INFO test ovis_json_test ended
2022-10-31 09:29:26 INFO: ----------------------------------------------
2022-10-31 09:29:27 INFO: ======== updtr_add_test ========
2022-10-31 09:29:27 INFO: CMD: python3 updtr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/updtr_add_test
2022-10-31 09:29:28,383 __main__ INFO -- Get or create the cluster --
2022-10-31 09:29:28,383 TADA INFO starting test `updtr_add test`
2022-10-31 09:29:28,384 TADA INFO   test-id: 30ffda9a2b18aebbcb62ab2ed96483d4a342def8b87cdab86456dc4f95ff2897
2022-10-31 09:29:28,384 TADA INFO   test-suite: LDMSD
2022-10-31 09:29:28,384 TADA INFO   test-name: updtr_add test
2022-10-31 09:29:28,384 TADA INFO   test-user: narate
2022-10-31 09:29:28,384 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:29:36,247 __main__ INFO -- Start daemons --
2022-10-31 09:29:39,908 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:29:40,223 __main__ INFO All LDMSDs are up.
2022-10-31 09:29:41,443 TADA INFO assertion 1, Add an updater with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:29:42,661 TADA INFO assertion 2, Add an updater with a zero interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:29:43,865 TADA INFO assertion 3, Add an updater with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:29:45,072 TADA INFO assertion 4, Add an updater with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-31 09:29:46,277 TADA INFO assertion 5, Add an updater with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:29:48,711 TADA INFO assertion 6, Add an updater without an offset: report(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-31 09:29:51,138 TADA INFO assertion 7, Add an updater with a valid offset: report(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-31 09:29:52,354 TADA INFO assertion 8, Add an updater with an existing name: report(rc = 17) == expect(rc = 17), passed
2022-10-31 09:29:52,354 __main__ INFO --- done ---
2022-10-31 09:29:52,355 TADA INFO test updtr_add test ended
2022-10-31 09:30:04 INFO: ----------------------------------------------
2022-10-31 09:30:05 INFO: ======== updtr_del_test ========
2022-10-31 09:30:05 INFO: CMD: python3 updtr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/updtr_del_test
2022-10-31 09:30:06,052 __main__ INFO -- Get or create the cluster --
2022-10-31 09:30:06,052 TADA INFO starting test `updtr_add test`
2022-10-31 09:30:06,052 TADA INFO   test-id: 34637fb42519952bdd18c7721d7acac953c0c714f827afbebabda06e75f9337f
2022-10-31 09:30:06,052 TADA INFO   test-suite: LDMSD
2022-10-31 09:30:06,052 TADA INFO   test-name: updtr_add test
2022-10-31 09:30:06,052 TADA INFO   test-user: narate
2022-10-31 09:30:06,052 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:30:13,839 __main__ INFO -- Start daemons --
2022-10-31 09:30:17,504 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:30:17,815 __main__ INFO All LDMSDs are up.
2022-10-31 09:30:19,048 TADA INFO assertion 1, updtr_del a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 09:30:20,270 TADA INFO assertion 2, updtr_del a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-31 09:30:21,488 TADA INFO assertion 3, updtr_del a stopped updater: report(rc = 0) == expect(rc = 0), passed
2022-10-31 09:30:22,701 TADA INFO assertion 4, updtr_del a just-added updater: report(rc = 0) == expect(rc = 0), passed
2022-10-31 09:30:22,701 __main__ INFO --- done ---
2022-10-31 09:30:22,701 TADA INFO test updtr_add test ended
2022-10-31 09:30:34 INFO: ----------------------------------------------
2022-10-31 09:30:35 INFO: ======== updtr_match_add_test ========
2022-10-31 09:30:35 INFO: CMD: python3 updtr_match_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/updtr_match_add_test
2022-10-31 09:30:36,440 __main__ INFO -- Get or create the cluster --
2022-10-31 09:30:36,440 TADA INFO starting test `updtr_add test`
2022-10-31 09:30:36,440 TADA INFO   test-id: b9c51c1a76f31c83a677f95d08957c711f15ecb8f8e850f1149520e36fc17e36
2022-10-31 09:30:36,440 TADA INFO   test-suite: LDMSD
2022-10-31 09:30:36,440 TADA INFO   test-name: updtr_add test
2022-10-31 09:30:36,441 TADA INFO   test-user: narate
2022-10-31 09:30:36,441 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:30:44,181 __main__ INFO -- Start daemons --
2022-10-31 09:30:47,816 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:30:48,155 __main__ INFO All LDMSDs are up.
2022-10-31 09:30:49,368 TADA INFO assertion 1, updtr_match_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:30:50,590 TADA INFO assertion 2, updtr_match_add with an invalid match: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:30:51,796 TADA INFO assertion 3, updtr_match_add of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 09:30:53,012 TADA INFO assertion 4, A success updtr_match_add: report(rc = 0) == expect(rc = 0), passed
2022-10-31 09:30:54,227 TADA INFO assertion 5, updtr_match_add of a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-31 09:30:54,227 __main__ INFO --- done ---
2022-10-31 09:30:54,227 TADA INFO test updtr_add test ended
2022-10-31 09:31:06 INFO: ----------------------------------------------
2022-10-31 09:31:07 INFO: ======== updtr_match_del_test ========
2022-10-31 09:31:07 INFO: CMD: python3 updtr_match_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/updtr_match_del_test
2022-10-31 09:31:07,895 __main__ INFO -- Get or create the cluster --
2022-10-31 09:31:07,895 TADA INFO starting test `updtr_add test`
2022-10-31 09:31:07,895 TADA INFO   test-id: ddc59ee7b48f993a55a54b0dc227114783a9a43636991031c5746b88beb23558
2022-10-31 09:31:07,895 TADA INFO   test-suite: LDMSD
2022-10-31 09:31:07,895 TADA INFO   test-name: updtr_add test
2022-10-31 09:31:07,895 TADA INFO   test-user: narate
2022-10-31 09:31:07,895 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:31:15,639 __main__ INFO -- Start daemons --
2022-10-31 09:31:19,350 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:31:19,658 __main__ INFO All LDMSDs are up.
2022-10-31 09:31:20,865 TADA INFO assertion 1, Send updtr_match_del with an invalid regex: report(rc = 2) == expect(rc = 22), passed
2022-10-31 09:31:22,085 TADA INFO assertion 2, Send updtr_match_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 09:31:23,317 TADA INFO assertion 3, Send updtr_match_del with a non-existing inst match: report(rc = 2) == expect(rc = 2), passed
2022-10-31 09:31:24,535 TADA INFO assertion 4, Send updtr_match_del with a non-existing schema match: report(rc = 2) == expect(rc = 2), passed
2022-10-31 09:31:25,761 TADA INFO assertion 5, Send updater_match_del with an invalid match type: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:31:26,982 TADA INFO assertion 6, Send updater_match_del with a valid regex of the inst type: report(rc = 0) == expect(rc = 0), passed
2022-10-31 09:31:28,199 TADA INFO assertion 7, Send updater_match_del with a valid regex of the schema type: report(rc = 0) == expect(rc = 0), passed
2022-10-31 09:31:28,200 __main__ INFO --- done ---
2022-10-31 09:31:28,200 TADA INFO test updtr_add test ended
2022-10-31 09:31:40 INFO: ----------------------------------------------
2022-10-31 09:31:40 INFO: ======== updtr_prdcr_add_test ========
2022-10-31 09:31:40 INFO: CMD: python3 updtr_prdcr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/updtr_prdcr_add_test
2022-10-31 09:31:41,689 __main__ INFO -- Get or create the cluster --
2022-10-31 09:31:41,689 TADA INFO starting test `updtr_add test`
2022-10-31 09:31:41,689 TADA INFO   test-id: 16b404be714d5c5ae398a80b70b264ca58408b5fc2d4e8e3703f3467c9fdd6ec
2022-10-31 09:31:41,689 TADA INFO   test-suite: LDMSD
2022-10-31 09:31:41,689 TADA INFO   test-name: updtr_add test
2022-10-31 09:31:41,690 TADA INFO   test-user: narate
2022-10-31 09:31:41,690 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:31:49,436 __main__ INFO -- Start daemons --
2022-10-31 09:31:53,129 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:31:53,433 __main__ INFO All LDMSDs are up.
2022-10-31 09:31:54,642 TADA INFO assertion 1, Send updtr_prdcr_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:31:57,086 TADA INFO assertion 2, Send updtr_prdcr_add with a regex matching no prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-31 09:31:59,504 TADA INFO assertion 3, Send updtr_prdcdr_add with a regex matching some prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-31 09:32:00,714 TADA INFO assertion 4, Send updtr_prdcdr_add to a running updtr: report(rc = 16) == expect(rc = 16), passed
2022-10-31 09:32:01,925 TADA INFO assertion 5, Send updtr_prdcr_add to a not-existing updtr: report(rc = 2) == expect(rc = 2), passed
2022-10-31 09:32:01,925 __main__ INFO --- done ---
2022-10-31 09:32:01,925 TADA INFO test updtr_add test ended
2022-10-31 09:32:14 INFO: ----------------------------------------------
2022-10-31 09:32:14 INFO: ======== updtr_prdcr_del_test ========
2022-10-31 09:32:14 INFO: CMD: python3 updtr_prdcr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/updtr_prdcr_del_test
2022-10-31 09:32:15,589 __main__ INFO -- Get or create the cluster --
2022-10-31 09:32:15,589 TADA INFO starting test `updtr_add test`
2022-10-31 09:32:15,589 TADA INFO   test-id: 42c94632c1cafce182614c901982d0767fc44b23c1bc50a98146dbf92d402f23
2022-10-31 09:32:15,589 TADA INFO   test-suite: LDMSD
2022-10-31 09:32:15,589 TADA INFO   test-name: updtr_add test
2022-10-31 09:32:15,589 TADA INFO   test-user: narate
2022-10-31 09:32:15,590 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:32:23,659 __main__ INFO -- Start daemons --
2022-10-31 09:32:27,237 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:32:27,560 __main__ INFO All LDMSDs are up.
2022-10-31 09:32:28,780 TADA INFO assertion 1, Send updtr_prdcr_del with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:32:29,991 TADA INFO assertion 2, Send updtr_prdcr_del to a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-31 09:32:31,200 TADA INFO assertion 3, Send updtr_prdcr_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 09:32:33,628 TADA INFO assertion 4, Send updtr_prdcr_del successfully: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}], passed
2022-10-31 09:32:33,628 __main__ INFO --- done ---
2022-10-31 09:32:33,628 TADA INFO test updtr_add test ended
2022-10-31 09:32:45 INFO: ----------------------------------------------
2022-10-31 09:32:46 INFO: ======== updtr_start_test ========
2022-10-31 09:32:46 INFO: CMD: python3 updtr_start_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/updtr_start_test
2022-10-31 09:32:47,320 __main__ INFO -- Get or create the cluster --
2022-10-31 09:32:47,320 TADA INFO starting test `updtr_add test`
2022-10-31 09:32:47,320 TADA INFO   test-id: faf4805137b58d40a2709a0efb01b7283c502045957a13ce4bef521f64d952d9
2022-10-31 09:32:47,320 TADA INFO   test-suite: LDMSD
2022-10-31 09:32:47,320 TADA INFO   test-name: updtr_add test
2022-10-31 09:32:47,320 TADA INFO   test-user: narate
2022-10-31 09:32:47,321 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:32:54,989 __main__ INFO -- Start daemons --
2022-10-31 09:32:58,711 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:32:59,027 __main__ INFO All LDMSDs are up.
2022-10-31 09:33:00,255 TADA INFO assertion 1, updtr_start with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:33:01,479 TADA INFO assertion 2, updtr_start with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:33:02,681 TADA INFO assertion 3, updtr_start with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-31 09:33:03,906 TADA INFO assertion 4, updtr_start with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:33:05,109 TADA INFO assertion 5, updtr_start without an offset larger than interval: report(rc = 22) == expect(rc = 22), passed
2022-10-31 09:33:07,544 TADA INFO assertion 6, updtr_start that changes offset to no offset: report(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-31 09:33:08,761 TADA INFO assertion 7, updtr_start of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-31 09:33:11,182 TADA INFO assertion 8, updtr_start with a valid interval: report(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-31 09:33:13,593 TADA INFO assertion 9, updtr_start with a valid offset: report(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-31 09:33:16,019 TADA INFO assertion 10, updtr_start without giving interval and offset: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-31 09:33:17,242 TADA INFO assertion 11, updtr_start a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-31 09:33:17,242 __main__ INFO --- done ---
2022-10-31 09:33:17,242 TADA INFO test updtr_add test ended
2022-10-31 09:33:29 INFO: ----------------------------------------------
2022-10-31 09:33:30 INFO: ======== updtr_status_test ========
2022-10-31 09:33:30 INFO: CMD: python3 updtr_status_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/updtr_status_test
2022-10-31 09:33:30,879 __main__ INFO -- Get or create the cluster --
2022-10-31 09:33:30,879 TADA INFO starting test `updtr_status test`
2022-10-31 09:33:30,879 TADA INFO   test-id: 83cb63e238d075fb481d145807c59e30d8bb35b2b1f8be4c88ff96d7b93ba4b2
2022-10-31 09:33:30,879 TADA INFO   test-suite: LDMSD
2022-10-31 09:33:30,879 TADA INFO   test-name: updtr_status test
2022-10-31 09:33:30,879 TADA INFO   test-user: narate
2022-10-31 09:33:30,879 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:33:40,837 __main__ INFO -- Start daemons --
2022-10-31 09:33:45,707 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-31 09:33:46,122 __main__ INFO All LDMSDs are up.
2022-10-31 09:33:47,355 TADA INFO assertion 1, Send 'updtr_status' to an LDMSD without any Updaters: [], passed
2022-10-31 09:33:48,573 TADA INFO assertion 2, Send 'updtr_status name=foo', where updtr 'foo' doesn't exist.: report(updtr 'foo' doesn't exist.) == expect(updtr 'foo' doesn't exist.), passed
2022-10-31 09:33:49,797 TADA INFO assertion 3, Send 'updtr_status name=all', where 'all' exists.: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-31 09:33:51,027 TADA INFO assertion 4, Send 'updtr_status' to an LDMSD with a single Updater: report([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-31 09:33:52,246 TADA INFO assertion 5, Send 'updtr_status' to an LDMSD with 2 updaters: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-31 09:33:52,247 __main__ INFO --- done ---
2022-10-31 09:33:52,247 TADA INFO test updtr_status test ended
2022-10-31 09:34:05 INFO: ----------------------------------------------
2022-10-31 09:34:06 INFO: ======== ldmsd_flex_decomp_test ========
2022-10-31 09:34:06 INFO: CMD: python3 ldmsd_flex_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldmsd_flex_decomp_test
2022-10-31 09:34:06,894 TADA INFO starting test `ldmsd_flex_decomp_test`
2022-10-31 09:34:06,894 TADA INFO   test-id: 5e5194a83f3499e574fda3319d3c54b7ce733a9a5042e8d0e2fa7ef3c3267368
2022-10-31 09:34:06,894 TADA INFO   test-suite: LDMSD
2022-10-31 09:34:06,894 TADA INFO   test-name: ldmsd_flex_decomp_test
2022-10-31 09:34:06,894 TADA INFO   test-user: narate
2022-10-31 09:34:06,894 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:34:06,895 __main__ INFO -- Get or create the cluster --
2022-10-31 09:34:22,475 __main__ INFO -- Start daemons --
2022-10-31 09:34:32,721 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-31 09:35:21,795 TADA INFO assertion 1, test_sampler_95772b6 sos schema check: OK, passed
2022-10-31 09:35:21,795 TADA INFO assertion 2, record_sampler_e1f021f sos schema check: OK, passed
2022-10-31 09:35:21,795 TADA INFO assertion 3, fill sos schema check: OK, passed
2022-10-31 09:35:21,795 TADA INFO assertion 4, filter sos schema check: OK, passed
2022-10-31 09:35:21,796 TADA INFO assertion 5, record sos schema check: OK, passed
2022-10-31 09:35:21,796 TADA INFO assertion 6, test_sampler_95772b6 csv schema check: OK, passed
2022-10-31 09:35:21,796 TADA INFO assertion 7, record_sampler_e1f021f csv schema check: OK, passed
2022-10-31 09:35:21,796 TADA INFO assertion 8, fill csv schema check: OK, passed
2022-10-31 09:35:21,796 TADA INFO assertion 9, filter csv schema check: OK, passed
2022-10-31 09:35:21,796 TADA INFO assertion 10, record csv schema check: OK, passed
2022-10-31 09:35:21,796 TADA INFO assertion 11, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-31 09:35:21,797 TADA INFO assertion 12, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-31 09:35:21,797 TADA INFO assertion 13, fill kafka schema check: OK, passed
2022-10-31 09:35:21,797 TADA INFO assertion 14, filter kafka schema check: OK, passed
2022-10-31 09:35:21,797 TADA INFO assertion 15, record kafka schema check: OK, passed
2022-10-31 09:35:21,798 TADA INFO assertion 16, test_sampler_95772b6 sos data check: OK, passed
2022-10-31 09:35:21,871 TADA INFO assertion 17, record_sampler_e1f021f sos data check: OK, passed
2022-10-31 09:35:21,874 TADA INFO assertion 18, fill sos data check: OK, passed
2022-10-31 09:35:21,875 TADA INFO assertion 19, filter sos data check: OK, passed
2022-10-31 09:35:21,884 TADA INFO assertion 20, record sos data check: OK, passed
2022-10-31 09:35:21,885 TADA INFO assertion 21, test_sampler_95772b6 csv data check: OK, passed
2022-10-31 09:35:21,949 TADA INFO assertion 22, record_sampler_e1f021f csv data check: OK, passed
2022-10-31 09:35:21,951 TADA INFO assertion 23, fill csv data check: OK, passed
2022-10-31 09:35:21,953 TADA INFO assertion 24, filter csv data check: OK, passed
2022-10-31 09:35:21,961 TADA INFO assertion 25, record csv data check: OK, passed
2022-10-31 09:35:21,961 TADA INFO assertion 26, test_sampler_95772b6 kafka data check: OK, passed
2022-10-31 09:35:21,985 TADA INFO assertion 27, record_sampler_e1f021f kafka data check: OK, passed
2022-10-31 09:35:21,986 TADA INFO assertion 28, fill kafka data check: OK, passed
2022-10-31 09:35:21,987 TADA INFO assertion 29, filter kafka data check: OK, passed
2022-10-31 09:35:21,991 TADA INFO assertion 30, record kafka data check: OK, passed
2022-10-31 09:35:21,991 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-31 09:35:21,992 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-31 09:35:37 INFO: ----------------------------------------------
2022-10-31 09:35:38 INFO: ======== ldms_set_info_test ========
2022-10-31 09:35:38 INFO: CMD: python3 ldms_set_info_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/ldms_set_info_test
2022-10-31 09:35:48,883 TADA INFO starting test `ldms_set_info_test`
2022-10-31 09:35:48,884 TADA INFO   test-id: c93de7c18842b5112a7c80830803751dda540de63653994e3943f417e8c6ec61
2022-10-31 09:35:48,884 TADA INFO   test-suite: LDMSD
2022-10-31 09:35:48,884 TADA INFO   test-name: ldms_set_info_test
2022-10-31 09:35:48,884 TADA INFO   test-user: narate
2022-10-31 09:35:48,884 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:35:48,885 TADA INFO assertion 1, Adding set info key value pairs : -, passed
2022-10-31 09:35:48,885 TADA INFO assertion 2, Reset value of an existing pair : -, passed
2022-10-31 09:35:48,885 TADA INFO assertion 3, Get a value : -, passed
2022-10-31 09:35:48,885 TADA INFO assertion 4, Unset a pair : -, passed
2022-10-31 09:35:48,885 TADA INFO assertion 5, Traverse the local set info : -, passed
2022-10-31 09:35:48,885 TADA INFO assertion 6, Verifying the set info at the 1st level : -, passed
2022-10-31 09:35:48,886 TADA INFO assertion 7, Server resetting a key : -, passed
2022-10-31 09:35:48,886 TADA INFO assertion 8, Server unset a key : -, passed
2022-10-31 09:35:48,886 TADA INFO assertion 9, Server add a key : -, passed
2022-10-31 09:35:48,886 TADA INFO assertion 10, Adding a key : -, passed
2022-10-31 09:35:48,886 TADA INFO assertion 11, Add a key that is already in the remote list : -, passed
2022-10-31 09:35:48,886 TADA INFO assertion 12, Unset a key that appears in both local and remote list : -, passed
2022-10-31 09:35:48,887 TADA INFO assertion 13, Verifying the set_info at the 2nd level : -, passed
2022-10-31 09:35:48,887 TADA INFO assertion 14, Test set info propagation: resetting a key on the set origin : -, passed
2022-10-31 09:35:48,887 TADA INFO assertion 15, Test set info propagation: unsetting a key on the set origin : -, passed
2022-10-31 09:35:48,887 TADA INFO assertion 16, Test set info propagation: adding a key on the set origin : -, passed
2022-10-31 09:35:48,887 TADA INFO test ldms_set_info_test ended
2022-10-31 09:35:59 INFO: ----------------------------------------------
2022-10-31 09:36:00 INFO: ======== slurm_sampler2_test ========
2022-10-31 09:36:00 INFO: CMD: python3 slurm_sampler2_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-31-083642/data/slurm_sampler2_test
2022-10-31 09:36:01,141 TADA INFO starting test `slurm_sampler2_test`
2022-10-31 09:36:01,142 TADA INFO   test-id: b3bce32f9bf3d082f968736261506fc3572b19d10647fb2e83784801e832a743
2022-10-31 09:36:01,142 TADA INFO   test-suite: LDMSD
2022-10-31 09:36:01,142 TADA INFO   test-name: slurm_sampler2_test
2022-10-31 09:36:01,142 TADA INFO   test-user: narate
2022-10-31 09:36:01,142 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-31 09:36:01,143 __main__ INFO -- Get or create the cluster --
2022-10-31 09:36:14,781 __main__ INFO -- Add users --
2022-10-31 09:36:19,939 __main__ INFO -- Preparing job script & programs --
2022-10-31 09:36:20,702 __main__ INFO -- Start daemons --
2022-10-31 09:36:42,599 TADA INFO assertion 1, Processing the stream data from slurm_notifier: The metric values are as expected on all nodes., passed
2022-10-31 09:36:46,268 TADA INFO assertion 2.1, Deleting completed jobs -- job_init: The metric values are as expected on all nodes., passed
2022-10-31 09:36:47,900 TADA INFO assertion 2.2, Deleting completed jobs -- step_init: The metric values are as expected on all nodes., passed
2022-10-31 09:36:49,588 TADA INFO assertion 2.3, Deleting completed jobs -- task_init: The metric values are as expected on all nodes., passed
2022-10-31 09:36:51,251 TADA INFO assertion 2.4, Deleting completed jobs -- task_exit: The metric values are as expected on all nodes., passed
2022-10-31 09:36:52,929 TADA INFO assertion 2.5, Deleting completed jobs -- job_exit: The metric values are as expected on all nodes., passed
2022-10-31 09:36:56,560 TADA INFO assertion 3.1, Expanding the set heap -- job_init: The metric values are as expected on all nodes., passed
2022-10-31 09:36:58,216 TADA INFO assertion 3.2, Expanding the set heap -- step_init: The metric values are as expected on all nodes., passed
2022-10-31 09:37:01,116 TADA INFO assertion 3.3, Expanding the set heap -- task_init: The metric values are as expected on all nodes., passed
2022-10-31 09:37:04,083 TADA INFO assertion 3.4, Expanding the set heap -- task_exit: The metric values are as expected on all nodes., passed
2022-10-31 09:37:05,720 TADA INFO assertion 3.5, Expanding the set heap -- job_exit: The metric values are as expected on all nodes., passed
2022-10-31 09:37:11,988 TADA INFO assertion 4.1, Multi-tenant -- job_init: The metric values are as expected on all nodes., passed
2022-10-31 09:37:13,653 TADA INFO assertion 4.2, Multi-tenant -- step_init: The metric values are as expected on all nodes., passed
2022-10-31 09:37:16,108 TADA INFO assertion 4.3, Multi-tenant -- task_init: The metric values are as expected on all nodes., passed
2022-10-31 09:37:18,643 TADA INFO assertion 4.4, Multi-tenant -- task_exit: The metric values are as expected on all nodes., passed
2022-10-31 09:37:20,316 TADA INFO assertion 4.5, Multi-tenant -- job_exit: The metric values are as expected on all nodes., passed
2022-10-31 09:37:20,317 TADA INFO test slurm_sampler2_test ended
2022-10-31 09:37:34 INFO: ----------------------------------------------
2022-10-31 09:37:35 INFO: ======== test-ldms ========
2022-10-31 09:37:35 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-ldms/test.sh
2022-10-31T09:37:35-05:00 INFO: starting test-samp-1
d681f4e812ded5fa15c9ca4aa0257653d0cb3e90d345d225f1e5dc9fb5cc93d2
2022-10-31T09:37:37-05:00 INFO: starting test-samp-2
948ceafdd80516e0a69b7ff0b79d49931b73d329d1ac29ab34bdad96c5efe8b5
2022-10-31T09:37:39-05:00 INFO: starting test-samp-3
246f9dd881cd2fd0b9d6880b18345127c9481fc3d3c558c37239886cd6881a76
2022-10-31T09:37:41-05:00 INFO: starting test-samp-4
c49365b81ed1225eead86c2a68e680ae406e94c45ebf3e91a30ddaef8ed1a5d6
2022-10-31T09:37:43-05:00 INFO: test-samp-1 is running
2022-10-31T09:37:43-05:00 INFO: test-samp-2 is running
2022-10-31T09:37:43-05:00 INFO: test-samp-3 is running
2022-10-31T09:37:43-05:00 INFO: test-samp-4 is running
2022-10-31T09:37:43-05:00 INFO: starting test-agg-11
37e8d8b902c38a290ad02965c1927308be35c8c01bd3ffe292ed024acd01daf2
2022-10-31T09:37:45-05:00 INFO: starting test-agg-12
2dee56d7a1c19fb0997ba937b8870b063d48bef0b23e290a8008931f169ce4b2
2022-10-31T09:37:46-05:00 INFO: test-agg-11 is running
2022-10-31T09:37:46-05:00 INFO: test-agg-12 is running
2022-10-31T09:37:46-05:00 INFO: starting test-agg-2
f80345cc130a96d0905a9cafc645ddcadefa783d2b9fc5ada766779cb241f338
2022-10-31T09:37:48-05:00 INFO: test-agg-2 is running
2022-10-31T09:37:48-05:00 INFO: Collecting data (into SOS)
2022-10-31T09:37:58-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-31T09:38:00-05:00 INFO: check rc: 0
2022-10-31T09:38:00-05:00 INFO: Cleaning up ...
test-samp-1
test-samp-2
test-samp-3
test-samp-4
test-agg-11
test-agg-12
test-agg-2
2022-10-31T09:38:05-05:00 INFO: DONE
2022-10-31 09:38:15 INFO: ----------------------------------------------
2022-10-31 09:38:15 INFO: ======== test-maestro ========
2022-10-31 09:38:15 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro/test.sh
2022-10-31T09:38:15-05:00 INFO: starting mtest-maestro
c612940734a232719c7afb6d2e46d1d2d286d3068c4f15a60f0a4854b5c02c33
2022-10-31T09:38:17-05:00 INFO: starting mtest-samp-1
cce737d96427e3dab803bb1c9556131b6ec8990cf189c980edb3bddd36d2a6b2
2022-10-31T09:38:19-05:00 INFO: starting mtest-samp-2
a64d711343ef6d875cb21675309dda913dd7d994e3c18dd8ab3970b0d0c288d7
2022-10-31T09:38:21-05:00 INFO: starting mtest-samp-3
5d9fe2d508c0daadc270a74c87020f8cf2f88ab3136bab6c367785a5a5a1e509
2022-10-31T09:38:22-05:00 INFO: starting mtest-samp-4
4bd060059bc6f60c92fd707fb7eee7a034223a59b6bc0edcb0f320f62e1ecd86
2022-10-31T09:38:24-05:00 INFO: mtest-samp-1 is running
2022-10-31T09:38:24-05:00 INFO: mtest-samp-2 is running
2022-10-31T09:38:24-05:00 INFO: mtest-samp-3 is running
2022-10-31T09:38:24-05:00 INFO: mtest-samp-4 is running
2022-10-31T09:38:24-05:00 INFO: starting mtest-agg-11
b6f0da9d4770c1d22639ce1d0f4d1cdfe2b47cc7146120ab8fa35300ae9e3b7d
2022-10-31T09:38:25-05:00 INFO: starting mtest-agg-12
d46a8919897d17dee35cc058ed33dff583bbad8b8d0099127aedb5860ed5ee5a
2022-10-31T09:38:27-05:00 INFO: mtest-agg-11 is running
2022-10-31T09:38:27-05:00 INFO: mtest-agg-12 is running
2022-10-31T09:38:27-05:00 INFO: starting mtest-agg-2
1652c8f70365e1a0eadd20edc8a9e4636654bcd01c21884bbca7be59b6b5a52d
2022-10-31T09:38:28-05:00 INFO: mtest-agg-2 is running
2022-10-31T09:38:28-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-31T09:38:39-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-31T09:38:41-05:00 INFO: sos check rc: 0
2022-10-31T09:38:43-05:00 INFO: starting mtest-ui
e27b257f55c4a097f856ff6e653acc2cd420156bb5cd6400b42f80e1629539ac
2022-10-31T09:38:49-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4386332, 1667227111001.0508], [4386332, 1667227111001.3818], [4386704, 1667227112000.256], [4386704, 1667227112001.218], [4386704, 1667227112001.2422], [4386704, 1667227112001.2449], [4386704, 1667227113001.282], [4386704, 1667227113001.3398], [4386704, 1667227113001.345], [4386704, 1667227113001.914], [4386704, 1667227114000.5251], [4386704, 1667227114001.2349], [4386704, 1667227114001.3179], [4386704, 1667227114001.3289], [4386704, 1667227115001.052], [4386704, 1667227115001.058], [4386704, 1667227115001.3801], [4386704, 1667227115001.419], [4386704, 1667227116001.067], [4386704, 1667227116001.2002], [4386704, 1667227116001.223], [4386704, 1667227116001.2239], [4386704, 1667227117000.807], [4386704, 1667227117001.213], [4386704, 1667227117001.2952], [4386704, 1667227117001.3281], [4386704, 1667227118000.544], [4386704, 1667227118000.568], [4386704, 1667227118001.3281], [4386704, 1667227118001.3718]]}, {"target": "component_id", "datapoints": [[3, 1667227111001.0508], [1, 1667227111001.3818], [2, 1667227112000.256], [1, 1667227112001.218], [4, 1667227112001.2422], [3, 1667227112001.2449], [3, 1667227113001.282], [1, 1667227113001.3398], [2, 1667227113001.345], [4, 1667227113001.914], [1, 1667227114000.5251], [4, 1667227114001.2349], [2, 1667227114001.3179], [3, 1667227114001.3289], [3, 1667227115001.052], [1, 1667227115001.058], [4, 1667227115001.3801], [2, 1667227115001.419], [4, 1667227116001.067], [3, 1667227116001.2002], [2, 1667227116001.223], [1, 1667227116001.2239], [1, 1667227117000.807], [4, 1667227117001.213], [2, 1667227117001.2952], [3, 1667227117001.3281], [2, 1667227118000.544], [3, 1667227118000.568], [4, 1667227118001.3281], [1, 1667227118001.3718]]}, {"target": "job_id", "datapoints": [[0, 1667227111001.0508], [0, 1667227111001.3818], [0, 1667227112000.256], [0, 1667227112001.218], [0, 1667227112001.2422], [0, 1667227112001.2449], [0, 1667227113001.282], [0, 1667227113001.3398], [0, 1667227113001.345], [0, 1667227113001.914], [0, 1667227114000.5251], [0, 1667227114001.2349], [0, 1667227114001.3179], [0, 1667227114001.3289], [0, 1667227115001.052], [0, 1667227115001.058], [0, 1667227115001.3801], [0, 1667227115001.419], [0, 1667227116001.067], [0, 1667227116001.2002], [0, 1667227116001.223], [0, 1667227116001.2239], [0, 1667227117000.807], [0, 1667227117001.213], [0, 1667227117001.2952], [0, 1667227117001.3281], [0, 1667227118000.544], [0, 1667227118000.568], [0, 1667227118001.3281], [0, 1667227118001.3718]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-31T09:38:52-05:00 INFO: query check RC: 0
3af472c374a573bd03baae1f3692c9814fce93c50b81f681b59806af3b895752
2022-10-31T09:39:23-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2612    806 --:--:-- --:--:-- --:--:--  3421100   479  100   366  100   113   2610    806 --:--:-- --:--:-- --:--:--  3421
{"datasource":{"id":1,"uid":"yeoeeQH4k","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-31T09:39:24-05:00 INFO: Checking grafana data
2022-10-31T09:39:24-05:00 INFO: Grafana data check, rc: 0
2022-10-31T09:39:25-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-31T09:39:29-05:00 INFO: DONE
2022-10-31 09:39:39 INFO: ----------------------------------------------
2022-10-31 09:39:39 INFO: ======== test-maestro-hostmunge ========
2022-10-31 09:39:39 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-hostmunge/test.sh
2022-10-31T09:39:39-05:00 INFO: Checking munge on localhost
2022-10-31T09:39:39-05:00 INFO: munge encode/decode successfully
2022-10-31T09:39:39-05:00 INFO: starting mtest-maestro
e647c1dfc0b47890787a5cc2c7c32fa76baa9b91bca55ae058ce8b4f900cffb3
2022-10-31T09:39:42-05:00 INFO: starting mtest-samp-1
091027fa3e219b2ab3b671d2e994abf8c35e042dc1a4d4027fa26fbab64b3848
2022-10-31T09:39:43-05:00 INFO: starting mtest-samp-2
67e9b17c1290ed992368276a642de1cc59093956644cd12471a3fb2fa3820c2a
2022-10-31T09:39:45-05:00 INFO: starting mtest-samp-3
be42001dda9af5f2cdccd55b635c0c4ba88682edb787796f982bf5cf49e1f63c
2022-10-31T09:39:47-05:00 INFO: starting mtest-samp-4
1068d07aeacf01790ae39ed712d566d0a0a9edfba0fdf87dcd1ed9d2341baf7b
2022-10-31T09:39:48-05:00 INFO: mtest-samp-1 is running
2022-10-31T09:39:48-05:00 INFO: mtest-samp-2 is running
2022-10-31T09:39:48-05:00 INFO: mtest-samp-3 is running
2022-10-31T09:39:48-05:00 INFO: mtest-samp-4 is running
2022-10-31T09:39:48-05:00 INFO: starting mtest-agg-11
1f0d41ca36f9aec4b5780248533a054558874f362381b0641a3b6f7710a723cb
2022-10-31T09:39:50-05:00 INFO: starting mtest-agg-12
5eb6353de9acb4785f908e184f00c6c2bff54f4da1b0a8bf6f78e461a40fd424
2022-10-31T09:39:51-05:00 INFO: mtest-agg-11 is running
2022-10-31T09:39:51-05:00 INFO: mtest-agg-12 is running
2022-10-31T09:39:51-05:00 INFO: starting mtest-agg-2
27738496f78b05b09c34084face63bbb14567df6b724fbd63a97b9e01b7bbe2e
2022-10-31T09:39:53-05:00 INFO: mtest-agg-2 is running
2022-10-31T09:39:53-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-31T09:40:04-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-31T09:40:06-05:00 INFO: sos check rc: 0
2022-10-31T09:40:07-05:00 INFO: starting mtest-ui
94bb6ffb0f93facdc8b806f3dcdbc60d8bc1b3e04dfdb1b145fe97ce3db65bbc
2022-10-31T09:40:09-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4386640, 1667227196001.657], [4386640, 1667227196002.049], [4387008, 1667227197000.9448], [4387008, 1667227197001.2202], [4387008, 1667227197001.7778], [4387008, 1667227197002.024], [4387008, 1667227198000.995], [4387008, 1667227198001.3398], [4387008, 1667227198001.9358], [4387008, 1667227198001.937], [4387008, 1667227199001.495], [4387008, 1667227199001.497], [4387008, 1667227199002.0212], [4387008, 1667227199002.063], [4387008, 1667227200000.886], [4387008, 1667227200000.8909], [4387008, 1667227200001.145], [4387008, 1667227200001.349], [4387008, 1667227201001.3052], [4387008, 1667227201001.3079], [4387008, 1667227201001.461], [4387008, 1667227201001.826], [4387008, 1667227202001.461], [4387008, 1667227202001.466], [4387008, 1667227202001.469], [4387008, 1667227202001.577], [4387008, 1667227203001.311], [4387008, 1667227203001.587], [4387008, 1667227203001.627], [4387008, 1667227203001.632]]}, {"target": "component_id", "datapoints": [[3, 1667227196001.657], [1, 1667227196002.049], [3, 1667227197000.9448], [1, 1667227197001.2202], [4, 1667227197001.7778], [2, 1667227197002.024], [2, 1667227198000.995], [1, 1667227198001.3398], [4, 1667227198001.9358], [3, 1667227198001.937], [2, 1667227199001.495], [1, 1667227199001.497], [3, 1667227199002.0212], [4, 1667227199002.063], [4, 1667227200000.886], [2, 1667227200000.8909], [3, 1667227200001.145], [1, 1667227200001.349], [4, 1667227201001.3052], [3, 1667227201001.3079], [1, 1667227201001.461], [2, 1667227201001.826], [3, 1667227202001.461], [1, 1667227202001.466], [4, 1667227202001.469], [2, 1667227202001.577], [3, 1667227203001.311], [2, 1667227203001.587], [4, 1667227203001.627], [1, 1667227203001.632]]}, {"target": "job_id", "datapoints": [[0, 1667227196001.657], [0, 1667227196002.049], [0, 1667227197000.9448], [0, 1667227197001.2202], [0, 1667227197001.7778], [0, 1667227197002.024], [0, 1667227198000.995], [0, 1667227198001.3398], [0, 1667227198001.9358], [0, 1667227198001.937], [0, 1667227199001.495], [0, 1667227199001.497], [0, 1667227199002.0212], [0, 1667227199002.063], [0, 1667227200000.886], [0, 1667227200000.8909], [0, 1667227200001.145], [0, 1667227200001.349], [0, 1667227201001.3052], [0, 1667227201001.3079], [0, 1667227201001.461], [0, 1667227201001.826], [0, 1667227202001.461], [0, 1667227202001.466], [0, 1667227202001.469], [0, 1667227202001.577], [0, 1667227203001.311], [0, 1667227203001.587], [0, 1667227203001.627], [0, 1667227203001.632]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-31T09:40:11-05:00 INFO: query check RC: 0
721f157b48533bd86f07a2a0af305f6dd67a8d3db36d9051ab6969a7a7fb940d
2022-10-31T09:40:43-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2531    781 --:--:-- --:--:-- --:--:--  3326
{"datasource":{"id":1,"uid":"osjkRlNVk","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-31T09:40:44-05:00 INFO: Checking grafana data
2022-10-31T09:40:44-05:00 INFO: Grafana data check, rc: 0
2022-10-31T09:40:44-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-31T09:40:49-05:00 INFO: DONE
2022-10-31 09:40:59 INFO: ----------------------------------------------
2022-10-31 09:40:59 INFO: ======== test-maestro-munge ========
2022-10-31 09:40:59 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-munge/test.sh
1+0 records in
1+0 records out
4096 bytes (4.1 kB, 4.0 KiB) copied, 0.000319317 s, 12.8 MB/s
2022-10-31T09:41:00-05:00 INFO: starting mtest-maestro
5c9f203ed1f34a1fb0bd115e9d61baf1db4858ede05baf070871136ddac1e445
2022-10-31T09:41:02-05:00 INFO: starting mtest-samp-1
5139bb8d55d70e44a83d864dcc7fedea8ea0e41e82a19ea8ae8e68a6f970c887
2022-10-31T09:41:04-05:00 INFO: starting mtest-samp-2
35afda008269ac6d28734593c9d27c73008126126395f90003b2d91093f0b722
2022-10-31T09:41:07-05:00 INFO: starting mtest-samp-3
907630c8bc139837afc691fc96253f283f4a922dfd129d7bc2e7163acbcac8de
2022-10-31T09:41:08-05:00 INFO: starting mtest-samp-4
ad22a6f740f9c153a9f7efb7fe8f5df84ebba67a7ca5275d47985bdc13926df0
2022-10-31T09:41:09-05:00 INFO: mtest-samp-1 is running
2022-10-31T09:41:10-05:00 INFO: mtest-samp-2 is running
2022-10-31T09:41:10-05:00 INFO: mtest-samp-3 is running
2022-10-31T09:41:10-05:00 INFO: mtest-samp-4 is running
2022-10-31T09:41:10-05:00 INFO: starting mtest-agg-11
51f211868559ae6744b5bcf6715cb7fadd2b357a0f666307faf6f681f458369f
2022-10-31T09:41:11-05:00 INFO: starting mtest-agg-12
a47b382ce9193e89c09fa3c665034b973de63eed99567871bd02fe53960bd0ba
2022-10-31T09:41:13-05:00 INFO: mtest-agg-11 is running
2022-10-31T09:41:13-05:00 INFO: mtest-agg-12 is running
2022-10-31T09:41:13-05:00 INFO: starting mtest-agg-2
74b4a58fc4017aa5ec041438902d6842c3d18e222118b4f875bc01c61f2e7ee9
2022-10-31T09:41:14-05:00 INFO: mtest-agg-2 is running
2022-10-31T09:41:14-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-31T09:41:25-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-31T09:41:27-05:00 INFO: sos check rc: 0
2022-10-31T09:41:29-05:00 INFO: starting mtest-ui
d784bc8011b015514dc473cc4e93d127264ee5e7ec46b3b4c2e9ba10a6366e9c
2022-10-31T09:41:30-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4386932, 1667227279000.5178], [4386932, 1667227279001.517], [4387196, 1667227280001.2532], [4387196, 1667227280001.355], [4387196, 1667227280001.612], [4387196, 1667227280001.6309], [4387300, 1667227281000.56], [4387300, 1667227281000.673], [4387300, 1667227281001.727], [4387300, 1667227281001.769], [4387300, 1667227282001.7322], [4387300, 1667227282001.824], [4387300, 1667227282001.836], [4387300, 1667227282001.903], [4387300, 1667227283001.205], [4387300, 1667227283001.2239], [4387300, 1667227283001.3162], [4387300, 1667227283001.3298], [4387300, 1667227284001.3599], [4387300, 1667227284001.3691], [4387300, 1667227284001.3792], [4387300, 1667227284001.455]]}, {"target": "component_id", "datapoints": [[3, 1667227279000.5178], [1, 1667227279001.517], [4, 1667227280001.2532], [1, 1667227280001.355], [3, 1667227280001.612], [2, 1667227280001.6309], [4, 1667227281000.56], [1, 1667227281000.673], [3, 1667227281001.727], [2, 1667227281001.769], [4, 1667227282001.7322], [1, 1667227282001.824], [3, 1667227282001.836], [2, 1667227282001.903], [3, 1667227283001.205], [1, 1667227283001.2239], [2, 1667227283001.3162], [4, 1667227283001.3298], [3, 1667227284001.3599], [1, 1667227284001.3691], [4, 1667227284001.3792], [2, 1667227284001.455]]}, {"target": "job_id", "datapoints": [[0, 1667227279000.5178], [0, 1667227279001.517], [0, 1667227280001.2532], [0, 1667227280001.355], [0, 1667227280001.612], [0, 1667227280001.6309], [0, 1667227281000.56], [0, 1667227281000.673], [0, 1667227281001.727], [0, 1667227281001.769], [0, 1667227282001.7322], [0, 1667227282001.824], [0, 1667227282001.836], [0, 1667227282001.903], [0, 1667227283001.205], [0, 1667227283001.2239], [0, 1667227283001.3162], [0, 1667227283001.3298], [0, 1667227284001.3599], [0, 1667227284001.3691], [0, 1667227284001.3792], [0, 1667227284001.455]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-31T09:41:33-05:00 INFO: query check RC: 0
1772c492524dc3bf63c742a6602edf1af66715d34e894856787c33f13aa5550a
2022-10-31T09:42:04-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2463    760 --:--:-- --:--:-- --:--:--  3236
{"datasource":{"id":1,"uid":"bZpMglH4z","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-31T09:42:05-05:00 INFO: Checking grafana data
2022-10-31T09:42:05-05:00 INFO: Grafana data check, rc: 0
2022-10-31T09:42:05-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-31T09:42:10-05:00 INFO: DONE
2022-10-31 09:42:20 INFO: ----------------------------------------------
2022-10-31 09:42:20 INFO: ==== Summary ====
ldmsd_ctrl_test: [01;32mPASSED[0m
papi_store_test: [01;32mPASSED[0m
updtr_status_test: [01;32mPASSED[0m
ldmsd_auth_ovis_test: [01;32mPASSED[0m
store_app_test: [01;32mPASSED[0m
store_list_record_test: [01;32mPASSED[0m
set_array_test: [01;32mPASSED[0m
ovis_ev_test: [01;32mPASSED[0m
setgroup_test: [01;32mPASSED[0m
ldms_list_test: [01;32mPASSED[0m
slurm_stream_test: [01;32mPASSED[0m
maestro_cfg_test: [01;32mPASSED[0m
ldms_set_info_test: [01;32mPASSED[0m
spank_notifier_test: [01;32mPASSED[0m
agg_slurm_test: [01;31mFAILED[0m
updtr_match_add_test: [01;32mPASSED[0m
updtr_match_del_test: [01;32mPASSED[0m
ldmsd_stream_dir_test: [01;32mPASSED[0m
direct_prdcr_subscribe_test: [01;32mPASSED[0m
ldmsd_auth_test: [01;32mPASSED[0m
cont-test-maestro-munge: [01;32mPASSED[0m
cont-test-ldms: [01;32mPASSED[0m
prdcr_subscribe_test: [01;32mPASSED[0m
cont-test-maestro-hostmunge: [01;32mPASSED[0m
maestro_raft_test: [01;32mPASSED[0m
updtr_start_test: [01;32mPASSED[0m
failover_test: [01;32mPASSED[0m
ldms_record_test: [01;32mPASSED[0m
cont-test-maestro: [01;32mPASSED[0m
ldmsd_decomp_test: [01;32mPASSED[0m
ldmsd_flex_decomp_test: [01;32mPASSED[0m
quick_set_add_rm_test: [01;32mPASSED[0m
updtr_prdcr_del_test: [01;32mPASSED[0m
updtr_prdcr_add_test: [01;32mPASSED[0m
mt-slurm-test: [01;32mPASSED[0m
ovis_json_test: [01;32mPASSED[0m
papi_sampler_test: [01;32mPASSED[0m
syspapi_test: [01;32mPASSED[0m
updtr_del_test: [01;32mPASSED[0m
ldmsd_autointerval_test: [01;32mPASSED[0m
updtr_add_test: [01;32mPASSED[0m
ldmsd_stream_test: [01;32mPASSED[0m
direct_ldms_ls_conn_test: [01;32mPASSED[0m
set_array_hang_test: [01;32mPASSED[0m
slurm_sampler2_test: [01;32mPASSED[0m
ldms_schema_digest_test: [01;32mPASSED[0m
agg_test: [01;32mPASSED[0m
------------------------------------------
Total tests passed: 46/47
------------------------------------------
