2024-10-16 16:30:24 INFO: WORK_DIR: /mnt/300G/data/2024-10-16-163023
2024-10-16 16:30:24 INFO: LOG: /mnt/300G/data/2024-10-16-163023/cygnus-weekly.log
2024-10-16 16:30:24 INFO: OVIS_REPO: https://github.com/ovis-hpc/ovis
2024-10-16 16:30:24 INFO: OVIS_BRANCH: OVIS-4
2024-10-16 16:30:24 INFO: SOS_REPO: https://github.com/ovis-hpc/sos
2024-10-16 16:30:24 INFO: SOS_BRANCH: SOS-6
2024-10-16 16:30:24 INFO: MAESTRO_REPO: https://github.com/ovis-hpc/maestro
2024-10-16 16:30:24 INFO: MAESTRO_BRANCH: master
2024-10-16 16:30:24 INFO: OVIS_NEW_GIT_SHA: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:30:24 INFO: OVIS_OLD_GIT_SHA: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:30:24 INFO: CONT_GIT_SHA: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:30:24 INFO: -----------------------------------------------
2024-10-16 16:30:24 INFO: LDMS_TEST_REPO: https://github.com/ovis-hpc/ldms-test
2024-10-16 16:30:24 INFO: LDMS_TEST_BRANCH: master
2024-10-16 16:30:24 INFO: LDMS_TEST_NEW_GIT_SHA: 8f59ba47cdcaed15b2bfeabe21365437aba5432c
2024-10-16 16:30:24 INFO: LDMS_TEST_OLD_GIT_SHA: 1cfe9e4c12e8e2fa43bc2c7c80f91f732da9428d
2024-10-16 16:30:24 INFO: LDMS_TEST_GIT_SHA: dc42b0d9812f03d3d675ba9be73b95ddc29626df
~/cron/ldms-test ~/cron/ldms-test
/mnt/300G/data/2024-10-16-163023 ~/cron/ldms-test ~/cron/ldms-test
2024-10-16 16:30:25 INFO: Skip building on host because GIT SHA has not changed: 
04c74b7b45c1467071acf9512ffb3dfdd68bc649
OVIS_LDMS_OVIS_GIT_LONG "04c74b7b45c1467071acf9512ffb3dfdd68bc649"
2024-10-16 16:30:25 INFO: Skip building containerized binary because GIT SHA has not changed: 
2024-10-16 16:30:25 INFO: -- Installation process succeeded --
2024-10-16 16:30:25 INFO: ---------------------------------------------------------------
~/cron/ldms-test /mnt/300G/data/2024-10-16-163023
~/cron/ldms-test/weekly-report ~/cron/ldms-test /mnt/300G/data/2024-10-16-163023
From github.com:ldms-test/weekly-report
 * branch            master     -> FETCH_HEAD
HEAD is now at 388ad86 2024-10-16-133849
[master 6f7b44c] 2024-10-16-163023
 2 files changed, 33 insertions(+), 16477 deletions(-)
 rewrite test-all.log (99%)
To github.com:ldms-test/weekly-report
   388ad86..6f7b44c  master -> master
~/cron/ldms-test /mnt/300G/data/2024-10-16-163023
2024-10-16 16:30:27 INFO: ==== OVIS+SOS Installation Completed ====
2024-10-16 16:30:27 INFO: ==== Start batch testing ====
~/cron/ldms-test /mnt/300G/data/2024-10-16-163023 ~/cron/ldms-test ~/cron/ldms-test
2024-10-16 16:30:27 INFO: ======== direct_ldms_ls_conn_test ========
2024-10-16 16:30:27 INFO: CMD: python3 direct_ldms_ls_conn_test --prefix /opt/ovis --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/direct_ldms_ls_conn_test
2024-10-16 16:30:28,295 TADA INFO starting test `direct_ldms_ls_conn_test`
2024-10-16 16:30:28,295 TADA INFO   test-id: f7429d47183f89e7cac0f01d2ecff3f4ed8dad8bc94f66e6271f7ba20455b19f
2024-10-16 16:30:28,295 TADA INFO   test-suite: LDMSD
2024-10-16 16:30:28,295 TADA INFO   test-name: direct_ldms_ls_conn_test
2024-10-16 16:30:28,295 TADA INFO   test-user: narate
2024-10-16 16:30:28,295 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:30:28,757 __main__ INFO starting munged on cygnus-01-iw
2024-10-16 16:30:29,144 __main__ INFO starting munged on localhost
2024-10-16 16:30:29,375 __main__ INFO starting ldmsd on cygnus-01-iw
2024-10-16 16:30:29,710 TADA INFO assertion 0, Start ldmsd sampler and munged: OK, passed
2024-10-16 16:30:34,913 TADA INFO assertion 1, ldms_ls to the sampler: OK, passed
2024-10-16 16:30:34,913 __main__ INFO Stopping sampler daemon ...
2024-10-16 16:30:40,335 TADA INFO assertion 2, Kill the sampler: OK, passed
2024-10-16 16:30:40,377 TADA INFO assertion 3, ldms_ls to the dead sampler: got expected output, passed
2024-10-16 16:30:40,415 TADA INFO assertion 4, ldms_ls to a dead host: got expected output, passed
2024-10-16 16:30:40,416 TADA INFO test direct_ldms_ls_conn_test ended
2024-10-16 16:30:40,629 __main__ INFO stopping munged on cygnus-01-iw
2024-10-16 16:30:41,043 __main__ INFO stopping munged on localhost
2024-10-16 16:30:41 INFO: ----------------------------------------------
2024-10-16 16:30:41 INFO: ======== direct_prdcr_subscribe_test ========
2024-10-16 16:30:41 INFO: CMD: python3 direct_prdcr_subscribe_test --prefix /opt/ovis --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/direct_prdcr_subscribe_test
2024-10-16 16:30:41,881 TADA INFO starting test `direct_prdcr_subscribe_test`
2024-10-16 16:30:41,882 TADA INFO   test-id: 84dcdc07d8184c1d2d47deaca965a59ecd5642baea11f3be74f5940c6926de1c
2024-10-16 16:30:41,882 TADA INFO   test-suite: LDMSD
2024-10-16 16:30:41,882 TADA INFO   test-name: direct_prdcr_subscribe_test
2024-10-16 16:30:41,882 TADA INFO   test-user: narate
2024-10-16 16:30:41,882 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:30:43,827 __main__ INFO starting munged on cygnus-01-iw
2024-10-16 16:30:44,403 __main__ INFO starting munged on cygnus-05-iw
2024-10-16 16:30:44,957 __main__ INFO starting munged on cygnus-03-iw
2024-10-16 16:30:45,489 __main__ INFO starting munged on cygnus-04-iw
2024-10-16 16:30:45,786 __main__ INFO starting munged on localhost
2024-10-16 16:30:46,023 __main__ INFO starting ldmsd on cygnus-01-iw
2024-10-16 16:30:46,546 __main__ INFO starting ldmsd on cygnus-05-iw
2024-10-16 16:30:47,051 __main__ INFO starting ldmsd on cygnus-03-iw
2024-10-16 16:30:47,514 __main__ INFO starting ldmsd on cygnus-04-iw
2024-10-16 16:30:54,483 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2024-10-16 16:30:54,484 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2024-10-16 16:30:54,485 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2024-10-16 16:30:54,485 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2024-10-16 16:30:54,486 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verified, passed
2024-10-16 16:30:54,533 TADA INFO assertion 5, Stopping the producers succeeds: agg-1 producers stopped, passed
2024-10-16 16:30:55,535 TADA INFO assertion 6, Restarting the producers succeeds: agg-1 producers started, passed
2024-10-16 16:31:02,248 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2024-10-16 16:31:02,249 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2024-10-16 16:31:02,249 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2024-10-16 16:31:02,250 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2024-10-16 16:31:02,251 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verified, passed
2024-10-16 16:31:02,251 __main__ INFO stopping sampler-1
2024-10-16 16:31:03,675 TADA INFO assertion 12, stream-sampler-1 is not running: sampler-1 stopped, passed
2024-10-16 16:31:03,676 __main__ INFO starting sampler-1
2024-10-16 16:31:04,925 TADA INFO assertion 13, stream-sampler-1 has restarted: sampler-1 running, passed
2024-10-16 16:31:04,925 __main__ INFO allow some time for prdcr to reconnect ...
2024-10-16 16:31:10,937 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2024-10-16 16:31:10,938 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2024-10-16 16:31:10,938 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verified, passed
2024-10-16 16:31:10,940 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: unsubscribed, passed
2024-10-16 16:31:13,326 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2024-10-16 16:31:13,332 __main__ INFO stopping agg-1
2024-10-16 16:31:18,556 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2024-10-16 16:31:18,557 TADA INFO test direct_prdcr_subscribe_test ended
2024-10-16 16:31:18,761 __main__ INFO stopping munged on cygnus-01-iw
2024-10-16 16:31:19,177 __main__ INFO stopping ldmsd on cygnus-01-iw
2024-10-16 16:31:19,639 __main__ INFO stopping munged on cygnus-05-iw
2024-10-16 16:31:20,106 __main__ INFO stopping ldmsd on cygnus-05-iw
2024-10-16 16:31:20,554 __main__ INFO stopping munged on cygnus-03-iw
2024-10-16 16:31:21,188 __main__ INFO stopping munged on cygnus-04-iw
2024-10-16 16:31:21,608 __main__ INFO stopping ldmsd on cygnus-04-iw
2024-10-16 16:31:21,821 __main__ INFO stopping munged on localhost
2024-10-16 16:31:21 INFO: ----------------------------------------------
2024-10-16 16:31:23 INFO: PAPI: Of 40 available events, 8 are derived.
2024-10-16 16:31:23 INFO: PAPI_AVAIL: 40
2024-10-16 16:31:23 INFO: Add PAPI-related tests into the test list
2024-10-16 16:31:23 INFO: ======== agg_test ========
2024-10-16 16:31:23 INFO: CMD: python3 agg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/agg_test
2024-10-16 16:31:23,914 TADA INFO starting test `agg_test`
2024-10-16 16:31:23,914 TADA INFO   test-id: fb101541102fe68f558422a954d9e79e7636363c1bb30bd76fb4e72f23e891a3
2024-10-16 16:31:23,915 TADA INFO   test-suite: LDMSD
2024-10-16 16:31:23,915 TADA INFO   test-name: agg_test
2024-10-16 16:31:23,915 TADA INFO   test-user: narate
2024-10-16 16:31:23,915 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:31:23,915 __main__ INFO -- Get or create the cluster --
2024-10-16 16:31:55,551 __main__ INFO -- Start daemons --
2024-10-16 16:32:54,168 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:32:59,173 __main__ INFO -- ldms_ls to agg-2 --
2024-10-16 16:32:59,290 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2024-10-16 16:33:00,095 TADA INFO assertion 2, meminfo data verification: data verified, passed
2024-10-16 16:33:00,096 __main__ INFO -- Terminating ldmsd on node-1 --
2024-10-16 16:33:02,461 TADA INFO assertion 3, node-1 ldmsd terminated, sets removed from agg-11: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2024-10-16 16:33:02,681 TADA INFO assertion 4, node-1 ldmsd terminated, sets removed from agg-2: list({'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-3/meminfo', 'node-2/meminfo', 'node-4/meminfo'}), passed
2024-10-16 16:33:02,681 __main__ INFO -- Resurrecting ldmsd on node-1 --
2024-10-16 16:33:15,410 TADA INFO assertion 5, node-1 ldmsd revived, sets added to agg-11: list({'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo'}), passed
2024-10-16 16:33:15,538 TADA INFO assertion 6, node-1 ldmsd revived, sets added to agg-2: list({'node-3/meminfo', 'node-2/meminfo', 'node-1/meminfo', 'node-4/meminfo'}) == expect({'node-3/meminfo', 'node-2/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2024-10-16 16:33:15,538 __main__ INFO -- Terminating ldmsd on agg-11 --
2024-10-16 16:33:17,908 TADA INFO assertion 7, agg-11 ldmsd terminated, sets removed from agg-2: list({'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2024-10-16 16:33:18,039 TADA INFO assertion 8, agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2024-10-16 16:33:18,159 TADA INFO assertion 9, agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2024-10-16 16:33:18,159 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2024-10-16 16:33:27,740 TADA INFO assertion 10, agg-11 ldmsd revived, sets added to agg-2: list({'node-3/meminfo', 'node-2/meminfo', 'node-1/meminfo', 'node-4/meminfo'}) == expect({'node-3/meminfo', 'node-2/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2024-10-16 16:33:27,740 TADA INFO test agg_test ended
2024-10-16 16:33:43 INFO: ----------------------------------------------
2024-10-16 16:33:45 INFO: ======== failover_test ========
2024-10-16 16:33:45 INFO: CMD: python3 failover_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/failover_test
2024-10-16 16:33:46,347 TADA INFO starting test `failover_test`
2024-10-16 16:33:46,347 TADA INFO   test-id: ef7139973fbb3b8924b0595caa3e7e38cd7d70fa8d883a82be9cc4371eb5e73e
2024-10-16 16:33:46,347 TADA INFO   test-suite: LDMSD
2024-10-16 16:33:46,347 TADA INFO   test-name: failover_test
2024-10-16 16:33:46,347 TADA INFO   test-user: narate
2024-10-16 16:33:46,347 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:33:46,348 __main__ INFO -- Get or create the cluster --
2024-10-16 16:34:17,982 __main__ INFO -- Start daemons --
2024-10-16 16:35:13,423 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:35:28,434 __main__ INFO -- ldms_ls to agg-2 --
2024-10-16 16:35:28,567 TADA INFO assertion 1, 
ldms_ls agg-2: dir result verified, passed
2024-10-16 16:35:29,373 TADA INFO assertion 2, 
meminfo data verification: data verified, passed
2024-10-16 16:35:29,373 __main__ INFO -- Terminating ldmsd on agg-11 --
2024-10-16 16:35:34,724 TADA INFO assertion 3, 
agg-11 ldmsd terminated, sets added to agg-12: list({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}), passed
2024-10-16 16:35:34,845 TADA INFO assertion 4, 
agg-11 ldmsd terminated, all sets running on agg-2: list({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}), passed
2024-10-16 16:35:34,969 TADA INFO assertion 5, 
agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2024-10-16 16:35:35,095 TADA INFO assertion 6, 
agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2024-10-16 16:35:35,095 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2024-10-16 16:35:59,689 TADA INFO assertion 7, 
agg-11 ldmsd revived, sets removed from agg-12: list({'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo'}), passed
2024-10-16 16:35:59,807 TADA INFO assertion 8, 
agg-11 ldmsd revived, all sets running on agg-2: list({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}), passed
2024-10-16 16:35:59,808 __main__ INFO -- Terminating ldmsd on agg-12 --
2024-10-16 16:36:05,156 TADA INFO assertion 9, 
agg-12 ldmsd terminated, sets added to agg-11: list({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}), passed
2024-10-16 16:36:05,272 TADA INFO assertion 10, 
agg-12 ldmsd terminated, all sets running on agg-2: list({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}), passed
2024-10-16 16:36:05,389 TADA INFO assertion 11, 
agg-12 ldmsd terminated, node-2 ldmsd is still running: list({'node-2/meminfo'}) == expect({'node-2/meminfo'}), passed
2024-10-16 16:36:05,495 TADA INFO assertion 12, 
agg-12 ldmsd terminated, node-4 ldmsd is still running: list({'node-4/meminfo'}) == expect({'node-4/meminfo'}), passed
2024-10-16 16:36:05,495 __main__ INFO -- Resurrecting ldmsd on agg-12 --
2024-10-16 16:36:30,098 TADA INFO assertion 13, 
agg-12 ldmsd revived, sets removed from agg-11: list({'node-1/meminfo', 'node-3/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo'}), passed
2024-10-16 16:36:30,230 TADA INFO assertion 14, 
agg-12 ldmsd revived, all sets running on agg-2: list({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-4/meminfo', 'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo'}), passed
2024-10-16 16:36:30,231 TADA INFO test failover_test ended
2024-10-16 16:36:45 INFO: ----------------------------------------------
2024-10-16 16:36:48 INFO: ======== ldmsd_auth_ovis_test ========
2024-10-16 16:36:48 INFO: CMD: python3 ldmsd_auth_ovis_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_auth_ovis_test
2024-10-16 16:36:48,806 TADA INFO starting test `ldmsd_auth_ovis_test`
2024-10-16 16:36:48,806 TADA INFO   test-id: c15385b67ec8328052e48ee062f30c279e787a6f216d4eb5f6856d34d8691217
2024-10-16 16:36:48,806 TADA INFO   test-suite: LDMSD
2024-10-16 16:36:48,806 TADA INFO   test-name: ldmsd_auth_ovis_test
2024-10-16 16:36:48,806 TADA INFO   test-user: narate
2024-10-16 16:36:48,806 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:36:48,807 __main__ INFO -- Get or create the cluster --
2024-10-16 16:37:02,440 __main__ INFO -- Start daemons --
2024-10-16 16:37:11,471 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:37:16,613 TADA INFO assertion 1, ldms_ls with auth none: verified, passed
2024-10-16 16:37:16,740 TADA INFO assertion 2, ldms_ls with wrong secret: verified, passed
2024-10-16 16:37:16,865 TADA INFO assertion 3, ldms_ls 'dir' with right secret: verified, passed
2024-10-16 16:37:17,165 TADA INFO assertion 4, ldms_ls 'read' with right secret: verified, passed
2024-10-16 16:37:17,165 TADA INFO test ldmsd_auth_ovis_test ended
2024-10-16 16:37:28 INFO: ----------------------------------------------
2024-10-16 16:37:30 INFO: ======== ldmsd_auth_test ========
2024-10-16 16:37:30 INFO: CMD: python3 ldmsd_auth_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_auth_test
2024-10-16 16:37:31,641 TADA INFO starting test `ldmsd_auth_test`
2024-10-16 16:37:31,642 TADA INFO   test-id: 8d3abd40e07c749146ce8216b7adb645242d93fbe2cad281580bc4ddf4e1cc4b
2024-10-16 16:37:31,642 TADA INFO   test-suite: LDMSD
2024-10-16 16:37:31,642 TADA INFO   test-name: ldmsd_auth_test
2024-10-16 16:37:31,642 TADA INFO   test-user: narate
2024-10-16 16:37:31,642 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:37:31,643 __main__ INFO -- Get or create the cluster --
2024-10-16 16:38:03,156 __main__ INFO -- Start daemons --
2024-10-16 16:39:11,645 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:39:16,778 TADA INFO assertion 1, root@agg-2(dom3) ldms_ls to agg-2:10000: see all sets, passed
2024-10-16 16:39:16,892 TADA INFO assertion 2, user@agg-2(dom3) ldms_ls to agg-2:10000: see only meminfo, passed
2024-10-16 16:39:17,013 TADA INFO assertion 3, root@headnode(dom4) ldms_ls to agg-2:10001: see all sets, passed
2024-10-16 16:39:17,116 TADA INFO assertion 4, user@headnode(dom4) ldms_ls to agg-2:10001: see only meminfo, passed
2024-10-16 16:39:17,240 TADA INFO assertion 5, root@headnode(dom4) ldms_ls to agg-11:10000: connection rejected, passed
2024-10-16 16:39:17,240 TADA INFO test ldmsd_auth_test ended
2024-10-16 16:39:33 INFO: ----------------------------------------------
2024-10-16 16:39:35 INFO: ======== ldmsd_ctrl_test ========
2024-10-16 16:39:35 INFO: CMD: python3 ldmsd_ctrl_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_ctrl_test
2024-10-16 16:39:35,980 TADA INFO starting test `ldmsd_ctrl_test`
2024-10-16 16:39:35,980 TADA INFO   test-id: f2d5d60640d61e6cbc891a044574f53cd834aaa713eed27bc861c4433580e31b
2024-10-16 16:39:35,980 TADA INFO   test-suite: LDMSD
2024-10-16 16:39:35,980 TADA INFO   test-name: ldmsd_ctrl_test
2024-10-16 16:39:35,980 TADA INFO   test-user: narate
2024-10-16 16:39:35,981 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:39:35,981 __main__ INFO -- Get or create the cluster --
2024-10-16 16:39:55,380 __main__ INFO -- Start daemons --
2024-10-16 16:40:20,839 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:40:26,961 TADA INFO assertion 1, ldmsd_controller interactive session: connected, passed
2024-10-16 16:40:28,077 TADA INFO assertion 2, ldmsctl interactive session: connected, passed
2024-10-16 16:40:28,679 TADA INFO assertion 3, ldmsd_controller start bogus producer: expected output verified, passed
2024-10-16 16:40:29,280 TADA INFO assertion 4, ldmsctl start bogus producer: expected output verified, passed
2024-10-16 16:40:29,882 TADA INFO assertion 5, ldmsd_controller bogus command: expected output verified, passed
2024-10-16 16:40:30,483 TADA INFO assertion 6, ldmsctl bogus command: expected output verified, passed
2024-10-16 16:40:31,084 TADA INFO assertion 7, ldmsd_controller load bogus plugin: expected output verified, passed
2024-10-16 16:40:31,686 TADA INFO assertion 8, ldmsctl load bogus plugin: expected output verified, passed
2024-10-16 16:40:48,878 TADA INFO assertion 9, ldmsd_controller prdcr/updtr: verified, passed
2024-10-16 16:41:06,094 TADA INFO assertion 10, ldmsctl prdcr/updtr: verified, passed
2024-10-16 16:41:06,094 TADA INFO test ldmsd_ctrl_test ended
2024-10-16 16:41:19 INFO: ----------------------------------------------
2024-10-16 16:41:21 INFO: ======== ldmsd_stream_test2 ========
2024-10-16 16:41:21 INFO: CMD: python3 ldmsd_stream_test2 --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_stream_test2
2024-10-16 16:41:21,827 TADA INFO starting test `ldmsd_stream_test`
2024-10-16 16:41:21,827 TADA INFO   test-id: 3f236ba473d129f416a0ca18484c7ed391d15b4b91098c4aa6584b6228f614db
2024-10-16 16:41:21,827 TADA INFO   test-suite: LDMSD
2024-10-16 16:41:21,827 TADA INFO   test-name: ldmsd_stream_test
2024-10-16 16:41:21,827 TADA INFO   test-user: narate
2024-10-16 16:41:21,827 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:41:21,828 __main__ INFO -- Get or create the cluster --
2024-10-16 16:41:41,455 __main__ INFO -- Start daemons --
2024-10-16 16:42:05,257 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:42:07,260 root INFO starting /tada-src/python/pypubsub.py on narate-ldmsd_stream_test2-04c74b7-new 
2024-10-16 16:42:09,478 root INFO starting /tada-src/python/pypubsub.py on narate-ldmsd_stream_test2-04c74b7-agg-2 
2024-10-16 16:42:19,143 TADA INFO assertion 1, Check data from old ldmsd_stream at agg-1: , passed
2024-10-16 16:42:19,144 TADA INFO assertion 2, Check data from old ldmsd_stream at agg-2: , passed
2024-10-16 16:42:19,144 TADA INFO assertion 3, Check data from old ldmsd_stream at the last subscriber: , passed
2024-10-16 16:42:19,145 TADA INFO assertion 4, Check data from the matching new ldms stream at agg-1: , passed
2024-10-16 16:42:19,145 TADA INFO assertion 5, Check data from the matching new ldms stream at agg-2: , passed
2024-10-16 16:42:19,145 TADA INFO assertion 6, Check data from the matching new ldms stream at the last subscriber: , passed
2024-10-16 16:42:19,145 TADA INFO assertion 7, Check data from the non-matching new ldms stream at agg-1: , passed
2024-10-16 16:42:19,146 TADA INFO assertion 8, Check data from the non-matching new ldms stream at agg-2: , passed
2024-10-16 16:42:19,146 TADA INFO assertion 9, Check data from the non-matching new ldms stream at last subscriber: , passed
2024-10-16 16:42:19,746 TADA INFO assertion 10, Check stream_stats before stream data transfer: , passed
2024-10-16 16:42:19,747 TADA INFO assertion 11, Check stream_client_stats before stream data transfer: , passed
2024-10-16 16:42:19,747 TADA INFO assertion 12, Check stream_stats after stream data transfer: , passed
2024-10-16 16:42:19,747 TADA INFO assertion 13, Check stream_client_stats after stream data transfer: , passed
2024-10-16 16:42:19,747 TADA INFO test ldmsd_stream_test ended
2024-10-16 16:42:33 INFO: ----------------------------------------------
2024-10-16 16:42:35 INFO: ======== maestro_cfg_test ========
2024-10-16 16:42:35 INFO: CMD: python3 maestro_cfg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/maestro_cfg_test
2024-10-16 16:42:35,778 TADA INFO starting test `maestro_cfg_test`
2024-10-16 16:42:35,778 TADA INFO   test-id: 9d71ec7fbb10fac9836ed0089bcec1c0026e762a6b239be24ff75b92cf3a3755
2024-10-16 16:42:35,778 TADA INFO   test-suite: LDMSD
2024-10-16 16:42:35,778 TADA INFO   test-name: maestro_cfg_test
2024-10-16 16:42:35,778 TADA INFO   test-user: narate
2024-10-16 16:42:35,778 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:42:45,790 __main__ INFO -- Get or create cluster --
2024-10-16 16:43:29,832 __main__ INFO -- Start daemons --
2024-10-16 16:45:09,035 __main__ INFO ... make sure ldmsd's are up
2024-10-16 16:45:16,810 TADA INFO assertion 1, load maestro etcd cluster: etcd cluster loaded successfully, passed
2024-10-16 16:45:56,835 TADA INFO assertion 2, config ldmsd cluster with maestro: Maestro ldmsd configuration successful, passed
2024-10-16 16:45:58,577 TADA INFO assertion 3, verify sampler daemons: OK, passed
2024-10-16 16:45:59,221 TADA INFO assertion 4, verify L1 aggregator daemons: OK, passed
2024-10-16 16:45:59,492 TADA INFO assertion 5, verify L2 aggregator daemon: OK, passed
2024-10-16 16:45:59,862 TADA INFO assertion 6, verify data storage: OK, passed
---Wait for config to write to file---
2024-10-16 16:45:59,862 TADA INFO test maestro_cfg_test ended
2024-10-16 16:46:18 INFO: ----------------------------------------------
2024-10-16 16:46:20 INFO: ======== mt-slurm-test ========
2024-10-16 16:46:20 INFO: CMD: python3 mt-slurm-test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/mt-slurm-test
-- Get or create the cluster --
-- Start daemons --
... wait a bit to make sure ldmsd's are up
Every job in input data represented in output: : Passed
['# task_rank,timestamp', '0,1729115262.945505', '1,1729115262.945505', '2,1729115262.945505', '3,1729115262.945505', '4,1729115262.945505', '5,1729115263.953134', '6,1729115263.953134', '7,1729115263.953134', '8,1729115263.953134', '9,1729115264.981947', '10,1729115264.981947', '11,1729115264.981947', '12,1729115265.911378', '13,1729115265.911378', '14,1729115265.911378', '15,1729115265.911378', '16,1729115265.911378', '17,1729115265.911378', '18,1729115267.940909', '19,1729115267.940909', '20,1729115267.940909', '21,1729115267.940909', '22,1729115267.940909', '23,1729115267.940909', '24,1729115267.940909', '25,1729115267.940909', '26,1729115267.940909', '# Records 27/27.', '']
Job 10000 has 27 rank: : Passed
Job 10100 has 64 rank: : Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
Job 10000 has 3 nodes: node count 3 correct: Passed
Job 10100 has 4 nodes: node count 4 correct: Passed
2024-10-16 16:48:22 INFO: ----------------------------------------------
2024-10-16 16:48:24 INFO: ======== ovis_ev_test ========
2024-10-16 16:48:24 INFO: CMD: python3 ovis_ev_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ovis_ev_test
2024-10-16 16:48:25,693 __main__ INFO -- Create the cluster -- 
2024-10-16 16:48:42,268 TADA INFO starting test `ovis_ev_test`
2024-10-16 16:48:42,269 TADA INFO   test-id: 4a49db291dff94af10e610c16ef8f05636b5630b237e65293ffcd60adb1ecbaa
2024-10-16 16:48:42,269 TADA INFO   test-suite: test_ovis_ev
2024-10-16 16:48:42,269 TADA INFO   test-name: ovis_ev_test
2024-10-16 16:48:42,269 TADA INFO   test-user: narate
2024-10-16 16:48:42,269 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:48:42,270 TADA INFO assertion 1, Test posting an event without timeout: ovis_ev delivered the expected event., passed
2024-10-16 16:48:42,270 TADA INFO assertion 2, Test posting an event with a current timeout: ovis_ev delivered the expected event., passed
2024-10-16 16:48:42,270 TADA INFO assertion 3, Test posting an event with a future timeout: ovis_ev delivered the expected event., passed
2024-10-16 16:48:42,271 TADA INFO assertion 4, Test reposting a posted event: ev_post returned EBUSY when posted an already posted event, passed
2024-10-16 16:48:42,271 TADA INFO assertion 5, Test canceling a posted event: ovis_ev delivered the expected event., passed
2024-10-16 16:48:42,271 TADA INFO assertion 6, Test rescheduling a posted event: ovis_ev delivered the expected event., passed
2024-10-16 16:48:42,271 TADA INFO assertion 7, Test event deliver order: The event delivery order was correct., passed
2024-10-16 16:48:42,271 TADA INFO assertion 8, Test flushing events: Expected status (1) == delivered status (1), passed
2024-10-16 16:48:42,271 TADA INFO assertion 9, Test posting event on a flushed worker: Expected status (0) == delivered status (0), passed
2024-10-16 16:48:42,271 TADA INFO assertion 10, Test the case that multiple threads post the same event: ev_post returned the expected return code., passed
2024-10-16 16:48:42,272 TADA INFO test ovis_ev_test ended
2024-10-16 16:48:53 INFO: ----------------------------------------------
2024-10-16 16:48:55 INFO: ======== prdcr_subscribe_test ========
2024-10-16 16:48:55 INFO: CMD: python3 prdcr_subscribe_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/prdcr_subscribe_test
2024-10-16 16:48:56,048 TADA INFO starting test `prdcr_subscribe_test`
2024-10-16 16:48:56,048 TADA INFO   test-id: a7515792b7e2d036ce60ff8b80b4508706edad596080d5793c066b78b2d2ebcb
2024-10-16 16:48:56,048 TADA INFO   test-suite: LDMSD
2024-10-16 16:48:56,048 TADA INFO   test-name: prdcr_subscribe_test
2024-10-16 16:48:56,049 TADA INFO   test-user: narate
2024-10-16 16:48:56,049 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:49:59,499 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2024-10-16 16:49:59,499 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2024-10-16 16:49:59,500 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2024-10-16 16:49:59,500 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2024-10-16 16:49:59,500 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verification, passed
2024-10-16 16:49:59,897 TADA INFO assertion 5, Stopping the producers succeeds: , passed
2024-10-16 16:50:00,280 TADA INFO assertion 6, Restarting the producers succeeds: , passed
2024-10-16 16:50:08,313 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2024-10-16 16:50:08,314 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2024-10-16 16:50:08,314 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2024-10-16 16:50:08,314 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2024-10-16 16:50:08,315 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verification, passed
2024-10-16 16:50:09,538 TADA INFO assertion 12, stream-sampler-1 is not running: (running == False), passed
2024-10-16 16:50:18,126 TADA INFO assertion 13, stream-sampler-1 has restarted: (running == True), passed
2024-10-16 16:50:25,694 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2024-10-16 16:50:25,694 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2024-10-16 16:50:25,694 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verification, passed
2024-10-16 16:50:26,071 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: , passed
2024-10-16 16:50:29,373 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2024-10-16 16:50:35,200 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2024-10-16 16:50:35,201 TADA INFO test prdcr_subscribe_test ended
2024-10-16 16:50:48 INFO: ----------------------------------------------
2024-10-16 16:50:50 INFO: ======== set_array_test ========
2024-10-16 16:50:50 INFO: CMD: python3 set_array_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/set_array_test
2024-10-16 16:50:50,962 TADA INFO starting test `set_array_test`
2024-10-16 16:50:50,962 TADA INFO   test-id: 37c8c3003e014068bbcba176d739f6ae3aa084aceb159d552a56617d2bdb160c
2024-10-16 16:50:50,962 TADA INFO   test-suite: LDMSD
2024-10-16 16:50:50,962 TADA INFO   test-name: set_array_test
2024-10-16 16:50:50,962 TADA INFO   test-user: narate
2024-10-16 16:50:50,962 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:50:50,963 __main__ INFO -- Get or create the cluster --
2024-10-16 16:51:04,191 __main__ INFO -- Start daemons --
2024-10-16 16:51:13,253 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:51:40,538 TADA INFO assertion 1, 1st update got some callbacks: verified hunk of 5 snapshots, passed
2024-10-16 16:51:40,538 TADA INFO assertion 2, 2nd update got N callbacks: verified hunk of 5 snapshots, passed
2024-10-16 16:51:40,539 TADA INFO assertion 3, 3nd update got N callbacks: verified hunk of 5 snapshots, passed
2024-10-16 16:51:40,539 TADA INFO test set_array_test ended
2024-10-16 16:51:52 INFO: ----------------------------------------------
2024-10-16 16:51:54 INFO: ======== setgroup_test ========
2024-10-16 16:51:54 INFO: CMD: python3 setgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/setgroup_test
2024-10-16 16:51:54,898 TADA INFO starting test `setgroup_test`
2024-10-16 16:51:54,898 TADA INFO   test-id: a45b12685dd9cdf1695cddda808fb56fc166d0e3ecfb97b33cf3c0eedcfa4e13
2024-10-16 16:51:54,898 TADA INFO   test-suite: LDMSD
2024-10-16 16:51:54,899 TADA INFO   test-name: setgroup_test
2024-10-16 16:51:54,899 TADA INFO   test-user: narate
2024-10-16 16:51:54,899 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:51:54,900 __main__ INFO -- Get or create the cluster --
2024-10-16 16:52:14,215 __main__ INFO -- Start daemons --
2024-10-16 16:52:36,727 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:52:41,733 __main__ INFO -- ldms_ls to agg-2 --
2024-10-16 16:52:41,866 TADA INFO assertion 1, ldms_ls grp on agg-2: dir result verified, passed
2024-10-16 16:52:44,155 TADA INFO assertion 2, members on agg-2 are being updated: data verified, passed
2024-10-16 16:52:44,156 __main__ INFO -- Removing test_2 from grp --
2024-10-16 16:52:44,679 TADA INFO assertion 3, test_2 is removed fom grp on sampler: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2024-10-16 16:52:48,815 TADA INFO assertion 4, test_2 is removed from grp on agg-1: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2024-10-16 16:52:52,945 TADA INFO assertion 5, test_2 is removed from grp on agg-2: expect {'node-1/grp', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_1'}, passed
2024-10-16 16:52:56,949 __main__ INFO -- Adding test_2 back into grp --
2024-10-16 16:52:57,478 TADA INFO assertion 6, test_2 is added back to grp on sampler: expect {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, passed
2024-10-16 16:53:01,625 TADA INFO assertion 7, test_2 is added back to grp on agg-1: expect {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, passed
2024-10-16 16:53:03,757 TADA INFO assertion 8, test_2 is added back to grp on agg-2: expect {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, got {'node-1/grp', 'node-1/test_2', 'node-1/test_1'}, passed
2024-10-16 16:53:05,759 TADA INFO test setgroup_test ended
2024-10-16 16:53:19 INFO: ----------------------------------------------
2024-10-16 16:53:21 INFO: ======== slurm_stream_test ========
2024-10-16 16:53:21 INFO: CMD: python3 slurm_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/slurm_stream_test
2024-10-16 16:53:21,778 TADA INFO starting test `slurm_stream_test`
2024-10-16 16:53:21,778 TADA INFO   test-id: 802efeff5a4dd8dd4e94934c729f4be5b69daaf9ede75eb88b6674075c2d444b
2024-10-16 16:53:21,778 TADA INFO   test-suite: LDMSD
2024-10-16 16:53:21,778 TADA INFO   test-name: slurm_stream_test
2024-10-16 16:53:21,778 TADA INFO   test-user: narate
2024-10-16 16:53:21,778 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:53:21,779 __main__ INFO -- Get or create the cluster --
2024-10-16 16:53:36,759 __main__ INFO -- Start daemons --
2024-10-16 16:53:53,545 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:54:24,154 TADA INFO assertion 1, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:24,154 __main__ INFO 12345
2024-10-16 16:54:24,154 __main__ INFO 12345
2024-10-16 16:54:24,155 TADA INFO assertion 2, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,155 TADA INFO assertion 3, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2024-10-16 16:54:24,155 TADA INFO assertion 4, task_pid correctly represented: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,155 TADA INFO assertion 5, task_pid correctly represented: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,155 TADA INFO assertion 6, task_pid correctly represented: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,155 TADA INFO assertion 7, task_pid correctly represented: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,254 TADA INFO assertion 8, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:24,254 __main__ INFO 12345
2024-10-16 16:54:24,254 __main__ INFO 12345
2024-10-16 16:54:24,255 TADA INFO assertion 9, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,255 TADA INFO assertion 10, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2024-10-16 16:54:24,255 TADA INFO assertion 11, task_pid correctly represented: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,255 TADA INFO assertion 12, task_pid correctly represented: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,255 TADA INFO assertion 13, task_pid correctly represented: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,255 TADA INFO assertion 14, task_pid correctly represented: with mult jobs running for Job 12345, passed
2024-10-16 16:54:24,374 TADA INFO assertion 15, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:24,374 __main__ INFO 12346
2024-10-16 16:54:24,374 __main__ INFO 12346
2024-10-16 16:54:24,374 TADA INFO assertion 16, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,374 TADA INFO assertion 17, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2024-10-16 16:54:24,374 TADA INFO assertion 18, task_pid correctly represented: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,375 TADA INFO assertion 19, task_pid correctly represented: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,375 TADA INFO assertion 20, task_pid correctly represented: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,375 TADA INFO assertion 21, task_pid correctly represented: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,489 TADA INFO assertion 22, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:24,489 __main__ INFO 12346
2024-10-16 16:54:24,489 __main__ INFO 12346
2024-10-16 16:54:24,489 TADA INFO assertion 23, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,489 TADA INFO assertion 24, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2024-10-16 16:54:24,490 TADA INFO assertion 25, task_pid correctly represented: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,490 TADA INFO assertion 26, task_pid correctly represented: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,490 TADA INFO assertion 27, task_pid correctly represented: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,490 TADA INFO assertion 28, task_pid correctly represented: with mult jobs running for Job 12346, passed
2024-10-16 16:54:24,600 TADA INFO assertion 29, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:24,600 __main__ INFO 12347
2024-10-16 16:54:24,601 __main__ INFO 12347
2024-10-16 16:54:24,601 TADA INFO assertion 30, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,601 TADA INFO assertion 31, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2024-10-16 16:54:24,601 TADA INFO assertion 32, task_pid correctly represented: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,601 TADA INFO assertion 33, task_pid correctly represented: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,602 TADA INFO assertion 34, task_pid correctly represented: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,602 TADA INFO assertion 35, task_pid correctly represented: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,697 TADA INFO assertion 36, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:24,698 __main__ INFO 12347
2024-10-16 16:54:24,698 __main__ INFO 12347
2024-10-16 16:54:24,698 TADA INFO assertion 37, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,698 TADA INFO assertion 38, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2024-10-16 16:54:24,698 TADA INFO assertion 39, task_pid correctly represented: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,698 TADA INFO assertion 40, task_pid correctly represented: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,698 TADA INFO assertion 41, task_pid correctly represented: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,699 TADA INFO assertion 42, task_pid correctly represented: with mult jobs running for Job 12347, passed
2024-10-16 16:54:24,814 TADA INFO assertion 43, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:24,814 __main__ INFO 12348
2024-10-16 16:54:24,814 __main__ INFO 12348
2024-10-16 16:54:24,814 TADA INFO assertion 44, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,814 TADA INFO assertion 45, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2024-10-16 16:54:24,814 TADA INFO assertion 46, task_pid correctly represented: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,815 TADA INFO assertion 47, task_pid correctly represented: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,815 TADA INFO assertion 48, task_pid correctly represented: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,815 TADA INFO assertion 49, task_pid correctly represented: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,934 TADA INFO assertion 50, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:24,935 __main__ INFO 12348
2024-10-16 16:54:24,935 __main__ INFO 12348
2024-10-16 16:54:24,935 TADA INFO assertion 51, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,935 TADA INFO assertion 52, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2024-10-16 16:54:24,935 TADA INFO assertion 53, task_pid correctly represented: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,935 TADA INFO assertion 54, task_pid correctly represented: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,936 TADA INFO assertion 55, task_pid correctly represented: with mult jobs running for Job 12348, passed
2024-10-16 16:54:24,936 TADA INFO assertion 56, task_pid correctly represented: with mult jobs running for Job 12348, passed
2024-10-16 16:54:25,034 TADA INFO assertion 57, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:25,034 __main__ INFO 12355
2024-10-16 16:54:25,034 __main__ INFO 12355
2024-10-16 16:54:25,035 TADA INFO assertion 58, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,035 TADA INFO assertion 59, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2024-10-16 16:54:25,035 TADA INFO assertion 60, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,035 TADA INFO assertion 61, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,035 TADA INFO assertion 62, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,035 TADA INFO assertion 63, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,035 TADA INFO assertion 64, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,036 TADA INFO assertion 65, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,036 TADA INFO assertion 66, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,036 TADA INFO assertion 67, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,146 TADA INFO assertion 68, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:25,147 __main__ INFO 12355
2024-10-16 16:54:25,147 __main__ INFO 12355
2024-10-16 16:54:25,147 TADA INFO assertion 69, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,147 TADA INFO assertion 70, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2024-10-16 16:54:25,147 TADA INFO assertion 71, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,147 TADA INFO assertion 72, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,147 TADA INFO assertion 73, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,147 TADA INFO assertion 74, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,148 TADA INFO assertion 75, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,148 TADA INFO assertion 76, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,148 TADA INFO assertion 77, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,148 TADA INFO assertion 78, task_pid correctly represented: with mult jobs running for Job 12355, passed
2024-10-16 16:54:25,254 TADA INFO assertion 79, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:25,254 __main__ INFO 12356
2024-10-16 16:54:25,254 __main__ INFO 12356
2024-10-16 16:54:25,254 TADA INFO assertion 80, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,254 TADA INFO assertion 81, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2024-10-16 16:54:25,255 TADA INFO assertion 82, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,255 TADA INFO assertion 83, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,255 TADA INFO assertion 84, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,255 TADA INFO assertion 85, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,255 TADA INFO assertion 86, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,255 TADA INFO assertion 87, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,256 TADA INFO assertion 88, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,256 TADA INFO assertion 89, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,372 TADA INFO assertion 90, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:25,372 __main__ INFO 12356
2024-10-16 16:54:25,372 __main__ INFO 12356
2024-10-16 16:54:25,372 TADA INFO assertion 91, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,372 TADA INFO assertion 92, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2024-10-16 16:54:25,372 TADA INFO assertion 93, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,373 TADA INFO assertion 94, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,373 TADA INFO assertion 95, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,373 TADA INFO assertion 96, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,373 TADA INFO assertion 97, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,373 TADA INFO assertion 98, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,373 TADA INFO assertion 99, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,373 TADA INFO assertion 100, task_pid correctly represented: with mult jobs running for Job 12356, passed
2024-10-16 16:54:25,486 TADA INFO assertion 101, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:25,486 __main__ INFO 12357
2024-10-16 16:54:25,486 __main__ INFO 12357
2024-10-16 16:54:25,487 TADA INFO assertion 102, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,487 TADA INFO assertion 103, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2024-10-16 16:54:25,487 TADA INFO assertion 104, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,487 TADA INFO assertion 105, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,487 TADA INFO assertion 106, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,487 TADA INFO assertion 107, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,487 TADA INFO assertion 108, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,488 TADA INFO assertion 109, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,488 TADA INFO assertion 110, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,488 TADA INFO assertion 111, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,616 TADA INFO assertion 112, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:25,616 __main__ INFO 12357
2024-10-16 16:54:25,617 __main__ INFO 12357
2024-10-16 16:54:25,617 TADA INFO assertion 113, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,617 TADA INFO assertion 114, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2024-10-16 16:54:25,617 TADA INFO assertion 115, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,617 TADA INFO assertion 116, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,617 TADA INFO assertion 117, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,617 TADA INFO assertion 118, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,618 TADA INFO assertion 119, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,618 TADA INFO assertion 120, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,618 TADA INFO assertion 121, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,618 TADA INFO assertion 122, task_pid correctly represented: with mult jobs running for Job 12357, passed
2024-10-16 16:54:25,734 TADA INFO assertion 123, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:25,734 __main__ INFO 12358
2024-10-16 16:54:25,734 __main__ INFO 12358
2024-10-16 16:54:25,734 TADA INFO assertion 124, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,735 TADA INFO assertion 125, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2024-10-16 16:54:25,735 TADA INFO assertion 126, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,735 TADA INFO assertion 127, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,735 TADA INFO assertion 128, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,735 TADA INFO assertion 129, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,735 TADA INFO assertion 130, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,736 TADA INFO assertion 131, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,736 TADA INFO assertion 132, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,736 TADA INFO assertion 133, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,847 TADA INFO assertion 134, Job properly assigned to correct slot: correct job_id fills next slot, passed
2024-10-16 16:54:25,848 __main__ INFO 12358
2024-10-16 16:54:25,848 __main__ INFO 12358
2024-10-16 16:54:25,848 TADA INFO assertion 135, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,848 TADA INFO assertion 136, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2024-10-16 16:54:25,848 TADA INFO assertion 137, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,848 TADA INFO assertion 138, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,848 TADA INFO assertion 139, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,849 TADA INFO assertion 140, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,849 TADA INFO assertion 141, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,849 TADA INFO assertion 142, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,849 TADA INFO assertion 143, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:25,849 TADA INFO assertion 144, task_pid correctly represented: with mult jobs running for Job 12358, passed
2024-10-16 16:54:27,953 TADA INFO assertion 145, new job correctly replaces oldest slot: correct job_id fills next slot, passed
2024-10-16 16:54:27,953 __main__ INFO 12353
2024-10-16 16:54:27,954 __main__ INFO 12353
2024-10-16 16:54:27,954 TADA INFO assertion 146, new job_start correctly represented in metric set: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,954 TADA INFO assertion 147, new job_end correctly represented in metric set: with mutl jobs running, for Job 12353, passed
2024-10-16 16:54:27,954 TADA INFO assertion 148, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,954 TADA INFO assertion 149, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,954 TADA INFO assertion 150, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,954 TADA INFO assertion 151, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,955 TADA INFO assertion 152, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,955 TADA INFO assertion 153, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,955 TADA INFO assertion 154, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,955 TADA INFO assertion 155, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2024-10-16 16:54:27,955 __main__ INFO -- Test Finished --
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
2024-10-16 16:54:27,956 TADA INFO test slurm_stream_test ended
2024-10-16 16:54:39 INFO: ----------------------------------------------
2024-10-16 16:54:41 INFO: ======== spank_notifier_test ========
2024-10-16 16:54:41 INFO: CMD: python3 spank_notifier_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/spank_notifier_test
2024-10-16 16:54:42,228 TADA INFO starting test `spank_notifier_test`
2024-10-16 16:54:42,228 TADA INFO   test-id: ac18c54b325e3edbef45b8076c25ed81bcfc336b04c4f60f1e10f9e77a33c0cc
2024-10-16 16:54:42,229 TADA INFO   test-suite: Slurm_Plugins
2024-10-16 16:54:42,229 TADA INFO   test-name: spank_notifier_test
2024-10-16 16:54:42,229 TADA INFO   test-user: narate
2024-10-16 16:54:42,229 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:54:42,229 __main__ INFO -- Create the cluster --
2024-10-16 16:55:23,057 __main__ INFO -- Cleanup output --
2024-10-16 16:55:23,400 __main__ INFO -- Test bad plugstack config --
2024-10-16 16:55:23,400 __main__ INFO Starting slurm ...
2024-10-16 16:55:37,633 __main__ INFO Starting slurm ... OK
2024-10-16 16:55:58,119 __main__ INFO -- Submitting job with num_tasks 4 --
2024-10-16 16:55:58,228 __main__ INFO   jobid = 1
2024-10-16 16:55:58,435 __main__ INFO -- Submitting job with num_tasks 4 --
2024-10-16 16:55:58,544 __main__ INFO   jobid = 2
2024-10-16 16:55:58,759 __main__ INFO -- Submitting job with num_tasks 4 --
2024-10-16 16:55:58,873 __main__ INFO   jobid = 3
2024-10-16 16:55:59,101 __main__ INFO -- Submitting job with num_tasks 4 --
2024-10-16 16:55:59,236 __main__ INFO   jobid = 4
2024-10-16 16:56:08,944 TADA INFO assertion 60, Bad config does not affect jobs: jobs verified, passed
2024-10-16 16:56:08,944 __main__ INFO Killin slurm ...
2024-10-16 16:56:11,880 __main__ INFO Killin slurm ... OK
2024-10-16 16:56:31,880 __main__ INFO -- Start daemons --
2024-10-16 16:56:42,304 __main__ INFO Starting slurm ... OK
2024-10-16 16:57:02,556 __main__ INFO -- Submitting job with no stream listener --
2024-10-16 16:57:02,805 __main__ INFO -- Submitting job with num_tasks 8 --
2024-10-16 16:57:02,920 __main__ INFO   jobid = 5
2024-10-16 16:57:18,931 TADA INFO assertion 0, Missing stream listener on node-1 does not affect job execution: job output file created, passed
2024-10-16 16:57:18,932 TADA INFO assertion 1, Missing stream listener on node-2 does not affect job execution: job output file created, passed
2024-10-16 16:57:24,882 __main__ INFO -- Submitting job with listener --
2024-10-16 16:57:25,087 __main__ INFO -- Submitting job with num_tasks 1 --
2024-10-16 16:57:25,202 __main__ INFO   jobid = 6
2024-10-16 16:57:25,406 __main__ INFO -- Submitting job with num_tasks 2 --
2024-10-16 16:57:25,528 __main__ INFO   jobid = 7
2024-10-16 16:57:25,725 __main__ INFO -- Submitting job with num_tasks 4 --
2024-10-16 16:57:25,843 __main__ INFO   jobid = 8
2024-10-16 16:57:26,082 __main__ INFO -- Submitting job with num_tasks 8 --
2024-10-16 16:57:26,212 __main__ INFO   jobid = 9
2024-10-16 16:57:26,424 __main__ INFO -- Submitting job with num_tasks 27 --
2024-10-16 16:57:26,540 __main__ INFO   jobid = 10
2024-10-16 16:57:48,399 __main__ INFO -- Verifying Events --
2024-10-16 16:57:48,399 TADA INFO assertion 2, 1-task job: first event is 'init': `init` verified, passed
2024-10-16 16:57:48,399 TADA INFO assertion 3, 1-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2024-10-16 16:57:48,399 TADA INFO assertion 4, 1-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2024-10-16 16:57:48,399 TADA INFO assertion 5, 1-task job: third event is 'task_exit': `task_exit` verified, passed
2024-10-16 16:57:48,400 TADA INFO assertion 6, 1-task job: fourth event is 'exit': `exit` verified, passed
2024-10-16 16:57:48,400 TADA INFO assertion 7, 2-task job: first event is 'init': `init` verified, passed
2024-10-16 16:57:48,400 TADA INFO assertion 8, 2-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2024-10-16 16:57:48,400 TADA INFO assertion 9, 2-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2024-10-16 16:57:48,400 TADA INFO assertion 10, 2-task job: third event is 'task_exit': `task_exit` verified, passed
2024-10-16 16:57:48,401 TADA INFO assertion 11, 2-task job: fourth event is 'exit': `exit` verified, passed
2024-10-16 16:57:48,401 TADA INFO assertion 12, 4-task job: first event is 'init': `init` verified, passed
2024-10-16 16:57:48,401 TADA INFO assertion 13, 4-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2024-10-16 16:57:48,401 TADA INFO assertion 14, 4-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2024-10-16 16:57:48,401 TADA INFO assertion 15, 4-task job: third event is 'task_exit': `task_exit` verified, passed
2024-10-16 16:57:48,401 TADA INFO assertion 16, 4-task job: fourth event is 'exit': `exit` verified, passed
2024-10-16 16:57:48,402 TADA INFO assertion 17, 8-task job: first event is 'init': `init` verified, passed
2024-10-16 16:57:48,402 TADA INFO assertion 18, 8-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2024-10-16 16:57:48,402 TADA INFO assertion 19, 8-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2024-10-16 16:57:48,402 TADA INFO assertion 20, 8-task job: third event is 'task_exit': `task_exit` verified, passed
2024-10-16 16:57:48,402 TADA INFO assertion 21, 8-task job: fourth event is 'exit': `exit` verified, passed
2024-10-16 16:57:48,403 TADA INFO assertion 22, 27-task job: first event is 'init': step_init == init, failed
Traceback (most recent call last):
  File "spank_notifier_test", line 492, in <module>
    verify_jobinfo(cluster, test, node_events, jobinfo)
  File "spank_notifier_test", line 154, in verify_jobinfo
    test.assert_test(assert_no, False, '{0} == {1}'.format(ev['event'], 'init'))
  File "/home/narate/cron/ldms-test/TADA.py", line 157, in assert_test
    raise AssertionException(self.test_desc + ", " + cond_str + ": FAILED")
TADA.AssertionException: The test to verify ldmsd-stream SPANK notifier., step_init == init: FAILED
2024-10-16 16:57:48,404 TADA INFO assertion 23, 27-task job: 'step_init' event contains subscriber data: skipped
2024-10-16 16:57:48,404 TADA INFO assertion 24, 27-task job: second event is 'task_init_priv': skipped
2024-10-16 16:57:48,404 TADA INFO assertion 25, 27-task job: third event is 'task_exit': skipped
2024-10-16 16:57:48,404 TADA INFO assertion 26, 27-task job: fourth event is 'exit': skipped
2024-10-16 16:57:48,404 TADA INFO assertion 50, Multi-tenant verification: skipped
2024-10-16 16:57:48,405 TADA INFO assertion 51, Killing stream listener does not affect job execution on node-1: skipped
2024-10-16 16:57:48,405 TADA INFO assertion 52, Killing stream listener does not affect job execution on node-2: skipped
2024-10-16 16:57:48,405 TADA INFO test spank_notifier_test ended
2024-10-16 16:58:05 INFO: ----------------------------------------------
2024-10-16 16:58:07 INFO: ======== ldms_list_test ========
2024-10-16 16:58:07 INFO: CMD: python3 ldms_list_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_list_test
2024-10-16 16:58:08,177 TADA INFO starting test `ldms_list_test`
2024-10-16 16:58:08,177 TADA INFO   test-id: c07d6e7216b3620f7ecbde75092c9bf13028fa894c093be080d517d26450fc2d
2024-10-16 16:58:08,177 TADA INFO   test-suite: LDMSD
2024-10-16 16:58:08,177 TADA INFO   test-name: ldms_list_test
2024-10-16 16:58:08,177 TADA INFO   test-user: narate
2024-10-16 16:58:08,177 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 16:58:08,178 __main__ INFO -- Get or create the cluster --
2024-10-16 16:58:18,360 __main__ INFO -- Start daemons --
2024-10-16 16:58:26,712 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 16:58:28,714 __main__ INFO start list_samp.py and list_agg.py interactive sessions
2024-10-16 16:58:34,752 TADA INFO assertion 1, check list_sampler on list_agg.py: OK, passed
2024-10-16 16:58:34,753 TADA INFO assertion 2, (1st update) check set1 on list_samp.py: OK, passed
2024-10-16 16:58:34,753 TADA INFO assertion 3, (1st update) check set3_p on list_samp.py: OK, passed
2024-10-16 16:58:34,753 TADA INFO assertion 4, (1st update)check set3_c on list_samp.py: OK, passed
2024-10-16 16:58:34,754 TADA INFO assertion 5, (1st update)check set1 on list_agg.py: OK, passed
2024-10-16 16:58:34,754 TADA INFO assertion 6, (1st update)check set3_p on list_agg.py: OK, passed
2024-10-16 16:58:34,754 TADA INFO assertion 7, (1st update)check set3_c on list_agg.py: OK, passed
2024-10-16 16:58:34,754 __main__ INFO 2nd sampling on the sampler...
2024-10-16 16:58:41,964 TADA INFO assertion 8, (2nd update) check set1 on list_samp.py: OK, passed
2024-10-16 16:58:41,964 TADA INFO assertion 9, (2nd update) check set3_p on list_samp.py: OK, passed
2024-10-16 16:58:41,964 TADA INFO assertion 10, (2nd update) check set3_c on list_samp.py: OK, passed
2024-10-16 16:58:41,964 __main__ INFO 2nd update on the aggregator...
2024-10-16 16:58:49,174 TADA INFO assertion 11, (2nd update) check set1 on list_agg.py: OK, passed
2024-10-16 16:58:49,174 TADA INFO assertion 12, (2nd update) check set3_p on list_agg.py: OK, passed
2024-10-16 16:58:49,174 TADA INFO assertion 13, (2nd update) check set3_c on list_agg.py: OK, passed
2024-10-16 16:58:49,175 __main__ INFO 3rd sampling on the sampler...
2024-10-16 16:58:56,384 TADA INFO assertion 14, (3rd update) check set1 on list_samp.py: OK, passed
2024-10-16 16:58:56,384 TADA INFO assertion 15, (3rd update) check set3_p on list_samp.py: OK, passed
2024-10-16 16:58:56,384 TADA INFO assertion 16, (3rd update) check set3_c on list_samp.py: OK, passed
2024-10-16 16:58:56,385 __main__ INFO 3rd update on the aggregator...
2024-10-16 16:59:03,594 TADA INFO assertion 17, (3rd update) check set1 on list_agg.py: OK, passed
2024-10-16 16:59:03,594 TADA INFO assertion 18, (3rd update) check set3_p on list_agg.py: OK, passed
2024-10-16 16:59:03,594 TADA INFO assertion 19, (3rd update) check set3_c on list_agg.py: OK, passed
2024-10-16 16:59:03,595 __main__ INFO 4th sampling on the sampler...
2024-10-16 16:59:10,804 TADA INFO assertion 20, (4th update; list uncahnged) check set1 on list_samp.py: OK, passed
2024-10-16 16:59:10,804 TADA INFO assertion 21, (4th update; list uncahnged) check set3_p on list_samp.py: OK, passed
2024-10-16 16:59:10,804 TADA INFO assertion 22, (4th update; list uncahnged) check set3_c on list_samp.py: OK, passed
2024-10-16 16:59:10,805 __main__ INFO 4th update on the aggregator...
2024-10-16 16:59:18,014 TADA INFO assertion 23, (4th update; list uncahnged) check set1 on list_agg.py: OK, passed
2024-10-16 16:59:18,014 TADA INFO assertion 24, (4th update; list uncahnged) check set3_p on list_agg.py: OK, passed
2024-10-16 16:59:18,015 TADA INFO assertion 25, (4th update; list uncahnged) check set3_c on list_agg.py: OK, passed
2024-10-16 16:59:18,015 __main__ INFO 5th sampling on the sampler...
2024-10-16 16:59:25,224 TADA INFO assertion 26, (5th update; list del) check set1 on list_samp.py: OK, passed
2024-10-16 16:59:25,224 TADA INFO assertion 27, (5th update; list del) check set3_p on list_samp.py: OK, passed
2024-10-16 16:59:25,225 TADA INFO assertion 28, (5th update; list del) check set3_c on list_samp.py: OK, passed
2024-10-16 16:59:25,225 __main__ INFO 5th update on the aggregator...
2024-10-16 16:59:32,434 TADA INFO assertion 29, (5th update; list del) check set1 on list_agg.py: OK, passed
2024-10-16 16:59:32,434 TADA INFO assertion 30, (5th update; list del) check set3_p on list_agg.py: OK, passed
2024-10-16 16:59:32,435 TADA INFO assertion 31, (5th update; list del) check set3_c on list_agg.py: OK, passed
2024-10-16 16:59:32,435 __main__ INFO 6th sampling on the sampler...
2024-10-16 16:59:39,644 TADA INFO assertion 32, (6th update; list unchanged) check set1 on list_samp.py: OK, passed
2024-10-16 16:59:39,644 TADA INFO assertion 33, (6th update; list unchanged) check set3_p on list_samp.py: OK, passed
2024-10-16 16:59:39,645 TADA INFO assertion 34, (6th update; list unchanged) check set3_c on list_samp.py: OK, passed
2024-10-16 16:59:39,645 __main__ INFO 6th update on the updator...
2024-10-16 16:59:46,854 TADA INFO assertion 35, (6th update; list unchanged) check set1 on list_agg.py: OK, passed
2024-10-16 16:59:46,854 TADA INFO assertion 36, (6th update; list unchanged) check set3_p on list_agg.py: OK, passed
2024-10-16 16:59:46,855 TADA INFO assertion 37, (6th update; list unchanged) check set3_c on list_agg.py: OK, passed
2024-10-16 16:59:46,855 TADA INFO test ldms_list_test ended
2024-10-16 16:59:57 INFO: ----------------------------------------------
2024-10-16 16:59:59 INFO: ======== quick_set_add_rm_test ========
2024-10-16 16:59:59 INFO: CMD: python3 quick_set_add_rm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/quick_set_add_rm_test
2024-10-16 17:00:00,560 TADA INFO starting test `quick_set_add_rm_test`
2024-10-16 17:00:00,560 TADA INFO   test-id: 730043c8c624620169385a01cb9b7c854573eb5b0c9def4c5598d23efdc3162d
2024-10-16 17:00:00,560 TADA INFO   test-suite: LDMSD
2024-10-16 17:00:00,560 TADA INFO   test-name: quick_set_add_rm_test
2024-10-16 17:00:00,560 TADA INFO   test-user: narate
2024-10-16 17:00:00,560 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:00:00,561 __main__ INFO -- Get or create the cluster --
2024-10-16 17:00:16,992 __main__ INFO -- Start samp.py --
2024-10-16 17:00:22,109 TADA INFO assertion 1, start samp.py: prompt checked, passed
2024-10-16 17:00:22,109 __main__ INFO -- Start daemons --
2024-10-16 17:00:31,846 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:00:37,472 TADA INFO assertion 2, verify data: verified, passed
2024-10-16 17:00:42,141 TADA INFO assertion 3, samp.py adds set1 / verify data: verified, passed
2024-10-16 17:00:46,754 TADA INFO assertion 4, samp.py removes set1 / verify data: verified, passed
2024-10-16 17:00:51,395 TADA INFO assertion 5, samp.py quickly adds and removes set2 / verify data: verified, passed
2024-10-16 17:00:56,512 TADA INFO assertion 6, agg-1 log stays empty: verified, passed
2024-10-16 17:00:56,513 TADA INFO test quick_set_add_rm_test ended
2024-10-16 17:01:08 INFO: ----------------------------------------------
2024-10-16 17:01:10 INFO: ======== set_array_hang_test ========
2024-10-16 17:01:10 INFO: CMD: python3 set_array_hang_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/set_array_hang_test
2024-10-16 17:01:11,549 TADA INFO starting test `set_array_hang_test`
2024-10-16 17:01:11,549 TADA INFO   test-id: 15bf40a28981bc8265c6a78b661524d3b77f931c32fdb87d8d76797449602e51
2024-10-16 17:01:11,549 TADA INFO   test-suite: LDMSD
2024-10-16 17:01:11,549 TADA INFO   test-name: set_array_hang_test
2024-10-16 17:01:11,549 TADA INFO   test-user: narate
2024-10-16 17:01:11,550 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:01:11,550 __main__ INFO -- Get or create the cluster --
2024-10-16 17:01:21,699 __main__ INFO -- Start processes --
2024-10-16 17:01:21,700 __main__ INFO starting interactive set_array_samp.py
2024-10-16 17:01:24,717 TADA INFO assertion 1, start set_array_samp.py: data verified, passed
2024-10-16 17:01:27,736 TADA INFO assertion 2, start set_array_agg.py: data verified, passed
2024-10-16 17:01:34,945 TADA INFO assertion 3, agg update before the 1st sample: data verified, passed
2024-10-16 17:01:42,154 TADA INFO assertion 4, sampling 2 times then agg update: data verified, passed
2024-10-16 17:01:45,759 TADA INFO assertion 5, agg update w/o new sampling: data verified, passed
2024-10-16 17:01:52,969 TADA INFO assertion 6, sampling 5 times then agg update: data verified, passed
2024-10-16 17:01:52,970 TADA INFO test set_array_hang_test ended
2024-10-16 17:02:03 INFO: ----------------------------------------------
2024-10-16 17:02:06 INFO: ======== ldmsd_autointerval_test ========
2024-10-16 17:02:06 INFO: CMD: python3 ldmsd_autointerval_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_autointerval_test
2024-10-16 17:02:06,757 TADA INFO starting test `ldmsd_autointerval_test`
2024-10-16 17:02:06,757 TADA INFO   test-id: 1578ac9ff556dc5a40e91042ceda0605de45af53316dbda9ca075ba1073c4af7
2024-10-16 17:02:06,757 TADA INFO   test-suite: LDMSD
2024-10-16 17:02:06,757 TADA INFO   test-name: ldmsd_autointerval_test
2024-10-16 17:02:06,758 TADA INFO   test-user: narate
2024-10-16 17:02:06,758 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:02:06,758 __main__ INFO -- Get or create the cluster --
2024-10-16 17:02:23,134 __main__ INFO -- Start daemons --
2024-10-16 17:02:44,924 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:02:51,446 TADA INFO assertion 1, start all daemons and interactive controller: OK, passed
2024-10-16 17:02:53,685 TADA INFO assertion 2, verify sampling interval and update hints: verified, passed
2024-10-16 17:02:53,685 __main__ INFO Let them run for a while to collect data ...
2024-10-16 17:03:03,690 __main__ INFO Setting sample interval to 1000000 ...
2024-10-16 17:03:11,936 TADA INFO assertion 3, set and verify 2nd sampling interval / update hints: verified, passed
2024-10-16 17:03:11,936 __main__ INFO Let them run for a while to collect data ...
2024-10-16 17:03:21,942 __main__ INFO Setting sample interval to 2000000 ...
2024-10-16 17:03:30,197 TADA INFO assertion 4, set and verify 3rd sampling interval / update hints: verified, passed
2024-10-16 17:03:30,197 __main__ INFO Let them run for a while to collect data ...
2024-10-16 17:03:40,424 TADA INFO assertion 5, verify SOS data: timestamp differences in SOS show all 3 intervals, passed
2024-10-16 17:03:40,530 TADA INFO assertion 6, verify 'oversampled' in the agg2 log: OK, passed
2024-10-16 17:03:40,531 TADA INFO test ldmsd_autointerval_test ended
2024-10-16 17:03:53 INFO: ----------------------------------------------
2024-10-16 17:03:55 INFO: ======== ldms_record_test ========
2024-10-16 17:03:55 INFO: CMD: python3 ldms_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_record_test
2024-10-16 17:03:55,844 TADA INFO starting test `ldms_record_test`
2024-10-16 17:03:55,845 TADA INFO   test-id: 676610628316a1ff2cb635624bfb68933dce747f1c0a6ac19c61da67c7f77403
2024-10-16 17:03:55,845 TADA INFO   test-suite: LDMSD
2024-10-16 17:03:55,845 TADA INFO   test-name: ldms_record_test
2024-10-16 17:03:55,845 TADA INFO   test-user: narate
2024-10-16 17:03:55,845 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:03:55,846 __main__ INFO -- Get or create the cluster --
2024-10-16 17:04:05,992 __main__ INFO -- Start daemons --
2024-10-16 17:04:14,330 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:04:16,332 __main__ INFO start record_samp.py and record_agg.py interactive sessions
2024-10-16 17:04:22,369 TADA INFO assertion 1, check record_sampler on record_agg.py: OK, passed
2024-10-16 17:04:22,369 TADA INFO assertion 2, (1st update) check set1 on record_samp.py: OK, passed
2024-10-16 17:04:22,369 TADA INFO assertion 3, (1st update) check set3_p on record_samp.py: OK, passed
2024-10-16 17:04:22,370 TADA INFO assertion 4, (1st update) check set3_c on record_samp.py: OK, passed
2024-10-16 17:04:22,370 TADA INFO assertion 5, (1st update) check set1 on record_agg.py: OK, passed
2024-10-16 17:04:22,370 TADA INFO assertion 6, (1st update) check set3_p on record_agg.py: OK, passed
2024-10-16 17:04:22,371 TADA INFO assertion 7, (1st update) check set3_c on record_agg.py: OK, passed
2024-10-16 17:04:22,371 __main__ INFO 2nd sampling on the sampler...
2024-10-16 17:04:29,580 TADA INFO assertion 8, (2nd update) check set1 on record_samp.py: OK, passed
2024-10-16 17:04:29,580 TADA INFO assertion 9, (2nd update) check set3_p on record_samp.py: OK, passed
2024-10-16 17:04:29,581 TADA INFO assertion 10, (2nd update) check set3_c on record_samp.py: OK, passed
2024-10-16 17:04:29,581 __main__ INFO 2nd update on the aggregator...
2024-10-16 17:04:36,790 TADA INFO assertion 11, (2nd update) check set1 on record_agg.py: OK, passed
2024-10-16 17:04:36,790 TADA INFO assertion 12, (2nd update) check set3_p on record_agg.py: OK, passed
2024-10-16 17:04:36,791 TADA INFO assertion 13, (2nd update) check set3_c on record_agg.py: OK, passed
2024-10-16 17:04:36,791 __main__ INFO 3rd sampling on the sampler...
2024-10-16 17:04:44,000 TADA INFO assertion 14, (3rd update) check set1 on record_samp.py: OK, passed
2024-10-16 17:04:44,000 TADA INFO assertion 15, (3rd update) check set3_p on record_samp.py: OK, passed
2024-10-16 17:04:44,001 TADA INFO assertion 16, (3rd update) check set3_c on record_samp.py: OK, passed
2024-10-16 17:04:44,001 __main__ INFO 3rd update on the aggregator...
2024-10-16 17:04:51,210 TADA INFO assertion 17, (3rd update) check set1 on record_agg.py: OK, passed
2024-10-16 17:04:51,210 TADA INFO assertion 18, (3rd update) check set3_p on record_agg.py: OK, passed
2024-10-16 17:04:51,211 TADA INFO assertion 19, (3rd update) check set3_c on record_agg.py: OK, passed
2024-10-16 17:04:51,211 __main__ INFO 4th sampling on the sampler...
2024-10-16 17:04:58,420 TADA INFO assertion 20, (4th update; record uncahnged) check set1 on record_samp.py: OK, passed
2024-10-16 17:04:58,420 TADA INFO assertion 21, (4th update; record uncahnged) check set3_p on record_samp.py: OK, passed
2024-10-16 17:04:58,420 TADA INFO assertion 22, (4th update; record uncahnged) check set3_c on record_samp.py: OK, passed
2024-10-16 17:04:58,421 __main__ INFO 4th update on the aggregator...
2024-10-16 17:05:05,630 TADA INFO assertion 23, (4th update; record uncahnged) check set1 on record_agg.py: OK, passed
2024-10-16 17:05:05,630 TADA INFO assertion 24, (4th update; record uncahnged) check set3_p on record_agg.py: OK, passed
2024-10-16 17:05:05,630 TADA INFO assertion 25, (4th update; record uncahnged) check set3_c on record_agg.py: OK, passed
2024-10-16 17:05:05,631 __main__ INFO 5th sampling on the sampler...
2024-10-16 17:05:12,840 TADA INFO assertion 26, (5th update; record del) check set1 on record_samp.py: OK, passed
2024-10-16 17:05:12,840 TADA INFO assertion 27, (5th update; record del) check set3_p on record_samp.py: OK, passed
2024-10-16 17:05:12,841 TADA INFO assertion 28, (5th update; record del) check set3_c on record_samp.py: OK, passed
2024-10-16 17:05:12,841 __main__ INFO 5th update on the aggregator...
2024-10-16 17:05:20,050 TADA INFO assertion 29, (5th update; record del) check set1 on record_agg.py: OK, passed
2024-10-16 17:05:20,050 TADA INFO assertion 30, (5th update; record del) check set3_p on record_agg.py: OK, passed
2024-10-16 17:05:20,051 TADA INFO assertion 31, (5th update; record del) check set3_c on record_agg.py: OK, passed
2024-10-16 17:05:20,051 __main__ INFO 6th sampling on the sampler...
2024-10-16 17:05:27,260 TADA INFO assertion 32, (6th update; record unchanged) check set1 on record_samp.py: OK, passed
2024-10-16 17:05:27,260 TADA INFO assertion 33, (6th update; record unchanged) check set3_p on record_samp.py: OK, passed
2024-10-16 17:05:27,260 TADA INFO assertion 34, (6th update; record unchanged) check set3_c on record_samp.py: OK, passed
2024-10-16 17:05:27,261 __main__ INFO 6th update on the updator...
2024-10-16 17:05:34,470 TADA INFO assertion 35, (6th update; record unchanged) check set1 on record_agg.py: OK, passed
2024-10-16 17:05:34,470 TADA INFO assertion 36, (6th update; record unchanged) check set3_p on record_agg.py: OK, passed
2024-10-16 17:05:34,471 TADA INFO assertion 37, (6th update; record unchanged) check set3_c on record_agg.py: OK, passed
2024-10-16 17:05:34,471 TADA INFO test ldms_record_test ended
2024-10-16 17:05:45 INFO: ----------------------------------------------
2024-10-16 17:05:47 INFO: ======== ldms_schema_digest_test ========
2024-10-16 17:05:47 INFO: CMD: python3 ldms_schema_digest_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_schema_digest_test
2024-10-16 17:05:48,169 TADA INFO starting test `ldms_schema_digest_test`
2024-10-16 17:05:48,169 TADA INFO   test-id: 3de923a4d0583977b26ad92a18c3dcd4ae29bba9279c1a2279cd0aeddedec671
2024-10-16 17:05:48,170 TADA INFO   test-suite: LDMSD
2024-10-16 17:05:48,170 TADA INFO   test-name: ldms_schema_digest_test
2024-10-16 17:05:48,170 TADA INFO   test-user: narate
2024-10-16 17:05:48,170 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:05:48,170 __main__ INFO -- Get or create the cluster --
2024-10-16 17:06:04,546 __main__ INFO -- Start daemons --
2024-10-16 17:06:21,814 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:06:26,935 TADA INFO assertion 1, No schema digest from ldms_ls -v sampler: verified, passed
2024-10-16 17:06:27,039 TADA INFO assertion 2, Schema digest from ldms_ls -vv sampler is not empty: verified, passed
2024-10-16 17:06:27,177 TADA INFO assertion 3, Schema digest from ldms_ls -vv agg-1 is not empty: verified, passed
2024-10-16 17:06:27,371 TADA INFO assertion 4, Schema digest from Python ldms dir agg-1 is not empty: verified, passed
2024-10-16 17:06:27,371 TADA INFO assertion 5, Schema digest from Python ldms lokoup agg-1 is not empty: verified, passed
2024-10-16 17:06:27,371 TADA INFO assertion 6, All digests of the same set are the same: , passed
2024-10-16 17:06:29,822 TADA INFO assertion 7, Sets of same schema yield the same digest: check, passed
2024-10-16 17:06:29,822 TADA INFO assertion 8, Different schema (1-off metric) yield different digest: check, passed
2024-10-16 17:06:29,822 TADA INFO test ldms_schema_digest_test ended
2024-10-16 17:06:42 INFO: ----------------------------------------------
2024-10-16 17:06:44 INFO: ======== ldmsd_decomp_test ========
2024-10-16 17:06:44 INFO: CMD: python3 ldmsd_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_decomp_test
2024-10-16 17:06:45,046 TADA INFO starting test `ldmsd_decomp_test`
2024-10-16 17:06:45,047 TADA INFO   test-id: 8f0a3011d583b56896e95e685334c6603f462ab84eaf3f6a5d2edee2518231cf
2024-10-16 17:06:45,047 TADA INFO   test-suite: LDMSD
2024-10-16 17:06:45,047 TADA INFO   test-name: ldmsd_decomp_test
2024-10-16 17:06:45,047 TADA INFO   test-user: narate
2024-10-16 17:06:45,047 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:06:45,048 __main__ INFO -- Get or create the cluster --
2024-10-16 17:07:13,872 __main__ INFO -- Start daemons --
2024-10-16 17:07:57,411 __main__ INFO ... wait a bit to make sure ldmsd's are up
Traceback (most recent call last):
  File "ldmsd_decomp_test", line 437, in <module>
    raise RuntimeError(f"kafka-topic verification error, rc: {rc}, out: {out}")
RuntimeError: kafka-topic verification error, rc: 0, out: 
2024-10-16 17:08:25,474 TADA INFO assertion 1, `as_is` decomposition, test_sampler_8d2b8bd sos schema check: skipped
2024-10-16 17:08:25,474 TADA INFO assertion 2, `as_is` decomposition, test_sampler_95772b6 sos schema check: skipped
2024-10-16 17:08:25,474 TADA INFO assertion 3, `as_is` decomposition, record_sampler_e1f021f sos schema check: skipped
2024-10-16 17:08:25,474 TADA INFO assertion 4, `static` decomposition, fill sos schema check: skipped
2024-10-16 17:08:25,474 TADA INFO assertion 5, `static` decomposition, filter sos schema check: skipped
2024-10-16 17:08:25,475 TADA INFO assertion 6, `static` decomposition, record sos schema check: skipped
2024-10-16 17:08:25,475 TADA INFO assertion 7, `as_is` decomposition, test_sampler_8d2b8bd csv schema check: skipped
2024-10-16 17:08:25,475 TADA INFO assertion 8, `as_is` decomposition, test_sampler_95772b6 csv schema check: skipped
2024-10-16 17:08:25,475 TADA INFO assertion 9, `as_is` decomposition, record_sampler_e1f021f csv schema check: skipped
2024-10-16 17:08:25,475 TADA INFO assertion 10, `static` decomposition, fill csv schema check: skipped
2024-10-16 17:08:25,475 TADA INFO assertion 11, `static` decomposition, filter csv schema check: skipped
2024-10-16 17:08:25,475 TADA INFO assertion 12, `static` decomposition, record csv schema check: skipped
2024-10-16 17:08:25,476 TADA INFO assertion 13, `as_is` decomposition, test_sampler_8d2b8bd kafka schema check: skipped
2024-10-16 17:08:25,476 TADA INFO assertion 14, `as_is` decomposition, test_sampler_95772b6 kafka schema check: skipped
2024-10-16 17:08:25,476 TADA INFO assertion 15, `as_is` decomposition, record_sampler_e1f021f kafka schema check: skipped
2024-10-16 17:08:25,476 TADA INFO assertion 16, `static` decomposition, fill kafka schema check: skipped
2024-10-16 17:08:25,476 TADA INFO assertion 17, `static` decomposition, filter kafka schema check: skipped
2024-10-16 17:08:25,476 TADA INFO assertion 18, `static` decomposition, record kafka schema check: skipped
2024-10-16 17:08:25,476 TADA INFO assertion 19, `as_is` decomposition, test_sampler_8d2b8bd sos data check: skipped
2024-10-16 17:08:25,477 TADA INFO assertion 20, `as_is` decomposition, test_sampler_95772b6 sos data check: skipped
2024-10-16 17:08:25,477 TADA INFO assertion 21, `as_is` decomposition, record_sampler_e1f021f sos data check: skipped
2024-10-16 17:08:25,477 TADA INFO assertion 22, `static` decomposition, fill sos data check: skipped
2024-10-16 17:08:25,477 TADA INFO assertion 23, `static` decomposition, filter sos data check: skipped
2024-10-16 17:08:25,477 TADA INFO assertion 24, `static` decomposition, record sos data check: skipped
2024-10-16 17:08:25,477 TADA INFO assertion 25, `as_is` decomposition, test_sampler_8d2b8bd csv data check: skipped
2024-10-16 17:08:25,477 TADA INFO assertion 26, `as_is` decomposition, test_sampler_95772b6 csv data check: skipped
2024-10-16 17:08:25,478 TADA INFO assertion 27, `as_is` decomposition, record_sampler_e1f021f csv data check: skipped
2024-10-16 17:08:25,478 TADA INFO assertion 28, `static` decomposition, fill csv data check: skipped
2024-10-16 17:08:25,478 TADA INFO assertion 29, `static` decomposition, filter csv data check: skipped
2024-10-16 17:08:25,478 TADA INFO assertion 30, `static` decomposition, record csv data check: skipped
2024-10-16 17:08:25,478 TADA INFO assertion 31, `as_is` decomposition, test_sampler_8d2b8bd kafka data check: skipped
2024-10-16 17:08:25,478 TADA INFO assertion 32, `as_is` decomposition, test_sampler_95772b6 kafka data check: skipped
2024-10-16 17:08:25,478 TADA INFO assertion 33, `as_is` decomposition, record_sampler_e1f021f kafka data check: skipped
2024-10-16 17:08:25,479 TADA INFO assertion 34, `static` decomposition, fill kafka data check: skipped
2024-10-16 17:08:25,479 TADA INFO assertion 35, `static` decomposition, filter kafka data check: skipped
2024-10-16 17:08:25,479 TADA INFO assertion 36, `static` decomposition, record kafka data check: skipped
2024-10-16 17:08:25,479 TADA INFO test ldmsd_decomp_test ended
2024-10-16 17:08:40 INFO: ----------------------------------------------
2024-10-16 17:08:42 INFO: ======== ldmsd_decomp_no_fill_test ========
2024-10-16 17:08:42 INFO: CMD: python3 ldmsd_decomp_no_fill_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_decomp_no_fill_test
2024-10-16 17:08:43,269 TADA INFO starting test `ldmsd_decomp__no_fill_test`
2024-10-16 17:08:43,270 TADA INFO   test-id: 77457b2188ac918fce1166ee783961f77f9d4c09091c67a0f94580f5ef105aec
2024-10-16 17:08:43,270 TADA INFO   test-suite: LDMSD
2024-10-16 17:08:43,270 TADA INFO   test-name: ldmsd_decomp__no_fill_test
2024-10-16 17:08:43,270 TADA INFO   test-user: narate
2024-10-16 17:08:43,270 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:08:43,271 __main__ INFO -- Get or create the cluster --
2024-10-16 17:09:12,076 __main__ INFO -- Start daemons --
2024-10-16 17:09:57,324 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:10:46,824 TADA INFO assertion 1, `as_is` decomposition, test_sampler_28da463 sos schema check: OK, passed
2024-10-16 17:10:46,825 TADA INFO assertion 2, `as_is` decomposition, record_sampler_e1f021f sos schema check: OK, passed
2024-10-16 17:10:46,825 TADA INFO assertion 3, `as_is` decomposition, fill sos schema check: OK, passed
2024-10-16 17:10:46,825 TADA INFO assertion 4, `static` decomposition, filter sos schema check: OK, passed
2024-10-16 17:10:46,826 TADA INFO assertion 5, `static` decomposition, record sos schema check: OK, passed
2024-10-16 17:10:46,826 TADA INFO assertion 6, `as_is` decomposition, test_sampler_28da463 csv schema check: OK, passed
2024-10-16 17:10:46,826 TADA INFO assertion 7, `as_is` decomposition, record_sampler_e1f021f csv schema check: OK, passed
2024-10-16 17:10:46,826 TADA INFO assertion 8, `as_is` decomposition, fill csv schema check: OK, passed
2024-10-16 17:10:46,826 TADA INFO assertion 9, `static` decomposition, filter csv schema check: OK, passed
2024-10-16 17:10:46,826 TADA INFO assertion 10, `static` decomposition, record csv schema check: OK, passed
2024-10-16 17:10:46,827 TADA INFO assertion 11, `as_is` decomposition, test_sampler_28da463 kafka schema check: OK, passed
2024-10-16 17:10:46,827 TADA INFO assertion 12, `as_is` decomposition, record_sampler_e1f021f kafka schema check: OK, passed
2024-10-16 17:10:46,827 TADA INFO assertion 13, `as_is` decomposition, fill kafka schema check: OK, passed
2024-10-16 17:10:46,827 TADA INFO assertion 14, `static` decomposition, filter kafka schema check: OK, passed
2024-10-16 17:10:46,827 TADA INFO assertion 15, `static` decomposition, record kafka schema check: OK, passed
2024-10-16 17:10:46,830 TADA INFO assertion 16, `as_is` decomposition, test_sampler_28da463 sos data check: OK, passed
2024-10-16 17:10:46,913 TADA INFO assertion 17, `as_is` decomposition, record_sampler_e1f021f sos data check: OK, passed
2024-10-16 17:10:46,917 TADA INFO assertion 18, `as_is` decomposition, fill sos data check: OK, passed
2024-10-16 17:10:46,920 TADA INFO assertion 19, `static` decomposition, filter sos data check: OK, passed
2024-10-16 17:10:46,927 TADA INFO assertion 20, `static` decomposition, record sos data check: Expecting [{'LDMS_V_U64': 200003, 'LDMS_V_U64_ARRAY': [500003, 500004, 500005, 500006, 500007, 500008, 500009, 500010]}, {'LDMS_V_U64': 200004, 'LDMS_V_U64_ARRAY': [500004, 500005, 500006, 500007, 500008, 500009, 500010, 500011]}, {'LDMS_V_U64': 200005, 'LDMS_V_U64_ARRAY': [500005, 500006, 500007, 500008, 500009, 500010, 500011, 500012]}] but got [{'LDMS_V_U64': 200003, 'LDMS_V_U64_ARRAY': [0, 0, 0, 0, 0, 0, 0, 0]}, {'LDMS_V_U64': 200004, 'LDMS_V_U64_ARRAY': [0, 0, 0, 0, 0, 0, 0, 0]}, {'LDMS_V_U64': 200005, 'LDMS_V_U64_ARRAY': [0, 0, 0, 0, 0, 0, 0, 0]}], failed
Traceback (most recent call last):
  File "ldmsd_decomp_no_fill_test", line 858, in <module>
    check_fn(snap, i)
  File "ldmsd_decomp_no_fill_test", line 814, in record_snap_check
    test.assert_test(assert_id, False, f"Expecting {v0} but got {v1}")
  File "/home/narate/cron/ldms-test/TADA.py", line 157, in assert_test
    raise AssertionException(self.test_desc + ", " + cond_str + ": FAILED")
TADA.AssertionException: Decomposition test w/o fill, Expecting [{'LDMS_V_U64': 200003, 'LDMS_V_U64_ARRAY': [500003, 500004, 500005, 500006, 500007, 500008, 500009, 500010]}, {'LDMS_V_U64': 200004, 'LDMS_V_U64_ARRAY': [500004, 500005, 500006, 500007, 500008, 500009, 500010, 500011]}, {'LDMS_V_U64': 200005, 'LDMS_V_U64_ARRAY': [500005, 500006, 500007, 500008, 500009, 500010, 500011, 500012]}] but got [{'LDMS_V_U64': 200003, 'LDMS_V_U64_ARRAY': [0, 0, 0, 0, 0, 0, 0, 0]}, {'LDMS_V_U64': 200004, 'LDMS_V_U64_ARRAY': [0, 0, 0, 0, 0, 0, 0, 0]}, {'LDMS_V_U64': 200005, 'LDMS_V_U64_ARRAY': [0, 0, 0, 0, 0, 0, 0, 0]}]: FAILED
2024-10-16 17:10:46,929 TADA INFO assertion 21, `as_is` decomposition, test_sampler_28da463 csv data check: skipped
2024-10-16 17:10:46,929 TADA INFO assertion 22, `as_is` decomposition, record_sampler_e1f021f csv data check: skipped
2024-10-16 17:10:46,929 TADA INFO assertion 23, `as_is` decomposition, fill csv data check: skipped
2024-10-16 17:10:46,930 TADA INFO assertion 24, `static` decomposition, filter csv data check: skipped
2024-10-16 17:10:46,930 TADA INFO assertion 25, `static` decomposition, record csv data check: skipped
2024-10-16 17:10:46,930 TADA INFO assertion 26, `as_is` decomposition, test_sampler_28da463 kafka data check: skipped
2024-10-16 17:10:46,930 TADA INFO assertion 27, `as_is` decomposition, record_sampler_e1f021f kafka data check: skipped
2024-10-16 17:10:46,930 TADA INFO assertion 28, `as_is` decomposition, fill kafka data check: skipped
2024-10-16 17:10:46,930 TADA INFO assertion 29, `static` decomposition, filter kafka data check: skipped
2024-10-16 17:10:46,930 TADA INFO assertion 30, `static` decomposition, record kafka data check: skipped
2024-10-16 17:10:46,931 TADA INFO test ldmsd_decomp__no_fill_test ended
2024-10-16 17:11:02 INFO: ----------------------------------------------
2024-10-16 17:11:04 INFO: ======== ldmsd_stream_status_test ========
2024-10-16 17:11:04 INFO: CMD: python3 ldmsd_stream_status_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_stream_status_test
2024-10-16 17:11:05,372 __main__ INFO -- Get or create the cluster --
2024-10-16 17:11:05,372 TADA INFO starting test `ldmsd_stream_status`
2024-10-16 17:11:05,372 TADA INFO   test-id: 7d08130ca3d2d4ac905b05a6be0d3a1117523ecdc89f35988eddb3d00881e02f
2024-10-16 17:11:05,372 TADA INFO   test-suite: LDMSD
2024-10-16 17:11:05,372 TADA INFO   test-name: ldmsd_stream_status
2024-10-16 17:11:05,372 TADA INFO   test-user: narate
2024-10-16 17:11:05,372 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:11:22,273 __main__ INFO -- Start daemons --
2024-10-16 17:11:47,123 __main__ INFO waiting ... for all LDMSDs to start
2024-10-16 17:11:47,466 __main__ INFO All LDMSDs are up.
2024-10-16 17:11:48,692 TADA INFO assertion 1, No Stream data: [] == [], passed
2024-10-16 17:11:50,034 TADA INFO assertion 2, stream_status -- one stream message: [{'name': 'foo', 'rx': {'bytes': 6, 'count': 1, 'first_ts': 1729116708.8053703, 'last_ts': 1729116708.8053703}, 'sources': {'0.0.0.0:0': {'bytes': 6, 'count': 1, 'first_ts': 1729116708.8053703, 'last_ts': 1729116708.8053703}}, 'clients': []}] == [{'name': 'foo', 'rx': {'count': 1, 'bytes': 6, 'first_ts': 1729116708.8053703, 'last_ts': 1729116708.8053703}, 'sources': {'0.0.0.0:0': {'count': 1, 'bytes': 6, 'first_ts': 1729116708.8053703, 'last_ts': 1729116708.8053703}}, 'clients': []}], passed
2024-10-16 17:11:52,464 TADA INFO assertion 3, stream_status --  multiple stream messages: [{'name': 'foo', 'rx': {'bytes': 18, 'count': 3, 'first_ts': 1729116708.8053703, 'last_ts': 1729116711.2313502}, 'sources': {'0.0.0.0:0': {'bytes': 18, 'count': 3, 'first_ts': 1729116708.8053703, 'last_ts': 1729116711.2313502}}, 'clients': []}] == [{'name': 'foo', 'rx': {'count': 3, 'bytes': 18, 'first_ts': 1729116708.8053703, 'last_ts': 1729116711.2313502}, 'sources': {'0.0.0.0:0': {'count': 3, 'bytes': 18, 'first_ts': 1729116708.8053703, 'last_ts': 1729116711.2313502}}, 'clients': []}], passed
2024-10-16 17:11:56,251 TADA INFO assertion 4, stream_status -- mulitple streams: [{'name': 'bar', 'rx': {'bytes': 48, 'count': 3, 'first_ts': 1729116713.8021457, 'last_ts': 1729116715.0214643}, 'sources': {'0.0.0.0:0': {'bytes': 48, 'count': 3, 'first_ts': 1729116713.8021457, 'last_ts': 1729116715.0214643}}, 'clients': []}, {'name': 'foo', 'rx': {'bytes': 12, 'count': 2, 'first_ts': 1729116712.5685654, 'last_ts': 1729116713.6718645}, 'sources': {'0.0.0.0:0': {'bytes': 12, 'count': 2, 'first_ts': 1729116712.5685654, 'last_ts': 1729116713.6718645}}, 'clients': []}] == [{'name': 'bar', 'rx': {'count': 3, 'bytes': 48, 'first_ts': 1729116713.8021457, 'last_ts': 1729116715.0214643}, 'sources': {'0.0.0.0:0': {'count': 3, 'bytes': 48, 'first_ts': 1729116713.8021457, 'last_ts': 1729116715.0214643}}, 'clients': []}, {'name': 'foo', 'rx': {'count': 2, 'bytes': 12, 'first_ts': 1729116712.5685654, 'last_ts': 1729116713.6718645}, 'sources': {'0.0.0.0:0': {'count': 2, 'bytes': 12, 'first_ts': 1729116712.5685654, 'last_ts': 1729116713.6718645}}, 'clients': []}], passed
2024-10-16 17:11:59,897 TADA INFO assertion 5, stream_status to agg after one producer republished stream: [{'name': 'foo', 'rx': {'bytes': 12, 'count': 2, 'first_ts': 1729116717.57725, 'last_ts': 1729116718.6842365}, 'sources': {'10.1.218.2:10001': {'bytes': 12, 'count': 2, 'first_ts': 1729116717.57725, 'last_ts': 1729116718.6842365}}, 'clients': []}] == [{'name': 'foo', 'rx': {'count': 2, 'bytes': 12, 'first_ts': 1729116717.57725, 'last_ts': 1729116718.6842365}, 'sources': {'10.1.218.2:10001': {'count': 2, 'bytes': 12, 'first_ts': 1729116717.57725, 'last_ts': 1729116718.6842365}}, 'clients': []}], passed
2024-10-16 17:12:01,450 TADA INFO assertion 6, stream_status to agg after two producers republished stream: [{'name': 'foo', 'rx': {'bytes': 30, 'count': 5, 'first_ts': 1729116717.57725, 'last_ts': 1729116720.2329853}, 'sources': {'10.1.218.2:10001': {'bytes': 12, 'count': 2, 'first_ts': 1729116717.57725, 'last_ts': 1729116718.6842365}, '10.1.218.4:10001': {'bytes': 18, 'count': 3, 'first_ts': 1729116720.003856, 'last_ts': 1729116720.2329853}}, 'clients': []}] == [{'name': 'foo', 'rx': {'count': 5, 'bytes': 30, 'first_ts': 1729116717.57725, 'last_ts': 1729116720.2329853}, 'sources': {'10.1.218.2:10001': {'count': 2, 'bytes': 12, 'first_ts': 1729116717.57725, 'last_ts': 1729116718.6842365}, '10.1.218.4:10001': {'count': 3, 'bytes': 18, 'first_ts': 1729116720.003856, 'last_ts': 1729116720.2329853}}, 'clients': []}], passed
2024-10-16 17:12:01,451 TADA INFO test ldmsd_stream_status ended
2024-10-16 17:12:13 INFO: ----------------------------------------------
2024-10-16 17:12:15 INFO: ======== store_list_record_test ========
2024-10-16 17:12:15 INFO: CMD: python3 store_list_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/store_list_record_test
2024-10-16 17:12:16,547 __main__ INFO -- Get or create the cluster --
2024-10-16 17:12:16,548 TADA INFO starting test `store_sos_lists_test`
2024-10-16 17:12:16,548 TADA INFO   test-id: 5df59a2419b10f8df2505b7e885f9a3bd3a3a9dce9c4185bfea00e4be25a9fe9
2024-10-16 17:12:16,548 TADA INFO   test-suite: LDMSD
2024-10-16 17:12:16,548 TADA INFO   test-name: store_sos_lists_test
2024-10-16 17:12:16,548 TADA INFO   test-user: narate
2024-10-16 17:12:16,548 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:12:33,001 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:12:58,834 __main__ INFO All sampler daemons are up.
2024-10-16 17:12:58,950 TADA INFO assertion 1, aggregator with store_sos has started properly.: agg_sos.check_ldmsd(), passed
2024-10-16 17:12:59,055 TADA INFO assertion 2, aggregator with store_csv has started properly.: agg_csv.check_ldmsd(), passed
2024-10-16 17:13:00,394 TADA INFO assertion 3, store_sos is storing data.: file_exists(a) for a in supported_schema, passed
2024-10-16 17:13:01,138 TADA INFO assertion 4, store_sos stores data correctly.: verify_data(db) for db in all_db, passed
2024-10-16 17:13:10,318 TADA INFO assertion 5, store_sos stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2024-10-16 17:13:10,998 TADA INFO assertion 6, store_sos reports multiple list errror messages resulted by the config file.: store_sos reported the multiple list error messages., passed
2024-10-16 17:13:16,020 TADA INFO assertion 7, store_sos reports multiple list errror messages resulted by ldmsd_controller.: store_sos reported the multiple list error messages., passed
2024-10-16 17:13:16,370 TADA INFO assertion 8, store_csv is storing data.: file_exists(a) for a in supported_schema, passed
2024-10-16 17:13:22,854 TADA INFO assertion 9, store_csv stores data correctly.: verify_data(db) for db in all_db, passed
2024-10-16 17:13:32,692 TADA INFO assertion 10, store_csv stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2024-10-16 17:13:33,353 TADA INFO assertion 11, store_csv reports multiple list errror messages resulted by the config file.: store_csv reported the multiple list error messages., passed
2024-10-16 17:13:38,456 TADA INFO assertion 12, store_csv reports multiple list errror messages resulted by ldmsd_controller.: store_csv reported the multiple list error messages., passed
2024-10-16 17:13:38,456 TADA INFO test store_sos_lists_test ended
2024-10-16 17:13:51 INFO: ----------------------------------------------
2024-10-16 17:13:53 INFO: ======== maestro_raft_test ========
2024-10-16 17:13:53 INFO: CMD: python3 maestro_raft_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/maestro_raft_test
2024-10-16 17:13:53,789 TADA INFO starting test `maestro_raft_test`
2024-10-16 17:13:53,790 TADA INFO   test-id: 3120c79db787c3364092e47862c55eaf38c3270cc58a54c2d1675c4feaef1174
2024-10-16 17:13:53,790 TADA INFO   test-suite: LDMSD
2024-10-16 17:13:53,790 TADA INFO   test-name: maestro_raft_test
2024-10-16 17:13:53,790 TADA INFO   test-user: narate
2024-10-16 17:13:53,790 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:14:03,802 __main__ INFO -- Get or create cluster --
2024-10-16 17:15:00,441 __main__ INFO -- Start daemons --
2024-10-16 17:16:36,056 __main__ INFO -- making known hosts (ssh) --
2024-10-16 17:16:43,140 __main__ INFO ... make sure ldmsd's are up
2024-10-16 17:16:59,266 __main__ INFO Wait a bit for all maestro daemons to sync...
2024-10-16 17:17:09,938 TADA INFO assertion 1, Statuses of maestros, 1 leader + 2 followers: [('FOLLOWER', 2), ('LEADER', 1)], passed
2024-10-16 17:17:22,537 TADA INFO assertion 2, All ldmsds are up and configured: sets verified, passed
2024-10-16 17:17:22,823 TADA INFO assertion 3, Data are being stored: data check, passed
2024-10-16 17:17:27,720 TADA INFO assertion 4, New leader elected: checked, passed
2024-10-16 17:17:35,153 __main__ INFO Wait a bit for agg4 reconfiguration ...
2024-10-16 17:18:37,778 TADA INFO assertion 5, Restarted ldmsd is configured: sets verified, passed
2024-10-16 17:18:38,157 TADA INFO assertion 6, New data are presented in the store: data check, passed
2024-10-16 17:18:49,155 TADA INFO assertion 7, The restarted maestro becomes a follower: checked, passed
---Wait for config to write to file---
2024-10-16 17:18:49,155 TADA INFO test maestro_raft_test ended
2024-10-16 17:19:11 INFO: ----------------------------------------------
2024-10-16 17:19:13 INFO: ======== ovis_json_test ========
2024-10-16 17:19:13 INFO: CMD: python3 ovis_json_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ovis_json_test
2024-10-16 17:19:14,274 __main__ INFO -- Create the cluster -- 
2024-10-16 17:19:26,709 TADA INFO starting test `ovis_json_test`
2024-10-16 17:19:26,710 TADA INFO   test-id: cda3765af9c90e5e9eeae1fdaa0193ece5251d069f5d6d1a945fa776273f9fde
2024-10-16 17:19:26,710 TADA INFO   test-suite: OVIS-LIB
2024-10-16 17:19:26,710 TADA INFO   test-name: ovis_json_test
2024-10-16 17:19:26,710 TADA INFO   test-user: narate
2024-10-16 17:19:26,710 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:19:26,711 TADA INFO assertion 1, Test creating a JSON integer entity: (type is JSON_INT_VALUE) && (1 == e->value.int_), passed
2024-10-16 17:19:26,711 TADA INFO assertion 2, Test creating a JSON boolean entity: (type is JSON_BOOL_VALUE) && (1 == e->value.bool_), passed
2024-10-16 17:19:26,711 TADA INFO assertion 3, Test creating a JSON float entity: (type is JSON_FLOAT_VALUE) && (1.1 == e->value.double_), passed
2024-10-16 17:19:26,711 TADA INFO assertion 4, Test creating a JSON string entity: (type is JSON_STRING_VALUE) && (foo == e->value.str_->str), passed
2024-10-16 17:19:26,711 TADA INFO assertion 5, Test creating a JSON attribute entity: (type is JSON_ATTR_VALUE) && (name == <attr name>) && (value == <attr value>), passed
2024-10-16 17:19:26,711 TADA INFO assertion 6, Test creating a JSON list entity: (type is JSON_LIST_VALUE) && (0 == Number of elements) && (list is empty), passed
2024-10-16 17:19:26,711 TADA INFO assertion 7, Test creating a JSON dictionary entity: (type is JSON_DICT_VALUE) && (dict table is empty), passed
2024-10-16 17:19:26,712 TADA INFO assertion 8, Test creating a JSON null entity: (type is JSON_NULL_VALUE) && (0 == e->value.int_), passed
2024-10-16 17:19:26,712 TADA INFO assertion 9, Test parsing a JSON integer string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2024-10-16 17:19:26,712 TADA INFO assertion 10, Test parsing a JSON false boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2024-10-16 17:19:26,712 TADA INFO assertion 11, Test parsing a JSON true boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2024-10-16 17:19:26,712 TADA INFO assertion 12, Test parsing a JSON float string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2024-10-16 17:19:26,712 TADA INFO assertion 13, Test parsing a JSON string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2024-10-16 17:19:26,712 TADA INFO assertion 15, Test parsing a JSON dict string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2024-10-16 17:19:26,712 TADA INFO assertion 16, Test parsing a JSON null string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2024-10-16 17:19:26,713 TADA INFO assertion 17, Test parsing an invalid string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2024-10-16 17:19:26,713 TADA INFO assertion 17, Test parsing an invalid string: 0 != json_parse_buffer(), passed
2024-10-16 17:19:26,713 TADA INFO assertion 18, Test dumping a JSON integer entity: 1 == 1, passed
2024-10-16 17:19:26,713 TADA INFO assertion 19, Test dumping a JSON false boolean entity: false == false, passed
2024-10-16 17:19:26,713 TADA INFO assertion 20, Test dumping a JSON true boolean entity: true == true, passed
2024-10-16 17:19:26,713 TADA INFO assertion 21, Test dumping a JSON float entity: 1.100000 == 1.100000, passed
2024-10-16 17:19:26,713 TADA INFO assertion 22, Test dumping a JSON string entity: "foo" == "foo", passed
2024-10-16 17:19:26,713 TADA INFO assertion 23, Test dumping a JSON attr entity: "name":"foo" == jb->buf, passed
2024-10-16 17:19:26,714 TADA INFO assertion 24, Test dumping a JSON list entity: [1,false,1.100000,"foo",[],{},null] == [1,false,1.100000,"foo",[],{},null], passed
2024-10-16 17:19:26,714 TADA INFO assertion 25, Test dumping a JSON dict entity: {"int":1,"bool":true,"float":1.100000,"string":"foo","list":[1,false,1.100000,"foo",[],{},null],"dict":{"attr_1":"value_1"},"null":null} == {"null":null,"list":[1,false,1.100000,"foo",[],{},null],"string":"foo","float":1.100000,"bool":true,"dict":{"attr_1":"value_1"},"int":1}, passed
2024-10-16 17:19:26,714 TADA INFO assertion 26, Test dumping a JSON null entity: null == null, passed
2024-10-16 17:19:26,714 TADA INFO assertion 27, Test dumping a JSON entity to a non-empty jbuf: This is a book."FOO" == This is a book."FOO", passed
2024-10-16 17:19:26,714 TADA INFO assertion 28, Test copying a JSON integer entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,714 TADA INFO assertion 29, Test copying a JSON false boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,715 TADA INFO assertion 30, Test copying a JSON true boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,715 TADA INFO assertion 31, Test copying a JSON float entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,715 TADA INFO assertion 32, Test copying a JSON string entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,715 TADA INFO assertion 33, Test copying a JSON attribute entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,715 TADA INFO assertion 34, Test copying a JSON list entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,715 TADA INFO assertion 35, Test copying a JSON dict entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,716 TADA INFO assertion 36, Test copying a JSON null entity: is_same_entity(expected, json_entity_copy(expected), passed
2024-10-16 17:19:26,716 TADA INFO assertion 37, Test obtaining the number of attributes: 7 == json_attr_count(dict), passed
2024-10-16 17:19:26,716 TADA INFO assertion 38, Test finding an existing attribute: 0 != json_attr_find(), passed
2024-10-16 17:19:26,716 TADA INFO assertion 39, Test finding a non-existng attribute: 0 == json_attr_find(), passed
2024-10-16 17:19:26,716 TADA INFO assertion 40, Test finding the value of an existing attribute: 0 != json_value_find(), passed
2024-10-16 17:19:26,716 TADA INFO assertion 41, Test finding the value of a non-existing attribute: 0 == json_value_find(), passed
2024-10-16 17:19:26,716 TADA INFO assertion 42, Test adding a new attribute to a dictionary: (0 == json_attr_add() && (0 != json_attr_find()), passed
2024-10-16 17:19:26,717 TADA INFO assertion 43, Test replacing the value of an existing attribute: (0 == json_attr_add()) && (0 != json_value_find()) && (is_same_entity(old_v, new_v)), passed
2024-10-16 17:19:26,717 TADA INFO assertion 44, Test removing an existing attribute: (0 = json_attr_rem()) && (0 == json_attr_find()), passed
2024-10-16 17:19:26,717 TADA INFO assertion 45, Test removing a non-existing attribute: (ENOENT == json_attr_rem()), passed
2024-10-16 17:19:26,717 TADA INFO assertion 46, Test creating a dictionary by json_dict_build: expected == json_dict_build(...), passed
2024-10-16 17:19:26,717 TADA INFO assertion 47, Test adding attributes and replacing attribute values by json_dict_build: expected == json_dict_build(d, ...), passed
2024-10-16 17:19:26,717 TADA INFO assertion 48, Test json_dict_merge(): The merged dictionary is correct., passed
2024-10-16 17:19:26,717 TADA INFO assertion 49, Test json_list_len(): 7 == json_list_len(), passed
2024-10-16 17:19:26,718 TADA INFO assertion 50, Test adding items to a list: 0 == strcmp(exp_str, json_entity_dump(l)->buf, passed
2024-10-16 17:19:26,718 TADA INFO assertion 51, Test removing an existing item by json_item_rem(): 0 == json_item_rem(), passed
2024-10-16 17:19:26,718 TADA INFO assertion 52, Test removing a non-existing item by json_item_rem(): ENOENT == json_item_rem(), passed
2024-10-16 17:19:26,718 TADA INFO assertion 53, Test popping an existing item from a list by json_item_pop(): NULL == json_item_pop(len + 3), passed
2024-10-16 17:19:26,718 TADA INFO assertion 54, Test popping a non-existing item from a list by json_item_pop(): NULL != json_item_pop(len - 1), passed
2024-10-16 17:19:26,718 TADA INFO test ovis_json_test ended
2024-10-16 17:19:37 INFO: ----------------------------------------------
2024-10-16 17:19:39 INFO: ======== updtr_add_test ========
2024-10-16 17:19:39 INFO: CMD: python3 updtr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_add_test
2024-10-16 17:19:40,471 __main__ INFO -- Get or create the cluster --
2024-10-16 17:19:40,471 TADA INFO starting test `updtr_add test`
2024-10-16 17:19:40,471 TADA INFO   test-id: acebcf61249b3942fcf1e2cd1a0f417daf34ea3bcc0e93412baad7f3da8c0ab7
2024-10-16 17:19:40,472 TADA INFO   test-suite: LDMSD
2024-10-16 17:19:40,472 TADA INFO   test-name: updtr_add test
2024-10-16 17:19:40,472 TADA INFO   test-user: narate
2024-10-16 17:19:40,472 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:19:56,558 __main__ INFO -- Start daemons --
2024-10-16 17:20:21,464 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:20:21,797 __main__ INFO All LDMSDs are up.
2024-10-16 17:20:23,022 TADA INFO assertion 1, Add an updater with a negative interval: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:20:24,256 TADA INFO assertion 2, Add an updater with a zero interval: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:20:25,475 TADA INFO assertion 3, Add an updater with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:20:26,689 TADA INFO assertion 4, Add an updater with a negative offset: report(rc = 0) == expect(rc = 0), passed
2024-10-16 17:20:27,895 TADA INFO assertion 5, Add an updater with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:20:30,329 TADA INFO assertion 6, Add an updater without an offset: report(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2024-10-16 17:20:32,778 TADA INFO assertion 7, Add an updater with a valid offset: report(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2024-10-16 17:20:34,005 TADA INFO assertion 8, Add an updater with an existing name: report(rc = 17) == expect(rc = 17), passed
2024-10-16 17:20:34,005 __main__ INFO --- done ---
2024-10-16 17:20:34,006 TADA INFO test updtr_add test ended
2024-10-16 17:20:46 INFO: ----------------------------------------------
2024-10-16 17:20:48 INFO: ======== updtr_del_test ========
2024-10-16 17:20:48 INFO: CMD: python3 updtr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_del_test
2024-10-16 17:20:49,168 __main__ INFO -- Get or create the cluster --
2024-10-16 17:20:49,168 TADA INFO starting test `updtr_add test`
2024-10-16 17:20:49,168 TADA INFO   test-id: f7c611bc8ab066dcd7750f68416f61858db55282a2de22a93a3fd2f68f3da3d6
2024-10-16 17:20:49,168 TADA INFO   test-suite: LDMSD
2024-10-16 17:20:49,168 TADA INFO   test-name: updtr_add test
2024-10-16 17:20:49,168 TADA INFO   test-user: narate
2024-10-16 17:20:49,168 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:21:05,472 __main__ INFO -- Start daemons --
2024-10-16 17:21:30,341 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:21:30,671 __main__ INFO All LDMSDs are up.
2024-10-16 17:21:31,899 TADA INFO assertion 1, updtr_del a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:21:33,131 TADA INFO assertion 2, updtr_del a running updater: report(rc = 16) == expect(rc = 16), passed
2024-10-16 17:21:34,344 TADA INFO assertion 3, updtr_del a stopped updater: report(rc = 0) == expect(rc = 0), passed
2024-10-16 17:21:35,570 TADA INFO assertion 4, updtr_del a just-added updater: report(rc = 0) == expect(rc = 0), passed
2024-10-16 17:21:35,571 __main__ INFO --- done ---
2024-10-16 17:21:35,571 TADA INFO test updtr_add test ended
2024-10-16 17:21:47 INFO: ----------------------------------------------
2024-10-16 17:21:50 INFO: ======== updtr_match_add_test ========
2024-10-16 17:21:50 INFO: CMD: python3 updtr_match_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_match_add_test
2024-10-16 17:21:50,736 __main__ INFO -- Get or create the cluster --
2024-10-16 17:21:50,736 TADA INFO starting test `updtr_add test`
2024-10-16 17:21:50,736 TADA INFO   test-id: 464eafd722b1e33a708efcbff1721ebb3622afce6e6851af22b2c47a5a15cc47
2024-10-16 17:21:50,736 TADA INFO   test-suite: LDMSD
2024-10-16 17:21:50,736 TADA INFO   test-name: updtr_add test
2024-10-16 17:21:50,736 TADA INFO   test-user: narate
2024-10-16 17:21:50,736 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:22:06,941 __main__ INFO -- Start daemons --
2024-10-16 17:22:31,807 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:22:32,144 __main__ INFO All LDMSDs are up.
2024-10-16 17:22:33,384 TADA INFO assertion 1, updtr_match_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:22:34,607 TADA INFO assertion 2, updtr_match_add with an invalid match: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:22:35,820 TADA INFO assertion 3, updtr_match_add of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:22:37,018 TADA INFO assertion 4, A success updtr_match_add: report(rc = 0) == expect(rc = 0), passed
2024-10-16 17:22:38,240 TADA INFO assertion 5, updtr_match_add of a running updater: report(rc = 16) == expect(rc = 16), passed
2024-10-16 17:22:38,240 __main__ INFO --- done ---
2024-10-16 17:22:38,240 TADA INFO test updtr_add test ended
2024-10-16 17:22:50 INFO: ----------------------------------------------
2024-10-16 17:22:52 INFO: ======== updtr_match_del_test ========
2024-10-16 17:22:52 INFO: CMD: python3 updtr_match_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_match_del_test
2024-10-16 17:22:53,439 __main__ INFO -- Get or create the cluster --
2024-10-16 17:22:53,439 TADA INFO starting test `updtr_add test`
2024-10-16 17:22:53,439 TADA INFO   test-id: 196a8a0456c1dd99e1a28395d98037a452733c627a8c65fef83385f4db163d2c
2024-10-16 17:22:53,439 TADA INFO   test-suite: LDMSD
2024-10-16 17:22:53,439 TADA INFO   test-name: updtr_add test
2024-10-16 17:22:53,439 TADA INFO   test-user: narate
2024-10-16 17:22:53,439 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:23:09,910 __main__ INFO -- Start daemons --
2024-10-16 17:23:34,552 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:23:34,861 __main__ INFO All LDMSDs are up.
2024-10-16 17:23:36,072 TADA INFO assertion 1, Send updtr_match_del with an invalid regex: report(rc = 2) == expect(rc = 22), passed
2024-10-16 17:23:37,299 TADA INFO assertion 2, Send updtr_match_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:23:38,512 TADA INFO assertion 3, Send updtr_match_del with a non-existing inst match: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:23:39,729 TADA INFO assertion 4, Send updtr_match_del with a non-existing schema match: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:23:40,946 TADA INFO assertion 5, Send updater_match_del with an invalid match type: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:23:42,165 TADA INFO assertion 6, Send updater_match_del with a valid regex of the inst type: report(rc = 0) == expect(rc = 0), passed
2024-10-16 17:23:43,388 TADA INFO assertion 7, Send updater_match_del with a valid regex of the schema type: report(rc = 0) == expect(rc = 0), passed
2024-10-16 17:23:43,388 __main__ INFO --- done ---
2024-10-16 17:23:43,389 TADA INFO test updtr_add test ended
2024-10-16 17:23:55 INFO: ----------------------------------------------
2024-10-16 17:23:57 INFO: ======== updtr_prdcr_add_test ========
2024-10-16 17:23:57 INFO: CMD: python3 updtr_prdcr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_prdcr_add_test
2024-10-16 17:23:58,391 __main__ INFO -- Get or create the cluster --
2024-10-16 17:23:58,391 TADA INFO starting test `updtr_add test`
2024-10-16 17:23:58,391 TADA INFO   test-id: 3454f254c5956a01f5a86da4a9eb1ddbd3e49bf8b9fcfa9d3afba7afc9e933e4
2024-10-16 17:23:58,391 TADA INFO   test-suite: LDMSD
2024-10-16 17:23:58,391 TADA INFO   test-name: updtr_add test
2024-10-16 17:23:58,391 TADA INFO   test-user: narate
2024-10-16 17:23:58,391 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:24:14,704 __main__ INFO -- Start daemons --
2024-10-16 17:24:39,480 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:24:39,805 __main__ INFO All LDMSDs are up.
2024-10-16 17:24:41,031 TADA INFO assertion 1, Send updtr_prdcr_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:24:43,469 TADA INFO assertion 2, Send updtr_prdcr_add with a regex matching no prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2024-10-16 17:24:45,924 TADA INFO assertion 3, Send updtr_prdcdr_add with a regex matching some prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2024-10-16 17:24:47,134 TADA INFO assertion 4, Send updtr_prdcdr_add to a running updtr: report(rc = 16) == expect(rc = 16), passed
2024-10-16 17:24:48,350 TADA INFO assertion 5, Send updtr_prdcr_add to a not-existing updtr: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:24:48,350 __main__ INFO --- done ---
2024-10-16 17:24:48,351 TADA INFO test updtr_add test ended
2024-10-16 17:25:00 INFO: ----------------------------------------------
2024-10-16 17:25:02 INFO: ======== updtr_prdcr_del_test ========
2024-10-16 17:25:02 INFO: CMD: python3 updtr_prdcr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_prdcr_del_test
2024-10-16 17:25:03,426 __main__ INFO -- Get or create the cluster --
2024-10-16 17:25:03,427 TADA INFO starting test `updtr_add test`
2024-10-16 17:25:03,427 TADA INFO   test-id: 0f35377af821311923239e16e4fa0996a1882cf2c296a4f5ea0bcee82adb687c
2024-10-16 17:25:03,427 TADA INFO   test-suite: LDMSD
2024-10-16 17:25:03,427 TADA INFO   test-name: updtr_add test
2024-10-16 17:25:03,427 TADA INFO   test-user: narate
2024-10-16 17:25:03,427 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:25:19,562 __main__ INFO -- Start daemons --
2024-10-16 17:25:44,358 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:25:44,685 __main__ INFO All LDMSDs are up.
2024-10-16 17:25:45,903 TADA INFO assertion 1, Send updtr_prdcr_del with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:25:47,124 TADA INFO assertion 2, Send updtr_prdcr_del to a running updater: report(rc = 16) == expect(rc = 16), passed
2024-10-16 17:25:48,336 TADA INFO assertion 3, Send updtr_prdcr_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:25:50,793 TADA INFO assertion 4, Send updtr_prdcr_del successfully: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}], passed
2024-10-16 17:25:50,794 __main__ INFO --- done ---
2024-10-16 17:25:50,794 TADA INFO test updtr_add test ended
2024-10-16 17:26:03 INFO: ----------------------------------------------
2024-10-16 17:26:05 INFO: ======== updtr_start_test ========
2024-10-16 17:26:05 INFO: CMD: python3 updtr_start_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_start_test
2024-10-16 17:26:06,017 __main__ INFO -- Get or create the cluster --
2024-10-16 17:26:06,017 TADA INFO starting test `updtr_add test`
2024-10-16 17:26:06,017 TADA INFO   test-id: 960aceb647e4eb06e24687cb5d9cf52d0cd0968f71f1826ad2071933777bea4d
2024-10-16 17:26:06,017 TADA INFO   test-suite: LDMSD
2024-10-16 17:26:06,017 TADA INFO   test-name: updtr_add test
2024-10-16 17:26:06,017 TADA INFO   test-user: narate
2024-10-16 17:26:06,017 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:26:22,150 __main__ INFO -- Start daemons --
2024-10-16 17:26:47,001 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:26:47,326 __main__ INFO All LDMSDs are up.
2024-10-16 17:26:48,541 TADA INFO assertion 1, updtr_start with a negative interval: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:26:49,762 TADA INFO assertion 2, updtr_start with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:26:50,977 TADA INFO assertion 3, updtr_start with a negative offset: report(rc = 0) == expect(rc = 0), passed
2024-10-16 17:26:52,204 TADA INFO assertion 4, updtr_start with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:26:53,428 TADA INFO assertion 5, updtr_start without an offset larger than interval: report(rc = 22) == expect(rc = 22), passed
2024-10-16 17:26:55,861 TADA INFO assertion 6, updtr_start that changes offset to no offset: report(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2024-10-16 17:26:57,076 TADA INFO assertion 7, updtr_start of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:26:59,524 TADA INFO assertion 8, updtr_start with a valid interval: report(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2024-10-16 17:27:01,960 TADA INFO assertion 9, updtr_start with a valid offset: report(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2024-10-16 17:27:04,389 TADA INFO assertion 10, updtr_start without giving interval and offset: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2024-10-16 17:27:05,604 TADA INFO assertion 11, updtr_start a running updater: report(rc = 16) == expect(rc = 16), passed
2024-10-16 17:27:05,604 __main__ INFO --- done ---
2024-10-16 17:27:05,604 TADA INFO test updtr_add test ended
2024-10-16 17:27:17 INFO: ----------------------------------------------
2024-10-16 17:27:19 INFO: ======== updtr_status_test ========
2024-10-16 17:27:19 INFO: CMD: python3 updtr_status_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_status_test
2024-10-16 17:27:20,705 __main__ INFO -- Get or create the cluster --
2024-10-16 17:27:20,706 TADA INFO starting test `updtr_status test`
2024-10-16 17:27:20,706 TADA INFO   test-id: c23710e10e0f924ed67313ca97e6c754043084c0361e5548e6df102e5d26bcf7
2024-10-16 17:27:20,706 TADA INFO   test-suite: LDMSD
2024-10-16 17:27:20,706 TADA INFO   test-name: updtr_status test
2024-10-16 17:27:20,706 TADA INFO   test-user: narate
2024-10-16 17:27:20,706 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:27:40,019 __main__ INFO -- Start daemons --
2024-10-16 17:28:06,869 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:28:07,293 __main__ INFO All LDMSDs are up.
2024-10-16 17:28:08,518 TADA INFO assertion 1, Send 'updtr_status' to an LDMSD without any Updaters: [], passed
2024-10-16 17:28:09,745 TADA INFO assertion 2, Send 'updtr_status name=foo', where updtr 'foo' doesn't exist.: report(updtr 'foo' doesn't exist.) == expect(updtr 'foo' doesn't exist.), passed
2024-10-16 17:28:10,955 TADA INFO assertion 3, Send 'updtr_status name=all', where 'all' exists.: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2024-10-16 17:28:12,172 TADA INFO assertion 4, Send 'updtr_status' to an LDMSD with a single Updater: report([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2024-10-16 17:28:13,380 TADA INFO assertion 5, Send 'updtr_status' to an LDMSD with 2 updaters: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2024-10-16 17:28:13,381 __main__ INFO --- done ---
2024-10-16 17:28:13,381 TADA INFO test updtr_status test ended
2024-10-16 17:28:26 INFO: ----------------------------------------------
2024-10-16 17:28:28 INFO: ======== updtr_stop_test ========
2024-10-16 17:28:28 INFO: CMD: python3 updtr_stop_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/updtr_stop_test
2024-10-16 17:28:29,139 __main__ INFO -- Get or create the cluster --
2024-10-16 17:28:29,139 TADA INFO starting test `updtr_add test`
2024-10-16 17:28:29,139 TADA INFO   test-id: 4348e092fd77059997871adb24a39bd543c349dfaf48e20ee95f527d951fd2e5
2024-10-16 17:28:29,139 TADA INFO   test-suite: LDMSD
2024-10-16 17:28:29,139 TADA INFO   test-name: updtr_add test
2024-10-16 17:28:29,139 TADA INFO   test-user: narate
2024-10-16 17:28:29,139 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:28:45,655 __main__ INFO -- Start daemons --
2024-10-16 17:29:10,473 __main__ INFO Waiting ... for all LDMSDs to start
2024-10-16 17:29:10,805 __main__ INFO All LDMSDs are up.
2024-10-16 17:29:12,027 TADA INFO assertion 1, Send updtr_stop for a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2024-10-16 17:29:14,462 TADA INFO assertion 2, Send updtr_stop to a running updater: report(rc = 0, status = [{'name': 'running', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'running', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}], passed
2024-10-16 17:29:15,681 TADA INFO assertion 3, Send updtr_stop to a stopped updater: report(rc = 0) == expect(rc = 0), passed
2024-10-16 17:29:15,682 __main__ INFO --- done ---
2024-10-16 17:29:15,682 TADA INFO test updtr_add test ended
2024-10-16 17:29:28 INFO: ----------------------------------------------
2024-10-16 17:29:30 INFO: ======== ldmsd_flex_decomp_test ========
2024-10-16 17:29:30 INFO: CMD: python3 ldmsd_flex_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_flex_decomp_test
2024-10-16 17:29:30,856 TADA INFO starting test `ldmsd_flex_decomp_test`
2024-10-16 17:29:30,856 TADA INFO   test-id: b810230eb73b66fe92a1b0a607f0721ce22f9af50d86e27861b13ea869db6404
2024-10-16 17:29:30,856 TADA INFO   test-suite: LDMSD
2024-10-16 17:29:30,857 TADA INFO   test-name: ldmsd_flex_decomp_test
2024-10-16 17:29:30,857 TADA INFO   test-user: narate
2024-10-16 17:29:30,857 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:29:30,858 __main__ INFO -- Get or create the cluster --
2024-10-16 17:29:59,419 __main__ INFO -- Start daemons --
2024-10-16 17:30:42,646 __main__ INFO ... wait a bit to make sure ldmsd's are up
Traceback (most recent call last):
  File "ldmsd_flex_decomp_test", line 461, in <module>
    raise RuntimeError(f"kafka-topic verification error, rc: {rc}, out: {out}")
RuntimeError: kafka-topic verification error, rc: 0, out: 
2024-10-16 17:31:10,713 TADA INFO assertion 1, test_sampler_95772b6 sos schema check: skipped
2024-10-16 17:31:10,713 TADA INFO assertion 2, record_sampler_e1f021f sos schema check: skipped
2024-10-16 17:31:10,713 TADA INFO assertion 3, fill sos schema check: skipped
2024-10-16 17:31:10,714 TADA INFO assertion 4, filter sos schema check: skipped
2024-10-16 17:31:10,714 TADA INFO assertion 5, record sos schema check: skipped
2024-10-16 17:31:10,714 TADA INFO assertion 6, test_sampler_95772b6 csv schema check: skipped
2024-10-16 17:31:10,714 TADA INFO assertion 7, record_sampler_e1f021f csv schema check: skipped
2024-10-16 17:31:10,714 TADA INFO assertion 8, fill csv schema check: skipped
2024-10-16 17:31:10,714 TADA INFO assertion 9, filter csv schema check: skipped
2024-10-16 17:31:10,714 TADA INFO assertion 10, record csv schema check: skipped
2024-10-16 17:31:10,715 TADA INFO assertion 11, test_sampler_95772b6 kafka schema check: skipped
2024-10-16 17:31:10,715 TADA INFO assertion 12, record_sampler_e1f021f kafka schema check: skipped
2024-10-16 17:31:10,715 TADA INFO assertion 13, fill kafka schema check: skipped
2024-10-16 17:31:10,715 TADA INFO assertion 14, filter kafka schema check: skipped
2024-10-16 17:31:10,715 TADA INFO assertion 15, record kafka schema check: skipped
2024-10-16 17:31:10,715 TADA INFO assertion 16, test_sampler_95772b6 sos data check: skipped
2024-10-16 17:31:10,715 TADA INFO assertion 17, record_sampler_e1f021f sos data check: skipped
2024-10-16 17:31:10,716 TADA INFO assertion 18, fill sos data check: skipped
2024-10-16 17:31:10,716 TADA INFO assertion 19, filter sos data check: skipped
2024-10-16 17:31:10,716 TADA INFO assertion 20, record sos data check: skipped
2024-10-16 17:31:10,716 TADA INFO assertion 21, test_sampler_95772b6 csv data check: skipped
2024-10-16 17:31:10,716 TADA INFO assertion 22, record_sampler_e1f021f csv data check: skipped
2024-10-16 17:31:10,716 TADA INFO assertion 23, fill csv data check: skipped
2024-10-16 17:31:10,716 TADA INFO assertion 24, filter csv data check: skipped
2024-10-16 17:31:10,716 TADA INFO assertion 25, record csv data check: skipped
2024-10-16 17:31:10,717 TADA INFO assertion 26, test_sampler_95772b6 kafka data check: skipped
2024-10-16 17:31:10,717 TADA INFO assertion 27, record_sampler_e1f021f kafka data check: skipped
2024-10-16 17:31:10,717 TADA INFO assertion 28, fill kafka data check: skipped
2024-10-16 17:31:10,717 TADA INFO assertion 29, filter kafka data check: skipped
2024-10-16 17:31:10,717 TADA INFO assertion 30, record kafka data check: skipped
2024-10-16 17:31:10,717 TADA INFO test ldmsd_flex_decomp_test ended
2024-10-16 17:31:25 INFO: ----------------------------------------------
2024-10-16 17:31:27 INFO: ======== ldms_set_info_test ========
2024-10-16 17:31:27 INFO: CMD: python3 ldms_set_info_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_set_info_test
2024-10-16 17:31:45,498 TADA INFO starting test `ldms_set_info_test`
2024-10-16 17:31:45,498 TADA INFO   test-id: 70a83363a5a016f4efc3b42befb1908dd193145b424b6a883b905b6a5040dc99
2024-10-16 17:31:45,498 TADA INFO   test-suite: LDMSD
2024-10-16 17:31:45,498 TADA INFO   test-name: ldms_set_info_test
2024-10-16 17:31:45,498 TADA INFO   test-user: narate
2024-10-16 17:31:45,498 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:31:45,499 TADA INFO assertion 1, Adding set info key value pairs : -, passed
2024-10-16 17:31:45,499 TADA INFO assertion 2, Reset value of an existing pair : -, passed
2024-10-16 17:31:45,499 TADA INFO assertion 3, Get a value : -, passed
2024-10-16 17:31:45,499 TADA INFO assertion 4, Unset a pair : -, passed
2024-10-16 17:31:45,499 TADA INFO assertion 5, Traverse the local set info : -, passed
2024-10-16 17:31:45,500 TADA INFO assertion 6, Verifying the set info at the 1st level : -, passed
2024-10-16 17:31:45,500 TADA INFO assertion 7, Server resetting a key : -, passed
2024-10-16 17:31:45,500 TADA INFO assertion 8, Server unset a key : -, passed
2024-10-16 17:31:45,500 TADA INFO assertion 9, Server add a key : -, passed
2024-10-16 17:31:45,500 TADA INFO assertion 10, Adding a key : -, passed
2024-10-16 17:31:45,500 TADA INFO assertion 11, Add a key that is already in the remote list : -, passed
2024-10-16 17:31:45,500 TADA INFO assertion 12, Unset a key that appears in both local and remote list : -, passed
2024-10-16 17:31:45,501 TADA INFO assertion 13, Verifying the set_info at the 2nd level : -, passed
2024-10-16 17:31:45,501 TADA INFO assertion 14, Test set info propagation: resetting a key on the set origin : -, passed
2024-10-16 17:31:45,501 TADA INFO assertion 15, Test set info propagation: unsetting a key on the set origin : -, passed
2024-10-16 17:31:45,501 TADA INFO assertion 16, Test set info propagation: adding a key on the set origin : -, passed
2024-10-16 17:31:45,501 TADA INFO test ldms_set_info_test ended
2024-10-16 17:31:56 INFO: ----------------------------------------------
2024-10-16 17:31:58 INFO: ======== slurm_sampler2_test ========
2024-10-16 17:31:58 INFO: CMD: python3 slurm_sampler2_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/slurm_sampler2_test
2024-10-16 17:31:59,256 TADA INFO starting test `slurm_sampler2_test`
2024-10-16 17:31:59,256 TADA INFO   test-id: 7140ea2485f756748de640da236883475d1dd580d2d6ae05d68eefbc25eb0ad5
2024-10-16 17:31:59,256 TADA INFO   test-suite: LDMSD
2024-10-16 17:31:59,256 TADA INFO   test-name: slurm_sampler2_test
2024-10-16 17:31:59,256 TADA INFO   test-user: narate
2024-10-16 17:31:59,256 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:31:59,257 __main__ INFO -- Get or create the cluster --
2024-10-16 17:32:24,878 __main__ INFO -- Add users --
2024-10-16 17:32:30,069 __main__ INFO -- Preparing job script & programs --
2024-10-16 17:32:30,709 __main__ INFO -- Start daemons --
2024-10-16 17:33:27,634 TADA INFO assertion 1, Processing the stream data from slurm_notifier: The metric values are as expected on all nodes., passed
2024-10-16 17:33:32,370 TADA INFO assertion 2.1, Deleting completed jobs -- job_init: The metric values are as expected on all nodes., passed
2024-10-16 17:33:35,090 TADA INFO assertion 2.2, Deleting completed jobs -- step_init: The metric values are as expected on all nodes., passed
2024-10-16 17:33:37,846 TADA INFO assertion 2.3, Deleting completed jobs -- task_init: The metric values are as expected on all nodes., passed
2024-10-16 17:33:40,550 TADA INFO assertion 2.4, Deleting completed jobs -- task_exit: The metric values are as expected on all nodes., passed
2024-10-16 17:33:43,278 TADA INFO assertion 2.5, Deleting completed jobs -- job_exit: The metric values are as expected on all nodes., passed
2024-10-16 17:33:48,022 TADA INFO assertion 3.1, Expanding the set heap -- job_init: The metric values are as expected on all nodes., passed
2024-10-16 17:33:50,728 TADA INFO assertion 3.2, Expanding the set heap -- step_init: The metric values are as expected on all nodes., passed
2024-10-16 17:33:54,754 TADA INFO assertion 3.3, Expanding the set heap -- task_init: The metric values are as expected on all nodes., passed
2024-10-16 17:33:58,771 TADA INFO assertion 3.4, Expanding the set heap -- task_exit: The metric values are as expected on all nodes., passed
2024-10-16 17:34:01,510 TADA INFO assertion 3.5, Expanding the set heap -- job_exit: The metric values are as expected on all nodes., passed
2024-10-16 17:34:07,882 TADA INFO assertion 4.1, Multi-tenant -- job_init: The metric values are as expected on all nodes., passed
2024-10-16 17:34:09,591 TADA INFO assertion 4.2, Multi-tenant -- step_init: The metric values are as expected on all nodes., passed
2024-10-16 17:34:12,198 TADA INFO assertion 4.3, Multi-tenant -- task_init: The metric values are as expected on all nodes., passed
2024-10-16 17:34:14,838 TADA INFO assertion 4.4, Multi-tenant -- task_exit: The metric values are as expected on all nodes., passed
2024-10-16 17:34:16,570 TADA INFO assertion 4.5, Multi-tenant -- job_exit: The metric values are as expected on all nodes., passed
2024-10-16 17:34:16,570 TADA INFO test slurm_sampler2_test ended
2024-10-16 17:34:31 INFO: ----------------------------------------------
2024-10-16 17:34:33 INFO: ======== libovis_log_test ========
2024-10-16 17:34:33 INFO: CMD: python3 libovis_log_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/libovis_log_test
2024-10-16 17:34:34,371 TADA INFO starting test `libovis_log_test`
2024-10-16 17:34:34,372 TADA INFO   test-id: bb8e039e9beb02cd0ffef9a631b5dd098899d3978146cfb35b4fc63a9cc97bb5
2024-10-16 17:34:34,372 TADA INFO   test-suite: LDMSD
2024-10-16 17:34:34,372 TADA INFO   test-name: libovis_log_test
2024-10-16 17:34:34,372 TADA INFO   test-user: narate
2024-10-16 17:34:34,372 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:34:34,372 __main__ INFO -- Create the cluster -- 
2024-10-16 17:34:46,271 __main__ INFO -- Start daemons --
2024-10-16 17:34:48,502 TADA INFO assertion 1, Call ovis_log_init() with valid arguments: 'return_code=0' and 'liovis_log_test' in 'Wed Oct 16 17:34:47 2024:         : libovis_log_test: return_code=0
', passed
2024-10-16 17:34:49,613 TADA INFO assertion 2, Call ovis_log_init() with name = NULL: ('return_code=0' and ': :') in 'Wed Oct 16 17:34:48 2024:         : : return_code=0
', passed
2024-10-16 17:34:50,724 TADA INFO assertion 3, Call ovis_log_init() with an invalid level: 'return_code=22' in 'Wed Oct 16 17:34:49 2024:         : : return_code=22
', passed
2024-10-16 17:34:51,838 TADA INFO assertion 4, Call ovis_log_init() with an invalid mode: 'return_code=22' in 'Wed Oct 16 17:34:50 2024:         : : return_code=22
', passed
2024-10-16 17:34:52,508 TADA INFO assertion 6, Log messages to a file: 0 == ovis_log_open(/var/log/6.log) # (0), passed
2024-10-16 17:34:53,620 TADA INFO assertion 5, Log messages to stdout: 'return_code=0' in 'Wed Oct 16 17:34:52 2024:         : : return_code=0
', passed
2024-10-16 17:34:53,730 TADA INFO assertion 7, Open the log file at a non-existing path: 'Could not open the log file' in 'Wed Oct 16 17:34:53 2024:         : test: result=0
Wed Oct 16 17:34:53 2024:    ERROR: test: Could not open the log file named '/data/log/foo/7.log'
Wed Oct 16 17:34:53 2024:    ERROR: test: Failed to open the log file at /data/log/foo/7.log. Error 22
', passed
2024-10-16 17:34:54,306 TADA INFO assertion 8, Reopen the log file at another path: ovis_log_open() closes and opens the second path successfully, passed
2024-10-16 17:34:54,722 TADA INFO assertion 9, Convert 'DEBUG,INFO' integer to a string: DEBUG,INFO == DEBUG,INFO (expected), passed
2024-10-16 17:34:54,845 TADA INFO assertion 10, Convert 'DEBUG,WARNING' integer to a string: DEBUG,WARNING == DEBUG,WARNING (expected), passed
2024-10-16 17:34:54,955 TADA INFO assertion 11, Convert 'DEBUG,ERROR' integer to a string: DEBUG,ERROR == DEBUG,ERROR (expected), passed
2024-10-16 17:34:55,052 TADA INFO assertion 12, Convert 'DEBUG,CRITICAL' integer to a string: DEBUG,CRITICAL == DEBUG,CRITICAL (expected), passed
2024-10-16 17:34:55,158 TADA INFO assertion 13, Convert 'INFO,WARNING' integer to a string: INFO,WARNING == INFO,WARNING (expected), passed
2024-10-16 17:34:55,266 TADA INFO assertion 14, Convert 'INFO,ERROR' integer to a string: INFO,ERROR == INFO,ERROR (expected), passed
2024-10-16 17:34:55,383 TADA INFO assertion 15, Convert 'INFO,CRITICAL' integer to a string: INFO,CRITICAL == INFO,CRITICAL (expected), passed
2024-10-16 17:34:55,507 TADA INFO assertion 16, Convert 'WARNING,ERROR' integer to a string: WARNING,ERROR == WARNING,ERROR (expected), passed
2024-10-16 17:34:55,605 TADA INFO assertion 17, Convert 'WARNING,CRITICAL' integer to a string: WARNING,CRITICAL == WARNING,CRITICAL (expected), passed
2024-10-16 17:34:55,727 TADA INFO assertion 18, Convert 'ERROR,CRITICAL' integer to a string: ERROR,CRITICAL == ERROR,CRITICAL (expected), passed
2024-10-16 17:34:55,863 TADA INFO assertion 19, Convert 'DEBUG,INFO,WARNING' integer to a string: DEBUG,INFO,WARNING == DEBUG,INFO,WARNING (expected), passed
2024-10-16 17:34:55,970 TADA INFO assertion 20, Convert 'DEBUG,INFO,ERROR' integer to a string: DEBUG,INFO,ERROR == DEBUG,INFO,ERROR (expected), passed
2024-10-16 17:34:56,079 TADA INFO assertion 21, Convert 'DEBUG,INFO,CRITICAL' integer to a string: DEBUG,INFO,CRITICAL == DEBUG,INFO,CRITICAL (expected), passed
2024-10-16 17:34:56,192 TADA INFO assertion 22, Convert 'DEBUG,WARNING,ERROR' integer to a string: DEBUG,WARNING,ERROR == DEBUG,WARNING,ERROR (expected), passed
2024-10-16 17:34:56,297 TADA INFO assertion 23, Convert 'DEBUG,WARNING,CRITICAL' integer to a string: DEBUG,WARNING,CRITICAL == DEBUG,WARNING,CRITICAL (expected), passed
2024-10-16 17:34:56,418 TADA INFO assertion 24, Convert 'DEBUG,ERROR,CRITICAL' integer to a string: DEBUG,ERROR,CRITICAL == DEBUG,ERROR,CRITICAL (expected), passed
2024-10-16 17:34:56,533 TADA INFO assertion 25, Convert 'INFO,WARNING,ERROR' integer to a string: INFO,WARNING,ERROR == INFO,WARNING,ERROR (expected), passed
2024-10-16 17:34:56,637 TADA INFO assertion 26, Convert 'INFO,WARNING,CRITICAL' integer to a string: INFO,WARNING,CRITICAL == INFO,WARNING,CRITICAL (expected), passed
2024-10-16 17:34:56,742 TADA INFO assertion 27, Convert 'INFO,ERROR,CRITICAL' integer to a string: INFO,ERROR,CRITICAL == INFO,ERROR,CRITICAL (expected), passed
2024-10-16 17:34:56,861 TADA INFO assertion 28, Convert 'WARNING,ERROR,CRITICAL' integer to a string: WARNING,ERROR,CRITICAL == WARNING,ERROR,CRITICAL (expected), passed
2024-10-16 17:34:56,986 TADA INFO assertion 29, Convert 'DEBUG,INFO,WARNING,ERROR' integer to a string: DEBUG,INFO,WARNING,ERROR == DEBUG,INFO,WARNING,ERROR (expected), passed
2024-10-16 17:34:57,087 TADA INFO assertion 30, Convert 'DEBUG,INFO,WARNING,CRITICAL' integer to a string: DEBUG,INFO,WARNING,CRITICAL == DEBUG,INFO,WARNING,CRITICAL (expected), passed
2024-10-16 17:34:57,196 TADA INFO assertion 31, Convert 'DEBUG,INFO,ERROR,CRITICAL' integer to a string: DEBUG,INFO,ERROR,CRITICAL == DEBUG,INFO,ERROR,CRITICAL (expected), passed
2024-10-16 17:34:57,313 TADA INFO assertion 32, Convert 'DEBUG,WARNING,ERROR,CRITICAL' integer to a string: DEBUG,WARNING,ERROR,CRITICAL == DEBUG,WARNING,ERROR,CRITICAL (expected), passed
2024-10-16 17:34:57,418 TADA INFO assertion 33, Convert 'INFO,WARNING,ERROR,CRITICAL' integer to a string: INFO,WARNING,ERROR,CRITICAL == INFO,WARNING,ERROR,CRITICAL (expected), passed
2024-10-16 17:34:57,532 TADA INFO assertion 34, Convert 'DEBUG,INFO,WARNING,ERROR,CRITICAL' integer to a string: DEBUG,INFO,WARNING,ERROR,CRITICAL == DEBUG,INFO,WARNING,ERROR,CRITICAL (expected), passed
2024-10-16 17:34:57,657 TADA INFO assertion 35, Convert 'DEBUG,' integer to a string: DEBUG, == DEBUG, (expected), passed
2024-10-16 17:34:57,758 TADA INFO assertion 36, Convert 'INFO,' integer to a string: INFO, == INFO, (expected), passed
2024-10-16 17:34:57,862 TADA INFO assertion 37, Convert 'WARNING,' integer to a string: WARNING, == WARNING, (expected), passed
2024-10-16 17:34:57,974 TADA INFO assertion 38, Convert 'ERROR,' integer to a string: ERROR, == ERROR, (expected), passed
2024-10-16 17:34:58,084 TADA INFO assertion 39, Convert 'CRITICAL,' integer to a string: CRITICAL, == CRITICAL, (expected), passed
2024-10-16 17:34:58,193 TADA INFO assertion 40, Convert an invalid integer to a level string: (null) == (null) (expected), passed
2024-10-16 17:34:58,314 TADA INFO assertion 41, Convert the 'DEBUG,INFO' to an integer: 3 == 3 (expected), passed
2024-10-16 17:34:58,430 TADA INFO assertion 42, Convert the 'DEBUG,WARNING' to an integer: 5 == 5 (expected), passed
2024-10-16 17:34:58,538 TADA INFO assertion 43, Convert the 'DEBUG,ERROR' to an integer: 9 == 9 (expected), passed
2024-10-16 17:34:58,657 TADA INFO assertion 44, Convert the 'DEBUG,CRITICAL' to an integer: 17 == 17 (expected), passed
2024-10-16 17:34:58,770 TADA INFO assertion 45, Convert the 'INFO,WARNING' to an integer: 6 == 6 (expected), passed
2024-10-16 17:34:58,887 TADA INFO assertion 46, Convert the 'INFO,ERROR' to an integer: 10 == 10 (expected), passed
2024-10-16 17:34:58,995 TADA INFO assertion 47, Convert the 'INFO,CRITICAL' to an integer: 18 == 18 (expected), passed
2024-10-16 17:34:59,120 TADA INFO assertion 48, Convert the 'WARNING,ERROR' to an integer: 12 == 12 (expected), passed
2024-10-16 17:34:59,226 TADA INFO assertion 49, Convert the 'WARNING,CRITICAL' to an integer: 20 == 20 (expected), passed
2024-10-16 17:34:59,325 TADA INFO assertion 50, Convert the 'ERROR,CRITICAL' to an integer: 24 == 24 (expected), passed
2024-10-16 17:34:59,432 TADA INFO assertion 51, Convert the 'DEBUG,INFO,WARNING' to an integer: 7 == 7 (expected), passed
2024-10-16 17:34:59,545 TADA INFO assertion 52, Convert the 'DEBUG,INFO,ERROR' to an integer: 11 == 11 (expected), passed
2024-10-16 17:34:59,652 TADA INFO assertion 53, Convert the 'DEBUG,INFO,CRITICAL' to an integer: 19 == 19 (expected), passed
2024-10-16 17:34:59,770 TADA INFO assertion 54, Convert the 'DEBUG,WARNING,ERROR' to an integer: 13 == 13 (expected), passed
2024-10-16 17:34:59,888 TADA INFO assertion 55, Convert the 'DEBUG,WARNING,CRITICAL' to an integer: 21 == 21 (expected), passed
2024-10-16 17:34:59,997 TADA INFO assertion 56, Convert the 'DEBUG,ERROR,CRITICAL' to an integer: 25 == 25 (expected), passed
2024-10-16 17:35:00,098 TADA INFO assertion 57, Convert the 'INFO,WARNING,ERROR' to an integer: 14 == 14 (expected), passed
2024-10-16 17:35:00,213 TADA INFO assertion 58, Convert the 'INFO,WARNING,CRITICAL' to an integer: 22 == 22 (expected), passed
2024-10-16 17:35:00,315 TADA INFO assertion 59, Convert the 'INFO,ERROR,CRITICAL' to an integer: 26 == 26 (expected), passed
2024-10-16 17:35:00,423 TADA INFO assertion 60, Convert the 'WARNING,ERROR,CRITICAL' to an integer: 28 == 28 (expected), passed
2024-10-16 17:35:00,536 TADA INFO assertion 61, Convert the 'DEBUG,INFO,WARNING,ERROR' to an integer: 15 == 15 (expected), passed
2024-10-16 17:35:00,652 TADA INFO assertion 62, Convert the 'DEBUG,INFO,WARNING,CRITICAL' to an integer: 23 == 23 (expected), passed
2024-10-16 17:35:00,763 TADA INFO assertion 63, Convert the 'DEBUG,INFO,ERROR,CRITICAL' to an integer: 27 == 27 (expected), passed
2024-10-16 17:35:00,866 TADA INFO assertion 64, Convert the 'DEBUG,WARNING,ERROR,CRITICAL' to an integer: 29 == 29 (expected), passed
2024-10-16 17:35:00,978 TADA INFO assertion 65, Convert the 'INFO,WARNING,ERROR,CRITICAL' to an integer: 30 == 30 (expected), passed
2024-10-16 17:35:01,088 TADA INFO assertion 66, Convert the 'DEBUG,INFO,WARNING,ERROR,CRITICAL' to an integer: 31 == 31 (expected), passed
2024-10-16 17:35:01,193 TADA INFO assertion 67, Convert the 'DEBUG,' to an integer: 1 == 1 (expected), passed
2024-10-16 17:35:01,307 TADA INFO assertion 68, Convert the 'INFO,' to an integer: 2 == 2 (expected), passed
2024-10-16 17:35:01,415 TADA INFO assertion 69, Convert the 'WARNING,' to an integer: 4 == 4 (expected), passed
2024-10-16 17:35:01,510 TADA INFO assertion 70, Convert the 'ERROR,' to an integer: 8 == 8 (expected), passed
2024-10-16 17:35:01,623 TADA INFO assertion 71, Convert the 'CRITICAL,' to an integer: 16 == 16 (expected), passed
2024-10-16 17:35:01,750 TADA INFO assertion 72, Convert the 'DEBUG' to an integer: 31 == 31 (expected), passed
2024-10-16 17:35:01,861 TADA INFO assertion 73, Convert the 'INFO' to an integer: 30 == 30 (expected), passed
2024-10-16 17:35:01,972 TADA INFO assertion 74, Convert the 'WARNING' to an integer: 28 == 28 (expected), passed
2024-10-16 17:35:02,083 TADA INFO assertion 75, Convert the 'ERROR' to an integer: 24 == 24 (expected), passed
2024-10-16 17:35:02,189 TADA INFO assertion 76, Convert the 'CRITICAL' to an integer: 16 == 16 (expected), passed
2024-10-16 17:35:02,294 TADA INFO assertion 77, Convert an invalid level string to an integer: -22 == -22 (expected), passed
2024-10-16 17:35:02,926 TADA INFO assertion 78, Verify that no messages were printed when the level is QUIET.: No messages were printed., passed
2024-10-16 17:35:03,246 TADA INFO assertion 79, Verify that messages of DEBUG,INFO were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:03,589 TADA INFO assertion 80, Verify that messages of DEBUG,WARNING were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:03,901 TADA INFO assertion 81, Verify that messages of DEBUG,ERROR were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:04,234 TADA INFO assertion 82, Verify that messages of DEBUG,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:04,570 TADA INFO assertion 83, Verify that messages of INFO,WARNING were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:04,891 TADA INFO assertion 84, Verify that messages of INFO,ERROR were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:05,225 TADA INFO assertion 85, Verify that messages of INFO,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:05,539 TADA INFO assertion 86, Verify that messages of WARNING,ERROR were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:05,857 TADA INFO assertion 87, Verify that messages of WARNING,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:06,184 TADA INFO assertion 88, Verify that messages of ERROR,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:06,512 TADA INFO assertion 89, Verify that messages of DEBUG,INFO,WARNING were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:06,841 TADA INFO assertion 90, Verify that messages of DEBUG,INFO,ERROR were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:07,194 TADA INFO assertion 91, Verify that messages of DEBUG,INFO,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:07,539 TADA INFO assertion 92, Verify that messages of DEBUG,WARNING,ERROR were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:07,844 TADA INFO assertion 93, Verify that messages of DEBUG,WARNING,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:08,180 TADA INFO assertion 94, Verify that messages of DEBUG,ERROR,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:08,506 TADA INFO assertion 95, Verify that messages of INFO,WARNING,ERROR were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:08,850 TADA INFO assertion 96, Verify that messages of INFO,WARNING,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:09,166 TADA INFO assertion 97, Verify that messages of INFO,ERROR,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:09,498 TADA INFO assertion 98, Verify that messages of WARNING,ERROR,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:09,824 TADA INFO assertion 99, Verify that messages of DEBUG,INFO,WARNING,ERROR were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:10,167 TADA INFO assertion 100, Verify that messages of DEBUG,INFO,WARNING,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:10,481 TADA INFO assertion 101, Verify that messages of DEBUG,INFO,ERROR,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:10,807 TADA INFO assertion 102, Verify that messages of DEBUG,WARNING,ERROR,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:11,128 TADA INFO assertion 103, Verify that messages of INFO,WARNING,ERROR,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:11,460 TADA INFO assertion 104, Verify that messages of DEBUG,INFO,WARNING,ERROR,CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:11,776 TADA INFO assertion 105, Verify that messages of DEBUG, were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:12,122 TADA INFO assertion 106, Verify that messages of INFO, were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:12,459 TADA INFO assertion 107, Verify that messages of WARNING, were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:12,778 TADA INFO assertion 108, Verify that messages of ERROR, were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:13,107 TADA INFO assertion 109, Verify that messages of CRITICAL, were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:13,461 TADA INFO assertion 110, Verify that messages of DEBUG were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:13,788 TADA INFO assertion 111, Verify that messages of INFO were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:14,135 TADA INFO assertion 112, Verify that messages of WARNING were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:14,486 TADA INFO assertion 113, Verify that messages of ERROR were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:14,796 TADA INFO assertion 114, Verify that messages of CRITICAL were reported.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:15,433 TADA INFO assertion 116, Verify that ovis_log_close() works properly: ovis_log_close() works properly., passed
2024-10-16 17:35:17,304 TADA INFO assertion 115, Verify that applications can open, rename, and reopen log files to perform log rotation.: ovis_log supports open, rename (external), and reopen., passed
2024-10-16 17:35:17,712 TADA INFO assertion 117, Test a ovis_log_register() call with valid arguments: [{'idx': 0, 'return_code': 0, 'name': 'my_subsys', 'desc': 'my_subsys_desc', 'level': -1}] == [{'idx': 0, 'return_code': 0, 'name': 'my_subsys', 'desc': 'my_subsys_desc', 'level': -1}], passed
2024-10-16 17:35:17,834 TADA INFO assertion 118, Test a ovis_log_register() call with NULL name: [{'idx': 0, 'return_code': 22}] == [{'idx': 0, 'return_code': 22}], passed
2024-10-16 17:35:17,935 TADA INFO assertion 119, Test a ovis_log_register() call with NULL desc: [{'idx': 0, 'return_code': 22}] == [{'idx': 0, 'return_code': 22}], passed
2024-10-16 17:35:18,044 TADA INFO assertion 120, Test a ovis_log_register() call with an existing subsystem: [{'idx': 0, 'return_code': 0, 'name': 'my_subsys', 'desc': 'my_subsys_desc', 'level': -1}, {'idx': 1, 'return_code': 17}] == [{'idx': 0, 'return_code': 0, 'name': 'my_subsys', 'desc': 'my_subsys_desc', 'level': -1}, {'idx': 1, 'return_code': 17}], passed
2024-10-16 17:35:18,675 TADA INFO assertion 122, Verify that messages of DEBUG,INFO were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:19,016 TADA INFO assertion 123, Verify that messages of DEBUG,WARNING were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:19,328 TADA INFO assertion 124, Verify that messages of DEBUG,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:19,645 TADA INFO assertion 125, Verify that messages of DEBUG,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:19,977 TADA INFO assertion 126, Verify that messages of INFO,WARNING were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:20,312 TADA INFO assertion 127, Verify that messages of INFO,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:20,633 TADA INFO assertion 128, Verify that messages of INFO,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:20,929 TADA INFO assertion 129, Verify that messages of WARNING,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:21,273 TADA INFO assertion 130, Verify that messages of WARNING,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:21,586 TADA INFO assertion 131, Verify that messages of ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:21,902 TADA INFO assertion 132, Verify that messages of DEBUG,INFO,WARNING were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:22,247 TADA INFO assertion 133, Verify that messages of DEBUG,INFO,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:22,618 TADA INFO assertion 134, Verify that messages of DEBUG,INFO,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:22,942 TADA INFO assertion 135, Verify that messages of DEBUG,WARNING,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:23,267 TADA INFO assertion 136, Verify that messages of DEBUG,WARNING,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:23,586 TADA INFO assertion 137, Verify that messages of DEBUG,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:23,915 TADA INFO assertion 138, Verify that messages of INFO,WARNING,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:24,267 TADA INFO assertion 139, Verify that messages of INFO,WARNING,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:24,580 TADA INFO assertion 140, Verify that messages of INFO,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:24,918 TADA INFO assertion 141, Verify that messages of WARNING,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:25,267 TADA INFO assertion 142, Verify that messages of DEBUG,INFO,WARNING,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:25,618 TADA INFO assertion 143, Verify that messages of DEBUG,INFO,WARNING,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:25,941 TADA INFO assertion 144, Verify that messages of DEBUG,INFO,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:26,273 TADA INFO assertion 145, Verify that messages of DEBUG,WARNING,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:26,599 TADA INFO assertion 146, Verify that messages of INFO,WARNING,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:26,920 TADA INFO assertion 147, Verify that messages of DEBUG,INFO,WARNING,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:27,248 TADA INFO assertion 148, Verify that messages of DEBUG, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:27,563 TADA INFO assertion 149, Verify that messages of INFO, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:27,898 TADA INFO assertion 150, Verify that messages of WARNING, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:28,248 TADA INFO assertion 151, Verify that messages of ERROR, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:28,582 TADA INFO assertion 152, Verify that messages of CRITICAL, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:28,907 TADA INFO assertion 153, Verify that messages of DEBUG were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:29,216 TADA INFO assertion 154, Verify that messages of INFO were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:29,532 TADA INFO assertion 155, Verify that messages of WARNING were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:29,851 TADA INFO assertion 156, Verify that messages of ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:30,171 TADA INFO assertion 157, Verify that messages of CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:30,504 TADA INFO assertion 158, Verify that messages of DEBUG,INFO were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:30,839 TADA INFO assertion 159, Verify that messages of DEBUG,WARNING were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:31,185 TADA INFO assertion 160, Verify that messages of DEBUG,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:31,506 TADA INFO assertion 161, Verify that messages of DEBUG,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:31,844 TADA INFO assertion 162, Verify that messages of INFO,WARNING were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:32,165 TADA INFO assertion 163, Verify that messages of INFO,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:32,503 TADA INFO assertion 164, Verify that messages of INFO,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:32,806 TADA INFO assertion 165, Verify that messages of WARNING,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:33,164 TADA INFO assertion 166, Verify that messages of WARNING,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:33,504 TADA INFO assertion 167, Verify that messages of ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:33,843 TADA INFO assertion 168, Verify that messages of DEBUG,INFO,WARNING were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:34,176 TADA INFO assertion 169, Verify that messages of DEBUG,INFO,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:34,499 TADA INFO assertion 170, Verify that messages of DEBUG,INFO,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:34,848 TADA INFO assertion 171, Verify that messages of DEBUG,WARNING,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:35,143 TADA INFO assertion 172, Verify that messages of DEBUG,WARNING,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:35,458 TADA INFO assertion 173, Verify that messages of DEBUG,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:35,793 TADA INFO assertion 174, Verify that messages of INFO,WARNING,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:36,116 TADA INFO assertion 175, Verify that messages of INFO,WARNING,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:36,426 TADA INFO assertion 176, Verify that messages of INFO,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:36,738 TADA INFO assertion 177, Verify that messages of WARNING,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:37,051 TADA INFO assertion 178, Verify that messages of DEBUG,INFO,WARNING,ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:37,357 TADA INFO assertion 179, Verify that messages of DEBUG,INFO,WARNING,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:37,668 TADA INFO assertion 180, Verify that messages of DEBUG,INFO,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:38,020 TADA INFO assertion 181, Verify that messages of DEBUG,WARNING,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:38,343 TADA INFO assertion 182, Verify that messages of INFO,WARNING,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:38,655 TADA INFO assertion 183, Verify that messages of DEBUG,INFO,WARNING,ERROR,CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:39,001 TADA INFO assertion 184, Verify that messages of DEBUG, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:39,329 TADA INFO assertion 185, Verify that messages of INFO, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:39,665 TADA INFO assertion 186, Verify that messages of WARNING, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:39,979 TADA INFO assertion 187, Verify that messages of ERROR, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:40,320 TADA INFO assertion 188, Verify that messages of CRITICAL, were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:40,633 TADA INFO assertion 189, Verify that messages of DEBUG were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:40,974 TADA INFO assertion 190, Verify that messages of INFO were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:41,332 TADA INFO assertion 191, Verify that messages of WARNING were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:41,666 TADA INFO assertion 192, Verify that messages of ERROR were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:42,024 TADA INFO assertion 193, Verify that messages of CRITICAL were reported from a subsystem.: Only the messages with the level not less than 'ERROR' were logged., passed
2024-10-16 17:35:42,702 TADA INFO assertion 195, Verify that ovis_log_set_level_by_regex() returns an error when the given regular expression string is invalid.: 'result=22' in 'Wed Oct 16 17:35:42 2024:         : test: result=22
', passed
2024-10-16 17:35:43,027 TADA INFO assertion 194, Verify that ovis_log_set_level_by_regex() returns ENOENT when the given regular expression string doesn't match any logs.: 'result=2' in 'Wed Oct 16 17:35:42 2024:         : test: result=2
', passed
2024-10-16 17:35:43,375 TADA INFO assertion 196, Verify that ovis_log_set_level_by_regex() sets the level of the matched log subsystems to the given value.: ('config:' in 'Wed Oct 16 17:35:43 2024:         : config: ALWAYS' and (('CRITICAL' in 'Wed Oct 16 17:35:43 2024:         : config: ALWAYS') or ('ALWAYS' in Wed Oct 16 17:35:43 2024:         : config: ALWAYS)), passed
2024-10-16 17:35:44,018 TADA INFO assertion 197, Verify that ovis_log_list() works correctly.: '[{'name': 'test (default)', 'desc': 'The default log subsystem', 'level': 'CRITICAL,'}, {'name': 'config', 'desc': 'config', 'level': 'default'}, {'name': 'xprt', 'desc': 'xprt', 'level': 'ERROR,CRITICAL'}, {'name': 'xprt.ldms', 'desc': 'xprt.ldms', 'level': 'INFO,CRITICAL'}, {'name': 'xprt.zap', 'desc': 'xprt.zap', 'level': 'WARNING,'}]' == '[{'name': 'test (default)', 'desc': 'The default log subsystem', 'level': 'CRITICAL,'}, {'name': 'config', 'desc': 'config', 'level': 'default'}, {'name': 'xprt', 'desc': 'xprt', 'level': 'ERROR,CRITICAL'}, {'name': 'xprt.ldms', 'desc': 'xprt.ldms', 'level': 'INFO,CRITICAL'}, {'name': 'xprt.zap', 'desc': 'xprt.zap', 'level': 'WARNING,'}]', passed
2024-10-16 17:35:44,018 TADA INFO test libovis_log_test ended
2024-10-16 17:35:55 INFO: ----------------------------------------------
2024-10-16 17:35:57 INFO: ======== ldmsd_long_config_test ========
2024-10-16 17:35:57 INFO: CMD: python3 ldmsd_long_config_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_long_config_test
2024-10-16 17:35:57,907 TADA INFO starting test `ldmsd_long_config_line`
2024-10-16 17:35:57,907 TADA INFO   test-id: 01305a6a0c3d6aaa391d2c16734ee77f212fb804199b7bd59156908d5e6d8f33
2024-10-16 17:35:57,907 TADA INFO   test-suite: LDMSD
2024-10-16 17:35:57,907 TADA INFO   test-name: ldmsd_long_config_line
2024-10-16 17:35:57,908 TADA INFO   test-user: narate
2024-10-16 17:35:57,908 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:35:57,908 __main__ INFO ---Get or create the cluster --
2024-10-16 17:36:14,445 __main__ INFO --- Start daemons ---
2024-10-16 17:36:40,528 TADA INFO assertion 1, LDMSD correctly processes a config line in a config file: LDMSD processed the long config line in the config file correctly., passed
2024-10-16 17:36:41,086 TADA INFO assertion 2, LDMSD correctly handle a config line from ldmsd_controller: LDMSD receives the correct message from ldmsd_controller., passed
2024-10-16 17:36:41,755 TADA INFO assertion 3, LDMSD correctly handle a config line from ldmsctl: LDMSD receives the correct message from ldmsctl., passed
2024-10-16 17:36:41,755 TADA INFO test ldmsd_long_config_line ended
2024-10-16 17:36:54 INFO: ----------------------------------------------
2024-10-16 17:36:56 INFO: ======== ldms_rail_test ========
2024-10-16 17:36:56 INFO: CMD: python3 ldms_rail_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_rail_test
2024-10-16 17:36:56,792 TADA INFO starting test `ldms_rail_test`
2024-10-16 17:36:56,792 TADA INFO   test-id: 314d6420d0cf2b72f84ce57fe84ab4928ffea8eebf2f60434ea6a132c2b96cb1
2024-10-16 17:36:56,793 TADA INFO   test-suite: LDMSD
2024-10-16 17:36:56,793 TADA INFO   test-name: ldms_rail_test
2024-10-16 17:36:56,793 TADA INFO   test-user: narate
2024-10-16 17:36:56,793 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:36:56,793 __main__ INFO -- Get or create the cluster --
2024-10-16 17:37:12,994 __main__ INFO -- Start daemons --
2024-10-16 17:37:17,808 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:37:19,810 __main__ INFO start ldms_rail_server.py and ldms_rail_client.py interactive sessions
2024-10-16 17:37:22,831 TADA INFO assertion 1, Start interactive LDMS server: OK, passed
2024-10-16 17:37:25,849 TADA INFO assertion 2, Start interactive LDMS client: OK, passed
2024-10-16 17:37:29,453 TADA INFO assertion 3, Client rail has 8 endpoints on 8 thread pools: OK, passed
2024-10-16 17:37:33,058 TADA INFO assertion 4, Server rail has 8 endpoints on 8 thread pools: OK, passed
2024-10-16 17:37:36,663 TADA INFO assertion 5, Sets on client are processed by different threads: OK, passed
2024-10-16 17:37:40,268 TADA INFO assertion 6, Verify sets on the client: OK, passed
2024-10-16 17:37:43,287 TADA INFO assertion 7, Start interactive LDMS client2: OK, passed
2024-10-16 17:37:46,891 TADA INFO assertion 8, Client2 rail has 8 endpoints on 4 thread pools: OK, passed
2024-10-16 17:37:49,909 TADA INFO assertion 9, Client3 (wrong auth) cannot connect: OK, passed
2024-10-16 17:37:52,927 TADA INFO assertion 10, Start interactive client4 (for push mode): OK, passed
2024-10-16 17:37:52,927 __main__ INFO waiting push ...
2024-10-16 17:37:54,930 __main__ INFO server: sampling new data (2)
2024-10-16 17:37:59,536 __main__ INFO client4: set pushes received
2024-10-16 17:37:59,536 __main__ INFO client4: verifying data in sets
2024-10-16 17:38:03,141 __main__ INFO client4: verifying threads-sets-endpoints spread
2024-10-16 17:38:13,954 TADA INFO assertion 11, Client4 got push callback from the corresponding thread: OK, passed
2024-10-16 17:38:16,972 TADA INFO assertion 12, Client5 started (for clean-up path test): OK, passed
2024-10-16 17:38:16,972 __main__ INFO xprt close by client1
2024-10-16 17:38:29,788 TADA INFO assertion 13, Active-side close: client1 clean up: OK, passed
2024-10-16 17:38:33,393 TADA INFO assertion 14, Active-side close: server-side clean up: OK, passed
2024-10-16 17:38:49,813 TADA INFO assertion 15, Passive-side close: client2 clean up: OK, passed
2024-10-16 17:38:49,813 TADA INFO assertion 16, Passive-side close: server-side clean up: OK, passed
2024-10-16 17:38:55,420 TADA INFO assertion 17, Active-side term: server-side clean up: OK, passed
2024-10-16 17:39:02,629 TADA INFO assertion 18, Passive-side term: client5 clean up: OK, passed
2024-10-16 17:39:23,086 TADA INFO assertion 37, Passive endpoint recv_quota override: verified on both cli and srv, passed
2024-10-16 17:39:30,295 TADA INFO assertion 38, Passive endpoint recv_rate_limit override: verified on both cli and srv, passed
2024-10-16 17:39:41,108 TADA INFO assertion 19, server -> client overspending send: error message verified, passed
2024-10-16 17:39:51,922 TADA INFO assertion 20, client -> server overspending send: error message verified, passed
2024-10-16 17:39:55,527 TADA INFO assertion 21, verify send quota on the server: OK, passed
2024-10-16 17:39:59,132 TADA INFO assertion 22, verify send quota on the client: OK, passed
2024-10-16 17:40:07,242 TADA INFO assertion 23, server unblock, verify recv data: recv data verified, passed
2024-10-16 17:40:15,352 TADA INFO assertion 24, client unblock, verify recv data: recv data verified, passed
2024-10-16 17:40:18,957 TADA INFO assertion 25, verify send quota on the server: OK, passed
2024-10-16 17:40:22,562 TADA INFO assertion 26, verify send quota on the client: OK, passed
2024-10-16 17:40:26,167 TADA INFO assertion 27, server -> client send after get quota back: OK, passed
2024-10-16 17:40:29,772 TADA INFO assertion 28, client -> server send after get quota back: OK, passed
2024-10-16 17:40:33,377 TADA INFO assertion 29, verify send quota on the server: OK, passed
2024-10-16 17:40:36,982 TADA INFO assertion 30, verify send quota on the client: OK, passed
2024-10-16 17:40:40,587 TADA INFO assertion 31, server unblock, verify recv data: OK, passed
2024-10-16 17:40:44,192 TADA INFO assertion 32, client unblock, verify recv data: OK, passed
2024-10-16 17:40:47,797 TADA INFO assertion 33, verify send quota on the server: OK, passed
2024-10-16 17:40:51,401 TADA INFO assertion 34, verify send quota on the client: OK, passed
2024-10-16 17:40:55,006 TADA INFO assertion 35, verify send-quota deposits on the server: expected [16, 32, 32], got [16, 32, 32], passed
2024-10-16 17:40:58,611 TADA INFO assertion 36, verify send-quota deposits on the client: expected [16, 32, 32], got [16, 32, 32], passed
2024-10-16 17:40:58,612 TADA INFO test ldms_rail_test ended
2024-10-16 17:41:10 INFO: ----------------------------------------------
2024-10-16 17:41:12 INFO: ======== ldmsd_rail_test ========
2024-10-16 17:41:12 INFO: CMD: python3 ldmsd_rail_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_rail_test
2024-10-16 17:41:13,667 TADA INFO starting test `ldmsd_rail_test`
2024-10-16 17:41:13,667 TADA INFO   test-id: 9c9f04b9131360405a18d77074d3b55f7e1aef3a958e8ff4b11fd2d38ec39765
2024-10-16 17:41:13,667 TADA INFO   test-suite: LDMSD
2024-10-16 17:41:13,667 TADA INFO   test-name: ldmsd_rail_test
2024-10-16 17:41:13,667 TADA INFO   test-user: narate
2024-10-16 17:41:13,667 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:41:13,668 __main__ INFO -- Get or create the cluster --
2024-10-16 17:41:29,888 __main__ INFO -- Start daemons --
2024-10-16 17:41:49,783 root INFO starting /tada-src/python/ldmsd_rail_srv.py on narate-ldmsd_rail_test-04c74b7-node-2 
2024-10-16 17:41:51,997 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:41:54,501 TADA INFO assertion 1, agg2-srv xprt has correct number of rail endpoints (test prdcr_add 'rail' parameter: len == 4, passed
2024-10-16 17:41:55,002 TADA INFO assertion 2, agg2-srv xprt has correct send quota (test prdcr_add 'quota' parameter): quota: {obj}, passed
2024-10-16 17:41:56,631 TADA INFO assertion 3, srv-agg2 stream publish: OK, passed
2024-10-16 17:41:57,132 TADA INFO assertion 4, srv-agg2 stream publish exceeding send quota: checking..., passed
2024-10-16 17:41:58,636 TADA INFO assertion 5, srv-samp xprt has correct number of rail endpoints: len == 4, passed
2024-10-16 17:41:59,138 TADA INFO assertion 6, srv-samp xprt has correct send quota (test ldmsd -C option): quota: {obj}, passed
2024-10-16 17:42:00,753 TADA INFO assertion 7, srv-samp stream publish: OK, passed
2024-10-16 17:42:01,254 TADA INFO assertion 8, srv-samp stream publish exceeding send quota: checking..., passed
2024-10-16 17:42:01,255 TADA INFO test ldmsd_rail_test ended
2024-10-16 17:42:13 INFO: ----------------------------------------------
2024-10-16 17:42:15 INFO: ======== ldms_stream_test ========
2024-10-16 17:42:15 INFO: CMD: python3 ldms_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_stream_test
2024-10-16 17:42:16,502 TADA INFO starting test `ldms_stream_test`
2024-10-16 17:42:16,502 TADA INFO   test-id: 172ba19db102d7182858521dbf08eba3471051d0446895c73e7dc325e438c123
2024-10-16 17:42:16,502 TADA INFO   test-suite: LDMSD
2024-10-16 17:42:16,502 TADA INFO   test-name: ldms_stream_test
2024-10-16 17:42:16,502 TADA INFO   test-user: narate
2024-10-16 17:42:16,503 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:42:16,503 __main__ INFO -- Get or create the cluster --
2024-10-16 17:42:47,963 __main__ INFO -- Adding 'foo' and 'bar' users --
2024-10-16 17:42:58,661 __main__ INFO -- Start daemons --
2024-10-16 17:43:11,300 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:43:13,303 __main__ INFO start interactive stream servers
2024-10-16 17:43:13,303 __main__ INFO starting /tada-src/python/ldms_stream_server.py on narate-ldms_stream_test-04c74b7-node-7 
2024-10-16 17:43:16,322 __main__ INFO starting /tada-src/python/ldms_stream_server.py on narate-ldms_stream_test-04c74b7-node-6 
2024-10-16 17:43:19,342 __main__ INFO starting /tada-src/python/ldms_stream_server.py on narate-ldms_stream_test-04c74b7-node-5 
2024-10-16 17:43:22,359 __main__ INFO starting /tada-src/python/ldms_stream_server.py on narate-ldms_stream_test-04c74b7-node-4 
2024-10-16 17:43:25,378 __main__ INFO starting /tada-src/python/ldms_stream_server.py on narate-ldms_stream_test-04c74b7-node-3 
2024-10-16 17:43:28,397 __main__ INFO starting /tada-src/python/ldms_stream_server.py on narate-ldms_stream_test-04c74b7-node-2 
2024-10-16 17:43:31,415 __main__ INFO starting /tada-src/python/ldms_stream_server.py on narate-ldms_stream_test-04c74b7-node-1 
2024-10-16 17:43:34,432 __main__ INFO starting /tada-src/python/ldms_stream_publish.py on narate-ldms_stream_test-04c74b7-node-4 
2024-10-16 17:43:37,951 __main__ INFO starting /tada-src/python/ldms_stream_publish.py on narate-ldms_stream_test-04c74b7-node-5 
2024-10-16 17:43:41,470 __main__ INFO starting /tada-src/python/ldms_stream_publish.py on narate-ldms_stream_test-04c74b7-node-6 
2024-10-16 17:43:44,988 __main__ INFO starting /tada-src/python/ldms_stream_publish.py on narate-ldms_stream_test-04c74b7-node-7 
2024-10-16 17:43:48,507 __main__ INFO starting /tada-src/python/ldms_stream_publish.py on narate-ldms_stream_test-04c74b7-node-4 as foo
2024-10-16 17:43:52,026 __main__ INFO starting /tada-src/python/ldms_stream_publish.py on narate-ldms_stream_test-04c74b7-node-4 as bar
2024-10-16 17:43:55,545 __main__ INFO starting /tada-src/python/ldms_stream_client.py on narate-ldms_stream_test-04c74b7-node-8 as foo
2024-10-16 17:43:59,064 TADA INFO assertion 1, Publishing oversize data results in an error: checking..., passed
2024-10-16 17:43:59,577 __main__ INFO getting data from srv1
2024-10-16 17:44:02,083 __main__ INFO getting data from srv2
2024-10-16 17:44:04,590 __main__ INFO getting data from srv3
2024-10-16 17:44:07,096 __main__ INFO getting data from srv4
2024-10-16 17:44:09,602 __main__ INFO getting data from srv5
2024-10-16 17:44:12,108 __main__ INFO getting data from srv6
2024-10-16 17:44:14,614 __main__ INFO getting data from srv7
2024-10-16 17:44:17,119 __main__ INFO getting data from cli8foo
2024-10-16 17:44:19,626 TADA INFO assertion 2, JSON support (l3-stream): client data verified, passed
2024-10-16 17:44:19,627 __main__ INFO publishing 'four' on l3-stream by pub4
2024-10-16 17:44:20,129 __main__ INFO publishing 'five' on l3-stream by pub5
2024-10-16 17:44:20,631 __main__ INFO publishing 'six' on l3-stream by pub6
2024-10-16 17:44:21,134 __main__ INFO publishing 'seven' on l3-stream by pub7
2024-10-16 17:44:21,637 TADA INFO assertion 301, send-quota taken: quota: [114], passed
2024-10-16 17:44:21,637 __main__ INFO obtaining all client data (0)
2024-10-16 17:44:21,637 __main__ INFO getting data from srv1
2024-10-16 17:44:24,144 __main__ INFO getting data from srv2
2024-10-16 17:44:26,650 __main__ INFO getting data from srv3
2024-10-16 17:44:29,156 __main__ INFO getting data from srv4
2024-10-16 17:44:31,663 __main__ INFO getting data from srv5
2024-10-16 17:44:34,169 __main__ INFO getting data from srv6
2024-10-16 17:44:36,676 __main__ INFO getting data from srv7
2024-10-16 17:44:39,182 __main__ INFO getting data from cli8foo
2024-10-16 17:44:41,689 __main__ INFO obtaining all client data (1)
2024-10-16 17:44:41,689 __main__ INFO getting data from srv1
2024-10-16 17:44:44,195 __main__ INFO getting data from srv2
2024-10-16 17:44:46,702 __main__ INFO getting data from srv3
2024-10-16 17:44:49,208 __main__ INFO getting data from srv4
2024-10-16 17:44:51,714 __main__ INFO getting data from srv5
2024-10-16 17:44:54,219 __main__ INFO getting data from srv6
2024-10-16 17:44:56,725 __main__ INFO getting data from srv7
2024-10-16 17:44:59,231 __main__ INFO getting data from cli8foo
2024-10-16 17:45:01,737 __main__ INFO obtaining all client data (2)
2024-10-16 17:45:01,738 __main__ INFO getting data from srv1
2024-10-16 17:45:04,244 __main__ INFO getting data from srv2
2024-10-16 17:45:06,750 __main__ INFO getting data from srv3
2024-10-16 17:45:09,255 __main__ INFO getting data from srv4
2024-10-16 17:45:11,761 __main__ INFO getting data from srv5
2024-10-16 17:45:14,267 __main__ INFO getting data from srv6
2024-10-16 17:45:16,772 __main__ INFO getting data from srv7
2024-10-16 17:45:19,278 __main__ INFO getting data from cli8foo
2024-10-16 17:45:21,784 __main__ INFO obtaining all client data (3)
2024-10-16 17:45:21,785 __main__ INFO getting data from srv1
2024-10-16 17:45:24,291 __main__ INFO getting data from srv2
2024-10-16 17:45:26,796 __main__ INFO getting data from srv3
2024-10-16 17:45:29,302 __main__ INFO getting data from srv4
2024-10-16 17:45:31,808 __main__ INFO getting data from srv5
2024-10-16 17:45:34,314 __main__ INFO getting data from srv6
2024-10-16 17:45:36,820 __main__ INFO getting data from srv7
2024-10-16 17:45:39,325 __main__ INFO getting data from cli8foo
2024-10-16 17:45:42,333 TADA INFO assertion 302, send-quota returned: quota: [128], passed
2024-10-16 17:45:42,334 TADA INFO assertion 303, stream delivery spread among rails: tids: {204, 205}, passed
2024-10-16 17:45:42,335 TADA INFO assertion 3, l3-stream delivery: client data verified, passed
2024-10-16 17:45:42,335 __main__ INFO publishing 'four' on l2-stream by pub4
2024-10-16 17:45:42,837 __main__ INFO publishing 'five' on l2-stream by pub5
2024-10-16 17:45:43,339 __main__ INFO publishing 'six' on l2-stream by pub6
2024-10-16 17:45:43,841 __main__ INFO publishing 'seven' on l2-stream by pub7
2024-10-16 17:45:44,344 __main__ INFO obtaining all client data (0)
2024-10-16 17:45:44,344 __main__ INFO getting data from srv1
2024-10-16 17:45:46,851 __main__ INFO getting data from srv2
2024-10-16 17:45:49,357 __main__ INFO getting data from srv3
2024-10-16 17:45:51,864 __main__ INFO getting data from srv4
2024-10-16 17:45:54,370 __main__ INFO getting data from srv5
2024-10-16 17:45:56,877 __main__ INFO getting data from srv6
2024-10-16 17:45:59,383 __main__ INFO getting data from srv7
2024-10-16 17:46:01,890 __main__ INFO getting data from cli8foo
2024-10-16 17:46:04,396 __main__ INFO obtaining all client data (1)
2024-10-16 17:46:04,396 __main__ INFO getting data from srv1
2024-10-16 17:46:06,903 __main__ INFO getting data from srv2
2024-10-16 17:46:09,409 __main__ INFO getting data from srv3
2024-10-16 17:46:11,916 __main__ INFO getting data from srv4
2024-10-16 17:46:14,422 __main__ INFO getting data from srv5
2024-10-16 17:46:16,927 __main__ INFO getting data from srv6
2024-10-16 17:46:19,433 __main__ INFO getting data from srv7
2024-10-16 17:46:21,938 __main__ INFO getting data from cli8foo
2024-10-16 17:46:24,445 TADA INFO assertion 4, l2-stream delivery: client data verified, passed
2024-10-16 17:46:24,446 __main__ INFO publishing 'four' on l1-stream by pub4
2024-10-16 17:46:24,947 __main__ INFO publishing 'five' on l1-stream by pub5
2024-10-16 17:46:25,449 __main__ INFO publishing 'six' on l1-stream by pub6
2024-10-16 17:46:25,951 __main__ INFO publishing 'seven' on l1-stream by pub7
2024-10-16 17:46:26,454 __main__ INFO obtaining all client data (0)
2024-10-16 17:46:26,454 __main__ INFO getting data from srv1
2024-10-16 17:46:28,961 __main__ INFO getting data from srv2
2024-10-16 17:46:31,467 __main__ INFO getting data from srv3
2024-10-16 17:46:33,973 __main__ INFO getting data from srv4
2024-10-16 17:46:36,479 __main__ INFO getting data from srv5
2024-10-16 17:46:38,986 __main__ INFO getting data from srv6
2024-10-16 17:46:41,492 __main__ INFO getting data from srv7
2024-10-16 17:46:43,999 __main__ INFO getting data from cli8foo
2024-10-16 17:46:46,505 __main__ INFO obtaining all client data (1)
2024-10-16 17:46:46,505 __main__ INFO getting data from srv1
2024-10-16 17:46:49,012 __main__ INFO getting data from srv2
2024-10-16 17:46:51,517 __main__ INFO getting data from srv3
2024-10-16 17:46:54,024 __main__ INFO getting data from srv4
2024-10-16 17:46:56,529 __main__ INFO getting data from srv5
2024-10-16 17:46:59,035 __main__ INFO getting data from srv6
2024-10-16 17:47:01,540 __main__ INFO getting data from srv7
2024-10-16 17:47:04,046 __main__ INFO getting data from cli8foo
2024-10-16 17:47:06,553 TADA INFO assertion 5, l1-stream delivery: client data verified, passed
2024-10-16 17:47:06,554 __main__ INFO publishing 'four' on x-stream by pub4
2024-10-16 17:47:07,055 __main__ INFO publishing 'five' on x-stream by pub5
2024-10-16 17:47:07,557 __main__ INFO publishing 'six' on x-stream by pub6
2024-10-16 17:47:08,059 __main__ INFO publishing 'seven' on x-stream by pub7
2024-10-16 17:47:08,562 __main__ INFO obtaining all client data (0)
2024-10-16 17:47:08,562 __main__ INFO getting data from srv1
2024-10-16 17:47:11,068 __main__ INFO getting data from srv2
2024-10-16 17:47:13,574 __main__ INFO getting data from srv3
2024-10-16 17:47:16,080 __main__ INFO getting data from srv4
2024-10-16 17:47:18,586 __main__ INFO getting data from srv5
2024-10-16 17:47:21,092 __main__ INFO getting data from srv6
2024-10-16 17:47:23,599 __main__ INFO getting data from srv7
2024-10-16 17:47:26,105 __main__ INFO getting data from cli8foo
2024-10-16 17:47:28,611 __main__ INFO obtaining all client data (1)
2024-10-16 17:47:28,611 __main__ INFO getting data from srv1
2024-10-16 17:47:31,117 __main__ INFO getting data from srv2
2024-10-16 17:47:33,623 __main__ INFO getting data from srv3
2024-10-16 17:47:36,129 __main__ INFO getting data from srv4
2024-10-16 17:47:38,635 __main__ INFO getting data from srv5
2024-10-16 17:47:41,141 __main__ INFO getting data from srv6
2024-10-16 17:47:43,646 __main__ INFO getting data from srv7
2024-10-16 17:47:46,152 __main__ INFO getting data from cli8foo
2024-10-16 17:47:48,659 TADA INFO assertion 6, x-stream delivery: client data verified, passed
2024-10-16 17:47:48,659 __main__ INFO publishing 'four' on nada by pub4
2024-10-16 17:47:49,160 __main__ INFO publishing 'five' on nada by pub5
2024-10-16 17:47:49,662 __main__ INFO publishing 'six' on nada by pub6
2024-10-16 17:47:50,164 __main__ INFO publishing 'seven' on nada by pub7
2024-10-16 17:47:50,665 __main__ INFO obtaining all client data (0)
2024-10-16 17:47:50,666 __main__ INFO getting data from srv1
2024-10-16 17:47:53,171 __main__ INFO getting data from srv2
2024-10-16 17:47:55,677 __main__ INFO getting data from srv3
2024-10-16 17:47:58,182 __main__ INFO getting data from srv4
2024-10-16 17:48:00,689 __main__ INFO getting data from srv5
2024-10-16 17:48:03,194 __main__ INFO getting data from srv6
2024-10-16 17:48:05,700 __main__ INFO getting data from srv7
2024-10-16 17:48:08,206 __main__ INFO getting data from cli8foo
2024-10-16 17:48:10,712 __main__ INFO obtaining all client data (1)
2024-10-16 17:48:10,712 __main__ INFO getting data from srv1
2024-10-16 17:48:13,218 __main__ INFO getting data from srv2
2024-10-16 17:48:15,724 __main__ INFO getting data from srv3
2024-10-16 17:48:18,229 __main__ INFO getting data from srv4
2024-10-16 17:48:20,735 __main__ INFO getting data from srv5
2024-10-16 17:48:23,240 __main__ INFO getting data from srv6
2024-10-16 17:48:25,746 __main__ INFO getting data from srv7
2024-10-16 17:48:28,252 __main__ INFO getting data from cli8foo
2024-10-16 17:48:30,758 TADA INFO assertion 7, nada delivery: client data verified, passed
2024-10-16 17:48:30,758 __main__ INFO publishing 'four' on l3-stream by pub4 (0400)
2024-10-16 17:48:31,261 __main__ INFO publishing 'five' on l3-stream by pub5 (0400)
2024-10-16 17:48:31,763 __main__ INFO publishing 'six' on l3-stream by pub6 (0400)
2024-10-16 17:48:32,266 __main__ INFO publishing 'seven' on l3-stream by pub7 (0400)
2024-10-16 17:48:32,768 __main__ INFO obtaining all client data (0)
2024-10-16 17:48:32,768 __main__ INFO getting data from srv1
2024-10-16 17:48:35,275 __main__ INFO getting data from srv2
2024-10-16 17:48:37,781 __main__ INFO getting data from srv3
2024-10-16 17:48:40,288 __main__ INFO getting data from srv4
2024-10-16 17:48:42,794 __main__ INFO getting data from srv5
2024-10-16 17:48:45,301 __main__ INFO getting data from srv6
2024-10-16 17:48:47,807 __main__ INFO getting data from srv7
2024-10-16 17:48:50,313 __main__ INFO getting data from cli8foo
2024-10-16 17:48:52,819 __main__ INFO obtaining all client data (1)
2024-10-16 17:48:52,819 __main__ INFO getting data from srv1
2024-10-16 17:48:55,326 __main__ INFO getting data from srv2
2024-10-16 17:48:57,832 __main__ INFO getting data from srv3
2024-10-16 17:49:00,338 __main__ INFO getting data from srv4
2024-10-16 17:49:02,844 __main__ INFO getting data from srv5
2024-10-16 17:49:05,350 __main__ INFO getting data from srv6
2024-10-16 17:49:07,856 __main__ INFO getting data from srv7
2024-10-16 17:49:10,361 __main__ INFO getting data from cli8foo
2024-10-16 17:49:12,867 __main__ INFO obtaining all client data (2)
2024-10-16 17:49:12,867 __main__ INFO getting data from srv1
2024-10-16 17:49:15,374 __main__ INFO getting data from srv2
2024-10-16 17:49:17,879 __main__ INFO getting data from srv3
2024-10-16 17:49:20,385 __main__ INFO getting data from srv4
2024-10-16 17:49:22,891 __main__ INFO getting data from srv5
2024-10-16 17:49:25,396 __main__ INFO getting data from srv6
2024-10-16 17:49:27,902 __main__ INFO getting data from srv7
2024-10-16 17:49:30,407 __main__ INFO getting data from cli8foo
2024-10-16 17:49:32,913 __main__ INFO obtaining all client data (3)
2024-10-16 17:49:32,913 __main__ INFO getting data from srv1
2024-10-16 17:49:35,420 __main__ INFO getting data from srv2
2024-10-16 17:49:37,925 __main__ INFO getting data from srv3
2024-10-16 17:49:40,431 __main__ INFO getting data from srv4
2024-10-16 17:49:42,937 __main__ INFO getting data from srv5
2024-10-16 17:49:45,442 __main__ INFO getting data from srv6
2024-10-16 17:49:47,948 __main__ INFO getting data from srv7
2024-10-16 17:49:50,454 __main__ INFO getting data from cli8foo
2024-10-16 17:49:52,960 TADA INFO assertion 8, l3-stream by 'root' with 0400 permission: client data verified, passed
2024-10-16 17:49:52,961 __main__ INFO publishing 'four' on l3-stream by pub4 (0400) root as foo
2024-10-16 17:49:53,463 __main__ INFO publishing 'five' on l3-stream by pub5 (0400) root as foo
2024-10-16 17:49:53,966 __main__ INFO publishing 'six' on l3-stream by pub6 (0400) root as foo
2024-10-16 17:49:54,468 __main__ INFO publishing 'seven' on l3-stream by pub7 (0400) root as foo
2024-10-16 17:49:54,971 __main__ INFO obtaining all client data (0)
2024-10-16 17:49:54,971 __main__ INFO getting data from srv1
2024-10-16 17:49:57,477 __main__ INFO getting data from srv2
2024-10-16 17:49:59,984 __main__ INFO getting data from srv3
2024-10-16 17:50:02,490 __main__ INFO getting data from srv4
2024-10-16 17:50:04,996 __main__ INFO getting data from srv5
2024-10-16 17:50:07,503 __main__ INFO getting data from srv6
2024-10-16 17:50:10,010 __main__ INFO getting data from srv7
2024-10-16 17:50:12,516 __main__ INFO getting data from cli8foo
2024-10-16 17:50:15,023 __main__ INFO obtaining all client data (1)
2024-10-16 17:50:15,023 __main__ INFO getting data from srv1
2024-10-16 17:50:17,529 __main__ INFO getting data from srv2
2024-10-16 17:50:20,036 __main__ INFO getting data from srv3
2024-10-16 17:50:22,542 __main__ INFO getting data from srv4
2024-10-16 17:50:25,048 __main__ INFO getting data from srv5
2024-10-16 17:50:27,553 __main__ INFO getting data from srv6
2024-10-16 17:50:30,059 __main__ INFO getting data from srv7
2024-10-16 17:50:32,565 __main__ INFO getting data from cli8foo
2024-10-16 17:50:35,071 __main__ INFO obtaining all client data (2)
2024-10-16 17:50:35,071 __main__ INFO getting data from srv1
2024-10-16 17:50:37,578 __main__ INFO getting data from srv2
2024-10-16 17:50:40,084 __main__ INFO getting data from srv3
2024-10-16 17:50:42,589 __main__ INFO getting data from srv4
2024-10-16 17:50:45,095 __main__ INFO getting data from srv5
2024-10-16 17:50:47,601 __main__ INFO getting data from srv6
2024-10-16 17:50:50,106 __main__ INFO getting data from srv7
2024-10-16 17:50:52,612 __main__ INFO getting data from cli8foo
2024-10-16 17:50:55,119 __main__ INFO obtaining all client data (3)
2024-10-16 17:50:55,119 __main__ INFO getting data from srv1
2024-10-16 17:50:57,625 __main__ INFO getting data from srv2
2024-10-16 17:51:00,131 __main__ INFO getting data from srv3
2024-10-16 17:51:02,637 __main__ INFO getting data from srv4
2024-10-16 17:51:05,142 __main__ INFO getting data from srv5
2024-10-16 17:51:07,648 __main__ INFO getting data from srv6
2024-10-16 17:51:10,154 __main__ INFO getting data from srv7
2024-10-16 17:51:12,659 __main__ INFO getting data from cli8foo
2024-10-16 17:51:15,167 TADA INFO assertion 9, l3-stream by 'root' as 'foo' with 0400 permission: client data verified, passed
2024-10-16 17:51:15,167 __main__ INFO publishing 'four' on l3-stream by pub4 (0400) root as bar
2024-10-16 17:51:15,670 __main__ INFO publishing 'five' on l3-stream by pub5 (0400) root as bar
2024-10-16 17:51:16,172 __main__ INFO publishing 'six' on l3-stream by pub6 (0400) root as bar
2024-10-16 17:51:16,675 __main__ INFO publishing 'seven' on l3-stream by pub7 (0400) root as bar
2024-10-16 17:51:17,177 __main__ INFO obtaining all client data (0)
2024-10-16 17:51:17,178 __main__ INFO getting data from srv1
2024-10-16 17:51:19,684 __main__ INFO getting data from srv2
2024-10-16 17:51:22,191 __main__ INFO getting data from srv3
2024-10-16 17:51:24,697 __main__ INFO getting data from srv4
2024-10-16 17:51:27,204 __main__ INFO getting data from srv5
2024-10-16 17:51:29,710 __main__ INFO getting data from srv6
2024-10-16 17:51:32,217 __main__ INFO getting data from srv7
2024-10-16 17:51:34,723 __main__ INFO getting data from cli8foo
2024-10-16 17:51:37,229 __main__ INFO obtaining all client data (1)
2024-10-16 17:51:37,229 __main__ INFO getting data from srv1
2024-10-16 17:51:39,735 __main__ INFO getting data from srv2
2024-10-16 17:51:42,242 __main__ INFO getting data from srv3
2024-10-16 17:51:44,748 __main__ INFO getting data from srv4
2024-10-16 17:51:47,254 __main__ INFO getting data from srv5
2024-10-16 17:51:49,760 __main__ INFO getting data from srv6
2024-10-16 17:51:52,266 __main__ INFO getting data from srv7
2024-10-16 17:51:54,772 __main__ INFO getting data from cli8foo
2024-10-16 17:51:57,277 __main__ INFO obtaining all client data (2)
2024-10-16 17:51:57,277 __main__ INFO getting data from srv1
2024-10-16 17:51:59,784 __main__ INFO getting data from srv2
2024-10-16 17:52:02,290 __main__ INFO getting data from srv3
2024-10-16 17:52:04,795 __main__ INFO getting data from srv4
2024-10-16 17:52:07,301 __main__ INFO getting data from srv5
2024-10-16 17:52:09,807 __main__ INFO getting data from srv6
2024-10-16 17:52:12,313 __main__ INFO getting data from srv7
2024-10-16 17:52:14,818 __main__ INFO getting data from cli8foo
2024-10-16 17:52:17,324 __main__ INFO obtaining all client data (3)
2024-10-16 17:52:17,324 __main__ INFO getting data from srv1
2024-10-16 17:52:19,831 __main__ INFO getting data from srv2
2024-10-16 17:52:22,336 __main__ INFO getting data from srv3
2024-10-16 17:52:24,842 __main__ INFO getting data from srv4
2024-10-16 17:52:27,348 __main__ INFO getting data from srv5
2024-10-16 17:52:29,854 __main__ INFO getting data from srv6
2024-10-16 17:52:32,359 __main__ INFO getting data from srv7
2024-10-16 17:52:34,865 __main__ INFO getting data from cli8foo
2024-10-16 17:52:37,372 TADA INFO assertion 10, l3-stream by 'root' as 'bar' with 0400 permission: client data verified, passed
2024-10-16 17:52:37,372 __main__ INFO publishing 'four' on l3-stream by pub4 (0440) root as bar
2024-10-16 17:52:37,874 __main__ INFO publishing 'five' on l3-stream by pub5 (0440) root as bar
2024-10-16 17:52:38,377 __main__ INFO publishing 'six' on l3-stream by pub6 (0440) root as bar
2024-10-16 17:52:38,879 __main__ INFO publishing 'seven' on l3-stream by pub7 (0440) root as bar
2024-10-16 17:52:39,382 __main__ INFO obtaining all client data (0)
2024-10-16 17:52:39,382 __main__ INFO getting data from srv1
2024-10-16 17:52:41,888 __main__ INFO getting data from srv2
2024-10-16 17:52:44,395 __main__ INFO getting data from srv3
2024-10-16 17:52:46,901 __main__ INFO getting data from srv4
2024-10-16 17:52:49,408 __main__ INFO getting data from srv5
2024-10-16 17:52:51,914 __main__ INFO getting data from srv6
2024-10-16 17:52:54,421 __main__ INFO getting data from srv7
2024-10-16 17:52:56,927 __main__ INFO getting data from cli8foo
2024-10-16 17:52:59,433 __main__ INFO obtaining all client data (1)
2024-10-16 17:52:59,433 __main__ INFO getting data from srv1
2024-10-16 17:53:01,940 __main__ INFO getting data from srv2
2024-10-16 17:53:04,446 __main__ INFO getting data from srv3
2024-10-16 17:53:06,953 __main__ INFO getting data from srv4
2024-10-16 17:53:09,459 __main__ INFO getting data from srv5
2024-10-16 17:53:11,964 __main__ INFO getting data from srv6
2024-10-16 17:53:14,470 __main__ INFO getting data from srv7
2024-10-16 17:53:16,976 __main__ INFO getting data from cli8foo
2024-10-16 17:53:19,482 __main__ INFO obtaining all client data (2)
2024-10-16 17:53:19,482 __main__ INFO getting data from srv1
2024-10-16 17:53:21,988 __main__ INFO getting data from srv2
2024-10-16 17:53:24,494 __main__ INFO getting data from srv3
2024-10-16 17:53:27,000 __main__ INFO getting data from srv4
2024-10-16 17:53:29,505 __main__ INFO getting data from srv5
2024-10-16 17:53:32,011 __main__ INFO getting data from srv6
2024-10-16 17:53:34,517 __main__ INFO getting data from srv7
2024-10-16 17:53:37,023 __main__ INFO getting data from cli8foo
2024-10-16 17:53:39,528 __main__ INFO obtaining all client data (3)
2024-10-16 17:53:39,529 __main__ INFO getting data from srv1
2024-10-16 17:53:42,035 __main__ INFO getting data from srv2
2024-10-16 17:53:44,541 __main__ INFO getting data from srv3
2024-10-16 17:53:47,046 __main__ INFO getting data from srv4
2024-10-16 17:53:49,552 __main__ INFO getting data from srv5
2024-10-16 17:53:52,058 __main__ INFO getting data from srv6
2024-10-16 17:53:54,564 __main__ INFO getting data from srv7
2024-10-16 17:53:57,069 __main__ INFO getting data from cli8foo
2024-10-16 17:53:59,576 TADA INFO assertion 11, l3-stream by 'root' as 'bar' with 0440 permission: client data verified, passed
2024-10-16 17:54:00,078 TADA INFO assertion 12, l3-stream by 'foo' as 'bar' results in an error: checking..., passed
2024-10-16 17:54:00,078 __main__ INFO publishing 'four' on l3-stream by pub4foo (0440)
2024-10-16 17:54:00,580 __main__ INFO obtaining all client data (0)
2024-10-16 17:54:00,581 __main__ INFO getting data from srv1
2024-10-16 17:54:03,087 __main__ INFO getting data from srv2
2024-10-16 17:54:05,593 __main__ INFO getting data from srv3
2024-10-16 17:54:08,099 __main__ INFO getting data from srv4
2024-10-16 17:54:10,606 __main__ INFO getting data from srv5
2024-10-16 17:54:13,111 __main__ INFO getting data from srv6
2024-10-16 17:54:15,617 __main__ INFO getting data from srv7
2024-10-16 17:54:18,123 __main__ INFO getting data from cli8foo
2024-10-16 17:54:20,629 TADA INFO assertion 13, l3-stream by 'foo' with 0440 permission: client data verified, passed
2024-10-16 17:54:20,630 __main__ INFO publishing 'four' on l3-stream by pub4bar (0440)
2024-10-16 17:54:21,132 __main__ INFO obtaining all client data (0)
2024-10-16 17:54:21,133 __main__ INFO getting data from srv1
2024-10-16 17:54:23,639 __main__ INFO getting data from srv2
2024-10-16 17:54:26,145 __main__ INFO getting data from srv3
2024-10-16 17:54:28,651 __main__ INFO getting data from srv4
2024-10-16 17:54:31,158 __main__ INFO getting data from srv5
2024-10-16 17:54:33,663 __main__ INFO getting data from srv6
2024-10-16 17:54:36,169 __main__ INFO getting data from srv7
2024-10-16 17:54:38,675 __main__ INFO getting data from cli8foo
2024-10-16 17:54:41,181 TADA INFO assertion 14, l3-stream by 'bar' with 0440 permission: client data verified, passed
2024-10-16 17:54:44,689 TADA INFO assertion 15, Blocking client and asynchronous client have the same data: verified, passed
2024-10-16 17:54:46,193 __main__ INFO publishing 'four' on l3-stream by srv4
2024-10-16 17:54:46,695 __main__ INFO obtaining all client data (0)
2024-10-16 17:54:46,695 __main__ INFO getting data from srv1
2024-10-16 17:54:49,202 __main__ INFO getting data from srv2
2024-10-16 17:54:51,708 __main__ INFO getting data from srv3
2024-10-16 17:54:54,214 __main__ INFO getting data from srv4
2024-10-16 17:54:56,720 __main__ INFO getting data from srv5
2024-10-16 17:54:59,226 __main__ INFO getting data from srv6
2024-10-16 17:55:01,732 __main__ INFO getting data from srv7
2024-10-16 17:55:04,237 __main__ INFO getting data from cli8foo
2024-10-16 17:55:06,745 TADA INFO assertion 20, l3-stream publish from L1 (srv4): client data verified, passed
2024-10-16 17:55:06,745 __main__ INFO publishing 'four' on nada by srv4
2024-10-16 17:55:07,246 __main__ INFO obtaining all client data (0)
2024-10-16 17:55:07,247 __main__ INFO getting data from srv1
2024-10-16 17:55:09,752 __main__ INFO getting data from srv2
2024-10-16 17:55:12,258 __main__ INFO getting data from srv3
2024-10-16 17:55:14,764 __main__ INFO getting data from srv4
2024-10-16 17:55:17,270 __main__ INFO getting data from srv5
2024-10-16 17:55:19,776 __main__ INFO getting data from srv6
2024-10-16 17:55:22,281 __main__ INFO getting data from srv7
2024-10-16 17:55:24,787 __main__ INFO getting data from cli8foo
2024-10-16 17:55:27,293 TADA INFO assertion 21, nada publish from L1 (srv4): client data verified, passed
2024-10-16 17:55:30,888 TADA INFO assertion 22, Check stream stats in each process: verified, passed
2024-10-16 17:55:34,489 TADA INFO assertion 23, Check stream client stats in each process: verified, passed
2024-10-16 17:55:36,994 TADA INFO assertion 16, srv-6 clean up properly after srv-3 exited: checking..., passed
2024-10-16 17:55:36,994 TADA INFO assertion 17, srv-7 clean up properly after srv-3 exited: checking..., passed
2024-10-16 17:55:36,994 TADA INFO assertion 18, srv-1 clean up properly after srv-3 exited: checking..., passed
2024-10-16 17:55:36,994 __main__ INFO starting /tada-src/python/ldms_stream_server.py on narate-ldms_stream_test-04c74b7-node-3 
2024-10-16 17:55:40,514 __main__ INFO publishing 'seven' on l3-stream by pub7
2024-10-16 17:55:41,016 __main__ INFO obtaining all client data (0)
2024-10-16 17:55:41,017 __main__ INFO getting data from srv1
2024-10-16 17:55:43,523 __main__ INFO getting data from srv2
2024-10-16 17:55:46,029 __main__ INFO getting data from srv3
2024-10-16 17:55:48,535 __main__ INFO getting data from srv4
2024-10-16 17:55:51,041 __main__ INFO getting data from srv5
2024-10-16 17:55:53,547 __main__ INFO getting data from srv6
2024-10-16 17:55:56,053 __main__ INFO getting data from srv7
2024-10-16 17:55:58,559 __main__ INFO getting data from cli8foo
2024-10-16 17:56:01,066 TADA INFO assertion 19, l3-stream successfully delivered after srv-3 restarted: client data verified, passed
2024-10-16 17:56:01,067 TADA INFO test ldms_stream_test ended
2024-10-16 17:56:17 INFO: ----------------------------------------------
2024-10-16 17:56:19 INFO: ======== set_sec_mod_test ========
2024-10-16 17:56:19 INFO: CMD: python3 set_sec_mod_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/set_sec_mod_test
2024-10-16 17:56:19,878 TADA INFO starting test `set_sec_test`
2024-10-16 17:56:19,879 TADA INFO   test-id: 0eaca769c16677f2285405ae39a2f9f6d05c6e0688e47cff3c17c15661dc36a4
2024-10-16 17:56:19,879 TADA INFO   test-suite: LDMSD
2024-10-16 17:56:19,879 TADA INFO   test-name: set_sec_test
2024-10-16 17:56:19,879 TADA INFO   test-user: narate
2024-10-16 17:56:19,879 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:56:19,879 __main__ INFO ---Get or create the cluster ---
2024-10-16 17:56:33,032 __main__ INFO --- Start daemons ---
2024-10-16 17:56:53,031 TADA INFO assertion 1, Change UID to an existing username: {'set_1': {'uid': 1111, 'gid': 1000, 'perm': '0440'}} == {'set_1': {'uid': 1111, 'gid': 1000, 'perm': '0440'}}, passed
2024-10-16 17:56:54,250 TADA INFO assertion 2, Change UID to a not-existing username: errcode (22) == expected (22), passed
2024-10-16 17:56:55,672 TADA INFO assertion 3, Change UID to a valid UID: {'set_3': {'uid': 2222, 'gid': 1000, 'perm': '0440'}} == {'set_3': {'uid': 2222, 'gid': 1000, 'perm': '0440'}}, passed
2024-10-16 17:56:56,894 TADA INFO assertion 4, Change UID to an invalid UID: errcode (22) == expected (22), passed
2024-10-16 17:56:58,318 TADA INFO assertion 5, Change GID to an existing groupname: {'set_5': {'uid': 1000, 'gid': 1111, 'perm': '0440'}} == {'set_5': {'uid': 1000, 'gid': 1111, 'perm': '0440'}}, passed
2024-10-16 17:56:59,544 TADA INFO assertion 6, Change GID to a not-existing groupname: errcode (22) == expected (22), passed
2024-10-16 17:57:00,991 TADA INFO assertion 7, Change GID to a valid GID: {'set_7': {'uid': 1000, 'gid': 2222, 'perm': '0440'}} == {'set_7': {'uid': 1000, 'gid': 2222, 'perm': '0440'}}, passed
2024-10-16 17:57:02,219 TADA INFO assertion 8, Change GID to an invalid GID: errcode (22) == expected (22), passed
2024-10-16 17:57:03,634 TADA INFO assertion 9, Change permission bits to a valid permission value: {'set_9': {'uid': 1000, 'gid': 1000, 'perm': '0400'}} == {'set_9': {'uid': 1000, 'gid': 1000, 'perm': '0400'}}, passed
2024-10-16 17:57:04,866 TADA INFO assertion 10, Change permission bits to an invalid permission value: errcode (22) == expected (22), passed
2024-10-16 17:57:05,067 TADA INFO assertion 11, Verify that the aggregator got sets' new security info: {'set_9': {'uid': 1000, 'gid': 1000, 'perm': '0400'}, 'set_8': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_7': {'uid': 1000, 'gid': 2222, 'perm': '0440'}, 'set_6': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_5': {'uid': 1000, 'gid': 1111, 'perm': '0440'}, 'set_4': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_3': {'uid': 2222, 'gid': 1000, 'perm': '0440'}, 'set_2': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_10': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_1': {'uid': 1111, 'gid': 1000, 'perm': '0440'}} == {'set_1': {'uid': 1111, 'gid': 1000, 'perm': '0440'}, 'set_2': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_3': {'uid': 2222, 'gid': 1000, 'perm': '0440'}, 'set_4': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_5': {'uid': 1000, 'gid': 1111, 'perm': '0440'}, 'set_6': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_7': {'uid': 1000, 'gid': 2222, 'perm': '0440'}, 'set_8': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_9': {'uid': 1000, 'gid': 1000, 'perm': '0400'}, 'set_10': {'uid': 1000, 'gid': 1000, 'perm': '0440'}}, passed
2024-10-16 17:57:05,281 TADA INFO assertion 12.1, Clients with different UID and the same GID cannot access 0400 sets.: {'set_8': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_6': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_4': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_3': {'uid': 2222, 'gid': 1000, 'perm': '0440'}, 'set_2': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_10': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_1': {'uid': 1111, 'gid': 1000, 'perm': '0440'}} == {'set_1': {'uid': 1111, 'gid': 1000, 'perm': '0440'}, 'set_2': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_3': {'uid': 2222, 'gid': 1000, 'perm': '0440'}, 'set_4': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_6': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_8': {'uid': 1000, 'gid': 1000, 'perm': '0440'}, 'set_10': {'uid': 1000, 'gid': 1000, 'perm': '0440'}}, passed
2024-10-16 17:57:05,491 TADA INFO assertion 12.2, Clients with different UID and GID cannot access 04## sets.: {} == {}, passed
2024-10-16 17:57:05,491 __main__ INFO --- done ---
2024-10-16 17:57:05,491 TADA INFO test set_sec_test ended
2024-10-16 17:57:17 INFO: ----------------------------------------------
2024-10-16 17:57:19 INFO: ======== dump_cfg_test ========
2024-10-16 17:57:19 INFO: CMD: python3 dump_cfg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/dump_cfg_test
2024-10-16 17:57:20,070 TADA INFO starting test `dump_cfg_test`
2024-10-16 17:57:20,070 TADA INFO   test-id: 50582b73a7bafe4c84012a388922b0de0862a9f92fdbe16c84a8e88bc15a8877
2024-10-16 17:57:20,070 TADA INFO   test-suite: LDMSD
2024-10-16 17:57:20,070 TADA INFO   test-name: dump_cfg_test
2024-10-16 17:57:20,070 TADA INFO   test-user: narate
2024-10-16 17:57:20,070 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:57:20,071 __main__ INFO -- Get or create the cluster --
2024-10-16 17:57:39,465 __main__ INFO -- Start daemons --
2024-10-16 17:58:11,766 __main__ INFO -- Begin the test --
2024-10-16 17:58:17,294 TADA INFO assertion 1.1, Specify the command-line options: The generated configuration is as expected., passed
2024-10-16 17:58:23,006 TADA INFO assertion 1.2, Specify host at the command-line: The generated configuration is as expected., passed
2024-10-16 17:58:28,694 TADA INFO assertion 1.3, Specify auth_opt at the command-line: The generated configuration is as expected., passed
2024-10-16 17:58:34,478 TADA INFO assertion 2.1, Specify the command-line options in a configuration file: The generated configuration is as expected., passed
2024-10-16 17:58:40,264 TADA INFO assertion 3.1, Sampler configuration commands: The generated configuration is as expected., passed
2024-10-16 17:58:46,038 TADA INFO assertion 3.2, Sampler configuration commands with plugin-specific attributes: The generated configuration is as expected., passed
2024-10-16 17:58:51,916 TADA INFO assertion 4.1, Simple aggregator configuration commands: The generated configuration is as expected., passed
2024-10-16 17:58:57,750 TADA INFO assertion 5.1, prdcr_subscribe configuration commands: The generated configuration is as expected., passed
2024-10-16 17:58:57,865 __main__ INFO --- done ---
2024-10-16 17:58:57,866 TADA INFO test dump_cfg_test ended
2024-10-16 17:59:10 INFO: ----------------------------------------------
2024-10-16 17:59:12 INFO: ======== ldmsd_stream_rate_test ========
2024-10-16 17:59:12 INFO: CMD: python3 ldmsd_stream_rate_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_stream_rate_test
2024-10-16 17:59:13,632 TADA INFO starting test `ldmsd_stream_rate_test`
2024-10-16 17:59:13,633 TADA INFO   test-id: cb10df34b037af81bb102c49ae9d4a14681445143fad25a09a29704d5e552a39
2024-10-16 17:59:13,633 TADA INFO   test-suite: LDMSD
2024-10-16 17:59:13,633 TADA INFO   test-name: ldmsd_stream_rate_test
2024-10-16 17:59:13,633 TADA INFO   test-user: narate
2024-10-16 17:59:13,633 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 17:59:13,633 __main__ INFO -- Get or create the cluster --
2024-10-16 17:59:26,780 __main__ INFO -- Start daemons --
2024-10-16 17:59:43,773 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 17:59:45,775 root INFO starting /tada-src/python/pypubsub.py on narate-ldmsd_stream_rate_test-04c74b7-samp 
2024-10-16 17:59:47,994 root INFO starting /tada-src/python/pypubsub.py on narate-ldmsd_stream_rate_test-04c74b7-agg-1 
2024-10-16 18:00:00,727 TADA INFO assertion 1, Sampler cannot publish all data (prdcr rate limit): received stream data 34 is limited by prdcr rx_rate, passed
2024-10-16 18:00:00,728 TADA INFO assertion 2, After the wait, the sampler can publish: stream data received, passed
2024-10-16 18:00:00,728 TADA INFO assertion 3, Sampler cannot publish all data (stream rate limit): received stream data 34 is limited by stream rx_rate, passed
2024-10-16 18:00:00,728 TADA INFO assertion 4, After the wait, the sampler can publish: stream data received, passed
2024-10-16 18:00:00,729 TADA INFO test ldmsd_stream_rate_test ended
2024-10-16 18:00:12 INFO: ----------------------------------------------
2024-10-16 18:00:14 INFO: ======== ldms_rate_test ========
2024-10-16 18:00:14 INFO: CMD: python3 ldms_rate_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_rate_test
2024-10-16 18:00:15,208 TADA INFO starting test `ldms_rate_test`
2024-10-16 18:00:15,208 TADA INFO   test-id: 1aed968adc0291bbb507ccccb7f551db43fa6dc902df0978098d60bb635843af
2024-10-16 18:00:15,208 TADA INFO   test-suite: LDMSD
2024-10-16 18:00:15,209 TADA INFO   test-name: ldms_rate_test
2024-10-16 18:00:15,209 TADA INFO   test-user: narate
2024-10-16 18:00:15,209 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:00:15,209 __main__ INFO -- Get or create the cluster --
2024-10-16 18:00:25,392 __main__ INFO -- Start daemons --
2024-10-16 18:00:26,275 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 18:00:28,277 root INFO starting /tada-src/python/ldms_rate.py on narate-ldms_rate_test-04c74b7-node-1 
2024-10-16 18:00:30,494 root INFO starting /tada-src/python/ldms_rate.py on narate-ldms_rate_test-04c74b7-node-1 
2024-10-16 18:01:04,673 TADA INFO assertion 1, Publisher cannot publish all data (rail rate limit): received stream data is limited, passed
2024-10-16 18:01:05,175 TADA INFO assertion 2, Publisher get a rate limit error: publisher got rate limit errors, passed
2024-10-16 18:01:05,176 TADA INFO assertion 3, After the wait, the publisher can publish: stream data received, passed
2024-10-16 18:01:05,176 TADA INFO assertion 4, Publisher cannot publish all data (stream rate limit): received stream data is limited, passed
2024-10-16 18:01:05,678 TADA INFO assertion 5, Publisher get a rate limit error (by stream): publisher got rate limit errors, passed
2024-10-16 18:01:05,679 TADA INFO assertion 6, After the wait, the publisher can publish (by stream): stream data received, passed
2024-10-16 18:01:05,679 TADA INFO test ldms_rate_test ended
2024-10-16 18:01:16 INFO: ----------------------------------------------
2024-10-16 18:01:18 INFO: ======== ldms_ipv6_test ========
2024-10-16 18:01:18 INFO: CMD: python3 ldms_ipv6_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_ipv6_test
2024-10-16 18:01:19,339 TADA INFO starting test `ldms_ipv6_test`
2024-10-16 18:01:19,340 TADA INFO   test-id: 7f206f83cd3defd2125eba4e7abc7da94a83ffd78b471137e784d0ef26186080
2024-10-16 18:01:19,340 TADA INFO   test-suite: LDMSD
2024-10-16 18:01:19,340 TADA INFO   test-name: ldms_ipv6_test
2024-10-16 18:01:19,340 TADA INFO   test-user: narate
2024-10-16 18:01:19,340 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:01:19,341 __main__ INFO -- Get or create the cluster --
2024-10-16 18:01:36,539 __main__ INFO -- Start daemons --
2024-10-16 18:02:03,149 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 18:02:05,151 root INFO starting /tada-src/python/pypubsub.py on narate-ldms_ipv6_test-04c74b7-samp 
2024-10-16 18:02:07,370 root INFO starting /tada-src/python/pypubsub.py on narate-ldms_ipv6_test-04c74b7-agg-2 
2024-10-16 18:02:11,717 TADA INFO assertion 1, ldms_ls to samp using IPv6: expecting ['fd00:0:0:1::5'], got ['fd00:0:0:1::5'], passed
2024-10-16 18:02:11,834 TADA INFO assertion 2, ldms_ls to agg-2 using IPv6: expecting ['fd00:0:0:1::5'], got ['fd00:0:0:1::5'], passed
2024-10-16 18:02:11,835 TADA INFO assertion 3, ldms_ls to agg-2 contains 'samp/meminfo': samp/meminfo found, passed
2024-10-16 18:02:14,840 TADA INFO assertion 4, python stream publish using IPv6: verified, passed
2024-10-16 18:02:17,845 TADA INFO assertion 5, python stream subscribe using IPv6: verified, passed
2024-10-16 18:02:18,347 TADA INFO assertion 6, steam data contain IPv6 addressing: expecting fd00:0:0:1::5, got fd00:0:0:1::5, passed
2024-10-16 18:02:18,658 TADA INFO assertion 7, stream stats reported IPv6 addresses: Expecting fd00:0:0:1::3, got fd00:0:0:1::3, passed
2024-10-16 18:02:18,658 TADA INFO test ldms_ipv6_test ended
2024-10-16 18:02:37 INFO: ----------------------------------------------
2024-10-16 18:02:39 INFO: ======== ldmsd_decomp_static_omit_test ========
2024-10-16 18:02:39 INFO: CMD: python3 ldmsd_decomp_static_omit_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_decomp_static_omit_test
2024-10-16 18:02:40,033 TADA INFO starting test `ldmsd_decomp_static_omit_test`
2024-10-16 18:02:40,033 TADA INFO   test-id: d305bb5be37f112294361d59a9d949b748695cb28e2caf0596c8f9cedb5de42f
2024-10-16 18:02:40,033 TADA INFO   test-suite: LDMSD
2024-10-16 18:02:40,033 TADA INFO   test-name: ldmsd_decomp_static_omit_test
2024-10-16 18:02:40,033 TADA INFO   test-user: narate
2024-10-16 18:02:40,034 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:02:40,034 __main__ INFO -- Get or create the cluster --
2024-10-16 18:03:08,872 __main__ INFO -- Start daemons --
2024-10-16 18:03:54,231 __main__ INFO ... wait a bit to make sure ldmsd's are up
Traceback (most recent call last):
  File "ldmsd_decomp_static_omit_test", line 410, in <module>
    raise RuntimeError(f"kafka-topic verification error, rc: {rc}, out: {out}")
RuntimeError: kafka-topic verification error, rc: 0, out: filter

2024-10-16 18:04:22,446 TADA INFO assertion 1, `static` decomposition, filter sos schema check: skipped
2024-10-16 18:04:22,446 TADA INFO assertion 2, `static` decomposition, record sos schema check: skipped
2024-10-16 18:04:22,446 TADA INFO assertion 3, `static` decomposition, filter csv schema check: skipped
2024-10-16 18:04:22,447 TADA INFO assertion 4, `static` decomposition, record csv schema check: skipped
2024-10-16 18:04:22,447 TADA INFO assertion 5, `static` decomposition, filter kafka schema check: skipped
2024-10-16 18:04:22,447 TADA INFO assertion 6, `static` decomposition, record kafka schema check: skipped
2024-10-16 18:04:22,447 TADA INFO assertion 7, `static` decomposition, filter sos data check: skipped
2024-10-16 18:04:22,447 TADA INFO assertion 8, `static` decomposition, record sos data check: skipped
2024-10-16 18:04:22,447 TADA INFO assertion 9, `static` decomposition, filter csv data check: skipped
2024-10-16 18:04:22,447 TADA INFO assertion 10, `static` decomposition, record csv data check: skipped
2024-10-16 18:04:22,447 TADA INFO assertion 11, `static` decomposition, filter kafka data check: skipped
2024-10-16 18:04:22,448 TADA INFO assertion 12, `static` decomposition, record kafka data check: skipped
2024-10-16 18:04:22,448 TADA INFO test ldmsd_decomp_static_omit_test ended
2024-10-16 18:04:37 INFO: ----------------------------------------------
2024-10-16 18:04:39 INFO: ======== json_stream_sampler_test ========
2024-10-16 18:04:39 INFO: CMD: python3 json_stream_sampler_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/json_stream_sampler_test
2024-10-16 18:04:40,619 TADA INFO starting test `json_stream_sampler_test`
2024-10-16 18:04:40,619 TADA INFO   test-id: eee92b68efeeeb330f97abcbb1cd3bfadc4dbe9054d05d834291c47be76bc306
2024-10-16 18:04:40,619 TADA INFO   test-suite: LDMSD
2024-10-16 18:04:40,619 TADA INFO   test-name: json_stream_sampler_test
2024-10-16 18:04:40,619 TADA INFO   test-user: narate
2024-10-16 18:04:40,619 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:04:40,620 __main__ INFO -- Get or create the cluster --
2024-10-16 18:04:51,994 __main__ INFO -- Start daemons --
2024-10-16 18:05:01,270 __main__ INFO -- Begin the test --
2024-10-16 18:05:02,484 TADA INFO assertion config_0.1, Missing the producer attribute: Plugin reports an error., passed
2024-10-16 18:05:03,712 TADA INFO assertion config_0.2, Missing the stream attribute: Plugin reports an error., passed
2024-10-16 18:05:05,024 TADA INFO assertion config_1.0, Verify producer, stream, component_id, and heap_sz: Successfully send the request: config name=json_stream_sampler producer=node-1 instance=stream_1_set stream=stream_1 heap_sz=1MB, passed
2024-10-16 18:05:05,393 TADA INFO assertion create_1, Correctly create a set when subscribing to a single stream: Create a set, passed
2024-10-16 18:05:05,394 TADA INFO assertion config_1.1, Verify the default set UID: Set's UID(0) is 0., passed
2024-10-16 18:05:05,394 TADA INFO assertion config_1.2, Verify the default set GID: Set's GID(0) is 0., passed
2024-10-16 18:05:05,394 TADA INFO assertion config_1.3, Verify the default set Perm: Set's Perm(0440) is 0440., passed
2024-10-16 18:05:05,394 TADA INFO assertion encode_1.1, Correctly encode the metric values: Encode the metric values correctly, passed
2024-10-16 18:05:05,394 TADA INFO assertion encode_1.2, Correctly encode the metric types: Encode the metric types correctly, passed
2024-10-16 18:05:06,713 TADA INFO assertion config_2.0, Successfully configure the plugin with UID, GID, and perm: Successfully subscribe to the second stream, passed
2024-10-16 18:05:07,092 TADA INFO assertion create_2, Subscribe to multiple streams: Create the set of the second stream, passed
2024-10-16 18:05:07,093 TADA INFO assertion config_2.1, Verify the specified set UID: Set's UID(2000) is 2000., passed
2024-10-16 18:05:07,093 TADA INFO assertion config_2.2, Verify the specified set GID: Set's GID(2000) is 2000., passed
2024-10-16 18:05:07,093 TADA INFO assertion config_2.3, Verify the specified set Perm: Set's Perm(0400) is as expected(0400)., passed
2024-10-16 18:05:07,093 TADA INFO assertion encode_2.1, Correctly set the S_uid meta metric: S_uid(0) is 0., passed
2024-10-16 18:05:07,093 TADA INFO assertion encode_2.2, Correctly set the S_gid meta metric: S_gid(0) is 0., passed
2024-10-16 18:05:07,093 TADA INFO assertion encode_2.3, Correctly set the S_perm meta metric: S_perm(0400) is 0400., passed
2024-10-16 18:05:07,312 TADA INFO assertion sec_1, User who publishes the stream cannot see the sets if the set's UID/GID is different.: foo can sees the stream set., passed
2024-10-16 18:05:07,527 TADA INFO assertion sec_2, User can access the set if the UID/GID matches the set's credential.: bar can not see any sets., passed
2024-10-16 18:05:07,726 TADA INFO assertion sec_3, Root can access the set regardless.: Root can see all sets., passed
2024-10-16 18:05:13,605 TADA INFO assertion invalid_no_schema, Plugin properly handles invalid stream data, no_schema.: Plugin properly reported an error message., passed
2024-10-16 18:05:13,605 TADA INFO assertion invalid_not_dict, Plugin properly handles invalid stream data, not_dict.: Plugin properly reported an error message., passed
2024-10-16 18:05:13,605 TADA INFO assertion invalid_array_array, Plugin properly handles invalid stream data, array_array.: Plugin properly reported an error message., passed
2024-10-16 18:05:13,606 TADA INFO assertion invalid_array_mix, Plugin properly handles invalid stream data, array_mix.: Plugin properly reported an error message., passed
2024-10-16 18:05:15,300 TADA INFO assertion create_3, Successfully create a set when $_max_len is given in the stream data: Create a set with specified #_max_len, passed
2024-10-16 18:05:15,301 TADA INFO assertion encode_3, Correctly encode the metric values with #_max_len specified: Encode the metric values correctly, passed
2024-10-16 18:05:15,301 TADA INFO test json_stream_sampler_test ended
2024-10-16 18:05:26 INFO: ----------------------------------------------
2024-10-16 18:05:28 INFO: ======== ldms_qgroup_test ========
2024-10-16 18:05:28 INFO: CMD: python3 ldms_qgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldms_qgroup_test
2024-10-16 18:05:29,143 TADA INFO starting test `ldms_qgroup_test`
2024-10-16 18:05:29,143 TADA INFO   test-id: 01215a0768ea24c612c27869cb44625c3bb52b12e86e8d8e8eae3272c7c7f1fc
2024-10-16 18:05:29,143 TADA INFO   test-suite: LDMSD
2024-10-16 18:05:29,143 TADA INFO   test-name: ldms_qgroup_test
2024-10-16 18:05:29,143 TADA INFO   test-user: narate
2024-10-16 18:05:29,143 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:05:29,144 __main__ INFO -- Get or create the cluster --
2024-10-16 18:06:06,976 __main__ INFO -- Start daemons --
2024-10-16 18:06:22,515 __main__ INFO ... wait a bit to make sure daemons are up
2024-10-16 18:06:24,518 root INFO starting /tada-src/python/ldms_qgroup_samp.py on narate-ldms_qgroup_test-04c74b7-samp1 
2024-10-16 18:06:26,735 root INFO starting /tada-src/python/ldms_qgroup_samp.py on narate-ldms_qgroup_test-04c74b7-samp2 
2024-10-16 18:06:28,952 root INFO starting /tada-src/python/ldms_qgroup_samp.py on narate-ldms_qgroup_test-04c74b7-samp3 
2024-10-16 18:06:31,175 root INFO starting /tada-src/python/ldms_qgroup_samp.py on narate-ldms_qgroup_test-04c74b7-samp4 
2024-10-16 18:06:33,392 root INFO starting /tada-src/python/ldms_qgroup_samp.py on narate-ldms_qgroup_test-04c74b7-samp5 
2024-10-16 18:06:35,610 root INFO starting /tada-src/python/ldms_qgroup_samp.py on narate-ldms_qgroup_test-04c74b7-samp6 
2024-10-16 18:06:38,828 root INFO starting /tada-src/python/ldms_qgroup_agg1.py on narate-ldms_qgroup_test-04c74b7-agg11 
2024-10-16 18:06:41,049 root INFO starting /tada-src/python/ldms_qgroup_agg1.py on narate-ldms_qgroup_test-04c74b7-agg12 
2024-10-16 18:06:43,266 root INFO starting /tada-src/python/ldms_qgroup_agg1.py on narate-ldms_qgroup_test-04c74b7-agg13 
2024-10-16 18:06:46,485 root INFO starting /tada-src/python/ldms_qgroup_agg2.py on narate-ldms_qgroup_test-04c74b7-agg2 
2024-10-16 18:06:49,704 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldms_qgroup_test-04c74b7-samp1 
2024-10-16 18:06:51,922 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldms_qgroup_test-04c74b7-samp2 
2024-10-16 18:06:54,139 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldms_qgroup_test-04c74b7-samp3 
2024-10-16 18:06:56,358 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldms_qgroup_test-04c74b7-samp4 
2024-10-16 18:06:58,575 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldms_qgroup_test-04c74b7-samp5 
2024-10-16 18:07:00,794 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldms_qgroup_test-04c74b7-samp6 
2024-10-16 18:07:04,017 __main__ INFO -- starting app publisher --
2024-10-16 18:07:07,026 __main__ INFO -- Wait a minute to get data flow (without limit) --
2024-10-16 18:08:12,086 __main__ INFO -- Wait a minute to get data flow (with limit) --
2024-10-16 18:09:42,628 __main__ INFO -- stopping app publisher --
2024-10-16 18:09:45,637 __main__ INFO -- wait a bit to make sure the published data is flushed --
2024-10-16 18:09:50,644 __main__ INFO -- collecting logs --
2024-10-16 18:09:51,604 TADA INFO assertion 1, Throughput without limit: bps: 1740.0, OK, passed
2024-10-16 18:09:51,604 TADA INFO assertion 2, Data received after quota: OK, passed
2024-10-16 18:09:51,604 TADA INFO assertion 3, Throughput with limit: bps: 699.9666666666667, limit: 768.0, OK, passed
2024-10-16 18:09:51,605 TADA INFO assertion 4, Check data loss: No data missing, passed
2024-10-16 18:09:51,605 TADA INFO assertion 5, Check starvation: OK, passed
2024-10-16 18:09:51,605 __main__ INFO -- ramp up app1 for saturation test --
2024-10-16 18:09:52,107 __main__ INFO -- starting app1 publisher again (for saturation test) --
2024-10-16 18:09:52,608 __main__ INFO -- Wait a minute to get data flow (with limit) --
2024-10-16 18:10:53,170 __main__ INFO -- stopping app1 publisher --
2024-10-16 18:10:53,673 TADA INFO assertion 6, Single publisher saturation test: good saturation bps: 445.0 in expected range [409.6, 512.0] (cfg_bps: 768.0), passed
2024-10-16 18:10:53,674 TADA INFO test ldms_qgroup_test ended
2024-10-16 18:11:11 INFO: ----------------------------------------------
2024-10-16 18:11:13 INFO: ======== ldmsd_qgroup_test ========
2024-10-16 18:11:13 INFO: CMD: python3 ldmsd_qgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/ldmsd_qgroup_test
2024-10-16 18:11:14,136 TADA INFO starting test `ldmsd_qgroup_test`
2024-10-16 18:11:14,136 TADA INFO   test-id: 58bfc0d9ce1e30df26040a84c74624555c23f16eba101ea644d6d769d9d7e459
2024-10-16 18:11:14,136 TADA INFO   test-suite: LDMSD
2024-10-16 18:11:14,136 TADA INFO   test-name: ldmsd_qgroup_test
2024-10-16 18:11:14,136 TADA INFO   test-user: narate
2024-10-16 18:11:14,136 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:11:14,137 __main__ INFO -- Get or create the cluster --
2024-10-16 18:11:51,610 __main__ INFO -- Start daemons --
2024-10-16 18:13:23,232 __main__ INFO ... wait a bit to make sure daemons are up
2024-10-16 18:13:31,285 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldmsd_qgroup_test-04c74b7-samp1 
2024-10-16 18:13:33,503 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldmsd_qgroup_test-04c74b7-samp2 
2024-10-16 18:13:35,721 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldmsd_qgroup_test-04c74b7-samp3 
2024-10-16 18:13:37,938 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldmsd_qgroup_test-04c74b7-samp4 
2024-10-16 18:13:40,157 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldmsd_qgroup_test-04c74b7-samp5 
2024-10-16 18:13:42,378 root INFO starting /tada-src/python/ldms_qgroup_app.py on narate-ldmsd_qgroup_test-04c74b7-samp6 
2024-10-16 18:13:45,596 __main__ INFO -- starting app publisher --
2024-10-16 18:13:48,605 __main__ INFO -- Wait a minute to get data flow (without limit) --
2024-10-16 18:15:09,683 __main__ INFO -- Wait a minute to get data flow (with limit) --
2024-10-16 18:16:09,703 __main__ INFO -- stopping app publisher --
2024-10-16 18:16:12,711 __main__ INFO -- wait a bit to make sure the published data is flushed --
2024-10-16 18:16:17,718 __main__ INFO -- collecting logs --
2024-10-16 18:16:18,651 TADA INFO assertion 1, Throughput without limit: bps: 1758.15, OK, passed
2024-10-16 18:16:18,652 TADA INFO assertion 2, Data received after quota: OK, passed
2024-10-16 18:16:18,655 TADA INFO assertion 3, Throughput with limit: bps: 717.87, OK, passed
2024-10-16 18:16:18,656 TADA INFO assertion 4, Check data loss: No data missing, passed
2024-10-16 18:16:18,656 TADA INFO assertion 5, Check starvation: OK, passed
2024-10-16 18:16:18,656 __main__ INFO -- ramp up app1 for saturation test --
2024-10-16 18:16:19,157 __main__ INFO -- starting app1 publisher again (for saturation test) --
2024-10-16 18:16:19,659 __main__ INFO -- Wait a minute to get data flow (with limit) --
2024-10-16 18:17:19,700 __main__ INFO -- stopping app1 publisher --
2024-10-16 18:17:21,203 __main__ INFO -- reading stream dump --
2024-10-16 18:17:21,367 __main__ INFO -- calculating bps --
2024-10-16 18:17:21,386 TADA INFO assertion 6, Single publisher saturation test: good saturation bps: 441.6 in expected range [409.6, 512.0] (cfg_bps: 768.0), passed
2024-10-16 18:17:21,386 TADA INFO test ldmsd_qgroup_test ended
2024-10-16 18:17:38 INFO: ----------------------------------------------
2024-10-16 18:17:40 INFO: ======== agg_slurm_test ========
2024-10-16 18:17:40 INFO: CMD: python3 agg_slurm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/agg_slurm_test
2024-10-16 18:17:41,526 TADA INFO starting test `agg_slurm_test`
2024-10-16 18:17:41,527 TADA INFO   test-id: e333e904b54a0fb09b196c41f9e2ca3a5ba5352c0135fac4c6cbccb07e31eb46
2024-10-16 18:17:41,527 TADA INFO   test-suite: LDMSD
2024-10-16 18:17:41,527 TADA INFO   test-name: agg_slurm_test
2024-10-16 18:17:41,527 TADA INFO   test-user: narate
2024-10-16 18:17:41,527 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:17:41,528 __main__ INFO -- Get or create the cluster --
2024-10-16 18:18:07,231 __main__ INFO -- Preparing syspapi JSON file --
2024-10-16 18:18:07,340 __main__ INFO -- Preparing jobpapi JSON file --
2024-10-16 18:18:07,445 __main__ INFO -- Preparing job script & programs --
2024-10-16 18:18:08,819 __main__ INFO -- Start daemons --
2024-10-16 18:18:56,286 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 18:19:01,289 __main__ INFO -- ldms_ls to agg-2 --
2024-10-16 18:19:01,406 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2024-10-16 18:19:01,520 __main__ INFO -- Give syspapi some time to work before submitting job --
2024-10-16 18:19:06,525 __main__ INFO -- Submitting jobs --
2024-10-16 18:19:06,659 __main__ INFO job_one: 1
2024-10-16 18:19:06,788 __main__ INFO job_two: 2
2024-10-16 18:19:16,799 __main__ INFO -- Cancelling jobs --
2024-10-16 18:19:16,799 __main__ INFO job_one: 1
2024-10-16 18:19:16,918 __main__ INFO job_two: 2
2024-10-16 18:20:28,787 TADA INFO assertion 2, slurm data verification: get expected data from store, passed
2024-10-16 18:20:28,787 TADA INFO assertion 3, meminfo data verification: No data missing, failed
Traceback (most recent call last):
  File "agg_slurm_test", line 592, in <module>
    test.assert_test(3, len(meminfo) > 5 and missing_counts == 0, "No data missing")
  File "/home/narate/cron/ldms-test/TADA.py", line 157, in assert_test
    raise AssertionException(self.test_desc + ", " + cond_str + ": FAILED")
TADA.AssertionException: LDMSD 2-level agg with slurm, No data missing: FAILED
2024-10-16 18:20:28,788 TADA INFO assertion 4, (SYS/JOB) PAPI data verification: skipped
2024-10-16 18:20:28,789 TADA INFO test agg_slurm_test ended
2024-10-16 18:20:43 INFO: ----------------------------------------------
2024-10-16 18:20:45 INFO: ======== papi_sampler_test ========
2024-10-16 18:20:45 INFO: CMD: python3 papi_sampler_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/papi_sampler_test
2024-10-16 18:20:46,218 TADA INFO starting test `papi_sampler_test`
2024-10-16 18:20:46,218 TADA INFO   test-id: 0b66986cfb7aafce2d229a212026e439ec51f544fdb8b9ce440845a13974c7c3
2024-10-16 18:20:46,218 TADA INFO   test-suite: LDMSD
2024-10-16 18:20:46,218 TADA INFO   test-name: papi_sampler_test
2024-10-16 18:20:46,218 TADA INFO   test-user: narate
2024-10-16 18:20:46,218 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:20:46,219 __main__ INFO -- Get or create the cluster --
2024-10-16 18:20:59,882 __main__ INFO -- Start daemons --
2024-10-16 18:21:16,772 TADA INFO assertion 0, ldmsd has started: verified, passed
2024-10-16 18:21:17,009 TADA INFO assertion 1.1, Non-papi job is submitted: jobid(1) > 0, passed
2024-10-16 18:21:22,134 TADA INFO assertion 1.2, Non-papi job is running before ldms_ls: STATE = RUNNING, passed
2024-10-16 18:21:22,308 TADA INFO assertion 1.3, Non-papi job is running after ldms_ls: STATE = RUNNING, passed
2024-10-16 18:21:22,309 TADA INFO assertion 1, Non-papi job does not create set: verified, passed
2024-10-16 18:21:36,163 TADA INFO assertion 2, papi job creates set: PAPI set created, passed
2024-10-16 18:21:36,163 TADA INFO assertion 2.2, Schema name is set accordingly: schema name == papi0, passed
2024-10-16 18:21:36,163 TADA INFO assertion 2.1, Events in papi job set created according to config file: {'PAPI_TOT_INS'} == {'PAPI_TOT_INS'}, passed
2024-10-16 18:21:36,164 TADA INFO assertion 2.3, PAPI set has correct job_id: 2 == 2, passed
2024-10-16 18:21:36,404 TADA INFO assertion 2.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2024-10-16 18:21:42,230 TADA INFO assertion 3, papi job creates set: PAPI set created, passed
2024-10-16 18:21:42,230 TADA INFO assertion 3.2, Schema name is set accordingly: schema name == papi1, passed
2024-10-16 18:21:42,230 TADA INFO assertion 3.1, Events in papi job set created according to config file: {'PAPI_BR_MSP', 'PAPI_TOT_INS'} == {'PAPI_BR_MSP', 'PAPI_TOT_INS'}, passed
2024-10-16 18:21:42,230 TADA INFO assertion 3.3, PAPI set has correct job_id: 3 == 3, passed
2024-10-16 18:21:42,456 TADA INFO assertion 3.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2024-10-16 18:21:42,457 TADA INFO assertion 4, Multiple, concurrent jobs results in concurrent, multiple sets: LDMS sets ({'node-1/papi1/3.0', 'node-1/papi0/2.0', 'node-1/meminfo'}), passed
2024-10-16 18:21:53,029 TADA INFO assertion 6, PAPI set persists within `job_expiry` after job exited: verified, passed
2024-10-16 18:22:33,358 TADA INFO assertion 7, PAPI set is deleted after `2.2 x job_expiry` since job exited: node-1/meminfo deleted, passed
2024-10-16 18:22:35,702 TADA INFO assertion 8, Missing config file attribute is logged: : sampler.papi_sampler: papi_sampler[510]: papi_config object must contain either the 'file' or 'config' attribute., passed
2024-10-16 18:22:41,146 TADA INFO assertion 9, Bad config file is logged: : sampler.papi_sampler: configuration file syntax error., passed
2024-10-16 18:22:41,146 __main__ INFO -- Finishing Test --
2024-10-16 18:22:41,146 TADA INFO test papi_sampler_test ended
2024-10-16 18:22:41,146 __main__ INFO -- Cleaning up files --
2024-10-16 18:22:41,147 __main__ INFO -- Removing the virtual cluster --
2024-10-16 18:22:52 INFO: ----------------------------------------------
2024-10-16 18:22:54 INFO: ======== papi_store_test ========
2024-10-16 18:22:54 INFO: CMD: python3 papi_store_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/papi_store_test
2024-10-16 18:22:55,627 TADA INFO starting test `papi_store_test`
2024-10-16 18:22:55,628 TADA INFO   test-id: 42f96a6fe34309889af39711b2a31fab3d866a34cbb27c0db034e635ee257144
2024-10-16 18:22:55,628 TADA INFO   test-suite: LDMSD
2024-10-16 18:22:55,628 TADA INFO   test-name: papi_store_test
2024-10-16 18:22:55,628 TADA INFO   test-user: narate
2024-10-16 18:22:55,628 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:22:55,629 __main__ INFO -- Get or create the cluster --
2024-10-16 18:23:12,197 __main__ INFO -- Start daemons --
2024-10-16 18:24:00,795 TADA INFO assertion 1, Every job in the input data is represented in the output: {1, 2, 3, 4} = {1, 2, 3, 4}, passed
2024-10-16 18:24:00,795 TADA INFO assertion 2, Every event in every job results in a separate row in the output: verified, passed
2024-10-16 18:24:00,795 TADA INFO assertion 3, The schema name in the output matches the event name: verified, passed
2024-10-16 18:24:00,795 TADA INFO assertion 4, Each rank in the job results in a row per event in the output: verified, passed
2024-10-16 18:24:00,795 TADA INFO test papi_store_test ended
2024-10-16 18:24:13 INFO: ----------------------------------------------
2024-10-16 18:24:15 INFO: ======== store_app_test ========
2024-10-16 18:24:15 INFO: CMD: python3 store_app_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/store_app_test
2024-10-16 18:24:16,086 TADA INFO starting test `store_app_test`
2024-10-16 18:24:16,086 TADA INFO   test-id: fbc0ea36ddcd444bb419d8b327f743bdb806b9586458c53580df8e4190241edb
2024-10-16 18:24:16,086 TADA INFO   test-suite: LDMSD
2024-10-16 18:24:16,087 TADA INFO   test-name: store_app_test
2024-10-16 18:24:16,087 TADA INFO   test-user: narate
2024-10-16 18:24:16,087 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:24:16,088 __main__ INFO -- Get or create the cluster --
2024-10-16 18:24:42,552 __main__ INFO -- Preparing job script & programs --
2024-10-16 18:24:42,965 __main__ INFO -- Start daemons --
2024-10-16 18:25:30,320 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 18:25:35,327 __main__ INFO -- Submitting jobs --
2024-10-16 18:25:35,517 __main__ INFO job_one: 1
2024-10-16 18:25:40,740 __main__ INFO job_two: 2
2024-10-16 18:25:49,881 __main__ INFO Verifying data ...
2024-10-16 18:27:59,888 TADA INFO assertion 1, Verify data: sos data is not empty and sos data < ldms_ls data, passed
2024-10-16 18:27:59,889 TADA INFO test store_app_test ended
2024-10-16 18:28:14 INFO: ----------------------------------------------
2024-10-16 18:28:16 INFO: ======== syspapi_test ========
2024-10-16 18:28:16 INFO: CMD: python3 syspapi_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data/2024-10-16-163023 --data_root /mnt/300G/data/2024-10-16-163023/data/syspapi_test
2024-10-16 18:28:17,152 TADA INFO starting test `syspapi_test`
2024-10-16 18:28:17,152 TADA INFO   test-id: 96b00eef5985ce0cde4414bae71a2fb46e757917fcdaf05368e3e7edfd384fe2
2024-10-16 18:28:17,152 TADA INFO   test-suite: LDMSD
2024-10-16 18:28:17,152 TADA INFO   test-name: syspapi_test
2024-10-16 18:28:17,152 TADA INFO   test-user: narate
2024-10-16 18:28:17,152 TADA INFO   commit-id: 04c74b7b45c1467071acf9512ffb3dfdd68bc649
2024-10-16 18:28:17,153 __main__ INFO -- Get or create the cluster --
2024-10-16 18:28:39,679 __main__ INFO -- Write syspapi JSON config files --
2024-10-16 18:28:39,679 __main__ INFO    - db/syspapi-1.json
2024-10-16 18:28:39,680 __main__ INFO    - db/syspapi-bad.json
2024-10-16 18:28:39,681 __main__ INFO -- Start daemons --
2024-10-16 18:29:09,371 __main__ INFO ... wait a bit to make sure ldmsd's are up
2024-10-16 18:29:14,373 __main__ INFO -- Verifying --
2024-10-16 18:29:14,503 TADA INFO assertion 1, verify set creation by cfg_file: set existed (with correct instance name), passed
2024-10-16 18:29:14,503 TADA INFO assertion 2, verify schema name by cfg_file: verify schema name, passed
2024-10-16 18:29:14,641 TADA INFO assertion 3, verify metrics (events) by cfg_file: verify events (metrics), passed
2024-10-16 18:29:16,789 TADA INFO assertion 4, verify increment counters: verify increment of supported counters, passed
2024-10-16 18:29:16,907 TADA INFO assertion 5, verify cfg_file syntax error report: verify JSON parse error, passed
2024-10-16 18:29:17,001 TADA INFO assertion 6, verify cfg_file unsupported events report: verify unsupported event report, passed
2024-10-16 18:29:38,719 TADA INFO assertion 7, verify cfg_file for many events: each event has either 'sucees' or 'failed' report, passed
2024-10-16 18:29:38,719 __main__ INFO  events succeeded: 77
2024-10-16 18:29:38,720 __main__ INFO  events failed: 114
2024-10-16 18:29:38,720 TADA INFO test syspapi_test ended
2024-10-16 18:29:52 INFO: ----------------------------------------------
2024-10-16 18:29:54 INFO: ======== test-ldms ========
2024-10-16 18:29:54 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-ldms/test.sh
2024-10-16T18:29:54-05:00 INFO: starting test-samp-1
4ca9dad34c85431e44d0c285c1b630d73b239e6cd6e1923c34129714e5a03e5d
2024-10-16T18:29:58-05:00 INFO: starting test-samp-2
569e0c40eb986788fdba1416fd134836e5bcc8998e3e1d08fa70dbe2c57d809e
2024-10-16T18:30:00-05:00 INFO: starting test-samp-3
fe705c48038d1b012c1064c7313baf24481a01255300e2e4f704fff9eedce5fd
2024-10-16T18:30:03-05:00 INFO: starting test-samp-4
85c6db73c177e40ea5d03658b0ba1118692398394ae31f7a514022571cc59636
2024-10-16T18:30:06-05:00 INFO: test-samp-1 is running
2024-10-16T18:30:06-05:00 INFO: test-samp-2 is running
2024-10-16T18:30:06-05:00 INFO: test-samp-3 is running
2024-10-16T18:30:06-05:00 INFO: test-samp-4 is running
2024-10-16T18:30:06-05:00 INFO: starting test-agg-11
2e19fa26d6e01862c79bcb3b858e8708df9406ac5f089a9482f54281aed392d3
2024-10-16T18:30:09-05:00 INFO: starting test-agg-12
29087dc01b9cb4b1698fd9e13a6b93b2ee4c0c2acb09941e0300db2b683be32d
2024-10-16T18:30:12-05:00 INFO: test-agg-11 is running
2024-10-16T18:30:12-05:00 INFO: test-agg-12 is running
2024-10-16T18:30:12-05:00 INFO: starting test-agg-2
d888ad99b3de872519e9aa32a1a50d0bbdb73385a2781377d8df46cf8ad34455
2024-10-16T18:30:14-05:00 INFO: test-agg-2 is running
2024-10-16T18:30:14-05:00 INFO: Collecting data (into SOS)
2024-10-16T18:30:24-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2024-10-16T18:30:26-05:00 INFO: check rc: 0
2024-10-16T18:30:26-05:00 INFO: Cleaning up ...
test-samp-1
test-samp-2
test-samp-3
test-samp-4
test-agg-11
test-agg-12
test-agg-2
2024-10-16T18:30:31-05:00 INFO: DONE
2024-10-16 18:30:41 INFO: ----------------------------------------------
2024-10-16 18:30:41 INFO: ======== test-maestro ========
2024-10-16 18:30:41 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro/test.sh
2024-10-16T18:30:41-05:00 INFO: starting mtest-maestro
380dba68d15d417a62cbcb185071064bb426c2e00ea0b458430db5869f6836af
2024-10-16T18:30:43-05:00 INFO: starting mtest-samp-1
58203743d8e2833b673a2f50df490d050dbb8d82cc6cec87c417adf14ad665b2
2024-10-16T18:30:45-05:00 INFO: starting mtest-samp-2
24235ca44272e6228e7c95e260149fd602358819b1dc5f3963cc67ae0c0715b0
2024-10-16T18:30:46-05:00 INFO: starting mtest-samp-3
5ba142e5dac9f0e207ba55a43699718c762ece57fef32995ed40041385edd0a7
2024-10-16T18:30:48-05:00 INFO: starting mtest-samp-4
eff3718cd1922975c77245d86e2861771b39e50f4972fc87143598f19096f5f1
2024-10-16T18:30:50-05:00 INFO: mtest-samp-1 is running
2024-10-16T18:30:50-05:00 INFO: mtest-samp-2 is running
2024-10-16T18:30:50-05:00 INFO: mtest-samp-3 is running
2024-10-16T18:30:50-05:00 INFO: mtest-samp-4 is running
2024-10-16T18:30:50-05:00 INFO: starting mtest-agg-11
5f415c49760c6f7975808549e697b60edd94019d7555ff500fc0f1b61ad6b382
2024-10-16T18:30:51-05:00 INFO: starting mtest-agg-12
ba6e0c06a851dab1c502d99f96783b56c307c152c2348dc2305d699b9ce2597a
2024-10-16T18:30:52-05:00 INFO: mtest-agg-11 is running
2024-10-16T18:30:53-05:00 INFO: mtest-agg-12 is running
2024-10-16T18:30:53-05:00 INFO: starting mtest-agg-2
7b94b5cd4c7e41e878dffe39fd796fd5858e4192c3dff0e2a8511c4732bf39ff
2024-10-16T18:30:54-05:00 INFO: mtest-agg-2 is running
2024-10-16T18:30:54-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2024-10-16T18:32:55-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2024-10-16T18:32:57-05:00 INFO: sos check rc: 0
2024-10-16T18:32:58-05:00 INFO: starting mtest-ui
1ac7a814c8276dbd7960af8129877f603107e2c5f92e68ed8ced19855b810ca7
2024-10-16T18:33:05-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4452848, 1729121475002.058], [4452848, 1729121475002.062], [4452848, 1729121475002.062], [4452848, 1729121475002.065], [4453044, 1729121476001.211], [4453044, 1729121476001.215], [4453044, 1729121476001.217], [4453044, 1729121476001.219], [4453220, 1729121477001.352], [4453220, 1729121477001.355], [4453220, 1729121477001.3591], [4453220, 1729121477001.363], [4453220, 1729121478001.376], [4453220, 1729121478001.471], [4453220, 1729121478001.4778], [4453220, 1729121478001.491], [4453220, 1729121479001.512], [4453220, 1729121479001.603], [4453220, 1729121479001.604], [4453220, 1729121479001.6199], [4453212, 1729121480001.671], [4453212, 1729121480001.7542], [4453212, 1729121480001.7568], [4453212, 1729121480001.7751], [4453220, 1729121481001.794], [4453220, 1729121481001.871], [4453220, 1729121481001.8718], [4453220, 1729121481001.898], [4453220, 1729121482001.924], [4453220, 1729121482001.99], [4453220, 1729121482001.997], [4453220, 1729121482002.025], [4453220, 1729121483001.171], [4453220, 1729121483001.2349], [4453220, 1729121483002.046], [4453220, 1729121483002.1272], [4453220, 1729121484001.198], [4453220, 1729121484001.202], [4453220, 1729121484001.262], [4453220, 1729121484001.3079], [4453228, 1729121485000.4932], [4453228, 1729121485000.549], [4453228, 1729121485000.591], [4453228, 1729121485000.728], [4453220, 1729121486001.649], [4453220, 1729121486001.653], [4453220, 1729121486001.68], [4453220, 1729121486001.878], [4453220, 1729121487001.323], [4453220, 1729121487001.7961], [4453220, 1729121487001.797], [4453220, 1729121487001.7988], [4453220, 1729121488001.464], [4453220, 1729121488001.464], [4453220, 1729121488001.91], [4453220, 1729121488001.9258], [4453216, 1729121489001.618], [4453216, 1729121489001.6262], [4453216, 1729121489001.63], [4453216, 1729121489002.056], [4453220, 1729121490001.2002], [4453220, 1729121490001.202], [4453220, 1729121490001.7358], [4453220, 1729121490001.752], [4453220, 1729121491001.356], [4453220, 1729121491001.3599], [4453220, 1729121491001.3599], [4453220, 1729121491001.871], [4453220, 1729121492001.4878], [4453220, 1729121492001.492], [4453220, 1729121492001.494], [4453220, 1729121492001.495], [4453220, 1729121493001.621], [4453220, 1729121493001.621], [4453220, 1729121493001.624], [4453220, 1729121493001.625], [4453220, 1729121494001.7468], [4453220, 1729121494001.748], [4453220, 1729121494001.748], [4453220, 1729121494001.7542], [4453220, 1729121495001.072], [4453220, 1729121495001.8728], [4453220, 1729121495001.874], [4453220, 1729121495001.8801], [4453220, 1729121496001.232], [4453220, 1729121496001.2349], [4453220, 1729121496002.0322], [4453220, 1729121496002.033], [4453220, 1729121497001.158], [4453220, 1729121497001.1619], [4453220, 1729121497001.3599], [4453220, 1729121497001.37], [4453220, 1729121498001.282], [4453220, 1729121498001.2852], [4453220, 1729121498001.482], [4453220, 1729121498001.487], [4453220, 1729121499001.409], [4453220, 1729121499001.4148], [4453220, 1729121499001.6099], [4453220, 1729121499001.614], [4453220, 1729121500001.54], [4453220, 1729121500001.541], [4453220, 1729121500001.739], [4453220, 1729121500001.7468], [4453216, 1729121501001.6929], [4453216, 1729121501001.696], [4453216, 1729121501001.892], [4453216, 1729121501001.896], [4453220, 1729121502001.818], [4453220, 1729121502001.822], [4453220, 1729121502002.023], [4453220, 1729121502002.029], [4453220, 1729121503001.156], [4453220, 1729121503001.164], [4453220, 1729121503001.698], [4453220, 1729121503001.939], [4453220, 1729121504001.302], [4453220, 1729121504001.303], [4453220, 1729121504001.829], [4453220, 1729121504001.85], [4453220, 1729121505001.451], [4453220, 1729121505001.4521], [4453220, 1729121505001.454], [4453220, 1729121505001.965], [4453224, 1729121506000.761], [4453224, 1729121506001.585], [4453224, 1729121506001.628], [4453224, 1729121506001.6938], [4453220, 1729121507000.807], [4453220, 1729121507001.7148], [4453220, 1729121507001.727], [4453220, 1729121507001.8188], [4453220, 1729121508001.8481], [4453220, 1729121508001.849], [4453220, 1729121508001.85], [4453220, 1729121508001.952], [4453220, 1729121509001.845], [4453220, 1729121509001.967], [4453220, 1729121509001.984], [4453220, 1729121509002.086], [4453220, 1729121510001.23], [4453220, 1729121510001.994], [4453220, 1729121510001.996], [4453220, 1729121510002.113], [4453220, 1729121511001.279], [4453220, 1729121511001.375], [4453220, 1729121511001.958], [4453220, 1729121511002.115], [4453220, 1729121512001.257], [4453220, 1729121512001.26], [4453220, 1729121512001.4148], [4453220, 1729121512001.5], [4453220, 1729121513001.3938], [4453220, 1729121513001.402], [4453220, 1729121513001.559], [4453220, 1729121513001.625], [4453220, 1729121514001.537], [4453220, 1729121514001.543], [4453220, 1729121514001.709], [4453220, 1729121514001.7542], [4453220, 1729121515001.663], [4453220, 1729121515001.6719], [4453220, 1729121515001.834], [4453220, 1729121515001.876], [4453220, 1729121516001.229], [4453220, 1729121516001.752], [4453220, 1729121516001.772], [4453220, 1729121516001.975], [4453220, 1729121517001.3892], [4453220, 1729121517001.392], [4453220, 1729121517001.925], [4453220, 1729121517002.122], [4453220, 1729121518001.2532], [4453220, 1729121518001.51], [4453220, 1729121518001.525], [4453220, 1729121518002.059], [4453220, 1729121519001.1929], [4453220, 1729121519001.385], [4453220, 1729121519001.638], [4453220, 1729121519001.645], [4453220, 1729121520001.3281], [4453220, 1729121520001.519], [4453220, 1729121520001.7642], [4453220, 1729121520001.771], [4453220, 1729121521001.46], [4453220, 1729121521001.6619], [4453220, 1729121521001.891], [4453220, 1729121521001.899], [4453220, 1729121522001.615], [4453220, 1729121522001.8171], [4453220, 1729121522002.0469], [4453220, 1729121522002.049], [4453220, 1729121523001.182], [4453220, 1729121523001.185], [4453220, 1729121523001.7568], [4453220, 1729121523001.9531], [4453220, 1729121524001.3179], [4453220, 1729121524001.324], [4453220, 1729121524001.891], [4453220, 1729121524002.083], [4453220, 1729121525001.205], [4453220, 1729121525001.233], [4453220, 1729121525001.4321], [4453220, 1729121525001.4521], [4453220, 1729121526001.3289], [4453220, 1729121526001.3508], [4453220, 1729121526001.353], [4453220, 1729121526001.572], [4453220, 1729121527001.492], [4453220, 1729121527001.5], [4453220, 1729121527001.506], [4453220, 1729121527001.509], [4453220, 1729121528001.615], [4453220, 1729121528001.617], [4453220, 1729121528001.622], [4453220, 1729121528001.625], [4453216, 1729121529001.7659], [4453216, 1729121529001.7659], [4453216, 1729121529001.773], [4453216, 1729121529001.7751], [4453220, 1729121530001.8901], [4453220, 1729121530001.893], [4453220, 1729121530001.899], [4453220, 1729121530001.903], [4453220, 1729121531002.008], [4453220, 1729121531002.011], [4453220, 1729121531002.018], [4453220, 1729121531002.0212], [4453208, 1729121532001.17], [4453208, 1729121532001.1719], [4453208, 1729121532001.173], [4453208, 1729121532001.175], [4453220, 1729121533001.304], [4453220, 1729121533001.3062], [4453220, 1729121533001.307], [4453220, 1729121533001.3179], [4453220, 1729121534001.449], [4453220, 1729121534001.454], [4453220, 1729121534001.455], [4453220, 1729121534001.4568], [4453220, 1729121535001.5989], [4453220, 1729121535001.5989], [4453220, 1729121535001.602], [4453220, 1729121535001.604], [4453220, 1729121536001.727], [4453220, 1729121536001.727], [4453220, 1729121536001.728], [4453220, 1729121536001.7358], [4453216, 1729121537001.889], [4453216, 1729121537001.8938], [4453216, 1729121537001.896], [4453216, 1729121537001.897], [4453220, 1729121538002.023], [4453220, 1729121538002.023], [4453220, 1729121538002.026], [4453220, 1729121538002.03], [4453220, 1729121539001.17], [4453220, 1729121539001.174], [4453220, 1729121539001.175], [4453220, 1729121539001.177], [4453220, 1729121540001.3], [4453220, 1729121540001.302], [4453220, 1729121540001.303], [4453220, 1729121540001.313], [4453220, 1729121541001.4238], [4453220, 1729121541001.43], [4453220, 1729121541001.4312], [4453220, 1729121541001.4358], [4453220, 1729121542001.5842], [4453220, 1729121542001.588], [4453220, 1729121542001.589], [4453220, 1729121542001.591], [4453220, 1729121543001.727], [4453220, 1729121543001.729], [4453220, 1729121543001.731], [4453220, 1729121543001.7322], [4453220, 1729121544001.871], [4453220, 1729121544001.8728], [4453220, 1729121544001.875], [4453220, 1729121544001.876], [4453220, 1729121545001.992], [4453220, 1729121545001.998], [4453220, 1729121545001.9998], [4453220, 1729121545002.003], [4453220, 1729121546001.13], [4453220, 1729121546001.131], [4453220, 1729121546001.135], [4453220, 1729121546002.13], [4453220, 1729121547000.256], [4453220, 1729121547001.247], [4453220, 1729121547001.259], [4453220, 1729121547001.3079], [4453220, 1729121548001.408], [4453220, 1729121548001.412], [4453220, 1729121548001.4148], [4453220, 1729121548001.456], [4453220, 1729121549001.376], [4453220, 1729121549001.534], [4453220, 1729121549001.565], [4453220, 1729121549001.6], [4453220, 1729121550001.522], [4453220, 1729121550001.525], [4453220, 1729121550001.681], [4453220, 1729121550001.723], [4453220, 1729121551001.653], [4453220, 1729121551001.66], [4453220, 1729121551001.661], [4453220, 1729121551001.8591], [4453220, 1729121552001.7769], [4453220, 1729121552001.7769], [4453220, 1729121552001.781], [4453220, 1729121552001.987], [4453220, 1729121553001.718], [4453220, 1729121553001.856], [4453220, 1729121553001.8828], [4453220, 1729121553001.922], [4453220, 1729121554001.864], [4453220, 1729121554001.866], [4453220, 1729121554001.975], [4453220, 1729121554002.045], [4453220, 1729121555001.181], [4453220, 1729121555001.995], [4453220, 1729121555001.999], [4453220, 1729121555002.08], [4453220, 1729121556001.125], [4453220, 1729121556001.194], [4453220, 1729121556001.303], [4453220, 1729121556002.123], [4453220, 1729121557000.3672], [4453220, 1729121557001.259], [4453220, 1729121557001.3088], [4453220, 1729121557001.407], [4453220, 1729121558001.417], [4453220, 1729121558001.455], [4453220, 1729121558001.517], [4453220, 1729121558001.52], [4453220, 1729121559001.558], [4453220, 1729121559001.581], [4453220, 1729121559001.6409], [4453220, 1729121559001.643], [4453220, 1729121560001.6929], [4453220, 1729121560001.697], [4453220, 1729121560001.761], [4453220, 1729121560001.7642], [4453220, 1729121561001.822], [4453220, 1729121561001.8281], [4453220, 1729121561001.875], [4453220, 1729121561001.877], [4453220, 1729121562001.95], [4453220, 1729121562001.954], [4453220, 1729121562001.987], [4453220, 1729121562001.995], [4453220, 1729121563002.123], [4453220, 1729121563002.1272], [4453220, 1729121563002.1482], [4453220, 1729121563002.1602], [4453220, 1729121564001.216], [4453220, 1729121564001.2769], [4453220, 1729121564001.2942], [4453220, 1729121564001.3052], [4453220, 1729121565001.366], [4453220, 1729121565001.4138], [4453220, 1729121565001.434], [4453220, 1729121565001.44], [4453220, 1729121566001.5], [4453220, 1729121566001.532], [4453220, 1729121566001.5518], [4453220, 1729121566001.555], [4453220, 1729121567001.6409], [4453220, 1729121567001.6519], [4453220, 1729121567001.6692], [4453220, 1729121567001.68], [4453212, 1729121568001.8052], [4453212, 1729121568001.8098], [4453212, 1729121568001.821], [4453212, 1729121568001.823], [4453220, 1729121569001.963], [4453220, 1729121569001.969], [4453220, 1729121569001.971], [4453220, 1729121569001.972], [4453220, 1729121570002.097], [4453220, 1729121570002.0999], [4453220, 1729121570002.101], [4453220, 1729121570002.102], [4453220, 1729121571001.223], [4453220, 1729121571001.2249], [4453220, 1729121571001.226], [4453220, 1729121571001.2312], [4453220, 1729121572001.3691], [4453220, 1729121572001.37], [4453220, 1729121572001.3708], [4453220, 1729121572001.375], [4453224, 1729121573001.53], [4453224, 1729121573001.533], [4453224, 1729121573001.534], [4453224, 1729121573001.537], [4453220, 1729121574001.666], [4453220, 1729121574001.6729], [4453220, 1729121574001.677], [4453220, 1729121574001.677]]}, {"target": "component_id", "datapoints": [[4, 1729121475002.058], [2, 1729121475002.062], [3, 1729121475002.062], [1, 1729121475002.065], [3, 1729121476001.211], [1, 1729121476001.215], [2, 1729121476001.217], [4, 1729121476001.219], [2, 1729121477001.352], [3, 1729121477001.355], [4, 1729121477001.3591], [1, 1729121477001.363], [4, 1729121478001.376], [2, 1729121478001.471], [3, 1729121478001.4778], [1, 1729121478001.491], [4, 1729121479001.512], [3, 1729121479001.603], [2, 1729121479001.604], [1, 1729121479001.6199], [4, 1729121480001.671], [3, 1729121480001.7542], [2, 1729121480001.7568], [1, 1729121480001.7751], [4, 1729121481001.794], [3, 1729121481001.871], [2, 1729121481001.8718], [1, 1729121481001.898], [4, 1729121482001.924], [3, 1729121482001.99], [2, 1729121482001.997], [1, 1729121482002.025], [1, 1729121483001.171], [3, 1729121483001.2349], [4, 1729121483002.046], [2, 1729121483002.1272], [4, 1729121484001.198], [3, 1729121484001.202], [2, 1729121484001.262], [1, 1729121484001.3079], [3, 1729121485000.4932], [4, 1729121485000.549], [1, 1729121485000.591], [2, 1729121485000.728], [3, 1729121486001.649], [1, 1729121486001.653], [4, 1729121486001.68], [2, 1729121486001.878], [2, 1729121487001.323], [3, 1729121487001.7961], [1, 1729121487001.797], [4, 1729121487001.7988], [2, 1729121488001.464], [4, 1729121488001.464], [3, 1729121488001.91], [1, 1729121488001.9258], [2, 1729121489001.618], [3, 1729121489001.6262], [4, 1729121489001.63], [1, 1729121489002.056], [3, 1729121490001.2002], [1, 1729121490001.202], [4, 1729121490001.7358], [2, 1729121490001.752], [1, 1729121491001.356], [3, 1729121491001.3599], [4, 1729121491001.3599], [2, 1729121491001.871], [1, 1729121492001.4878], [4, 1729121492001.492], [3, 1729121492001.494], [2, 1729121492001.495], [2, 1729121493001.621], [4, 1729121493001.621], [3, 1729121493001.624], [1, 1729121493001.625], [4, 1729121494001.7468], [1, 1729121494001.748], [2, 1729121494001.748], [3, 1729121494001.7542], [1, 1729121495001.072], [3, 1729121495001.8728], [4, 1729121495001.874], [2, 1729121495001.8801], [1, 1729121496001.232], [3, 1729121496001.2349], [4, 1729121496002.0322], [2, 1729121496002.033], [4, 1729121497001.158], [2, 1729121497001.1619], [1, 1729121497001.3599], [3, 1729121497001.37], [2, 1729121498001.282], [4, 1729121498001.2852], [1, 1729121498001.482], [3, 1729121498001.487], [2, 1729121499001.409], [4, 1729121499001.4148], [1, 1729121499001.6099], [3, 1729121499001.614], [4, 1729121500001.54], [2, 1729121500001.541], [1, 1729121500001.739], [3, 1729121500001.7468], [2, 1729121501001.6929], [4, 1729121501001.696], [3, 1729121501001.892], [1, 1729121501001.896], [2, 1729121502001.818], [4, 1729121502001.822], [1, 1729121502002.023], [3, 1729121502002.029], [1, 1729121503001.156], [3, 1729121503001.164], [2, 1729121503001.698], [4, 1729121503001.939], [1, 1729121504001.302], [3, 1729121504001.303], [4, 1729121504001.829], [2, 1729121504001.85], [1, 1729121505001.451], [4, 1729121505001.4521], [3, 1729121505001.454], [2, 1729121505001.965], [1, 1729121506000.761], [3, 1729121506001.585], [4, 1729121506001.628], [2, 1729121506001.6938], [4, 1729121507000.807], [1, 1729121507001.7148], [3, 1729121507001.727], [2, 1729121507001.8188], [3, 1729121508001.8481], [4, 1729121508001.849], [1, 1729121508001.85], [2, 1729121508001.952], [3, 1729121509001.845], [1, 1729121509001.967], [4, 1729121509001.984], [2, 1729121509002.086], [2, 1729121510001.23], [3, 1729121510001.994], [1, 1729121510001.996], [4, 1729121510002.113], [4, 1729121511001.279], [2, 1729121511001.375], [1, 1729121511001.958], [3, 1729121511002.115], [3, 1729121512001.257], [1, 1729121512001.26], [4, 1729121512001.4148], [2, 1729121512001.5], [3, 1729121513001.3938], [1, 1729121513001.402], [4, 1729121513001.559], [2, 1729121513001.625], [3, 1729121514001.537], [1, 1729121514001.543], [4, 1729121514001.709], [2, 1729121514001.7542], [3, 1729121515001.663], [1, 1729121515001.6719], [4, 1729121515001.834], [2, 1729121515001.876], [2, 1729121516001.229], [3, 1729121516001.752], [1, 1729121516001.772], [4, 1729121516001.975], [3, 1729121517001.3892], [2, 1729121517001.392], [1, 1729121517001.925], [4, 1729121517002.122], [4, 1729121518001.2532], [2, 1729121518001.51], [3, 1729121518001.525], [1, 1729121518002.059], [1, 1729121519001.1929], [4, 1729121519001.385], [2, 1729121519001.638], [3, 1729121519001.645], [1, 1729121520001.3281], [4, 1729121520001.519], [2, 1729121520001.7642], [3, 1729121520001.771], [1, 1729121521001.46], [4, 1729121521001.6619], [2, 1729121521001.891], [3, 1729121521001.899], [1, 1729121522001.615], [4, 1729121522001.8171], [2, 1729121522002.0469], [3, 1729121522002.049], [3, 1729121523001.182], [2, 1729121523001.185], [1, 1729121523001.7568], [4, 1729121523001.9531], [2, 1729121524001.3179], [3, 1729121524001.324], [1, 1729121524001.891], [4, 1729121524002.083], [4, 1729121525001.205], [1, 1729121525001.233], [3, 1729121525001.4321], [2, 1729121525001.4521], [4, 1729121526001.3289], [1, 1729121526001.3508], [3, 1729121526001.353], [2, 1729121526001.572], [4, 1729121527001.492], [1, 1729121527001.5], [2, 1729121527001.506], [3, 1729121527001.509], [4, 1729121528001.615], [1, 1729121528001.617], [2, 1729121528001.622], [3, 1729121528001.625], [3, 1729121529001.7659], [4, 1729121529001.7659], [2, 1729121529001.773], [1, 1729121529001.7751], [4, 1729121530001.8901], [1, 1729121530001.893], [2, 1729121530001.899], [3, 1729121530001.903], [1, 1729121531002.008], [4, 1729121531002.011], [2, 1729121531002.018], [3, 1729121531002.0212], [2, 1729121532001.17], [3, 1729121532001.1719], [4, 1729121532001.173], [1, 1729121532001.175], [3, 1729121533001.304], [4, 1729121533001.3062], [2, 1729121533001.307], [1, 1729121533001.3179], [4, 1729121534001.449], [3, 1729121534001.454], [2, 1729121534001.455], [1, 1729121534001.4568], [2, 1729121535001.5989], [3, 1729121535001.5989], [4, 1729121535001.602], [1, 1729121535001.604], [3, 1729121536001.727], [4, 1729121536001.727], [2, 1729121536001.728], [1, 1729121536001.7358], [4, 1729121537001.889], [2, 1729121537001.8938], [1, 1729121537001.896], [3, 1729121537001.897], [2, 1729121538002.023], [4, 1729121538002.023], [3, 1729121538002.026], [1, 1729121538002.03], [2, 1729121539001.17], [1, 1729121539001.174], [3, 1729121539001.175], [4, 1729121539001.177], [3, 1729121540001.3], [2, 1729121540001.302], [1, 1729121540001.303], [4, 1729121540001.313], [2, 1729121541001.4238], [1, 1729121541001.43], [3, 1729121541001.4312], [4, 1729121541001.4358], [2, 1729121542001.5842], [1, 1729121542001.588], [4, 1729121542001.589], [3, 1729121542001.591], [3, 1729121543001.727], [2, 1729121543001.729], [1, 1729121543001.731], [4, 1729121543001.7322], [3, 1729121544001.871], [1, 1729121544001.8728], [2, 1729121544001.875], [4, 1729121544001.876], [3, 1729121545001.992], [1, 1729121545001.998], [2, 1729121545001.9998], [4, 1729121545002.003], [1, 1729121546001.13], [2, 1729121546001.131], [4, 1729121546001.135], [3, 1729121546002.13], [1, 1729121547000.256], [3, 1729121547001.247], [2, 1729121547001.259], [4, 1729121547001.3079], [3, 1729121548001.408], [2, 1729121548001.412], [1, 1729121548001.4148], [4, 1729121548001.456], [1, 1729121549001.376], [3, 1729121549001.534], [2, 1729121549001.565], [4, 1729121549001.6], [3, 1729121550001.522], [1, 1729121550001.525], [2, 1729121550001.681], [4, 1729121550001.723], [1, 1729121551001.653], [2, 1729121551001.66], [3, 1729121551001.661], [4, 1729121551001.8591], [1, 1729121552001.7769], [3, 1729121552001.7769], [2, 1729121552001.781], [4, 1729121552001.987], [4, 1729121553001.718], [1, 1729121553001.856], [3, 1729121553001.8828], [2, 1729121553001.922], [3, 1729121554001.864], [4, 1729121554001.866], [1, 1729121554001.975], [2, 1729121554002.045], [2, 1729121555001.181], [4, 1729121555001.995], [3, 1729121555001.999], [1, 1729121555002.08], [3, 1729121556001.125], [1, 1729121556001.194], [2, 1729121556001.303], [4, 1729121556002.123], [4, 1729121557000.3672], [3, 1729121557001.259], [1, 1729121557001.3088], [2, 1729121557001.407], [3, 1729121558001.417], [1, 1729121558001.455], [4, 1729121558001.517], [2, 1729121558001.52], [3, 1729121559001.558], [1, 1729121559001.581], [4, 1729121559001.6409], [2, 1729121559001.643], [3, 1729121560001.6929], [1, 1729121560001.697], [4, 1729121560001.761], [2, 1729121560001.7642], [1, 1729121561001.822], [3, 1729121561001.8281], [4, 1729121561001.875], [2, 1729121561001.877], [3, 1729121562001.95], [1, 1729121562001.954], [4, 1729121562001.987], [2, 1729121562001.995], [3, 1729121563002.123], [1, 1729121563002.1272], [4, 1729121563002.1482], [2, 1729121563002.1602], [1, 1729121564001.216], [3, 1729121564001.2769], [4, 1729121564001.2942], [2, 1729121564001.3052], [1, 1729121565001.366], [3, 1729121565001.4138], [4, 1729121565001.434], [2, 1729121565001.44], [1, 1729121566001.5], [3, 1729121566001.532], [2, 1729121566001.5518], [4, 1729121566001.555], [1, 1729121567001.6409], [3, 1729121567001.6519], [2, 1729121567001.6692], [4, 1729121567001.68], [3, 1729121568001.8052], [1, 1729121568001.8098], [2, 1729121568001.821], [4, 1729121568001.823], [3, 1729121569001.963], [2, 1729121569001.969], [1, 1729121569001.971], [4, 1729121569001.972], [1, 1729121570002.097], [4, 1729121570002.0999], [3, 1729121570002.101], [2, 1729121570002.102], [2, 1729121571001.223], [3, 1729121571001.2249], [4, 1729121571001.226], [1, 1729121571001.2312], [4, 1729121572001.3691], [2, 1729121572001.37], [1, 1729121572001.3708], [3, 1729121572001.375], [4, 1729121573001.53], [3, 1729121573001.533], [2, 1729121573001.534], [1, 1729121573001.537], [4, 1729121574001.666], [3, 1729121574001.6729], [1, 1729121574001.677], [2, 1729121574001.677]]}, {"target": "job_id", "datapoints": [[0, 1729121475002.058], [0, 1729121475002.062], [0, 1729121475002.062], [0, 1729121475002.065], [0, 1729121476001.211], [0, 1729121476001.215], [0, 1729121476001.217], [0, 1729121476001.219], [0, 1729121477001.352], [0, 1729121477001.355], [0, 1729121477001.3591], [0, 1729121477001.363], [0, 1729121478001.376], [0, 1729121478001.471], [0, 1729121478001.4778], [0, 1729121478001.491], [0, 1729121479001.512], [0, 1729121479001.603], [0, 1729121479001.604], [0, 1729121479001.6199], [0, 1729121480001.671], [0, 1729121480001.7542], [0, 1729121480001.7568], [0, 1729121480001.7751], [0, 1729121481001.794], [0, 1729121481001.871], [0, 1729121481001.8718], [0, 1729121481001.898], [0, 1729121482001.924], [0, 1729121482001.99], [0, 1729121482001.997], [0, 1729121482002.025], [0, 1729121483001.171], [0, 1729121483001.2349], [0, 1729121483002.046], [0, 1729121483002.1272], [0, 1729121484001.198], [0, 1729121484001.202], [0, 1729121484001.262], [0, 1729121484001.3079], [0, 1729121485000.4932], [0, 1729121485000.549], [0, 1729121485000.591], [0, 1729121485000.728], [0, 1729121486001.649], [0, 1729121486001.653], [0, 1729121486001.68], [0, 1729121486001.878], [0, 1729121487001.323], [0, 1729121487001.7961], [0, 1729121487001.797], [0, 1729121487001.7988], [0, 1729121488001.464], [0, 1729121488001.464], [0, 1729121488001.91], [0, 1729121488001.9258], [0, 1729121489001.618], [0, 1729121489001.6262], [0, 1729121489001.63], [0, 1729121489002.056], [0, 1729121490001.2002], [0, 1729121490001.202], [0, 1729121490001.7358], [0, 1729121490001.752], [0, 1729121491001.356], [0, 1729121491001.3599], [0, 1729121491001.3599], [0, 1729121491001.871], [0, 1729121492001.4878], [0, 1729121492001.492], [0, 1729121492001.494], [0, 1729121492001.495], [0, 1729121493001.621], [0, 1729121493001.621], [0, 1729121493001.624], [0, 1729121493001.625], [0, 1729121494001.7468], [0, 1729121494001.748], [0, 1729121494001.748], [0, 1729121494001.7542], [0, 1729121495001.072], [0, 1729121495001.8728], [0, 1729121495001.874], [0, 1729121495001.8801], [0, 1729121496001.232], [0, 1729121496001.2349], [0, 1729121496002.0322], [0, 1729121496002.033], [0, 1729121497001.158], [0, 1729121497001.1619], [0, 1729121497001.3599], [0, 1729121497001.37], [0, 1729121498001.282], [0, 1729121498001.2852], [0, 1729121498001.482], [0, 1729121498001.487], [0, 1729121499001.409], [0, 1729121499001.4148], [0, 1729121499001.6099], [0, 1729121499001.614], [0, 1729121500001.54], [0, 1729121500001.541], [0, 1729121500001.739], [0, 1729121500001.7468], [0, 1729121501001.6929], [0, 1729121501001.696], [0, 1729121501001.892], [0, 1729121501001.896], [0, 1729121502001.818], [0, 1729121502001.822], [0, 1729121502002.023], [0, 1729121502002.029], [0, 1729121503001.156], [0, 1729121503001.164], [0, 1729121503001.698], [0, 1729121503001.939], [0, 1729121504001.302], [0, 1729121504001.303], [0, 1729121504001.829], [0, 1729121504001.85], [0, 1729121505001.451], [0, 1729121505001.4521], [0, 1729121505001.454], [0, 1729121505001.965], [0, 1729121506000.761], [0, 1729121506001.585], [0, 1729121506001.628], [0, 1729121506001.6938], [0, 1729121507000.807], [0, 1729121507001.7148], [0, 1729121507001.727], [0, 1729121507001.8188], [0, 1729121508001.8481], [0, 1729121508001.849], [0, 1729121508001.85], [0, 1729121508001.952], [0, 1729121509001.845], [0, 1729121509001.967], [0, 1729121509001.984], [0, 1729121509002.086], [0, 1729121510001.23], [0, 1729121510001.994], [0, 1729121510001.996], [0, 1729121510002.113], [0, 1729121511001.279], [0, 1729121511001.375], [0, 1729121511001.958], [0, 1729121511002.115], [0, 1729121512001.257], [0, 1729121512001.26], [0, 1729121512001.4148], [0, 1729121512001.5], [0, 1729121513001.3938], [0, 1729121513001.402], [0, 1729121513001.559], [0, 1729121513001.625], [0, 1729121514001.537], [0, 1729121514001.543], [0, 1729121514001.709], [0, 1729121514001.7542], [0, 1729121515001.663], [0, 1729121515001.6719], [0, 1729121515001.834], [0, 1729121515001.876], [0, 1729121516001.229], [0, 1729121516001.752], [0, 1729121516001.772], [0, 1729121516001.975], [0, 1729121517001.3892], [0, 1729121517001.392], [0, 1729121517001.925], [0, 1729121517002.122], [0, 1729121518001.2532], [0, 1729121518001.51], [0, 1729121518001.525], [0, 1729121518002.059], [0, 1729121519001.1929], [0, 1729121519001.385], [0, 1729121519001.638], [0, 1729121519001.645], [0, 1729121520001.3281], [0, 1729121520001.519], [0, 1729121520001.7642], [0, 1729121520001.771], [0, 1729121521001.46], [0, 1729121521001.6619], [0, 1729121521001.891], [0, 1729121521001.899], [0, 1729121522001.615], [0, 1729121522001.8171], [0, 1729121522002.0469], [0, 1729121522002.049], [0, 1729121523001.182], [0, 1729121523001.185], [0, 1729121523001.7568], [0, 1729121523001.9531], [0, 1729121524001.3179], [0, 1729121524001.324], [0, 1729121524001.891], [0, 1729121524002.083], [0, 1729121525001.205], [0, 1729121525001.233], [0, 1729121525001.4321], [0, 1729121525001.4521], [0, 1729121526001.3289], [0, 1729121526001.3508], [0, 1729121526001.353], [0, 1729121526001.572], [0, 1729121527001.492], [0, 1729121527001.5], [0, 1729121527001.506], [0, 1729121527001.509], [0, 1729121528001.615], [0, 1729121528001.617], [0, 1729121528001.622], [0, 1729121528001.625], [0, 1729121529001.7659], [0, 1729121529001.7659], [0, 1729121529001.773], [0, 1729121529001.7751], [0, 1729121530001.8901], [0, 1729121530001.893], [0, 1729121530001.899], [0, 1729121530001.903], [0, 1729121531002.008], [0, 1729121531002.011], [0, 1729121531002.018], [0, 1729121531002.0212], [0, 1729121532001.17], [0, 1729121532001.1719], [0, 1729121532001.173], [0, 1729121532001.175], [0, 1729121533001.304], [0, 1729121533001.3062], [0, 1729121533001.307], [0, 1729121533001.3179], [0, 1729121534001.449], [0, 1729121534001.454], [0, 1729121534001.455], [0, 1729121534001.4568], [0, 1729121535001.5989], [0, 1729121535001.5989], [0, 1729121535001.602], [0, 1729121535001.604], [0, 1729121536001.727], [0, 1729121536001.727], [0, 1729121536001.728], [0, 1729121536001.7358], [0, 1729121537001.889], [0, 1729121537001.8938], [0, 1729121537001.896], [0, 1729121537001.897], [0, 1729121538002.023], [0, 1729121538002.023], [0, 1729121538002.026], [0, 1729121538002.03], [0, 1729121539001.17], [0, 1729121539001.174], [0, 1729121539001.175], [0, 1729121539001.177], [0, 1729121540001.3], [0, 1729121540001.302], [0, 1729121540001.303], [0, 1729121540001.313], [0, 1729121541001.4238], [0, 1729121541001.43], [0, 1729121541001.4312], [0, 1729121541001.4358], [0, 1729121542001.5842], [0, 1729121542001.588], [0, 1729121542001.589], [0, 1729121542001.591], [0, 1729121543001.727], [0, 1729121543001.729], [0, 1729121543001.731], [0, 1729121543001.7322], [0, 1729121544001.871], [0, 1729121544001.8728], [0, 1729121544001.875], [0, 1729121544001.876], [0, 1729121545001.992], [0, 1729121545001.998], [0, 1729121545001.9998], [0, 1729121545002.003], [0, 1729121546001.13], [0, 1729121546001.131], [0, 1729121546001.135], [0, 1729121546002.13], [0, 1729121547000.256], [0, 1729121547001.247], [0, 1729121547001.259], [0, 1729121547001.3079], [0, 1729121548001.408], [0, 1729121548001.412], [0, 1729121548001.4148], [0, 1729121548001.456], [0, 1729121549001.376], [0, 1729121549001.534], [0, 1729121549001.565], [0, 1729121549001.6], [0, 1729121550001.522], [0, 1729121550001.525], [0, 1729121550001.681], [0, 1729121550001.723], [0, 1729121551001.653], [0, 1729121551001.66], [0, 1729121551001.661], [0, 1729121551001.8591], [0, 1729121552001.7769], [0, 1729121552001.7769], [0, 1729121552001.781], [0, 1729121552001.987], [0, 1729121553001.718], [0, 1729121553001.856], [0, 1729121553001.8828], [0, 1729121553001.922], [0, 1729121554001.864], [0, 1729121554001.866], [0, 1729121554001.975], [0, 1729121554002.045], [0, 1729121555001.181], [0, 1729121555001.995], [0, 1729121555001.999], [0, 1729121555002.08], [0, 1729121556001.125], [0, 1729121556001.194], [0, 1729121556001.303], [0, 1729121556002.123], [0, 1729121557000.3672], [0, 1729121557001.259], [0, 1729121557001.3088], [0, 1729121557001.407], [0, 1729121558001.417], [0, 1729121558001.455], [0, 1729121558001.517], [0, 1729121558001.52], [0, 1729121559001.558], [0, 1729121559001.581], [0, 1729121559001.6409], [0, 1729121559001.643], [0, 1729121560001.6929], [0, 1729121560001.697], [0, 1729121560001.761], [0, 1729121560001.7642], [0, 1729121561001.822], [0, 1729121561001.8281], [0, 1729121561001.875], [0, 1729121561001.877], [0, 1729121562001.95], [0, 1729121562001.954], [0, 1729121562001.987], [0, 1729121562001.995], [0, 1729121563002.123], [0, 1729121563002.1272], [0, 1729121563002.1482], [0, 1729121563002.1602], [0, 1729121564001.216], [0, 1729121564001.2769], [0, 1729121564001.2942], [0, 1729121564001.3052], [0, 1729121565001.366], [0, 1729121565001.4138], [0, 1729121565001.434], [0, 1729121565001.44], [0, 1729121566001.5], [0, 1729121566001.532], [0, 1729121566001.5518], [0, 1729121566001.555], [0, 1729121567001.6409], [0, 1729121567001.6519], [0, 1729121567001.6692], [0, 1729121567001.68], [0, 1729121568001.8052], [0, 1729121568001.8098], [0, 1729121568001.821], [0, 1729121568001.823], [0, 1729121569001.963], [0, 1729121569001.969], [0, 1729121569001.971], [0, 1729121569001.972], [0, 1729121570002.097], [0, 1729121570002.0999], [0, 1729121570002.101], [0, 1729121570002.102], [0, 1729121571001.223], [0, 1729121571001.2249], [0, 1729121571001.226], [0, 1729121571001.2312], [0, 1729121572001.3691], [0, 1729121572001.37], [0, 1729121572001.3708], [0, 1729121572001.375], [0, 1729121573001.53], [0, 1729121573001.533], [0, 1729121573001.534], [0, 1729121573001.537], [0, 1729121574001.666], [0, 1729121574001.6729], [0, 1729121574001.677], [0, 1729121574001.677]]}]'
comp_ids:{1, 2, 3, 4}
2024-10-16T18:33:07-05:00 INFO: query check RC: 0
bd5aef0ffec5ae56df80de0393e7fdd78e82f0d7dedfcf8e9e783e7ad0eb8cb2
2024-10-16T18:33:38-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2669    824 --:--:-- --:--:-- --:--:--  3522
{"datasource":{"id":1,"uid":"2qKMa2iHz","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2024-10-16T18:33:39-05:00 INFO: Checking grafana data
2024-10-16T18:33:40-05:00 INFO: Grafana data check, rc: 0
2024-10-16T18:33:40-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2024-10-16T18:33:45-05:00 INFO: DONE
2024-10-16 18:33:55 INFO: ----------------------------------------------
2024-10-16 18:33:55 INFO: ======== test-maestro-hostmunge ========
2024-10-16 18:33:55 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-hostmunge/test.sh
2024-10-16T18:33:55-05:00 INFO: Checking munge on localhost
2024-10-16T18:33:55-05:00 INFO: munge encode/decode successfully
2024-10-16T18:33:55-05:00 INFO: starting mtest-maestro
8b83f6640133fc2ab59f97991b7aa3e0d408241d770cfedfe477a50a957d312d
2024-10-16T18:33:57-05:00 INFO: starting mtest-samp-1
fdd00b6b8d55c45654a0f596b2a506f573b8efc1e16d4596964373a91af584b9
2024-10-16T18:33:59-05:00 INFO: starting mtest-samp-2
d11ced57510713621830c14d7985aabaf803152263740a8548f8b16eb0696390
2024-10-16T18:34:01-05:00 INFO: starting mtest-samp-3
7798de8b2aebde3480316a666e8d4d3da50c9799a59b6ed690ba1acb6ab3e32f
2024-10-16T18:34:02-05:00 INFO: starting mtest-samp-4
157b118a1ea9c9038bb730a7234ab427c919eb049cd28e7cb1a338f64b2cd863
2024-10-16T18:34:04-05:00 INFO: mtest-samp-1 is running
2024-10-16T18:34:04-05:00 INFO: mtest-samp-2 is running
2024-10-16T18:34:04-05:00 INFO: mtest-samp-3 is running
2024-10-16T18:34:04-05:00 INFO: mtest-samp-4 is running
2024-10-16T18:34:04-05:00 INFO: starting mtest-agg-11
b908ff4efe8ce40ce250d3fa43aeb49d745d336e2162ec1e15242a99fd774361
2024-10-16T18:34:05-05:00 INFO: starting mtest-agg-12
c4dd6c28774ab3a756bc8d8638d28c243779b612ff09c267a0725a2280f1d5bf
2024-10-16T18:34:07-05:00 INFO: mtest-agg-11 is running
2024-10-16T18:34:07-05:00 INFO: mtest-agg-12 is running
2024-10-16T18:34:07-05:00 INFO: starting mtest-agg-2
761d5fc954874829ccaafb000264e8a16492c8519c6e9946f70219417aa4c00c
2024-10-16T18:34:08-05:00 INFO: mtest-agg-2 is running
2024-10-16T18:34:08-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2024-10-16T18:36:09-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2024-10-16T18:36:11-05:00 INFO: sos check rc: 0
2024-10-16T18:36:12-05:00 INFO: starting mtest-ui
1be8a83a9b8e5c655999449886826e91ed8400f3cd9eaee7befd853403a5b620
2024-10-16T18:36:14-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4453024, 1729121668000.5361], [4453024, 1729121668001.507], [4453024, 1729121668001.5261], [4453024, 1729121668001.578], [4453396, 1729121669001.677], [4453396, 1729121669001.681], [4453396, 1729121669001.687], [4453396, 1729121669001.728], [4453396, 1729121670001.822], [4453396, 1729121670001.823], [4453396, 1729121670001.825], [4453396, 1729121670001.853], [4453396, 1729121671001.969], [4453396, 1729121671001.977], [4453396, 1729121671001.977], [4453396, 1729121671001.98], [4453396, 1729121672002.0989], [4453396, 1729121672002.102], [4453396, 1729121672002.108], [4453396, 1729121672002.109], [4453396, 1729121673001.244], [4453396, 1729121673001.249], [4453396, 1729121673001.2522], [4453396, 1729121673001.254], [4453396, 1729121674001.402], [4453396, 1729121674001.4138], [4453396, 1729121674001.4138], [4453396, 1729121674001.417], [4453396, 1729121675001.53], [4453396, 1729121675001.541], [4453396, 1729121675001.543], [4453396, 1729121675001.551], [4453396, 1729121676001.676], [4453396, 1729121676001.6792], [4453396, 1729121676001.684], [4453396, 1729121676001.685], [4453396, 1729121677001.818], [4453396, 1729121677001.8271], [4453396, 1729121677001.8298], [4453396, 1729121677001.8298], [4453396, 1729121678001.964], [4453396, 1729121678001.965], [4453396, 1729121678001.97], [4453396, 1729121678001.971], [4453396, 1729121679002.0789], [4453396, 1729121679002.081], [4453396, 1729121679002.2222], [4453396, 1729121679002.227], [4453396, 1729121680001.234], [4453396, 1729121680001.236], [4453396, 1729121680001.367], [4453396, 1729121680001.375], [4453396, 1729121681001.3801], [4453396, 1729121681001.3818], [4453396, 1729121681001.49], [4453396, 1729121681001.503], [4453396, 1729121682001.509], [4453396, 1729121682001.512], [4453396, 1729121682001.609], [4453396, 1729121682001.621], [4453396, 1729121683001.65], [4453396, 1729121683001.654], [4453396, 1729121683001.762], [4453396, 1729121683001.779], [4453396, 1729121684001.8071], [4453396, 1729121684001.811], [4453396, 1729121684001.822], [4453396, 1729121684001.9048], [4453396, 1729121685001.969], [4453396, 1729121685001.973], [4453396, 1729121685001.973], [4453396, 1729121685002.043], [4453396, 1729121686001.184], [4453396, 1729121686002.113], [4453396, 1729121686002.114], [4453396, 1729121686002.114], [4453396, 1729121687001.2532], [4453396, 1729121687001.254], [4453396, 1729121687001.257], [4453396, 1729121687001.2979], [4453396, 1729121688001.386], [4453396, 1729121688001.388], [4453396, 1729121688001.391], [4453396, 1729121688001.413], [4453396, 1729121689001.547], [4453396, 1729121689001.547], [4453396, 1729121689001.551], [4453396, 1729121689001.553], [4453396, 1729121690001.706], [4453396, 1729121690001.707], [4453396, 1729121690001.71], [4453396, 1729121690001.7122], [4453396, 1729121691001.8408], [4453396, 1729121691001.842], [4453396, 1729121691001.849], [4453396, 1729121691001.8508], [4453396, 1729121692001.967], [4453396, 1729121692001.973], [4453396, 1729121692001.975], [4453396, 1729121692001.9788], [4453396, 1729121693002.101], [4453396, 1729121693002.111], [4453396, 1729121693002.111], [4453396, 1729121693002.112], [4453396, 1729121694001.23], [4453396, 1729121694001.241], [4453396, 1729121694001.241], [4453396, 1729121694001.244], [4453400, 1729121695001.395], [4453400, 1729121695001.396], [4453400, 1729121695001.399], [4453400, 1729121695001.4028], [4453396, 1729121696001.529], [4453396, 1729121696001.534], [4453396, 1729121696001.538], [4453396, 1729121696001.538], [4453396, 1729121697001.66], [4453396, 1729121697001.663], [4453396, 1729121697001.663], [4453396, 1729121697001.667], [4453396, 1729121698001.57], [4453396, 1729121698001.78], [4453396, 1729121698001.801], [4453396, 1729121698001.802], [4453396, 1729121699001.727], [4453396, 1729121699001.731], [4453396, 1729121699001.958], [4453396, 1729121699001.959], [4453400, 1729121700001.888], [4453400, 1729121700001.8901], [4453400, 1729121700002.1199], [4453400, 1729121700002.123], [4453396, 1729121701001.2668], [4453396, 1729121701001.269], [4453396, 1729121701002.027], [4453396, 1729121701002.034], [4453396, 1729121702001.156], [4453396, 1729121702001.1619], [4453396, 1729121702001.4001], [4453396, 1729121702001.406], [4453396, 1729121703001.2969], [4453396, 1729121703001.301], [4453396, 1729121703001.547], [4453396, 1729121703001.549], [4453396, 1729121704001.4348], [4453396, 1729121704001.445], [4453396, 1729121704001.688], [4453396, 1729121704001.696], [4453392, 1729121705001.594], [4453392, 1729121705001.5989], [4453392, 1729121705001.853], [4453392, 1729121705001.854], [4453396, 1729121706001.734], [4453396, 1729121706001.741], [4453396, 1729121706001.9998], [4453396, 1729121706002.001], [4453396, 1729121707001.141], [4453396, 1729121707001.145], [4453396, 1729121707001.867], [4453396, 1729121707001.878], [4453396, 1729121708001.052], [4453396, 1729121708001.291], [4453396, 1729121708001.2969], [4453396, 1729121708001.534], [4453396, 1729121709001.208], [4453396, 1729121709001.439], [4453396, 1729121709001.4458], [4453396, 1729121709001.688], [4453396, 1729121710001.314], [4453396, 1729121710001.511], [4453396, 1729121710001.5518], [4453396, 1729121710001.7659], [4453396, 1729121711001.48], [4453396, 1729121711001.485], [4453396, 1729121711001.489], [4453396, 1729121711001.707], [4453396, 1729121712001.618], [4453396, 1729121712001.619], [4453396, 1729121712001.636], [4453396, 1729121712001.846], [4453396, 1729121713001.752], [4453396, 1729121713001.752], [4453396, 1729121713001.758], [4453396, 1729121713001.982], [4453396, 1729121714001.893], [4453396, 1729121714001.896], [4453396, 1729121714001.9011], [4453396, 1729121714002.13], [4453396, 1729121715001.275], [4453396, 1729121715002.03], [4453396, 1729121715002.033], [4453396, 1729121715002.039], [4453396, 1729121716001.187], [4453396, 1729121716001.1892], [4453396, 1729121716001.1929], [4453396, 1729121716001.4321], [4453396, 1729121717001.3281], [4453396, 1729121717001.334], [4453396, 1729121717001.334], [4453396, 1729121717001.58], [4453396, 1729121718001.475], [4453396, 1729121718001.477], [4453396, 1729121718001.49], [4453396, 1729121718001.7239], [4453396, 1729121719001.608], [4453396, 1729121719001.614], [4453396, 1729121719001.615], [4453396, 1729121719001.865], [4453396, 1729121720001.7432], [4453396, 1729121720001.751], [4453396, 1729121720001.752], [4453396, 1729121720002.01], [4453396, 1729121721001.167], [4453396, 1729121721001.904], [4453396, 1729121721001.907], [4453396, 1729121721001.908], [4453396, 1729121722001.307], [4453396, 1729121722002.036], [4453396, 1729121722002.04], [4453396, 1729121722002.04], [4453396, 1729121723001.169], [4453396, 1729121723001.179], [4453396, 1729121723001.181], [4453396, 1729121723001.44], [4453396, 1729121724001.3062], [4453396, 1729121724001.3062], [4453396, 1729121724001.311], [4453396, 1729121724001.572], [4453396, 1729121725001.437], [4453396, 1729121725001.4421], [4453396, 1729121725001.4458], [4453396, 1729121725001.7002], [4453396, 1729121726001.6], [4453396, 1729121726001.602], [4453396, 1729121726001.603], [4453396, 1729121726001.857], [4453396, 1729121727001.741], [4453396, 1729121727001.7449], [4453396, 1729121727001.7449], [4453396, 1729121727001.993], [4453396, 1729121728001.223], [4453396, 1729121728001.782], [4453396, 1729121728001.844], [4453396, 1729121728001.874], [4453396, 1729121729000.9521], [4453396, 1729121729001.356], [4453396, 1729121729001.3828], [4453396, 1729121729002.031], [4453396, 1729121730001.176], [4453396, 1729121730001.511], [4453396, 1729121730001.518], [4453396, 1729121730001.521], [4453392, 1729121731001.3372], [4453392, 1729121731001.676], [4453392, 1729121731001.6792], [4453392, 1729121731001.681], [4453396, 1729121732001.479], [4453396, 1729121732001.8071], [4453396, 1729121732001.815], [4453396, 1729121732001.8198], [4453396, 1729121733001.623], [4453396, 1729121733001.949], [4453396, 1729121733001.959], [4453396, 1729121733001.961], [4453396, 1729121734001.7642], [4453396, 1729121734002.084], [4453396, 1729121734002.092], [4453396, 1729121734002.097], [4453396, 1729121735001.217], [4453396, 1729121735001.2212], [4453396, 1729121735001.23], [4453396, 1729121735001.9048], [4453396, 1729121736001.3298], [4453396, 1729121736001.332], [4453396, 1729121736001.406], [4453396, 1729121736001.983], [4453396, 1729121737001.485], [4453396, 1729121737001.5], [4453396, 1729121737001.503], [4453396, 1729121737001.508], [4453396, 1729121738001.625], [4453396, 1729121738001.6309], [4453396, 1729121738001.633], [4453396, 1729121738001.634], [4453396, 1729121739001.611], [4453396, 1729121739001.737], [4453396, 1729121739001.773], [4453396, 1729121739001.7878], [4453396, 1729121740001.75], [4453396, 1729121740001.868], [4453396, 1729121740001.9001], [4453396, 1729121740001.916], [4453396, 1729121741001.8838], [4453396, 1729121741001.984], [4453396, 1729121741002.0212], [4453396, 1729121741002.041], [4453396, 1729121742001.176], [4453396, 1729121742001.181], [4453396, 1729121742002.042], [4453396, 1729121742002.1272], [4453396, 1729121743001.186], [4453396, 1729121743001.258], [4453396, 1729121743001.3079], [4453396, 1729121743001.314], [4453396, 1729121744001.333], [4453396, 1729121744001.387], [4453396, 1729121744001.434], [4453396, 1729121744001.438], [4453396, 1729121745001.476], [4453396, 1729121745001.506], [4453396, 1729121745001.563], [4453396, 1729121745001.567], [4453396, 1729121746001.617], [4453396, 1729121746001.624], [4453396, 1729121746001.691], [4453396, 1729121746001.692], [4453396, 1729121747001.779], [4453396, 1729121747001.783], [4453396, 1729121747001.8372], [4453396, 1729121747001.84], [4453396, 1729121748001.9048], [4453396, 1729121748001.9148], [4453396, 1729121748001.952], [4453396, 1729121748001.962], [4453396, 1729121749002.062], [4453396, 1729121749002.065], [4453396, 1729121749002.093], [4453396, 1729121749002.108], [4453396, 1729121750000.8672], [4453396, 1729121750001.176], [4453396, 1729121750001.1992], [4453396, 1729121750001.2039], [4453396, 1729121751001.313], [4453396, 1729121751001.3271], [4453396, 1729121751001.3281], [4453396, 1729121751001.3289], [4453400, 1729121752001.4778], [4453400, 1729121752001.48], [4453400, 1729121752001.482], [4453400, 1729121752001.483], [4453396, 1729121753001.615], [4453396, 1729121753001.619], [4453396, 1729121753001.619], [4453396, 1729121753001.6199], [4453396, 1729121754001.7458], [4453396, 1729121754001.75], [4453396, 1729121754001.752], [4453396, 1729121754001.7542], [4453396, 1729121755001.875], [4453396, 1729121755001.8792], [4453396, 1729121755001.8792], [4453396, 1729121755001.882], [4453396, 1729121756002.01], [4453396, 1729121756002.014], [4453396, 1729121756002.016], [4453396, 1729121756002.018], [4453396, 1729121757001.174], [4453396, 1729121757001.177], [4453396, 1729121757001.1782], [4453396, 1729121757001.181], [4453396, 1729121758001.3152], [4453396, 1729121758001.3162], [4453396, 1729121758001.324], [4453396, 1729121758001.324], [4453396, 1729121759001.466], [4453396, 1729121759001.47], [4453396, 1729121759001.471], [4453396, 1729121759001.475], [4453396, 1729121760001.591], [4453396, 1729121760001.5989], [4453396, 1729121760001.602], [4453396, 1729121760001.602], [4453396, 1729121761001.7559], [4453396, 1729121761001.761], [4453396, 1729121761001.761], [4453396, 1729121761001.762], [4453404, 1729121762001.924], [4453404, 1729121762001.9258], [4453404, 1729121762001.927], [4453404, 1729121762001.93], [4453396, 1729121763002.072], [4453396, 1729121763002.072], [4453396, 1729121763002.072], [4453396, 1729121763002.081], [4453396, 1729121764001.212], [4453396, 1729121764001.213], [4453396, 1729121764001.215], [4453396, 1729121764001.216], [4453396, 1729121765001.346], [4453396, 1729121765001.3599], [4453396, 1729121765001.3618], [4453396, 1729121765001.3618], [4453396, 1729121766001.4878], [4453396, 1729121766001.491], [4453396, 1729121766001.493], [4453396, 1729121766001.498], [4453396, 1729121767001.612], [4453396, 1729121767001.686], [4453396, 1729121767001.7532], [4453396, 1729121767001.814], [4453396, 1729121768001.7778], [4453396, 1729121768001.7869], [4453396, 1729121768001.794], [4453396, 1729121768001.7988]]}, {"target": "component_id", "datapoints": [[3, 1729121668000.5361], [4, 1729121668001.507], [2, 1729121668001.5261], [1, 1729121668001.578], [2, 1729121669001.677], [4, 1729121669001.681], [3, 1729121669001.687], [1, 1729121669001.728], [2, 1729121670001.822], [3, 1729121670001.823], [4, 1729121670001.825], [1, 1729121670001.853], [2, 1729121671001.969], [3, 1729121671001.977], [4, 1729121671001.977], [1, 1729121671001.98], [1, 1729121672002.0989], [2, 1729121672002.102], [3, 1729121672002.108], [4, 1729121672002.109], [1, 1729121673001.244], [3, 1729121673001.249], [2, 1729121673001.2522], [4, 1729121673001.254], [3, 1729121674001.402], [1, 1729121674001.4138], [2, 1729121674001.4138], [4, 1729121674001.417], [3, 1729121675001.53], [2, 1729121675001.541], [4, 1729121675001.543], [1, 1729121675001.551], [3, 1729121676001.676], [4, 1729121676001.6792], [2, 1729121676001.684], [1, 1729121676001.685], [3, 1729121677001.818], [4, 1729121677001.8271], [1, 1729121677001.8298], [2, 1729121677001.8298], [3, 1729121678001.964], [1, 1729121678001.965], [4, 1729121678001.97], [2, 1729121678001.971], [1, 1729121679002.0789], [3, 1729121679002.081], [2, 1729121679002.2222], [4, 1729121679002.227], [3, 1729121680001.234], [1, 1729121680001.236], [2, 1729121680001.367], [4, 1729121680001.375], [3, 1729121681001.3801], [1, 1729121681001.3818], [2, 1729121681001.49], [4, 1729121681001.503], [1, 1729121682001.509], [3, 1729121682001.512], [2, 1729121682001.609], [4, 1729121682001.621], [3, 1729121683001.65], [1, 1729121683001.654], [2, 1729121683001.762], [4, 1729121683001.779], [3, 1729121684001.8071], [1, 1729121684001.811], [4, 1729121684001.822], [2, 1729121684001.9048], [3, 1729121685001.969], [1, 1729121685001.973], [4, 1729121685001.973], [2, 1729121685002.043], [2, 1729121686001.184], [1, 1729121686002.113], [3, 1729121686002.114], [4, 1729121686002.114], [3, 1729121687001.2532], [4, 1729121687001.254], [1, 1729121687001.257], [2, 1729121687001.2979], [3, 1729121688001.386], [1, 1729121688001.388], [4, 1729121688001.391], [2, 1729121688001.413], [3, 1729121689001.547], [4, 1729121689001.547], [1, 1729121689001.551], [2, 1729121689001.553], [3, 1729121690001.706], [4, 1729121690001.707], [1, 1729121690001.71], [2, 1729121690001.7122], [3, 1729121691001.8408], [4, 1729121691001.842], [2, 1729121691001.849], [1, 1729121691001.8508], [4, 1729121692001.967], [2, 1729121692001.973], [3, 1729121692001.975], [1, 1729121692001.9788], [4, 1729121693002.101], [1, 1729121693002.111], [2, 1729121693002.111], [3, 1729121693002.112], [4, 1729121694001.23], [2, 1729121694001.241], [3, 1729121694001.241], [1, 1729121694001.244], [3, 1729121695001.395], [4, 1729121695001.396], [2, 1729121695001.399], [1, 1729121695001.4028], [4, 1729121696001.529], [3, 1729121696001.534], [1, 1729121696001.538], [2, 1729121696001.538], [4, 1729121697001.66], [1, 1729121697001.663], [3, 1729121697001.663], [2, 1729121697001.667], [3, 1729121698001.57], [4, 1729121698001.78], [2, 1729121698001.801], [1, 1729121698001.802], [3, 1729121699001.727], [4, 1729121699001.731], [2, 1729121699001.958], [1, 1729121699001.959], [4, 1729121700001.888], [3, 1729121700001.8901], [2, 1729121700002.1199], [1, 1729121700002.123], [2, 1729121701001.2668], [1, 1729121701001.269], [4, 1729121701002.027], [3, 1729121701002.034], [4, 1729121702001.156], [3, 1729121702001.1619], [2, 1729121702001.4001], [1, 1729121702001.406], [4, 1729121703001.2969], [3, 1729121703001.301], [2, 1729121703001.547], [1, 1729121703001.549], [3, 1729121704001.4348], [4, 1729121704001.445], [1, 1729121704001.688], [2, 1729121704001.696], [3, 1729121705001.594], [4, 1729121705001.5989], [1, 1729121705001.853], [2, 1729121705001.854], [3, 1729121706001.734], [4, 1729121706001.741], [2, 1729121706001.9998], [1, 1729121706002.001], [2, 1729121707001.141], [1, 1729121707001.145], [3, 1729121707001.867], [4, 1729121707001.878], [4, 1729121708001.052], [2, 1729121708001.291], [1, 1729121708001.2969], [3, 1729121708001.534], [4, 1729121709001.208], [2, 1729121709001.439], [1, 1729121709001.4458], [3, 1729121709001.688], [4, 1729121710001.314], [2, 1729121710001.511], [1, 1729121710001.5518], [3, 1729121710001.7659], [2, 1729121711001.48], [3, 1729121711001.485], [4, 1729121711001.489], [1, 1729121711001.707], [2, 1729121712001.618], [4, 1729121712001.619], [3, 1729121712001.636], [1, 1729121712001.846], [2, 1729121713001.752], [3, 1729121713001.752], [4, 1729121713001.758], [1, 1729121713001.982], [2, 1729121714001.893], [3, 1729121714001.896], [4, 1729121714001.9011], [1, 1729121714002.13], [1, 1729121715001.275], [2, 1729121715002.03], [3, 1729121715002.033], [4, 1729121715002.039], [3, 1729121716001.187], [2, 1729121716001.1892], [4, 1729121716001.1929], [1, 1729121716001.4321], [2, 1729121717001.3281], [3, 1729121717001.334], [4, 1729121717001.334], [1, 1729121717001.58], [2, 1729121718001.475], [4, 1729121718001.477], [3, 1729121718001.49], [1, 1729121718001.7239], [2, 1729121719001.608], [4, 1729121719001.614], [3, 1729121719001.615], [1, 1729121719001.865], [2, 1729121720001.7432], [4, 1729121720001.751], [3, 1729121720001.752], [1, 1729121720002.01], [1, 1729121721001.167], [3, 1729121721001.904], [2, 1729121721001.907], [4, 1729121721001.908], [1, 1729121722001.307], [2, 1729121722002.036], [3, 1729121722002.04], [4, 1729121722002.04], [2, 1729121723001.169], [3, 1729121723001.179], [4, 1729121723001.181], [1, 1729121723001.44], [2, 1729121724001.3062], [3, 1729121724001.3062], [4, 1729121724001.311], [1, 1729121724001.572], [3, 1729121725001.437], [2, 1729121725001.4421], [4, 1729121725001.4458], [1, 1729121725001.7002], [3, 1729121726001.6], [4, 1729121726001.602], [2, 1729121726001.603], [1, 1729121726001.857], [2, 1729121727001.741], [3, 1729121727001.7449], [4, 1729121727001.7449], [1, 1729121727001.993], [1, 1729121728001.223], [4, 1729121728001.782], [2, 1729121728001.844], [3, 1729121728001.874], [4, 1729121729000.9521], [1, 1729121729001.356], [2, 1729121729001.3828], [3, 1729121729002.031], [3, 1729121730001.176], [1, 1729121730001.511], [4, 1729121730001.518], [2, 1729121730001.521], [3, 1729121731001.3372], [1, 1729121731001.676], [4, 1729121731001.6792], [2, 1729121731001.681], [3, 1729121732001.479], [2, 1729121732001.8071], [4, 1729121732001.815], [1, 1729121732001.8198], [3, 1729121733001.623], [2, 1729121733001.949], [4, 1729121733001.959], [1, 1729121733001.961], [3, 1729121734001.7642], [2, 1729121734002.084], [4, 1729121734002.092], [1, 1729121734002.097], [2, 1729121735001.217], [4, 1729121735001.2212], [1, 1729121735001.23], [3, 1729121735001.9048], [4, 1729121736001.3298], [1, 1729121736001.332], [2, 1729121736001.406], [3, 1729121736001.983], [1, 1729121737001.485], [2, 1729121737001.5], [3, 1729121737001.503], [4, 1729121737001.508], [1, 1729121738001.625], [2, 1729121738001.6309], [4, 1729121738001.633], [3, 1729121738001.634], [1, 1729121739001.611], [3, 1729121739001.737], [4, 1729121739001.773], [2, 1729121739001.7878], [1, 1729121740001.75], [3, 1729121740001.868], [4, 1729121740001.9001], [2, 1729121740001.916], [1, 1729121741001.8838], [3, 1729121741001.984], [4, 1729121741002.0212], [2, 1729121741002.041], [2, 1729121742001.176], [4, 1729121742001.181], [1, 1729121742002.042], [3, 1729121742002.1272], [1, 1729121743001.186], [3, 1729121743001.258], [2, 1729121743001.3079], [4, 1729121743001.314], [1, 1729121744001.333], [3, 1729121744001.387], [2, 1729121744001.434], [4, 1729121744001.438], [1, 1729121745001.476], [3, 1729121745001.506], [4, 1729121745001.563], [2, 1729121745001.567], [1, 1729121746001.617], [3, 1729121746001.624], [4, 1729121746001.691], [2, 1729121746001.692], [3, 1729121747001.779], [1, 1729121747001.783], [4, 1729121747001.8372], [2, 1729121747001.84], [3, 1729121748001.9048], [1, 1729121748001.9148], [4, 1729121748001.952], [2, 1729121748001.962], [3, 1729121749002.062], [1, 1729121749002.065], [4, 1729121749002.093], [2, 1729121749002.108], [2, 1729121750000.8672], [3, 1729121750001.176], [1, 1729121750001.1992], [4, 1729121750001.2039], [4, 1729121751001.313], [2, 1729121751001.3271], [3, 1729121751001.3281], [1, 1729121751001.3289], [4, 1729121752001.4778], [2, 1729121752001.48], [3, 1729121752001.482], [1, 1729121752001.483], [4, 1729121753001.615], [1, 1729121753001.619], [2, 1729121753001.619], [3, 1729121753001.6199], [1, 1729121754001.7458], [2, 1729121754001.75], [4, 1729121754001.752], [3, 1729121754001.7542], [4, 1729121755001.875], [1, 1729121755001.8792], [3, 1729121755001.8792], [2, 1729121755001.882], [2, 1729121756002.01], [1, 1729121756002.014], [4, 1729121756002.016], [3, 1729121756002.018], [4, 1729121757001.174], [1, 1729121757001.177], [3, 1729121757001.1782], [2, 1729121757001.181], [2, 1729121758001.3152], [4, 1729121758001.3162], [1, 1729121758001.324], [3, 1729121758001.324], [2, 1729121759001.466], [1, 1729121759001.47], [3, 1729121759001.471], [4, 1729121759001.475], [2, 1729121760001.591], [1, 1729121760001.5989], [3, 1729121760001.602], [4, 1729121760001.602], [3, 1729121761001.7559], [1, 1729121761001.761], [2, 1729121761001.761], [4, 1729121761001.762], [2, 1729121762001.924], [3, 1729121762001.9258], [4, 1729121762001.927], [1, 1729121762001.93], [2, 1729121763002.072], [3, 1729121763002.072], [4, 1729121763002.072], [1, 1729121763002.081], [2, 1729121764001.212], [3, 1729121764001.213], [4, 1729121764001.215], [1, 1729121764001.216], [4, 1729121765001.346], [2, 1729121765001.3599], [1, 1729121765001.3618], [3, 1729121765001.3618], [4, 1729121766001.4878], [1, 1729121766001.491], [3, 1729121766001.493], [2, 1729121766001.498], [4, 1729121767001.612], [3, 1729121767001.686], [1, 1729121767001.7532], [2, 1729121767001.814], [3, 1729121768001.7778], [1, 1729121768001.7869], [2, 1729121768001.794], [4, 1729121768001.7988]]}, {"target": "job_id", "datapoints": [[0, 1729121668000.5361], [0, 1729121668001.507], [0, 1729121668001.5261], [0, 1729121668001.578], [0, 1729121669001.677], [0, 1729121669001.681], [0, 1729121669001.687], [0, 1729121669001.728], [0, 1729121670001.822], [0, 1729121670001.823], [0, 1729121670001.825], [0, 1729121670001.853], [0, 1729121671001.969], [0, 1729121671001.977], [0, 1729121671001.977], [0, 1729121671001.98], [0, 1729121672002.0989], [0, 1729121672002.102], [0, 1729121672002.108], [0, 1729121672002.109], [0, 1729121673001.244], [0, 1729121673001.249], [0, 1729121673001.2522], [0, 1729121673001.254], [0, 1729121674001.402], [0, 1729121674001.4138], [0, 1729121674001.4138], [0, 1729121674001.417], [0, 1729121675001.53], [0, 1729121675001.541], [0, 1729121675001.543], [0, 1729121675001.551], [0, 1729121676001.676], [0, 1729121676001.6792], [0, 1729121676001.684], [0, 1729121676001.685], [0, 1729121677001.818], [0, 1729121677001.8271], [0, 1729121677001.8298], [0, 1729121677001.8298], [0, 1729121678001.964], [0, 1729121678001.965], [0, 1729121678001.97], [0, 1729121678001.971], [0, 1729121679002.0789], [0, 1729121679002.081], [0, 1729121679002.2222], [0, 1729121679002.227], [0, 1729121680001.234], [0, 1729121680001.236], [0, 1729121680001.367], [0, 1729121680001.375], [0, 1729121681001.3801], [0, 1729121681001.3818], [0, 1729121681001.49], [0, 1729121681001.503], [0, 1729121682001.509], [0, 1729121682001.512], [0, 1729121682001.609], [0, 1729121682001.621], [0, 1729121683001.65], [0, 1729121683001.654], [0, 1729121683001.762], [0, 1729121683001.779], [0, 1729121684001.8071], [0, 1729121684001.811], [0, 1729121684001.822], [0, 1729121684001.9048], [0, 1729121685001.969], [0, 1729121685001.973], [0, 1729121685001.973], [0, 1729121685002.043], [0, 1729121686001.184], [0, 1729121686002.113], [0, 1729121686002.114], [0, 1729121686002.114], [0, 1729121687001.2532], [0, 1729121687001.254], [0, 1729121687001.257], [0, 1729121687001.2979], [0, 1729121688001.386], [0, 1729121688001.388], [0, 1729121688001.391], [0, 1729121688001.413], [0, 1729121689001.547], [0, 1729121689001.547], [0, 1729121689001.551], [0, 1729121689001.553], [0, 1729121690001.706], [0, 1729121690001.707], [0, 1729121690001.71], [0, 1729121690001.7122], [0, 1729121691001.8408], [0, 1729121691001.842], [0, 1729121691001.849], [0, 1729121691001.8508], [0, 1729121692001.967], [0, 1729121692001.973], [0, 1729121692001.975], [0, 1729121692001.9788], [0, 1729121693002.101], [0, 1729121693002.111], [0, 1729121693002.111], [0, 1729121693002.112], [0, 1729121694001.23], [0, 1729121694001.241], [0, 1729121694001.241], [0, 1729121694001.244], [0, 1729121695001.395], [0, 1729121695001.396], [0, 1729121695001.399], [0, 1729121695001.4028], [0, 1729121696001.529], [0, 1729121696001.534], [0, 1729121696001.538], [0, 1729121696001.538], [0, 1729121697001.66], [0, 1729121697001.663], [0, 1729121697001.663], [0, 1729121697001.667], [0, 1729121698001.57], [0, 1729121698001.78], [0, 1729121698001.801], [0, 1729121698001.802], [0, 1729121699001.727], [0, 1729121699001.731], [0, 1729121699001.958], [0, 1729121699001.959], [0, 1729121700001.888], [0, 1729121700001.8901], [0, 1729121700002.1199], [0, 1729121700002.123], [0, 1729121701001.2668], [0, 1729121701001.269], [0, 1729121701002.027], [0, 1729121701002.034], [0, 1729121702001.156], [0, 1729121702001.1619], [0, 1729121702001.4001], [0, 1729121702001.406], [0, 1729121703001.2969], [0, 1729121703001.301], [0, 1729121703001.547], [0, 1729121703001.549], [0, 1729121704001.4348], [0, 1729121704001.445], [0, 1729121704001.688], [0, 1729121704001.696], [0, 1729121705001.594], [0, 1729121705001.5989], [0, 1729121705001.853], [0, 1729121705001.854], [0, 1729121706001.734], [0, 1729121706001.741], [0, 1729121706001.9998], [0, 1729121706002.001], [0, 1729121707001.141], [0, 1729121707001.145], [0, 1729121707001.867], [0, 1729121707001.878], [0, 1729121708001.052], [0, 1729121708001.291], [0, 1729121708001.2969], [0, 1729121708001.534], [0, 1729121709001.208], [0, 1729121709001.439], [0, 1729121709001.4458], [0, 1729121709001.688], [0, 1729121710001.314], [0, 1729121710001.511], [0, 1729121710001.5518], [0, 1729121710001.7659], [0, 1729121711001.48], [0, 1729121711001.485], [0, 1729121711001.489], [0, 1729121711001.707], [0, 1729121712001.618], [0, 1729121712001.619], [0, 1729121712001.636], [0, 1729121712001.846], [0, 1729121713001.752], [0, 1729121713001.752], [0, 1729121713001.758], [0, 1729121713001.982], [0, 1729121714001.893], [0, 1729121714001.896], [0, 1729121714001.9011], [0, 1729121714002.13], [0, 1729121715001.275], [0, 1729121715002.03], [0, 1729121715002.033], [0, 1729121715002.039], [0, 1729121716001.187], [0, 1729121716001.1892], [0, 1729121716001.1929], [0, 1729121716001.4321], [0, 1729121717001.3281], [0, 1729121717001.334], [0, 1729121717001.334], [0, 1729121717001.58], [0, 1729121718001.475], [0, 1729121718001.477], [0, 1729121718001.49], [0, 1729121718001.7239], [0, 1729121719001.608], [0, 1729121719001.614], [0, 1729121719001.615], [0, 1729121719001.865], [0, 1729121720001.7432], [0, 1729121720001.751], [0, 1729121720001.752], [0, 1729121720002.01], [0, 1729121721001.167], [0, 1729121721001.904], [0, 1729121721001.907], [0, 1729121721001.908], [0, 1729121722001.307], [0, 1729121722002.036], [0, 1729121722002.04], [0, 1729121722002.04], [0, 1729121723001.169], [0, 1729121723001.179], [0, 1729121723001.181], [0, 1729121723001.44], [0, 1729121724001.3062], [0, 1729121724001.3062], [0, 1729121724001.311], [0, 1729121724001.572], [0, 1729121725001.437], [0, 1729121725001.4421], [0, 1729121725001.4458], [0, 1729121725001.7002], [0, 1729121726001.6], [0, 1729121726001.602], [0, 1729121726001.603], [0, 1729121726001.857], [0, 1729121727001.741], [0, 1729121727001.7449], [0, 1729121727001.7449], [0, 1729121727001.993], [0, 1729121728001.223], [0, 1729121728001.782], [0, 1729121728001.844], [0, 1729121728001.874], [0, 1729121729000.9521], [0, 1729121729001.356], [0, 1729121729001.3828], [0, 1729121729002.031], [0, 1729121730001.176], [0, 1729121730001.511], [0, 1729121730001.518], [0, 1729121730001.521], [0, 1729121731001.3372], [0, 1729121731001.676], [0, 1729121731001.6792], [0, 1729121731001.681], [0, 1729121732001.479], [0, 1729121732001.8071], [0, 1729121732001.815], [0, 1729121732001.8198], [0, 1729121733001.623], [0, 1729121733001.949], [0, 1729121733001.959], [0, 1729121733001.961], [0, 1729121734001.7642], [0, 1729121734002.084], [0, 1729121734002.092], [0, 1729121734002.097], [0, 1729121735001.217], [0, 1729121735001.2212], [0, 1729121735001.23], [0, 1729121735001.9048], [0, 1729121736001.3298], [0, 1729121736001.332], [0, 1729121736001.406], [0, 1729121736001.983], [0, 1729121737001.485], [0, 1729121737001.5], [0, 1729121737001.503], [0, 1729121737001.508], [0, 1729121738001.625], [0, 1729121738001.6309], [0, 1729121738001.633], [0, 1729121738001.634], [0, 1729121739001.611], [0, 1729121739001.737], [0, 1729121739001.773], [0, 1729121739001.7878], [0, 1729121740001.75], [0, 1729121740001.868], [0, 1729121740001.9001], [0, 1729121740001.916], [0, 1729121741001.8838], [0, 1729121741001.984], [0, 1729121741002.0212], [0, 1729121741002.041], [0, 1729121742001.176], [0, 1729121742001.181], [0, 1729121742002.042], [0, 1729121742002.1272], [0, 1729121743001.186], [0, 1729121743001.258], [0, 1729121743001.3079], [0, 1729121743001.314], [0, 1729121744001.333], [0, 1729121744001.387], [0, 1729121744001.434], [0, 1729121744001.438], [0, 1729121745001.476], [0, 1729121745001.506], [0, 1729121745001.563], [0, 1729121745001.567], [0, 1729121746001.617], [0, 1729121746001.624], [0, 1729121746001.691], [0, 1729121746001.692], [0, 1729121747001.779], [0, 1729121747001.783], [0, 1729121747001.8372], [0, 1729121747001.84], [0, 1729121748001.9048], [0, 1729121748001.9148], [0, 1729121748001.952], [0, 1729121748001.962], [0, 1729121749002.062], [0, 1729121749002.065], [0, 1729121749002.093], [0, 1729121749002.108], [0, 1729121750000.8672], [0, 1729121750001.176], [0, 1729121750001.1992], [0, 1729121750001.2039], [0, 1729121751001.313], [0, 1729121751001.3271], [0, 1729121751001.3281], [0, 1729121751001.3289], [0, 1729121752001.4778], [0, 1729121752001.48], [0, 1729121752001.482], [0, 1729121752001.483], [0, 1729121753001.615], [0, 1729121753001.619], [0, 1729121753001.619], [0, 1729121753001.6199], [0, 1729121754001.7458], [0, 1729121754001.75], [0, 1729121754001.752], [0, 1729121754001.7542], [0, 1729121755001.875], [0, 1729121755001.8792], [0, 1729121755001.8792], [0, 1729121755001.882], [0, 1729121756002.01], [0, 1729121756002.014], [0, 1729121756002.016], [0, 1729121756002.018], [0, 1729121757001.174], [0, 1729121757001.177], [0, 1729121757001.1782], [0, 1729121757001.181], [0, 1729121758001.3152], [0, 1729121758001.3162], [0, 1729121758001.324], [0, 1729121758001.324], [0, 1729121759001.466], [0, 1729121759001.47], [0, 1729121759001.471], [0, 1729121759001.475], [0, 1729121760001.591], [0, 1729121760001.5989], [0, 1729121760001.602], [0, 1729121760001.602], [0, 1729121761001.7559], [0, 1729121761001.761], [0, 1729121761001.761], [0, 1729121761001.762], [0, 1729121762001.924], [0, 1729121762001.9258], [0, 1729121762001.927], [0, 1729121762001.93], [0, 1729121763002.072], [0, 1729121763002.072], [0, 1729121763002.072], [0, 1729121763002.081], [0, 1729121764001.212], [0, 1729121764001.213], [0, 1729121764001.215], [0, 1729121764001.216], [0, 1729121765001.346], [0, 1729121765001.3599], [0, 1729121765001.3618], [0, 1729121765001.3618], [0, 1729121766001.4878], [0, 1729121766001.491], [0, 1729121766001.493], [0, 1729121766001.498], [0, 1729121767001.612], [0, 1729121767001.686], [0, 1729121767001.7532], [0, 1729121767001.814], [0, 1729121768001.7778], [0, 1729121768001.7869], [0, 1729121768001.794], [0, 1729121768001.7988]]}]'
comp_ids:{1, 2, 3, 4}
2024-10-16T18:36:16-05:00 INFO: query check RC: 0
f14b79ffedf2d4a9b0136eb7bf8738007446c3f52e7d6ecda5dfff17f03d8078
2024-10-16T18:36:47-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2202    680 --:--:-- --:--:-- --:--:--  2903
{"datasource":{"id":1,"uid":"fbMda2mHk","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2024-10-16T18:36:49-05:00 INFO: Checking grafana data
2024-10-16T18:36:49-05:00 INFO: Grafana data check, rc: 0
2024-10-16T18:36:49-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2024-10-16T18:36:54-05:00 INFO: DONE
2024-10-16 18:37:04 INFO: ----------------------------------------------
2024-10-16 18:37:04 INFO: ======== test-maestro-munge ========
2024-10-16 18:37:04 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-munge/test.sh
1+0 records in
1+0 records out
4096 bytes (4.1 kB, 4.0 KiB) copied, 0.000308122 s, 13.3 MB/s
2024-10-16T18:37:05-05:00 INFO: starting mtest-maestro
fedb4878bf9c54f3362f96aec925898c4c95d3e1822d3744c3efc57c87d0b529
2024-10-16T18:37:07-05:00 INFO: starting mtest-samp-1
69ac3f70e81ff17a9d18f825b2e26c41ec4d9ea03c745d32e2d329d7f9bb9986
2024-10-16T18:37:09-05:00 INFO: starting mtest-samp-2
97f68e101e4bdb69016a3e3dd94357454a3becf7d72cf77f5ac86b8201b597ef
2024-10-16T18:37:11-05:00 INFO: starting mtest-samp-3
67ce7e05b181a1fe1e75ce0ffffd52bbd7fc8c4575aa5bcfc0897199a0e2d294
2024-10-16T18:37:13-05:00 INFO: starting mtest-samp-4
7656b128dd3f2468d0fb6e18bf7adcc8111f9d9893d3dd4b78ef9ead5dea4f43
2024-10-16T18:37:14-05:00 INFO: mtest-samp-1 is running
2024-10-16T18:37:14-05:00 INFO: mtest-samp-2 is running
2024-10-16T18:37:14-05:00 INFO: mtest-samp-3 is running
2024-10-16T18:37:14-05:00 INFO: mtest-samp-4 is running
2024-10-16T18:37:14-05:00 INFO: starting mtest-agg-11
e8f5b2a92dd0609188c0273cc6a7d41d270d3203faf460b00e4b90282f62c234
2024-10-16T18:37:15-05:00 INFO: starting mtest-agg-12
bddcd799dcfcd2a52d8b376e36abe350cab7f7d4b6dafd2df62140c52a0dd541
2024-10-16T18:37:17-05:00 INFO: mtest-agg-11 is running
2024-10-16T18:37:17-05:00 INFO: mtest-agg-12 is running
2024-10-16T18:37:17-05:00 INFO: starting mtest-agg-2
7387d0ceae2bd9edb6bdfeb6918b0c5e9d338a930cba6544b5e3de50fd16dd2f
2024-10-16T18:37:18-05:00 INFO: mtest-agg-2 is running
2024-10-16T18:37:18-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2024-10-16T18:39:19-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2024-10-16T18:39:22-05:00 INFO: sos check rc: 0
2024-10-16T18:39:23-05:00 INFO: starting mtest-ui
37947e042bbf204136abb981f95cedbb651bbdc81d644027b065e13d96af776b
2024-10-16T18:39:24-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4453424, 1729121857001.663], [4453424, 1729121857001.671], [4453652, 1729121858001.829], [4453652, 1729121858001.832], [4453788, 1729121859001.977], [4453788, 1729121859001.982], [4453788, 1729121859001.994], [4453788, 1729121859001.998], [4453796, 1729121860001.149], [4453796, 1729121860002.097], [4453796, 1729121860002.1062], [4453796, 1729121860002.108], [4453796, 1729121861001.24], [4453796, 1729121861001.244], [4453796, 1729121861001.2458], [4453796, 1729121861001.283], [4453796, 1729121862001.378], [4453796, 1729121862001.385], [4453796, 1729121862001.3892], [4453796, 1729121862001.412], [4453796, 1729121863001.449], [4453796, 1729121863001.52], [4453796, 1729121863001.528], [4453796, 1729121863001.546], [4453796, 1729121864000.7239], [4453796, 1729121864000.79], [4453796, 1729121864001.17], [4453796, 1729121864001.6409], [4453796, 1729121865001.3298], [4453796, 1729121865001.3362], [4453796, 1729121865001.76], [4453796, 1729121865001.949], [4453796, 1729121866001.483], [4453796, 1729121866001.4878], [4453796, 1729121866001.49], [4453796, 1729121866002.104], [4453796, 1729121867001.2559], [4453796, 1729121867001.63], [4453796, 1729121867001.6372], [4453796, 1729121867001.6372], [4453796, 1729121868001.4011], [4453796, 1729121868001.758], [4453796, 1729121868001.759], [4453796, 1729121868001.7632], [4453792, 1729121869001.562], [4453792, 1729121869001.908], [4453792, 1729121869001.91], [4453792, 1729121869001.9148], [4453796, 1729121870001.017], [4453796, 1729121870001.946], [4453796, 1729121870002.062], [4453796, 1729121870002.069], [4453796, 1729121871001.161], [4453796, 1729121871001.1619], [4453796, 1729121871001.182], [4453796, 1729121871001.1892], [4453796, 1729121872001.2988], [4453796, 1729121872001.301], [4453796, 1729121872001.3088], [4453796, 1729121872001.312], [4453796, 1729121873001.438], [4453796, 1729121873001.439], [4453796, 1729121873001.4421], [4453796, 1729121873001.445], [4453796, 1729121874001.583], [4453796, 1729121874001.583], [4453796, 1729121874001.587], [4453796, 1729121874001.587], [4453796, 1729121875001.738], [4453796, 1729121875001.739], [4453796, 1729121875001.744], [4453796, 1729121875001.7458], [4453796, 1729121876001.877], [4453796, 1729121876001.877], [4453796, 1729121876001.878], [4453796, 1729121876001.881], [4453796, 1729121877002.009], [4453796, 1729121877002.009], [4453796, 1729121877002.016], [4453796, 1729121877002.019], [4453796, 1729121878001.138], [4453796, 1729121878001.146], [4453796, 1729121878001.147], [4453796, 1729121878001.15], [4453796, 1729121879001.271], [4453796, 1729121879001.2732], [4453796, 1729121879001.2742], [4453796, 1729121879001.276], [4453788, 1729121880001.434], [4453788, 1729121880001.437], [4453788, 1729121880001.437], [4453788, 1729121880001.441], [4453796, 1729121881001.564], [4453796, 1729121881001.572], [4453796, 1729121881001.573], [4453796, 1729121881001.575], [4453796, 1729121882001.7039], [4453796, 1729121882001.708], [4453796, 1729121882001.709], [4453796, 1729121882001.71], [4453796, 1729121883001.84], [4453796, 1729121883001.843], [4453796, 1729121883001.844], [4453796, 1729121883001.846], [4453796, 1729121884001.964], [4453796, 1729121884001.974], [4453796, 1729121884001.975], [4453796, 1729121884001.981], [4453796, 1729121885002.122], [4453796, 1729121885002.129], [4453796, 1729121885002.1309], [4453796, 1729121885002.134], [4453796, 1729121886001.282], [4453796, 1729121886001.2842], [4453796, 1729121886001.286], [4453796, 1729121886001.29], [4453796, 1729121887001.4102], [4453796, 1729121887001.417], [4453796, 1729121887001.419], [4453796, 1729121887001.422], [4453796, 1729121888001.546], [4453796, 1729121888001.555], [4453796, 1729121888001.556], [4453796, 1729121888001.559], [4453796, 1729121889001.706], [4453796, 1729121889001.7112], [4453796, 1729121889001.713], [4453796, 1729121889001.7139], [4453800, 1729121890001.227], [4453800, 1729121890001.843], [4453800, 1729121890001.864], [4453800, 1729121890001.871], [4453796, 1729121891000.394], [4453796, 1729121891001.982], [4453796, 1729121891002.002], [4453796, 1729121891002.006], [4453796, 1729121892001.133], [4453796, 1729121892001.134], [4453796, 1729121892001.529], [4453796, 1729121892002.1062], [4453796, 1729121893001.251], [4453796, 1729121893001.27], [4453796, 1729121893001.271], [4453796, 1729121893001.674], [4453796, 1729121894001.3938], [4453796, 1729121894001.396], [4453796, 1729121894001.4038], [4453796, 1729121894001.8079], [4453796, 1729121895001.291], [4453796, 1729121895001.511], [4453796, 1729121895001.527], [4453796, 1729121895001.942], [4453796, 1729121896001.4521], [4453796, 1729121896001.4531], [4453796, 1729121896001.651], [4453796, 1729121896002.09], [4453796, 1729121897001.234], [4453796, 1729121897001.6], [4453796, 1729121897001.608], [4453796, 1729121897001.6099], [4453796, 1729121898001.373], [4453796, 1729121898001.7358], [4453796, 1729121898001.738], [4453796, 1729121898001.739], [4453796, 1729121899001.516], [4453796, 1729121899001.877], [4453796, 1729121899001.8792], [4453796, 1729121899001.8828], [4453796, 1729121900001.655], [4453796, 1729121900002.003], [4453796, 1729121900002.012], [4453796, 1729121900002.016], [4453796, 1729121901001.1619], [4453796, 1729121901001.1619], [4453796, 1729121901001.166], [4453796, 1729121901001.8098], [4453796, 1729121902001.303], [4453796, 1729121902001.3052], [4453796, 1729121902001.3062], [4453796, 1729121902001.942], [4453796, 1729121903001.438], [4453796, 1729121903001.445], [4453796, 1729121903001.4458], [4453796, 1729121903002.08], [4453796, 1729121904001.212], [4453796, 1729121904001.582], [4453796, 1729121904001.586], [4453796, 1729121904001.586], [4453796, 1729121905001.354], [4453796, 1729121905001.7122], [4453796, 1729121905001.713], [4453796, 1729121905001.719], [4453796, 1729121906001.51], [4453796, 1729121906001.871], [4453796, 1729121906001.875], [4453796, 1729121906001.877], [4453796, 1729121907001.653], [4453796, 1729121907002.002], [4453796, 1729121907002.004], [4453796, 1729121907002.108], [4453796, 1729121908001.133], [4453796, 1729121908001.142], [4453796, 1729121908001.244], [4453796, 1729121908001.79], [4453796, 1729121909001.293], [4453796, 1729121909001.2952], [4453796, 1729121909001.2988], [4453796, 1729121909001.912], [4453796, 1729121910001.429], [4453796, 1729121910001.43], [4453796, 1729121910001.44], [4453796, 1729121910001.443], [4453792, 1729121911001.596], [4453792, 1729121911001.598], [4453792, 1729121911001.602], [4453792, 1729121911001.602], [4453796, 1729121912001.723], [4453796, 1729121912001.728], [4453796, 1729121912001.7332], [4453796, 1729121912001.734], [4453796, 1729121913001.8618], [4453796, 1729121913001.8618], [4453796, 1729121913001.866], [4453796, 1729121913001.866], [4453796, 1729121914001.991], [4453796, 1729121914001.992], [4453796, 1729121914001.992], [4453796, 1729121914001.997], [4453796, 1729121915002.125], [4453796, 1729121915002.125], [4453796, 1729121915002.126], [4453796, 1729121915002.129], [4453796, 1729121916001.2869], [4453796, 1729121916001.29], [4453796, 1729121916001.291], [4453796, 1729121916001.2942], [4453796, 1729121917001.416], [4453796, 1729121917001.4248], [4453796, 1729121917001.427], [4453796, 1729121917001.428], [4453796, 1729121918001.559], [4453796, 1729121918001.561], [4453796, 1729121918001.563], [4453796, 1729121918001.564], [4453796, 1729121919001.7039], [4453796, 1729121919001.7122], [4453796, 1729121919001.7139], [4453796, 1729121919001.7148], [4453796, 1729121920001.8308], [4453796, 1729121920001.832], [4453796, 1729121920001.8372], [4453796, 1729121920001.8408], [4453804, 1729121921001.628], [4453804, 1729121921001.957], [4453804, 1729121921001.985], [4453804, 1729121921002.0889], [4453796, 1729121922001.2522], [4453796, 1729121922001.2522], [4453796, 1729121922001.259], [4453796, 1729121922002.14], [4453796, 1729121923001.2878], [4453796, 1729121923001.3901], [4453796, 1729121923001.392], [4453796, 1729121923001.395], [4453796, 1729121924001.4348], [4453796, 1729121924001.532], [4453796, 1729121924001.534], [4453796, 1729121924001.539], [4453796, 1729121925001.575], [4453796, 1729121925001.659], [4453796, 1729121925001.66], [4453796, 1729121925001.665], [4453796, 1729121926001.7258], [4453796, 1729121926001.7952], [4453796, 1729121926001.801], [4453796, 1729121926001.801], [4453796, 1729121927001.886], [4453796, 1729121927001.945], [4453796, 1729121927001.949], [4453796, 1729121927001.951], [4453796, 1729121928002.018], [4453796, 1729121928002.073], [4453796, 1729121928002.076], [4453796, 1729121928002.076], [4453796, 1729121929001.175], [4453796, 1729121929001.222], [4453796, 1729121929001.223], [4453796, 1729121929001.226], [4453796, 1729121930001.3052], [4453796, 1729121930001.345], [4453796, 1729121930001.346], [4453796, 1729121930001.3499], [4453796, 1729121931001.447], [4453796, 1729121931001.483], [4453796, 1729121931001.485], [4453796, 1729121931001.49], [4453796, 1729121932001.6099], [4453796, 1729121932001.638], [4453796, 1729121932001.64], [4453796, 1729121932001.643], [4453796, 1729121933001.7532], [4453796, 1729121933001.7668], [4453796, 1729121933001.7668], [4453796, 1729121933001.7761], [4453796, 1729121934001.892], [4453796, 1729121934001.899], [4453796, 1729121934001.903], [4453796, 1729121934001.906], [4453796, 1729121935002.023], [4453796, 1729121935002.029], [4453796, 1729121935002.0322], [4453796, 1729121935002.033], [4453796, 1729121936001.171], [4453796, 1729121936001.1719], [4453796, 1729121936001.18], [4453796, 1729121936001.184], [4453796, 1729121937001.3298], [4453796, 1729121937001.3372], [4453796, 1729121937001.3398], [4453796, 1729121937001.342], [4453796, 1729121938001.458], [4453796, 1729121938001.465], [4453796, 1729121938001.47], [4453796, 1729121938001.47], [4453796, 1729121939001.587], [4453796, 1729121939001.595], [4453796, 1729121939001.596], [4453796, 1729121939001.602], [4453796, 1729121940001.618], [4453796, 1729121940001.703], [4453796, 1729121940001.71], [4453796, 1729121940001.7222], [4453796, 1729121941001.755], [4453796, 1729121941001.822], [4453796, 1729121941001.835], [4453796, 1729121941001.8481], [4453796, 1729121942001.918], [4453796, 1729121942001.976], [4453796, 1729121942001.99], [4453796, 1729121942002.005], [4453796, 1729121943001.155], [4453796, 1729121943002.0742], [4453796, 1729121943002.118], [4453796, 1729121943002.1372], [4453796, 1729121944001.213], [4453796, 1729121944001.248], [4453796, 1729121944001.257], [4453796, 1729121944001.28], [4453796, 1729121945001.082], [4453796, 1729121945001.3481], [4453796, 1729121945001.373], [4453796, 1729121945001.377], [4453796, 1729121946001.2239], [4453796, 1729121946001.227], [4453796, 1729121946001.482], [4453796, 1729121946001.485], [4453800, 1729121947001.3801], [4453800, 1729121947001.386], [4453800, 1729121947001.639], [4453800, 1729121947001.644], [4453796, 1729121948001.527], [4453796, 1729121948001.5308], [4453796, 1729121948001.779], [4453796, 1729121948001.783], [4453796, 1729121949001.686], [4453796, 1729121949001.688], [4453796, 1729121949001.935], [4453796, 1729121949001.937], [4453796, 1729121950001.842], [4453796, 1729121950001.843], [4453796, 1729121950002.081], [4453796, 1729121950002.083], [4453796, 1729121951001.2212], [4453796, 1729121951001.223], [4453796, 1729121951001.989], [4453796, 1729121951001.993], [4453796, 1729121952001.3271], [4453796, 1729121952001.355], [4453796, 1729121952002.1099], [4453796, 1729121952002.135], [4453796, 1729121953001.271], [4453796, 1729121953001.2732], [4453796, 1729121953001.2778], [4453796, 1729121953001.512], [4453796, 1729121954001.42], [4453796, 1729121954001.422], [4453796, 1729121954001.4321], [4453796, 1729121954001.6519], [4453796, 1729121955001.569], [4453796, 1729121955001.57], [4453796, 1729121955001.57], [4453796, 1729121955001.7888], [4453796, 1729121956001.709], [4453796, 1729121956001.7112], [4453796, 1729121956001.713], [4453796, 1729121956001.929], [4453796, 1729121957001.8582], [4453796, 1729121957001.866], [4453796, 1729121957001.871], [4453796, 1729121957002.072], [4453796, 1729121958001.229], [4453796, 1729121958002.014], [4453796, 1729121958002.015], [4453796, 1729121958002.016]]}, {"target": "component_id", "datapoints": [[3, 1729121857001.663], [2, 1729121857001.671], [2, 1729121858001.829], [3, 1729121858001.832], [1, 1729121859001.977], [2, 1729121859001.982], [3, 1729121859001.994], [4, 1729121859001.998], [4, 1729121860001.149], [3, 1729121860002.097], [1, 1729121860002.1062], [2, 1729121860002.108], [2, 1729121861001.24], [1, 1729121861001.244], [3, 1729121861001.2458], [4, 1729121861001.283], [2, 1729121862001.378], [3, 1729121862001.385], [1, 1729121862001.3892], [4, 1729121862001.412], [2, 1729121863001.449], [3, 1729121863001.52], [1, 1729121863001.528], [4, 1729121863001.546], [3, 1729121864000.7239], [2, 1729121864000.79], [1, 1729121864001.17], [4, 1729121864001.6409], [3, 1729121865001.3298], [1, 1729121865001.3362], [4, 1729121865001.76], [2, 1729121865001.949], [3, 1729121866001.483], [1, 1729121866001.4878], [4, 1729121866001.49], [2, 1729121866002.104], [2, 1729121867001.2559], [4, 1729121867001.63], [1, 1729121867001.6372], [3, 1729121867001.6372], [2, 1729121868001.4011], [3, 1729121868001.758], [4, 1729121868001.759], [1, 1729121868001.7632], [2, 1729121869001.562], [3, 1729121869001.908], [1, 1729121869001.91], [4, 1729121869001.9148], [2, 1729121870001.017], [3, 1729121870001.946], [4, 1729121870002.062], [1, 1729121870002.069], [3, 1729121871001.161], [2, 1729121871001.1619], [4, 1729121871001.182], [1, 1729121871001.1892], [2, 1729121872001.2988], [3, 1729121872001.301], [4, 1729121872001.3088], [1, 1729121872001.312], [3, 1729121873001.438], [4, 1729121873001.439], [2, 1729121873001.4421], [1, 1729121873001.445], [1, 1729121874001.583], [2, 1729121874001.583], [3, 1729121874001.587], [4, 1729121874001.587], [1, 1729121875001.738], [3, 1729121875001.739], [4, 1729121875001.744], [2, 1729121875001.7458], [1, 1729121876001.877], [3, 1729121876001.877], [4, 1729121876001.878], [2, 1729121876001.881], [3, 1729121877002.009], [4, 1729121877002.009], [1, 1729121877002.016], [2, 1729121877002.019], [4, 1729121878001.138], [3, 1729121878001.146], [1, 1729121878001.147], [2, 1729121878001.15], [4, 1729121879001.271], [3, 1729121879001.2732], [1, 1729121879001.2742], [2, 1729121879001.276], [3, 1729121880001.434], [1, 1729121880001.437], [4, 1729121880001.437], [2, 1729121880001.441], [4, 1729121881001.564], [3, 1729121881001.572], [1, 1729121881001.573], [2, 1729121881001.575], [1, 1729121882001.7039], [4, 1729121882001.708], [3, 1729121882001.709], [2, 1729121882001.71], [4, 1729121883001.84], [3, 1729121883001.843], [1, 1729121883001.844], [2, 1729121883001.846], [4, 1729121884001.964], [1, 1729121884001.974], [3, 1729121884001.975], [2, 1729121884001.981], [1, 1729121885002.122], [4, 1729121885002.129], [3, 1729121885002.1309], [2, 1729121885002.134], [1, 1729121886001.282], [3, 1729121886001.2842], [4, 1729121886001.286], [2, 1729121886001.29], [3, 1729121887001.4102], [1, 1729121887001.417], [4, 1729121887001.419], [2, 1729121887001.422], [3, 1729121888001.546], [1, 1729121888001.555], [4, 1729121888001.556], [2, 1729121888001.559], [2, 1729121889001.706], [4, 1729121889001.7112], [1, 1729121889001.713], [3, 1729121889001.7139], [4, 1729121890001.227], [3, 1729121890001.843], [1, 1729121890001.864], [2, 1729121890001.871], [4, 1729121891000.394], [3, 1729121891001.982], [1, 1729121891002.002], [2, 1729121891002.006], [2, 1729121892001.133], [1, 1729121892001.134], [4, 1729121892001.529], [3, 1729121892002.1062], [3, 1729121893001.251], [2, 1729121893001.27], [1, 1729121893001.271], [4, 1729121893001.674], [2, 1729121894001.3938], [3, 1729121894001.396], [1, 1729121894001.4038], [4, 1729121894001.8079], [3, 1729121895001.291], [2, 1729121895001.511], [1, 1729121895001.527], [4, 1729121895001.942], [2, 1729121896001.4521], [3, 1729121896001.4531], [1, 1729121896001.651], [4, 1729121896002.09], [4, 1729121897001.234], [3, 1729121897001.6], [2, 1729121897001.608], [1, 1729121897001.6099], [4, 1729121898001.373], [3, 1729121898001.7358], [1, 1729121898001.738], [2, 1729121898001.739], [4, 1729121899001.516], [3, 1729121899001.877], [1, 1729121899001.8792], [2, 1729121899001.8828], [4, 1729121900001.655], [1, 1729121900002.003], [2, 1729121900002.012], [3, 1729121900002.016], [1, 1729121901001.1619], [3, 1729121901001.1619], [2, 1729121901001.166], [4, 1729121901001.8098], [1, 1729121902001.303], [2, 1729121902001.3052], [3, 1729121902001.3062], [4, 1729121902001.942], [3, 1729121903001.438], [1, 1729121903001.445], [2, 1729121903001.4458], [4, 1729121903002.08], [4, 1729121904001.212], [3, 1729121904001.582], [1, 1729121904001.586], [2, 1729121904001.586], [4, 1729121905001.354], [3, 1729121905001.7122], [2, 1729121905001.713], [1, 1729121905001.719], [4, 1729121906001.51], [2, 1729121906001.871], [3, 1729121906001.875], [1, 1729121906001.877], [4, 1729121907001.653], [2, 1729121907002.002], [1, 1729121907002.004], [3, 1729121907002.108], [1, 1729121908001.133], [2, 1729121908001.142], [3, 1729121908001.244], [4, 1729121908001.79], [2, 1729121909001.293], [3, 1729121909001.2952], [1, 1729121909001.2988], [4, 1729121909001.912], [1, 1729121910001.429], [2, 1729121910001.43], [3, 1729121910001.44], [4, 1729121910001.443], [1, 1729121911001.596], [2, 1729121911001.598], [3, 1729121911001.602], [4, 1729121911001.602], [1, 1729121912001.723], [2, 1729121912001.728], [3, 1729121912001.7332], [4, 1729121912001.734], [1, 1729121913001.8618], [4, 1729121913001.8618], [2, 1729121913001.866], [3, 1729121913001.866], [2, 1729121914001.991], [1, 1729121914001.992], [3, 1729121914001.992], [4, 1729121914001.997], [1, 1729121915002.125], [3, 1729121915002.125], [2, 1729121915002.126], [4, 1729121915002.129], [4, 1729121916001.2869], [1, 1729121916001.29], [3, 1729121916001.291], [2, 1729121916001.2942], [4, 1729121917001.416], [1, 1729121917001.4248], [3, 1729121917001.427], [2, 1729121917001.428], [4, 1729121918001.559], [1, 1729121918001.561], [2, 1729121918001.563], [3, 1729121918001.564], [2, 1729121919001.7039], [1, 1729121919001.7122], [3, 1729121919001.7139], [4, 1729121919001.7148], [1, 1729121920001.8308], [2, 1729121920001.832], [4, 1729121920001.8372], [3, 1729121920001.8408], [2, 1729121921001.628], [4, 1729121921001.957], [1, 1729121921001.985], [3, 1729121921002.0889], [2, 1729121922001.2522], [3, 1729121922001.2522], [4, 1729121922001.259], [1, 1729121922002.14], [1, 1729121923001.2878], [2, 1729121923001.3901], [3, 1729121923001.392], [4, 1729121923001.395], [1, 1729121924001.4348], [2, 1729121924001.532], [3, 1729121924001.534], [4, 1729121924001.539], [1, 1729121925001.575], [2, 1729121925001.659], [3, 1729121925001.66], [4, 1729121925001.665], [1, 1729121926001.7258], [3, 1729121926001.7952], [2, 1729121926001.801], [4, 1729121926001.801], [1, 1729121927001.886], [3, 1729121927001.945], [2, 1729121927001.949], [4, 1729121927001.951], [1, 1729121928002.018], [2, 1729121928002.073], [3, 1729121928002.076], [4, 1729121928002.076], [1, 1729121929001.175], [4, 1729121929001.222], [2, 1729121929001.223], [3, 1729121929001.226], [1, 1729121930001.3052], [4, 1729121930001.345], [2, 1729121930001.346], [3, 1729121930001.3499], [1, 1729121931001.447], [4, 1729121931001.483], [2, 1729121931001.485], [3, 1729121931001.49], [1, 1729121932001.6099], [4, 1729121932001.638], [2, 1729121932001.64], [3, 1729121932001.643], [1, 1729121933001.7532], [2, 1729121933001.7668], [4, 1729121933001.7668], [3, 1729121933001.7761], [2, 1729121934001.892], [4, 1729121934001.899], [1, 1729121934001.903], [3, 1729121934001.906], [4, 1729121935002.023], [2, 1729121935002.029], [1, 1729121935002.0322], [3, 1729121935002.033], [1, 1729121936001.171], [2, 1729121936001.1719], [4, 1729121936001.18], [3, 1729121936001.184], [1, 1729121937001.3298], [4, 1729121937001.3372], [3, 1729121937001.3398], [2, 1729121937001.342], [1, 1729121938001.458], [4, 1729121938001.465], [2, 1729121938001.47], [3, 1729121938001.47], [1, 1729121939001.587], [3, 1729121939001.595], [2, 1729121939001.596], [4, 1729121939001.602], [3, 1729121940001.618], [1, 1729121940001.703], [2, 1729121940001.71], [4, 1729121940001.7222], [3, 1729121941001.755], [1, 1729121941001.822], [2, 1729121941001.835], [4, 1729121941001.8481], [3, 1729121942001.918], [1, 1729121942001.976], [2, 1729121942001.99], [4, 1729121942002.005], [4, 1729121943001.155], [3, 1729121943002.0742], [1, 1729121943002.118], [2, 1729121943002.1372], [3, 1729121944001.213], [1, 1729121944001.248], [2, 1729121944001.257], [4, 1729121944001.28], [3, 1729121945001.082], [4, 1729121945001.3481], [1, 1729121945001.373], [2, 1729121945001.377], [2, 1729121946001.2239], [3, 1729121946001.227], [4, 1729121946001.482], [1, 1729121946001.485], [3, 1729121947001.3801], [2, 1729121947001.386], [1, 1729121947001.639], [4, 1729121947001.644], [2, 1729121948001.527], [3, 1729121948001.5308], [4, 1729121948001.779], [1, 1729121948001.783], [2, 1729121949001.686], [3, 1729121949001.688], [4, 1729121949001.935], [1, 1729121949001.937], [2, 1729121950001.842], [3, 1729121950001.843], [4, 1729121950002.081], [1, 1729121950002.083], [1, 1729121951001.2212], [4, 1729121951001.223], [2, 1729121951001.989], [3, 1729121951001.993], [4, 1729121952001.3271], [1, 1729121952001.355], [3, 1729121952002.1099], [2, 1729121952002.135], [3, 1729121953001.271], [4, 1729121953001.2732], [2, 1729121953001.2778], [1, 1729121953001.512], [2, 1729121954001.42], [3, 1729121954001.422], [4, 1729121954001.4321], [1, 1729121954001.6519], [2, 1729121955001.569], [3, 1729121955001.57], [4, 1729121955001.57], [1, 1729121955001.7888], [2, 1729121956001.709], [3, 1729121956001.7112], [4, 1729121956001.713], [1, 1729121956001.929], [4, 1729121957001.8582], [3, 1729121957001.866], [2, 1729121957001.871], [1, 1729121957002.072], [1, 1729121958001.229], [4, 1729121958002.014], [2, 1729121958002.015], [3, 1729121958002.016]]}, {"target": "job_id", "datapoints": [[0, 1729121857001.663], [0, 1729121857001.671], [0, 1729121858001.829], [0, 1729121858001.832], [0, 1729121859001.977], [0, 1729121859001.982], [0, 1729121859001.994], [0, 1729121859001.998], [0, 1729121860001.149], [0, 1729121860002.097], [0, 1729121860002.1062], [0, 1729121860002.108], [0, 1729121861001.24], [0, 1729121861001.244], [0, 1729121861001.2458], [0, 1729121861001.283], [0, 1729121862001.378], [0, 1729121862001.385], [0, 1729121862001.3892], [0, 1729121862001.412], [0, 1729121863001.449], [0, 1729121863001.52], [0, 1729121863001.528], [0, 1729121863001.546], [0, 1729121864000.7239], [0, 1729121864000.79], [0, 1729121864001.17], [0, 1729121864001.6409], [0, 1729121865001.3298], [0, 1729121865001.3362], [0, 1729121865001.76], [0, 1729121865001.949], [0, 1729121866001.483], [0, 1729121866001.4878], [0, 1729121866001.49], [0, 1729121866002.104], [0, 1729121867001.2559], [0, 1729121867001.63], [0, 1729121867001.6372], [0, 1729121867001.6372], [0, 1729121868001.4011], [0, 1729121868001.758], [0, 1729121868001.759], [0, 1729121868001.7632], [0, 1729121869001.562], [0, 1729121869001.908], [0, 1729121869001.91], [0, 1729121869001.9148], [0, 1729121870001.017], [0, 1729121870001.946], [0, 1729121870002.062], [0, 1729121870002.069], [0, 1729121871001.161], [0, 1729121871001.1619], [0, 1729121871001.182], [0, 1729121871001.1892], [0, 1729121872001.2988], [0, 1729121872001.301], [0, 1729121872001.3088], [0, 1729121872001.312], [0, 1729121873001.438], [0, 1729121873001.439], [0, 1729121873001.4421], [0, 1729121873001.445], [0, 1729121874001.583], [0, 1729121874001.583], [0, 1729121874001.587], [0, 1729121874001.587], [0, 1729121875001.738], [0, 1729121875001.739], [0, 1729121875001.744], [0, 1729121875001.7458], [0, 1729121876001.877], [0, 1729121876001.877], [0, 1729121876001.878], [0, 1729121876001.881], [0, 1729121877002.009], [0, 1729121877002.009], [0, 1729121877002.016], [0, 1729121877002.019], [0, 1729121878001.138], [0, 1729121878001.146], [0, 1729121878001.147], [0, 1729121878001.15], [0, 1729121879001.271], [0, 1729121879001.2732], [0, 1729121879001.2742], [0, 1729121879001.276], [0, 1729121880001.434], [0, 1729121880001.437], [0, 1729121880001.437], [0, 1729121880001.441], [0, 1729121881001.564], [0, 1729121881001.572], [0, 1729121881001.573], [0, 1729121881001.575], [0, 1729121882001.7039], [0, 1729121882001.708], [0, 1729121882001.709], [0, 1729121882001.71], [0, 1729121883001.84], [0, 1729121883001.843], [0, 1729121883001.844], [0, 1729121883001.846], [0, 1729121884001.964], [0, 1729121884001.974], [0, 1729121884001.975], [0, 1729121884001.981], [0, 1729121885002.122], [0, 1729121885002.129], [0, 1729121885002.1309], [0, 1729121885002.134], [0, 1729121886001.282], [0, 1729121886001.2842], [0, 1729121886001.286], [0, 1729121886001.29], [0, 1729121887001.4102], [0, 1729121887001.417], [0, 1729121887001.419], [0, 1729121887001.422], [0, 1729121888001.546], [0, 1729121888001.555], [0, 1729121888001.556], [0, 1729121888001.559], [0, 1729121889001.706], [0, 1729121889001.7112], [0, 1729121889001.713], [0, 1729121889001.7139], [0, 1729121890001.227], [0, 1729121890001.843], [0, 1729121890001.864], [0, 1729121890001.871], [0, 1729121891000.394], [0, 1729121891001.982], [0, 1729121891002.002], [0, 1729121891002.006], [0, 1729121892001.133], [0, 1729121892001.134], [0, 1729121892001.529], [0, 1729121892002.1062], [0, 1729121893001.251], [0, 1729121893001.27], [0, 1729121893001.271], [0, 1729121893001.674], [0, 1729121894001.3938], [0, 1729121894001.396], [0, 1729121894001.4038], [0, 1729121894001.8079], [0, 1729121895001.291], [0, 1729121895001.511], [0, 1729121895001.527], [0, 1729121895001.942], [0, 1729121896001.4521], [0, 1729121896001.4531], [0, 1729121896001.651], [0, 1729121896002.09], [0, 1729121897001.234], [0, 1729121897001.6], [0, 1729121897001.608], [0, 1729121897001.6099], [0, 1729121898001.373], [0, 1729121898001.7358], [0, 1729121898001.738], [0, 1729121898001.739], [0, 1729121899001.516], [0, 1729121899001.877], [0, 1729121899001.8792], [0, 1729121899001.8828], [0, 1729121900001.655], [0, 1729121900002.003], [0, 1729121900002.012], [0, 1729121900002.016], [0, 1729121901001.1619], [0, 1729121901001.1619], [0, 1729121901001.166], [0, 1729121901001.8098], [0, 1729121902001.303], [0, 1729121902001.3052], [0, 1729121902001.3062], [0, 1729121902001.942], [0, 1729121903001.438], [0, 1729121903001.445], [0, 1729121903001.4458], [0, 1729121903002.08], [0, 1729121904001.212], [0, 1729121904001.582], [0, 1729121904001.586], [0, 1729121904001.586], [0, 1729121905001.354], [0, 1729121905001.7122], [0, 1729121905001.713], [0, 1729121905001.719], [0, 1729121906001.51], [0, 1729121906001.871], [0, 1729121906001.875], [0, 1729121906001.877], [0, 1729121907001.653], [0, 1729121907002.002], [0, 1729121907002.004], [0, 1729121907002.108], [0, 1729121908001.133], [0, 1729121908001.142], [0, 1729121908001.244], [0, 1729121908001.79], [0, 1729121909001.293], [0, 1729121909001.2952], [0, 1729121909001.2988], [0, 1729121909001.912], [0, 1729121910001.429], [0, 1729121910001.43], [0, 1729121910001.44], [0, 1729121910001.443], [0, 1729121911001.596], [0, 1729121911001.598], [0, 1729121911001.602], [0, 1729121911001.602], [0, 1729121912001.723], [0, 1729121912001.728], [0, 1729121912001.7332], [0, 1729121912001.734], [0, 1729121913001.8618], [0, 1729121913001.8618], [0, 1729121913001.866], [0, 1729121913001.866], [0, 1729121914001.991], [0, 1729121914001.992], [0, 1729121914001.992], [0, 1729121914001.997], [0, 1729121915002.125], [0, 1729121915002.125], [0, 1729121915002.126], [0, 1729121915002.129], [0, 1729121916001.2869], [0, 1729121916001.29], [0, 1729121916001.291], [0, 1729121916001.2942], [0, 1729121917001.416], [0, 1729121917001.4248], [0, 1729121917001.427], [0, 1729121917001.428], [0, 1729121918001.559], [0, 1729121918001.561], [0, 1729121918001.563], [0, 1729121918001.564], [0, 1729121919001.7039], [0, 1729121919001.7122], [0, 1729121919001.7139], [0, 1729121919001.7148], [0, 1729121920001.8308], [0, 1729121920001.832], [0, 1729121920001.8372], [0, 1729121920001.8408], [0, 1729121921001.628], [0, 1729121921001.957], [0, 1729121921001.985], [0, 1729121921002.0889], [0, 1729121922001.2522], [0, 1729121922001.2522], [0, 1729121922001.259], [0, 1729121922002.14], [0, 1729121923001.2878], [0, 1729121923001.3901], [0, 1729121923001.392], [0, 1729121923001.395], [0, 1729121924001.4348], [0, 1729121924001.532], [0, 1729121924001.534], [0, 1729121924001.539], [0, 1729121925001.575], [0, 1729121925001.659], [0, 1729121925001.66], [0, 1729121925001.665], [0, 1729121926001.7258], [0, 1729121926001.7952], [0, 1729121926001.801], [0, 1729121926001.801], [0, 1729121927001.886], [0, 1729121927001.945], [0, 1729121927001.949], [0, 1729121927001.951], [0, 1729121928002.018], [0, 1729121928002.073], [0, 1729121928002.076], [0, 1729121928002.076], [0, 1729121929001.175], [0, 1729121929001.222], [0, 1729121929001.223], [0, 1729121929001.226], [0, 1729121930001.3052], [0, 1729121930001.345], [0, 1729121930001.346], [0, 1729121930001.3499], [0, 1729121931001.447], [0, 1729121931001.483], [0, 1729121931001.485], [0, 1729121931001.49], [0, 1729121932001.6099], [0, 1729121932001.638], [0, 1729121932001.64], [0, 1729121932001.643], [0, 1729121933001.7532], [0, 1729121933001.7668], [0, 1729121933001.7668], [0, 1729121933001.7761], [0, 1729121934001.892], [0, 1729121934001.899], [0, 1729121934001.903], [0, 1729121934001.906], [0, 1729121935002.023], [0, 1729121935002.029], [0, 1729121935002.0322], [0, 1729121935002.033], [0, 1729121936001.171], [0, 1729121936001.1719], [0, 1729121936001.18], [0, 1729121936001.184], [0, 1729121937001.3298], [0, 1729121937001.3372], [0, 1729121937001.3398], [0, 1729121937001.342], [0, 1729121938001.458], [0, 1729121938001.465], [0, 1729121938001.47], [0, 1729121938001.47], [0, 1729121939001.587], [0, 1729121939001.595], [0, 1729121939001.596], [0, 1729121939001.602], [0, 1729121940001.618], [0, 1729121940001.703], [0, 1729121940001.71], [0, 1729121940001.7222], [0, 1729121941001.755], [0, 1729121941001.822], [0, 1729121941001.835], [0, 1729121941001.8481], [0, 1729121942001.918], [0, 1729121942001.976], [0, 1729121942001.99], [0, 1729121942002.005], [0, 1729121943001.155], [0, 1729121943002.0742], [0, 1729121943002.118], [0, 1729121943002.1372], [0, 1729121944001.213], [0, 1729121944001.248], [0, 1729121944001.257], [0, 1729121944001.28], [0, 1729121945001.082], [0, 1729121945001.3481], [0, 1729121945001.373], [0, 1729121945001.377], [0, 1729121946001.2239], [0, 1729121946001.227], [0, 1729121946001.482], [0, 1729121946001.485], [0, 1729121947001.3801], [0, 1729121947001.386], [0, 1729121947001.639], [0, 1729121947001.644], [0, 1729121948001.527], [0, 1729121948001.5308], [0, 1729121948001.779], [0, 1729121948001.783], [0, 1729121949001.686], [0, 1729121949001.688], [0, 1729121949001.935], [0, 1729121949001.937], [0, 1729121950001.842], [0, 1729121950001.843], [0, 1729121950002.081], [0, 1729121950002.083], [0, 1729121951001.2212], [0, 1729121951001.223], [0, 1729121951001.989], [0, 1729121951001.993], [0, 1729121952001.3271], [0, 1729121952001.355], [0, 1729121952002.1099], [0, 1729121952002.135], [0, 1729121953001.271], [0, 1729121953001.2732], [0, 1729121953001.2778], [0, 1729121953001.512], [0, 1729121954001.42], [0, 1729121954001.422], [0, 1729121954001.4321], [0, 1729121954001.6519], [0, 1729121955001.569], [0, 1729121955001.57], [0, 1729121955001.57], [0, 1729121955001.7888], [0, 1729121956001.709], [0, 1729121956001.7112], [0, 1729121956001.713], [0, 1729121956001.929], [0, 1729121957001.8582], [0, 1729121957001.866], [0, 1729121957001.871], [0, 1729121957002.072], [0, 1729121958001.229], [0, 1729121958002.014], [0, 1729121958002.015], [0, 1729121958002.016]]}]'
comp_ids:{1, 2, 3, 4}
2024-10-16T18:39:27-05:00 INFO: query check RC: 0
e7587a024ee8c0b1783c3f7ebb9ae34220d5160d1bc61192d94fe2f3c44b25db
2024-10-16T18:39:58-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2911    898 --:--:-- --:--:-- --:--:--  3832
{"datasource":{"id":1,"uid":"X3qoahmHk","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2024-10-16T18:39:59-05:00 INFO: Checking grafana data
2024-10-16T18:40:00-05:00 INFO: Grafana data check, rc: 0
2024-10-16T18:40:00-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2024-10-16T18:40:05-05:00 INFO: DONE
2024-10-16 18:40:15 INFO: ----------------------------------------------
2024-10-16 18:40:15 INFO: ==== Summary ====
ldmsd_ctrl_test: [01;32mPASSED[0m
papi_store_test: [01;32mPASSED[0m
updtr_status_test: [01;32mPASSED[0m
ldms_qgroup_test: [01;32mPASSED[0m
ldmsd_decomp_static_omit_test: [01;31mFAILED[0m
ldms_stream_test: [01;32mPASSED[0m
ldmsd_auth_ovis_test: [01;32mPASSED[0m
store_app_test: [01;32mPASSED[0m
store_list_record_test: [01;32mPASSED[0m
ldmsd_qgroup_test: [01;32mPASSED[0m
set_array_test: [01;32mPASSED[0m
ovis_ev_test: [01;32mPASSED[0m
setgroup_test: [01;32mPASSED[0m
ldms_list_test: [01;32mPASSED[0m
slurm_stream_test: [01;32mPASSED[0m
maestro_cfg_test: [01;32mPASSED[0m
ldms_set_info_test: [01;32mPASSED[0m
spank_notifier_test: [01;31mFAILED[0m
agg_slurm_test: [01;31mFAILED[0m
updtr_match_add_test: [01;32mPASSED[0m
updtr_match_del_test: [01;32mPASSED[0m
direct_prdcr_subscribe_test: [01;32mPASSED[0m
ldmsd_auth_test: [01;32mPASSED[0m
updtr_stop_test: [01;32mPASSED[0m
cont-test-maestro-munge: [01;32mPASSED[0m
cont-test-ldms: [01;32mPASSED[0m
prdcr_subscribe_test: [01;32mPASSED[0m
cont-test-maestro-hostmunge: [01;32mPASSED[0m
ldmsd_long_config_test: [01;32mPASSED[0m
maestro_raft_test: [01;32mPASSED[0m
dump_cfg_test: [01;32mPASSED[0m
ldmsd_stream_test2: [01;32mPASSED[0m
updtr_start_test: [01;32mPASSED[0m
failover_test: [01;32mPASSED[0m
ldmsd_rail_test: [01;32mPASSED[0m
ldms_record_test: [01;32mPASSED[0m
libovis_log_test: [01;32mPASSED[0m
set_sec_mod_test: [01;32mPASSED[0m
cont-test-maestro: [01;32mPASSED[0m
ldmsd_decomp_test: [01;31mFAILED[0m
ldmsd_stream_status_test: [01;32mPASSED[0m
json_stream_sampler_test: [01;32mPASSED[0m
ldmsd_flex_decomp_test: [01;31mFAILED[0m
ldms_ipv6_test: [01;32mPASSED[0m
ldmsd_stream_rate_test: [01;32mPASSED[0m
quick_set_add_rm_test: [01;32mPASSED[0m
updtr_prdcr_del_test: [01;32mPASSED[0m
ldmsd_decomp_no_fill_test: [01;31mFAILED[0m
updtr_prdcr_add_test: [01;32mPASSED[0m
mt-slurm-test: [01;32mPASSED[0m
ovis_json_test: [01;32mPASSED[0m
papi_sampler_test: [01;32mPASSED[0m
syspapi_test: [01;32mPASSED[0m
updtr_del_test: [01;32mPASSED[0m
ldmsd_autointerval_test: [01;32mPASSED[0m
ldms_rail_test: [01;32mPASSED[0m
updtr_add_test: [01;32mPASSED[0m
direct_ldms_ls_conn_test: [01;32mPASSED[0m
set_array_hang_test: [01;32mPASSED[0m
ldms_rate_test: [01;32mPASSED[0m
slurm_sampler2_test: [01;32mPASSED[0m
ldms_schema_digest_test: [01;32mPASSED[0m
agg_test: [01;32mPASSED[0m
------------------------------------------
Total tests passed: 57/63
------------------------------------------
