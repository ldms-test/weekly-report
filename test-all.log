2022-10-27 20:43:40 INFO: WORK_DIR: /mnt/300G/data/2022-10-27-204339
2022-10-27 20:43:40 INFO: LOG: /mnt/300G/data/2022-10-27-204339/cygnus-weekly.log
~/cron/ldms-test ~/cron/ldms-test
/mnt/300G/data/2022-10-27-204339 ~/cron/ldms-test ~/cron/ldms-test
2022-10-27 20:43:41 INFO: Skip building on host because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:43:41 INFO: Skip building containerized binary because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:43:41 INFO: -- Installation process succeeded --
2022-10-27 20:43:41 INFO: ---------------------------------------------------------------
~/cron/ldms-test /mnt/300G/data/2022-10-27-204339
~/cron/ldms-test/weekly-report ~/cron/ldms-test /mnt/300G/data/2022-10-27-204339
HEAD is now at b766134 2022-10-27-154535
[master e4ad7c4] 2022-10-27-204339
 2 files changed, 14 insertions(+), 2035 deletions(-)
 rewrite test-all.log (99%)
To github.com:ldms-test/weekly-report
   b766134..e4ad7c4  master -> master
~/cron/ldms-test /mnt/300G/data/2022-10-27-204339
2022-10-27 20:43:43 INFO: ==== OVIS+SOS Installation Completed ====
2022-10-27 20:43:43 INFO: ==== Start batch testing ====
~/cron/ldms-test /mnt/300G/data/2022-10-27-204339 ~/cron/ldms-test ~/cron/ldms-test
2022-10-27 20:43:43 INFO: ======== direct_ldms_ls_conn_test ========
2022-10-27 20:43:43 INFO: CMD: python3 direct_ldms_ls_conn_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/direct_ldms_ls_conn_test
2022-10-27 20:43:43,870 TADA INFO starting test `direct_ldms_ls_conn_test`
2022-10-27 20:43:43,870 TADA INFO   test-id: 2a3c72d1ead67f74a5dc41a364c04fb596db8354bf7f26c7023b091ff87bbf31
2022-10-27 20:43:43,870 TADA INFO   test-suite: LDMSD
2022-10-27 20:43:43,870 TADA INFO   test-name: direct_ldms_ls_conn_test
2022-10-27 20:43:43,870 TADA INFO   test-user: narate
2022-10-27 20:43:43,870 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:43:44,334 __main__ INFO starting munged on cygnus-01-iw
2022-10-27 20:43:44,658 __main__ INFO starting munged on localhost
2022-10-27 20:43:44,893 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-27 20:43:45,193 TADA INFO assertion 0, Start ldmsd sampler and munged: OK, passed
2022-10-27 20:43:50,386 TADA INFO assertion 1, ldms_ls to the sampler: OK, passed
2022-10-27 20:43:50,387 __main__ INFO Stopping sampler daemon ...
2022-10-27 20:43:55,796 TADA INFO assertion 2, Kill the sampler: OK, passed
2022-10-27 20:43:55,831 TADA INFO assertion 3, ldms_ls to the dead sampler: got expected output, passed
2022-10-27 20:43:55,865 TADA INFO assertion 4, ldms_ls to a dead host: got expected output, passed
2022-10-27 20:43:55,866 TADA INFO test direct_ldms_ls_conn_test ended
2022-10-27 20:43:56,067 __main__ INFO stopping munged on cygnus-01-iw
2022-10-27 20:43:56,477 __main__ INFO stopping munged on localhost
2022-10-27 20:43:56 INFO: ----------------------------------------------
2022-10-27 20:43:56 INFO: ======== direct_prdcr_subscribe_test ========
2022-10-27 20:43:56 INFO: CMD: python3 direct_prdcr_subscribe_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/direct_prdcr_subscribe_test
2022-10-27 20:43:57,305 TADA INFO starting test `direct_prdcr_subscribe_test`
2022-10-27 20:43:57,306 TADA INFO   test-id: 168b5aedf0cd4843bf7e2635479f73022fd84324a54e217fe09b193efe5dd2bc
2022-10-27 20:43:57,306 TADA INFO   test-suite: LDMSD
2022-10-27 20:43:57,306 TADA INFO   test-name: direct_prdcr_subscribe_test
2022-10-27 20:43:57,306 TADA INFO   test-user: narate
2022-10-27 20:43:57,306 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:43:59,225 __main__ INFO starting munged on cygnus-01-iw
2022-10-27 20:44:00,037 __main__ INFO starting munged on cygnus-02-iw
2022-10-27 20:44:00,761 __main__ INFO starting munged on cygnus-03-iw
2022-10-27 20:44:01,526 __main__ INFO starting munged on cygnus-04-iw
2022-10-27 20:44:01,840 __main__ INFO starting munged on localhost
2022-10-27 20:44:02,076 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-27 20:44:02,577 __main__ INFO starting ldmsd on cygnus-02-iw
2022-10-27 20:44:03,085 __main__ INFO starting ldmsd on cygnus-03-iw
2022-10-27 20:44:03,589 __main__ INFO starting ldmsd on cygnus-04-iw
2022-10-27 20:44:10,512 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-27 20:44:10,513 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-27 20:44:10,514 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-27 20:44:10,514 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-27 20:44:10,515 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verified, passed
2022-10-27 20:44:10,554 TADA INFO assertion 5, Stopping the producers succeeds: agg-1 producers stopped, passed
2022-10-27 20:44:11,556 TADA INFO assertion 6, Restarting the producers succeeds: agg-1 producers started, passed
2022-10-27 20:44:18,205 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-27 20:44:18,206 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-27 20:44:18,206 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-27 20:44:18,207 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-27 20:44:18,208 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verified, passed
2022-10-27 20:44:18,208 __main__ INFO stopping sampler-1
2022-10-27 20:44:19,641 TADA INFO assertion 12, stream-sampler-1 is not running: sampler-1 stopped, passed
2022-10-27 20:44:19,641 __main__ INFO starting sampler-1
2022-10-27 20:44:20,887 TADA INFO assertion 13, stream-sampler-1 has restarted: sampler-1 running, passed
2022-10-27 20:44:20,887 __main__ INFO allow some time for prdcr to reconnect ...
2022-10-27 20:44:26,840 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-27 20:44:26,841 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-27 20:44:26,841 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verified, passed
2022-10-27 20:44:26,843 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: unsubscribed, passed
2022-10-27 20:44:29,037 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-27 20:44:29,041 __main__ INFO stopping agg-1
2022-10-27 20:44:34,251 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-27 20:44:34,251 TADA INFO test direct_prdcr_subscribe_test ended
2022-10-27 20:44:34,463 __main__ INFO stopping munged on cygnus-01-iw
2022-10-27 20:44:34,882 __main__ INFO stopping ldmsd on cygnus-01-iw
2022-10-27 20:44:35,307 __main__ INFO stopping munged on cygnus-02-iw
2022-10-27 20:44:35,718 __main__ INFO stopping ldmsd on cygnus-02-iw
2022-10-27 20:44:36,127 __main__ INFO stopping munged on cygnus-03-iw
2022-10-27 20:44:36,751 __main__ INFO stopping munged on cygnus-04-iw
2022-10-27 20:44:37,174 __main__ INFO stopping ldmsd on cygnus-04-iw
2022-10-27 20:44:37,388 __main__ INFO stopping munged on localhost
2022-10-27 20:44:37 INFO: ----------------------------------------------
2022-10-27 20:44:37 INFO: ======== agg_slurm_test ========
2022-10-27 20:44:37 INFO: CMD: python3 agg_slurm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/agg_slurm_test
2022-10-27 20:44:38,265 TADA INFO starting test `agg_slurm_test`
2022-10-27 20:44:38,265 TADA INFO   test-id: 99cb3007fab63648da806ab335a639337cab34b7fb9318a7995ee73169d4f497
2022-10-27 20:44:38,265 TADA INFO   test-suite: LDMSD
2022-10-27 20:44:38,265 TADA INFO   test-name: agg_slurm_test
2022-10-27 20:44:38,266 TADA INFO   test-user: narate
2022-10-27 20:44:38,266 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:44:38,267 __main__ INFO -- Get or create the cluster --
2022-10-27 20:44:52,068 __main__ INFO -- Preparing syspapi JSON file --
2022-10-27 20:44:52,164 __main__ INFO -- Preparing jobpapi JSON file --
2022-10-27 20:44:52,271 __main__ INFO -- Preparing job script & programs --
2022-10-27 20:44:53,630 __main__ INFO -- Start daemons --
2022-10-27 20:45:05,817 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 20:45:10,822 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 20:45:10,949 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-27 20:45:11,046 __main__ INFO -- Give syspapi some time to work before submitting job --
2022-10-27 20:45:16,050 __main__ INFO -- Submitting jobs --
2022-10-27 20:45:16,175 __main__ INFO job_one: 1
2022-10-27 20:45:16,306 __main__ INFO job_two: 2
2022-10-27 20:45:26,316 __main__ INFO -- Cancelling jobs --
2022-10-27 20:45:26,317 __main__ INFO job_one: 1
2022-10-27 20:45:26,439 __main__ INFO job_two: 2
2022-10-27 20:46:38,639 TADA INFO assertion 2, slurm data verification: get expected data from store, passed
2022-10-27 20:46:38,640 TADA INFO assertion 3, meminfo data verification: No data missing, passed
2022-10-27 20:46:38,641 TADA INFO assertion 4, (SYS/JOB) PAPI data verification: No data missing, passed
2022-10-27 20:46:38,641 TADA INFO test agg_slurm_test ended
2022-10-27 20:46:53 INFO: ----------------------------------------------
2022-10-27 20:46:54 INFO: ======== papi_sampler_test ========
2022-10-27 20:46:54 INFO: CMD: python3 papi_sampler_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/papi_sampler_test
2022-10-27 20:46:54,796 TADA INFO starting test `papi_sampler_test`
2022-10-27 20:46:54,797 TADA INFO   test-id: 45cf8ecbbe9e38efb1764d7f2e3be3c3ebc154aa127de5a8f0362f9e273d1791
2022-10-27 20:46:54,797 TADA INFO   test-suite: LDMSD
2022-10-27 20:46:54,797 TADA INFO   test-name: papi_sampler_test
2022-10-27 20:46:54,797 TADA INFO   test-user: narate
2022-10-27 20:46:54,797 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:46:54,798 __main__ INFO -- Get or create the cluster --
2022-10-27 20:47:00,036 __main__ INFO -- Start daemons --
2022-10-27 20:47:10,098 TADA INFO assertion 0, ldmsd has started: verified, passed
2022-10-27 20:47:10,314 TADA INFO assertion 1.1, Non-papi job is submitted: jobid(1) > 0, passed
2022-10-27 20:47:15,449 TADA INFO assertion 1.2, Non-papi job is running before ldms_ls: STATE = RUNNING, passed
2022-10-27 20:47:15,627 TADA INFO assertion 1.3, Non-papi job is running after ldms_ls: STATE = RUNNING, passed
2022-10-27 20:47:15,627 TADA INFO assertion 1, Non-papi job does not create set: verified, passed
2022-10-27 20:47:29,438 TADA INFO assertion 2, papi job creates set: PAPI set created, passed
2022-10-27 20:47:29,438 TADA INFO assertion 2.2, Schema name is set accordingly: schema name == papi0, passed
2022-10-27 20:47:29,438 TADA INFO assertion 2.1, Events in papi job set created according to config file: {'PAPI_TOT_INS'} == {'PAPI_TOT_INS'}, passed
2022-10-27 20:47:29,438 TADA INFO assertion 2.3, PAPI set has correct job_id: 2 == 2, passed
2022-10-27 20:47:29,648 TADA INFO assertion 2.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-27 20:47:35,458 TADA INFO assertion 3, papi job creates set: PAPI set created, passed
2022-10-27 20:47:35,458 TADA INFO assertion 3.2, Schema name is set accordingly: schema name == papi1, passed
2022-10-27 20:47:35,458 TADA INFO assertion 3.1, Events in papi job set created according to config file: {'PAPI_TOT_INS', 'PAPI_BR_MSP'} == {'PAPI_TOT_INS', 'PAPI_BR_MSP'}, passed
2022-10-27 20:47:35,459 TADA INFO assertion 3.3, PAPI set has correct job_id: 3 == 3, passed
2022-10-27 20:47:35,665 TADA INFO assertion 3.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-27 20:47:35,665 TADA INFO assertion 4, Multiple, concurrent jobs results in concurrent, multiple sets: LDMS sets ({'node-1/papi1/3.0', 'node-1/papi0/2.0', 'node-1/meminfo'}), passed
2022-10-27 20:47:46,208 TADA INFO assertion 6, PAPI set persists within `job_expiry` after job exited: verified, passed
2022-10-27 20:48:26,518 TADA INFO assertion 7, PAPI set is deleted after `2.2 x job_expiry` since job exited: node-1/meminfo deleted, passed
2022-10-27 20:48:28,884 TADA INFO assertion 8, Missing config file attribute is logged: : papi_sampler[519]: papi_config object must contain either the 'file' or 'config' attribute., passed
2022-10-27 20:48:34,378 TADA INFO assertion 9, Bad config file is logged: : papi_sampler: configuration file syntax error., passed
2022-10-27 20:48:39,832 TADA INFO assertion 10, Unsupported events are logged: : papi_sampler: PAPI error 'Event does not exist' translating event code 'FOO', passed
2022-10-27 20:48:39,832 __main__ INFO -- Finishing Test --
2022-10-27 20:48:39,833 TADA INFO test papi_sampler_test ended
2022-10-27 20:48:39,833 __main__ INFO -- Cleaning up files --
2022-10-27 20:48:39,834 __main__ INFO -- Removing the virtual cluster --
2022-10-27 20:48:51 INFO: ----------------------------------------------
2022-10-27 20:48:52 INFO: ======== papi_store_test ========
2022-10-27 20:48:52 INFO: CMD: python3 papi_store_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/papi_store_test
2022-10-27 20:48:52,805 TADA INFO starting test `papi_store_test`
2022-10-27 20:48:52,805 TADA INFO   test-id: 025b2765c668ef957b0f45c18ac2cde8ffef744aad394dfdcb5877ea0bc04bd5
2022-10-27 20:48:52,805 TADA INFO   test-suite: LDMSD
2022-10-27 20:48:52,806 TADA INFO   test-name: papi_store_test
2022-10-27 20:48:52,806 TADA INFO   test-user: narate
2022-10-27 20:48:52,806 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:48:52,807 __main__ INFO -- Get or create the cluster --
2022-10-27 20:49:00,325 __main__ INFO -- Start daemons --
2022-10-27 20:49:31,660 TADA INFO assertion 1, Every job in the input data is represented in the output: {1, 2, 3, 4} = {1, 2, 3, 4}, passed
2022-10-27 20:49:31,660 TADA INFO assertion 2, Every event in every job results in a separate row in the output: verified, passed
2022-10-27 20:49:31,660 TADA INFO assertion 3, The schema name in the output matches the event name: verified, passed
2022-10-27 20:49:31,660 TADA INFO assertion 4, Each rank in the job results in a row per event in the output: verified, passed
2022-10-27 20:49:31,660 TADA INFO test papi_store_test ended
2022-10-27 20:49:43 INFO: ----------------------------------------------
2022-10-27 20:49:44 INFO: ======== store_app_test ========
2022-10-27 20:49:44 INFO: CMD: python3 store_app_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/store_app_test
2022-10-27 20:49:45,430 TADA INFO starting test `store_app_test`
2022-10-27 20:49:45,431 TADA INFO   test-id: 39d2f42d1f49f84ae0fe1e8beddc9df8a1c4bcebd1a64c03dd40a328fc4a0035
2022-10-27 20:49:45,431 TADA INFO   test-suite: LDMSD
2022-10-27 20:49:45,431 TADA INFO   test-name: store_app_test
2022-10-27 20:49:45,431 TADA INFO   test-user: narate
2022-10-27 20:49:45,431 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:49:45,432 __main__ INFO -- Get or create the cluster --
2022-10-27 20:49:59,740 __main__ INFO -- Preparing job script & programs --
2022-10-27 20:50:00,128 __main__ INFO -- Start daemons --
2022-10-27 20:50:12,473 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 20:50:17,480 __main__ INFO -- Submitting jobs --
2022-10-27 20:50:17,698 __main__ INFO job_one: 1
2022-10-27 20:50:22,828 __main__ INFO job_two: 2
2022-10-27 20:50:32,286 __main__ INFO Verifying data ...
2022-10-27 20:52:29,192 TADA INFO assertion 1, Verify data: sos data is not empty and sos data < ldms_ls data, passed
2022-10-27 20:52:29,192 TADA INFO test store_app_test ended
2022-10-27 20:52:43 INFO: ----------------------------------------------
2022-10-27 20:52:44 INFO: ======== syspapi_test ========
2022-10-27 20:52:44 INFO: CMD: python3 syspapi_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/syspapi_test
2022-10-27 20:52:44,883 TADA INFO starting test `syspapi_test`
2022-10-27 20:52:44,883 TADA INFO   test-id: 7a962c3975dd714cf78fcee33e29bda7858b812e065db3573d8c0d3666c4a6aa
2022-10-27 20:52:44,883 TADA INFO   test-suite: LDMSD
2022-10-27 20:52:44,883 TADA INFO   test-name: syspapi_test
2022-10-27 20:52:44,883 TADA INFO   test-user: narate
2022-10-27 20:52:44,883 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:52:44,884 __main__ INFO -- Get or create the cluster --
2022-10-27 20:52:56,499 __main__ INFO -- Write syspapi JSON config files --
2022-10-27 20:52:56,499 __main__ INFO    - db/syspapi-1.json
2022-10-27 20:52:56,500 __main__ INFO    - db/syspapi-bad.json
2022-10-27 20:52:56,501 __main__ INFO -- Start daemons --
2022-10-27 20:53:04,929 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 20:53:09,934 __main__ INFO -- Verifying --
2022-10-27 20:53:10,062 TADA INFO assertion 1, verify set creation by cfg_file: set existed (with correct instance name), passed
2022-10-27 20:53:10,062 TADA INFO assertion 2, verify schema name by cfg_file: verify schema name, passed
2022-10-27 20:53:10,187 TADA INFO assertion 3, verify metrics (events) by cfg_file: verify events (metrics), passed
2022-10-27 20:53:12,316 TADA INFO assertion 4, verify increment counters: verify increment of supported counters, passed
2022-10-27 20:53:12,427 TADA INFO assertion 5, verify cfg_file syntax error report: verify JSON parse error, passed
2022-10-27 20:53:12,585 TADA INFO assertion 6, verify cfg_file unsupported events report: verify unsupported event report, passed
2022-10-27 20:53:34,009 TADA INFO assertion 7, verify cfg_file for many events: each event has either 'sucees' or 'failed' report, passed
2022-10-27 20:53:34,009 __main__ INFO  events succeeded: 77
2022-10-27 20:53:34,009 __main__ INFO  events failed: 114
2022-10-27 20:53:34,009 TADA INFO test syspapi_test ended
2022-10-27 20:53:47 INFO: ----------------------------------------------
2022-10-27 20:53:48 INFO: ======== agg_test ========
2022-10-27 20:53:48 INFO: CMD: python3 agg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/agg_test
2022-10-27 20:53:48,820 TADA INFO starting test `agg_test`
2022-10-27 20:53:48,820 TADA INFO   test-id: f4f83932f81a033f89d18aba9f63207abb957016075d320283d0e6bc8979bd06
2022-10-27 20:53:48,820 TADA INFO   test-suite: LDMSD
2022-10-27 20:53:48,820 TADA INFO   test-name: agg_test
2022-10-27 20:53:48,820 TADA INFO   test-user: narate
2022-10-27 20:53:48,820 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:53:48,821 __main__ INFO -- Get or create the cluster --
2022-10-27 20:54:06,456 __main__ INFO -- Start daemons --
2022-10-27 20:54:15,609 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 20:54:20,615 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 20:54:20,754 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-27 20:54:21,539 TADA INFO assertion 2, meminfo data verification: data verified, passed
2022-10-27 20:54:21,539 __main__ INFO -- Terminating ldmsd on node-1 --
2022-10-27 20:54:23,871 TADA INFO assertion 3, node-1 ldmsd terminated, sets removed from agg-11: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 20:54:24,093 TADA INFO assertion 4, node-1 ldmsd terminated, sets removed from agg-2: list({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:54:24,093 __main__ INFO -- Resurrecting ldmsd on node-1 --
2022-10-27 20:54:29,762 TADA INFO assertion 5, node-1 ldmsd revived, sets added to agg-11: list({'node-1/meminfo', 'node-3/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo'}), passed
2022-10-27 20:54:29,880 TADA INFO assertion 6, node-1 ldmsd revived, sets added to agg-2: list({'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:54:29,880 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-27 20:54:32,245 TADA INFO assertion 7, agg-11 ldmsd terminated, sets removed from agg-2: list({'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:54:32,373 TADA INFO assertion 8, agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-27 20:54:32,497 TADA INFO assertion 9, agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 20:54:32,497 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-27 20:54:38,154 TADA INFO assertion 10, agg-11 ldmsd revived, sets added to agg-2: list({'node-1/meminfo', 'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo'}) == expect({'node-1/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:54:38,154 TADA INFO test agg_test ended
2022-10-27 20:54:53 INFO: ----------------------------------------------
2022-10-27 20:54:54 INFO: ======== failover_test ========
2022-10-27 20:54:54 INFO: CMD: python3 failover_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/failover_test
2022-10-27 20:54:55,126 TADA INFO starting test `failover_test`
2022-10-27 20:54:55,126 TADA INFO   test-id: 7eb63a10741e4d66f4817e6cef22aecc2f5d50766017300b5aa5d3ed4f9ad4dd
2022-10-27 20:54:55,127 TADA INFO   test-suite: LDMSD
2022-10-27 20:54:55,127 TADA INFO   test-name: failover_test
2022-10-27 20:54:55,127 TADA INFO   test-user: narate
2022-10-27 20:54:55,127 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:54:55,128 __main__ INFO -- Get or create the cluster --
2022-10-27 20:55:12,644 __main__ INFO -- Start daemons --
2022-10-27 20:55:21,961 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 20:55:36,976 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 20:55:37,120 TADA INFO assertion 1, 
ldms_ls agg-2: dir result verified, passed
2022-10-27 20:55:37,864 TADA INFO assertion 2, 
meminfo data verification: data verified, passed
2022-10-27 20:55:37,865 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-27 20:55:43,215 TADA INFO assertion 3, 
agg-11 ldmsd terminated, sets added to agg-12: list({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:55:43,324 TADA INFO assertion 4, 
agg-11 ldmsd terminated, all sets running on agg-2: list({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:55:43,431 TADA INFO assertion 5, 
agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-27 20:55:43,555 TADA INFO assertion 6, 
agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 20:55:43,556 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-27 20:56:04,272 TADA INFO assertion 7, 
agg-11 ldmsd revived, sets removed from agg-12: list({'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:56:04,388 TADA INFO assertion 8, 
agg-11 ldmsd revived, all sets running on agg-2: list({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:56:04,388 __main__ INFO -- Terminating ldmsd on agg-12 --
2022-10-27 20:56:09,705 TADA INFO assertion 9, 
agg-12 ldmsd terminated, sets added to agg-11: list({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:56:09,823 TADA INFO assertion 10, 
agg-12 ldmsd terminated, all sets running on agg-2: list({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:56:09,938 TADA INFO assertion 11, 
agg-12 ldmsd terminated, node-2 ldmsd is still running: list({'node-2/meminfo'}) == expect({'node-2/meminfo'}), passed
2022-10-27 20:56:10,043 TADA INFO assertion 12, 
agg-12 ldmsd terminated, node-4 ldmsd is still running: list({'node-4/meminfo'}) == expect({'node-4/meminfo'}), passed
2022-10-27 20:56:10,044 __main__ INFO -- Resurrecting ldmsd on agg-12 --
2022-10-27 20:56:30,688 TADA INFO assertion 13, 
agg-12 ldmsd revived, sets removed from agg-11: list({'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 20:56:30,821 TADA INFO assertion 14, 
agg-12 ldmsd revived, all sets running on agg-2: list({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo', 'node-4/meminfo'}), passed
2022-10-27 20:56:30,822 TADA INFO test failover_test ended
2022-10-27 20:56:46 INFO: ----------------------------------------------
2022-10-27 20:56:47 INFO: ======== ldmsd_auth_ovis_test ========
2022-10-27 20:56:47 INFO: CMD: python3 ldmsd_auth_ovis_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldmsd_auth_ovis_test
2022-10-27 20:56:47,750 TADA INFO starting test `ldmsd_auth_ovis_test`
2022-10-27 20:56:47,750 TADA INFO   test-id: efdec26efc375751966127822c3b24f08efd284e2f876d2e81e8f8f5eb3e1866
2022-10-27 20:56:47,750 TADA INFO   test-suite: LDMSD
2022-10-27 20:56:47,750 TADA INFO   test-name: ldmsd_auth_ovis_test
2022-10-27 20:56:47,750 TADA INFO   test-user: narate
2022-10-27 20:56:47,750 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:56:47,751 __main__ INFO -- Get or create the cluster --
2022-10-27 20:56:52,928 __main__ INFO -- Start daemons --
2022-10-27 20:56:54,917 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 20:57:00,045 TADA INFO assertion 1, ldms_ls with auth none: verified, passed
2022-10-27 20:57:00,170 TADA INFO assertion 2, ldms_ls with wrong secret: verified, passed
2022-10-27 20:57:00,293 TADA INFO assertion 3, ldms_ls 'dir' with right secret: verified, passed
2022-10-27 20:57:00,579 TADA INFO assertion 4, ldms_ls 'read' with right secret: verified, passed
2022-10-27 20:57:00,579 TADA INFO test ldmsd_auth_ovis_test ended
2022-10-27 20:57:12 INFO: ----------------------------------------------
2022-10-27 20:57:12 INFO: ======== ldmsd_auth_test ========
2022-10-27 20:57:12 INFO: CMD: python3 ldmsd_auth_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldmsd_auth_test
2022-10-27 20:57:13,619 TADA INFO starting test `ldmsd_auth_test`
2022-10-27 20:57:13,620 TADA INFO   test-id: 31d5976e33ae83dc76976d75314b9c918ef720b7882fb5bdbfbeced68f5b7a0f
2022-10-27 20:57:13,620 TADA INFO   test-suite: LDMSD
2022-10-27 20:57:13,620 TADA INFO   test-name: ldmsd_auth_test
2022-10-27 20:57:13,620 TADA INFO   test-user: narate
2022-10-27 20:57:13,620 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:57:13,620 __main__ INFO -- Get or create the cluster --
2022-10-27 20:57:31,754 __main__ INFO -- Start daemons --
2022-10-27 20:57:50,529 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 20:57:55,661 TADA INFO assertion 1, root@agg-2(dom3) ldms_ls to agg-2:10000: see all sets, passed
2022-10-27 20:57:55,790 TADA INFO assertion 2, user@agg-2(dom3) ldms_ls to agg-2:10000: see only meminfo, passed
2022-10-27 20:57:55,924 TADA INFO assertion 3, root@headnode(dom4) ldms_ls to agg-2:10001: see all sets, passed
2022-10-27 20:57:56,036 TADA INFO assertion 4, user@headnode(dom4) ldms_ls to agg-2:10001: see only meminfo, passed
2022-10-27 20:57:56,147 TADA INFO assertion 5, root@headnode(dom4) ldms_ls to agg-11:10000: connection rejected, passed
2022-10-27 20:57:56,147 TADA INFO test ldmsd_auth_test ended
2022-10-27 20:58:11 INFO: ----------------------------------------------
2022-10-27 20:58:12 INFO: ======== ldmsd_ctrl_test ========
2022-10-27 20:58:12 INFO: CMD: python3 ldmsd_ctrl_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldmsd_ctrl_test
2022-10-27 20:58:13,420 TADA INFO starting test `ldmsd_ctrl_test`
2022-10-27 20:58:13,420 TADA INFO   test-id: 923e23bf387bc3c27c457cc340fa9ef7855aebb028c0fc927e22058f92c5323a
2022-10-27 20:58:13,420 TADA INFO   test-suite: LDMSD
2022-10-27 20:58:13,420 TADA INFO   test-name: ldmsd_ctrl_test
2022-10-27 20:58:13,420 TADA INFO   test-user: narate
2022-10-27 20:58:13,421 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:58:13,421 __main__ INFO -- Get or create the cluster --
2022-10-27 20:58:22,619 __main__ INFO -- Start daemons --
2022-10-27 20:58:27,008 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 20:58:33,130 TADA INFO assertion 1, ldmsd_controller interactive session: connected, passed
2022-10-27 20:58:34,244 TADA INFO assertion 2, ldmsctl interactive session: connected, passed
2022-10-27 20:58:34,845 TADA INFO assertion 3, ldmsd_controller start bogus producer: expected output verified, passed
2022-10-27 20:58:35,447 TADA INFO assertion 4, ldmsctl start bogus producer: expected output verified, passed
2022-10-27 20:58:36,048 TADA INFO assertion 5, ldmsd_controller bogus command: expected output verified, passed
2022-10-27 20:58:36,650 TADA INFO assertion 6, ldmsctl bogus command: expected output verified, passed
2022-10-27 20:58:37,251 TADA INFO assertion 7, ldmsd_controller load bogus plugin: expected output verified, passed
2022-10-27 20:58:37,853 TADA INFO assertion 8, ldmsctl load bogus plugin: expected output verified, passed
2022-10-27 20:58:55,035 TADA INFO assertion 9, ldmsd_controller prdcr/updtr: verified, passed
2022-10-27 20:59:12,232 TADA INFO assertion 10, ldmsctl prdcr/updtr: verified, passed
2022-10-27 20:59:12,232 TADA INFO test ldmsd_ctrl_test ended
2022-10-27 20:59:24 INFO: ----------------------------------------------
2022-10-27 20:59:25 INFO: ======== ldmsd_stream_test ========
2022-10-27 20:59:25 INFO: CMD: python3 ldmsd_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldmsd_stream_test
2022-10-27 20:59:26,560 TADA INFO starting test `ldmsd_stream_test`
2022-10-27 20:59:26,560 TADA INFO   test-id: d50bd3f0c5efd68e231dcd5fb080cbb875794c94b25ad270ae68bc97f9d7291b
2022-10-27 20:59:26,560 TADA INFO   test-suite: LDMSD
2022-10-27 20:59:26,560 TADA INFO   test-name: ldmsd_stream_test
2022-10-27 20:59:26,560 TADA INFO   test-user: narate
2022-10-27 20:59:26,560 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 20:59:37,898 __main__ INFO waiting for libraries to be available across all containers...
2022-10-27 20:59:38,753 __main__ INFO _lib_avail: True
2022-10-27 21:00:46,221 __main__ INFO test ldmsd_stream_subscribe with large json streams
2022-10-27 21:00:52,361 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 21:01:05,858 __main__ INFO --- Verifying the received streams
2022-10-27 21:01:07,497 TADA INFO assertion 1, ldmsd_stream_subscribe receives large json streams: Verify all streams were received correctly, passed
2022-10-27 21:01:07,733 __main__ INFO test LDMSD with large json streams
2022-10-27 21:01:13,817 __main__ INFO --- Sending stream to samplerd
2022-10-27 21:01:32,831 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 21:01:35,252 TADA INFO assertion 2, samplerd receives large json streams: Verify all streams were received correctly, passed
2022-10-27 21:01:35,252 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 21:01:37,655 TADA INFO assertion 3, agg receives large json streams: Verify all streams were received correctly, passed
2022-10-27 21:01:37,655 __main__ INFO test ldmsd_stream_subscribe with small json streams
2022-10-27 21:01:43,773 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 21:03:39,886 __main__ INFO --- Verifying the received streams
2022-10-27 21:03:41,798 TADA INFO assertion 4, ldmsd_stream_subscribe receives small json streams: Verify all streams were received correctly, passed
2022-10-27 21:03:42,015 __main__ INFO test LDMSD with small json streams
2022-10-27 21:03:48,055 __main__ INFO --- Sending stream to samplerd
2022-10-27 21:05:49,593 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 21:05:52,432 TADA INFO assertion 5, samplerd receives small json streams: Verify all streams were received correctly, passed
2022-10-27 21:05:52,432 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 21:05:55,265 TADA INFO assertion 6, agg receives small json streams: Verify all streams were received correctly, passed
2022-10-27 21:05:55,265 __main__ INFO test ldmsd_stream_subscribe with large string streams
2022-10-27 21:06:01,375 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 21:06:14,534 __main__ INFO --- Verifying the received streams
2022-10-27 21:06:16,141 TADA INFO assertion 7, ldmsd_stream_subscribe receives large string streams: Verify all streams were received correctly, passed
2022-10-27 21:06:16,357 __main__ INFO test LDMSD with large string streams
2022-10-27 21:06:22,413 __main__ INFO --- Sending stream to samplerd
2022-10-27 21:06:41,097 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 21:06:42,251 TADA INFO assertion 8, samplerd receives large string streams: Verify all streams were received correctly, passed
2022-10-27 21:06:42,252 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 21:06:43,417 TADA INFO assertion 9, agg receives large string streams: Verify all streams were received correctly, passed
2022-10-27 21:06:43,417 __main__ INFO test ldmsd_stream_subscribe with small string streams
2022-10-27 21:06:49,529 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 21:08:45,330 __main__ INFO --- Verifying the received streams
2022-10-27 21:08:47,302 TADA INFO assertion 10, ldmsd_stream_subscribe receives small string streams: Verify all streams were received correctly, passed
2022-10-27 21:08:47,500 __main__ INFO test LDMSD with small string streams
2022-10-27 21:08:53,515 __main__ INFO --- Sending stream to samplerd
2022-10-27 21:10:54,432 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 21:10:55,614 TADA INFO assertion 11, samplerd receives small string streams: Verify all streams were received correctly, passed
2022-10-27 21:10:55,614 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 21:10:56,803 TADA INFO assertion 12, agg receives small string streams: Verify all streams were received correctly, passed
2022-10-27 21:10:56,804 TADA INFO test ldmsd_stream_test ended
2022-10-27 21:11:11 INFO: ----------------------------------------------
2022-10-27 21:11:12 INFO: ======== maestro_cfg_test ========
2022-10-27 21:11:12 INFO: CMD: python3 maestro_cfg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/maestro_cfg_test
2022-10-27 21:11:13,405 TADA INFO starting test `maestro_cfg_test`
2022-10-27 21:11:13,405 TADA INFO   test-id: 7862bdf37a48dddaa3059f00e758925d9ba2a7dc607d67bb37dfaa2e9399a168
2022-10-27 21:11:13,405 TADA INFO   test-suite: LDMSD
2022-10-27 21:11:13,405 TADA INFO   test-name: maestro_cfg_test
2022-10-27 21:11:13,405 TADA INFO   test-user: narate
2022-10-27 21:11:13,405 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:11:23,417 __main__ INFO -- Get or create cluster --
2022-10-27 21:11:49,368 __main__ INFO -- Start daemons --
2022-10-27 21:12:04,245 __main__ INFO ... make sure ldmsd's are up
2022-10-27 21:12:11,858 TADA INFO assertion 1, load maestro etcd cluster: etcd cluster loaded successfully, passed
2022-10-27 21:12:51,905 TADA INFO assertion 2, config ldmsd cluster with maestro: Maestro ldmsd configuration successful, passed
2022-10-27 21:12:53,468 TADA INFO assertion 3, verify sampler daemons: OK, passed
2022-10-27 21:12:54,074 TADA INFO assertion 4, verify L1 aggregator daemons: OK, passed
2022-10-27 21:12:54,317 TADA INFO assertion 5, verify L2 aggregator daemon: OK, passed
2022-10-27 21:12:54,618 TADA INFO assertion 6, verify data storage: OK, passed
---Wait for config to write to file---
2022-10-27 21:12:54,619 TADA INFO test maestro_cfg_test ended
2022-10-27 21:13:12 INFO: ----------------------------------------------
2022-10-27 21:13:13 INFO: ======== mt-slurm-test ========
2022-10-27 21:13:13 INFO: CMD: python3 mt-slurm-test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/mt-slurm-test
-- Get or create the cluster --
-- Start daemons --
... wait a bit to make sure ldmsd's are up
Every job in input data represented in output: : Passed
['# task_rank,timestamp', '0,1666923233.967266', '1,1666923233.967266', '2,1666923233.967266', '3,1666923233.967266', '4,1666923233.967266', '5,1666923233.967266', '6,1666923233.967266', '7,1666923233.967266', '8,1666923234.935983', '9,1666923235.933674', '10,1666923235.933674', '11,1666923235.933674', '12,1666923235.933674', '13,1666923235.933674', '14,1666923235.933674', '15,1666923236.979458', '16,1666923236.979458', '17,1666923236.979458', '18,1666923237.969300', '19,1666923237.969300', '20,1666923237.969300', '21,1666923237.969300', '22,1666923238.988869', '23,1666923238.988869', '24,1666923238.988869', '25,1666923238.988869', '26,1666923238.988869', '# Records 27/27.', '']
Job 10000 has 27 rank: : Passed
Job 10100 has 64 rank: : Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
Job 10000 has 3 nodes: node count 3 correct: Passed
Job 10100 has 4 nodes: node count 4 correct: Passed
2022-10-27 21:14:32 INFO: ----------------------------------------------
2022-10-27 21:14:33 INFO: ======== ovis_ev_test ========
2022-10-27 21:14:33 INFO: CMD: python3 ovis_ev_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ovis_ev_test
2022-10-27 21:14:34,267 __main__ INFO -- Create the cluster -- 
2022-10-27 21:14:43,611 TADA INFO starting test `ovis_ev_test`
2022-10-27 21:14:43,611 TADA INFO   test-id: 08b5d9bc54a916c6d07f01597b2d8e23509031ba4fae8b1ce3a96053d08703c5
2022-10-27 21:14:43,611 TADA INFO   test-suite: test_ovis_ev
2022-10-27 21:14:43,611 TADA INFO   test-name: ovis_ev_test
2022-10-27 21:14:43,611 TADA INFO   test-user: narate
2022-10-27 21:14:43,611 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:14:43,612 TADA INFO assertion 1, Test posting an event without timeout: ovis_ev delivered the expected event., passed
2022-10-27 21:14:43,612 TADA INFO assertion 2, Test posting an event with a current timeout: ovis_ev delivered the expected event., passed
2022-10-27 21:14:43,612 TADA INFO assertion 3, Test posting an event with a future timeout: ovis_ev delivered the expected event., passed
2022-10-27 21:14:43,613 TADA INFO assertion 4, Test reposting a posted event: ev_post returned EBUSY when posted an already posted event, passed
2022-10-27 21:14:43,613 TADA INFO assertion 5, Test canceling a posted event: ovis_ev delivered the expected event., passed
2022-10-27 21:14:43,613 TADA INFO assertion 6, Test rescheduling a posted event: ovis_ev delivered the expected event., passed
2022-10-27 21:14:43,613 TADA INFO assertion 7, Test event deliver order: The event delivery order was correct., passed
2022-10-27 21:14:43,613 TADA INFO assertion 8, Test flushing events: Expected status (1) == delivered status (1), passed
2022-10-27 21:14:43,613 TADA INFO assertion 9, Test posting event on a flushed worker: Expected status (0) == delivered status (0), passed
2022-10-27 21:14:43,614 TADA INFO assertion 10, Test the case that multiple threads post the same event: ev_post returned the expected return code., passed
2022-10-27 21:14:43,614 TADA INFO test ovis_ev_test ended
2022-10-27 21:14:54 INFO: ----------------------------------------------
2022-10-27 21:14:55 INFO: ======== prdcr_subscribe_test ========
2022-10-27 21:14:55 INFO: CMD: python3 prdcr_subscribe_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/prdcr_subscribe_test
2022-10-27 21:14:55,950 TADA INFO starting test `prdcr_subscribe_test`
2022-10-27 21:14:55,950 TADA INFO   test-id: c720db05b6cd9b85b13eab823f5b8d73cd8e4c56eb7027246c44f082f9e2184f
2022-10-27 21:14:55,950 TADA INFO   test-suite: LDMSD
2022-10-27 21:14:55,950 TADA INFO   test-name: prdcr_subscribe_test
2022-10-27 21:14:55,950 TADA INFO   test-user: narate
2022-10-27 21:14:55,950 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:15:31,465 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-27 21:15:31,466 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-27 21:15:31,466 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-27 21:15:31,466 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-27 21:15:31,466 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verification, passed
2022-10-27 21:15:31,817 TADA INFO assertion 5, Stopping the producers succeeds: , passed
2022-10-27 21:15:32,190 TADA INFO assertion 6, Restarting the producers succeeds: , passed
2022-10-27 21:15:40,190 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-27 21:15:40,191 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-27 21:15:40,191 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-27 21:15:40,191 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-27 21:15:40,192 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verification, passed
2022-10-27 21:15:41,402 TADA INFO assertion 12, stream-sampler-1 is not running: (running == False), passed
2022-10-27 21:15:42,984 TADA INFO assertion 13, stream-sampler-1 has restarted: (running == True), passed
2022-10-27 21:15:50,523 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-27 21:15:50,524 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-27 21:15:50,525 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verification, passed
2022-10-27 21:15:50,899 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: , passed
2022-10-27 21:15:54,225 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-27 21:16:00,006 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-27 21:16:00,007 TADA INFO test prdcr_subscribe_test ended
2022-10-27 21:16:12 INFO: ----------------------------------------------
2022-10-27 21:16:13 INFO: ======== set_array_test ========
2022-10-27 21:16:13 INFO: CMD: python3 set_array_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/set_array_test
2022-10-27 21:16:14,373 TADA INFO starting test `set_array_test`
2022-10-27 21:16:14,373 TADA INFO   test-id: 18cfb800980858a6f76aa0fade71fcb17c9e64dbf30e527415a4cf940109c69d
2022-10-27 21:16:14,374 TADA INFO   test-suite: LDMSD
2022-10-27 21:16:14,374 TADA INFO   test-name: set_array_test
2022-10-27 21:16:14,374 TADA INFO   test-user: narate
2022-10-27 21:16:14,374 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:16:14,374 __main__ INFO -- Get or create the cluster --
2022-10-27 21:16:19,633 __main__ INFO -- Start daemons --
2022-10-27 21:16:21,618 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:16:50,536 TADA INFO assertion 1, 1st update got some callbacks: verified hunk of 10 snapshots, passed
2022-10-27 21:16:50,537 TADA INFO assertion 2, 2nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-27 21:16:50,537 TADA INFO assertion 3, 3nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-27 21:16:50,537 TADA INFO test set_array_test ended
2022-10-27 21:17:01 INFO: ----------------------------------------------
2022-10-27 21:17:02 INFO: ======== setgroup_test ========
2022-10-27 21:17:02 INFO: CMD: python3 setgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/setgroup_test
2022-10-27 21:17:03,522 TADA INFO starting test `setgroup_test`
2022-10-27 21:17:03,523 TADA INFO   test-id: bdc000eab71e3087b7c5999a6d5d4fda6323dc30e99d00ec574f1884856b35f3
2022-10-27 21:17:03,523 TADA INFO   test-suite: LDMSD
2022-10-27 21:17:03,523 TADA INFO   test-name: setgroup_test
2022-10-27 21:17:03,523 TADA INFO   test-user: narate
2022-10-27 21:17:03,523 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:17:03,524 __main__ INFO -- Get or create the cluster --
2022-10-27 21:17:12,761 __main__ INFO -- Start daemons --
2022-10-27 21:17:17,199 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:17:22,201 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 21:17:22,339 TADA INFO assertion 1, ldms_ls grp on agg-2: dir result verified, passed
2022-10-27 21:17:24,589 TADA INFO assertion 2, members on agg-2 are being updated: data verified, passed
2022-10-27 21:17:24,589 __main__ INFO -- Removing test_2 from grp --
2022-10-27 21:17:25,066 TADA INFO assertion 3, test_2 is removed fom grp on sampler: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 21:17:29,195 TADA INFO assertion 4, test_2 is removed from grp on agg-1: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 21:17:33,329 TADA INFO assertion 5, test_2 is removed from grp on agg-2: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 21:17:37,333 __main__ INFO -- Adding test_2 back into grp --
2022-10-27 21:17:37,812 TADA INFO assertion 6, test_2 is added back to grp on sampler: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 21:17:41,934 TADA INFO assertion 7, test_2 is added back to grp on agg-1: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 21:17:44,053 TADA INFO assertion 8, test_2 is added back to grp on agg-2: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 21:17:46,056 TADA INFO test setgroup_test ended
2022-10-27 21:17:58 INFO: ----------------------------------------------
2022-10-27 21:17:59 INFO: ======== slurm_stream_test ========
2022-10-27 21:17:59 INFO: CMD: python3 slurm_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/slurm_stream_test
2022-10-27 21:18:00,202 TADA INFO starting test `slurm_stream_test`
2022-10-27 21:18:00,202 TADA INFO   test-id: ce2993c7997197db76f98be2ae7b176e1b92203e17683e7fc7bba272fb3d9eec
2022-10-27 21:18:00,202 TADA INFO   test-suite: LDMSD
2022-10-27 21:18:00,202 TADA INFO   test-name: slurm_stream_test
2022-10-27 21:18:00,203 TADA INFO   test-user: narate
2022-10-27 21:18:00,203 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:18:00,203 __main__ INFO -- Get or create the cluster --
2022-10-27 21:18:07,071 __main__ INFO -- Start daemons --
2022-10-27 21:18:09,680 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:18:39,619 TADA INFO assertion 1, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:39,619 __main__ INFO 12345
2022-10-27 21:18:39,620 __main__ INFO 12345
2022-10-27 21:18:39,620 TADA INFO assertion 2, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,620 TADA INFO assertion 3, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-27 21:18:39,620 TADA INFO assertion 4, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,620 TADA INFO assertion 5, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,620 TADA INFO assertion 6, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,620 TADA INFO assertion 7, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,728 TADA INFO assertion 8, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:39,728 __main__ INFO 12345
2022-10-27 21:18:39,728 __main__ INFO 12345
2022-10-27 21:18:39,728 TADA INFO assertion 9, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,728 TADA INFO assertion 10, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-27 21:18:39,728 TADA INFO assertion 11, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,729 TADA INFO assertion 12, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,729 TADA INFO assertion 13, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,729 TADA INFO assertion 14, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 21:18:39,859 TADA INFO assertion 15, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:39,859 __main__ INFO 12346
2022-10-27 21:18:39,859 __main__ INFO 12346
2022-10-27 21:18:39,859 TADA INFO assertion 16, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,859 TADA INFO assertion 17, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-27 21:18:39,860 TADA INFO assertion 18, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,860 TADA INFO assertion 19, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,860 TADA INFO assertion 20, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,860 TADA INFO assertion 21, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,972 TADA INFO assertion 22, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:39,972 __main__ INFO 12346
2022-10-27 21:18:39,972 __main__ INFO 12346
2022-10-27 21:18:39,972 TADA INFO assertion 23, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,972 TADA INFO assertion 24, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-27 21:18:39,972 TADA INFO assertion 25, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,972 TADA INFO assertion 26, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,973 TADA INFO assertion 27, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 21:18:39,973 TADA INFO assertion 28, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 21:18:40,089 TADA INFO assertion 29, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:40,089 __main__ INFO 12347
2022-10-27 21:18:40,089 __main__ INFO 12347
2022-10-27 21:18:40,089 TADA INFO assertion 30, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,090 TADA INFO assertion 31, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-27 21:18:40,090 TADA INFO assertion 32, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,090 TADA INFO assertion 33, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,090 TADA INFO assertion 34, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,090 TADA INFO assertion 35, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,197 TADA INFO assertion 36, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:40,197 __main__ INFO 12347
2022-10-27 21:18:40,197 __main__ INFO 12347
2022-10-27 21:18:40,197 TADA INFO assertion 37, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,197 TADA INFO assertion 38, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-27 21:18:40,197 TADA INFO assertion 39, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,198 TADA INFO assertion 40, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,198 TADA INFO assertion 41, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,198 TADA INFO assertion 42, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 21:18:40,318 TADA INFO assertion 43, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:40,318 __main__ INFO 12348
2022-10-27 21:18:40,318 __main__ INFO 12348
2022-10-27 21:18:40,318 TADA INFO assertion 44, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,319 TADA INFO assertion 45, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-27 21:18:40,319 TADA INFO assertion 46, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,319 TADA INFO assertion 47, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,319 TADA INFO assertion 48, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,319 TADA INFO assertion 49, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,425 TADA INFO assertion 50, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:40,425 __main__ INFO 12348
2022-10-27 21:18:40,426 __main__ INFO 12348
2022-10-27 21:18:40,426 TADA INFO assertion 51, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,426 TADA INFO assertion 52, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-27 21:18:40,426 TADA INFO assertion 53, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,426 TADA INFO assertion 54, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,426 TADA INFO assertion 55, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,427 TADA INFO assertion 56, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 21:18:40,543 TADA INFO assertion 57, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:40,543 __main__ INFO 12355
2022-10-27 21:18:40,543 __main__ INFO 12355
2022-10-27 21:18:40,543 TADA INFO assertion 58, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,543 TADA INFO assertion 59, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-27 21:18:40,544 TADA INFO assertion 60, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,544 TADA INFO assertion 61, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,544 TADA INFO assertion 62, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,545 TADA INFO assertion 63, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,545 TADA INFO assertion 64, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,545 TADA INFO assertion 65, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,545 TADA INFO assertion 66, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,545 TADA INFO assertion 67, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,658 TADA INFO assertion 68, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:40,658 __main__ INFO 12355
2022-10-27 21:18:40,658 __main__ INFO 12355
2022-10-27 21:18:40,658 TADA INFO assertion 69, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,659 TADA INFO assertion 70, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-27 21:18:40,659 TADA INFO assertion 71, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,659 TADA INFO assertion 72, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,659 TADA INFO assertion 73, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,659 TADA INFO assertion 74, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,659 TADA INFO assertion 75, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,660 TADA INFO assertion 76, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,660 TADA INFO assertion 77, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,660 TADA INFO assertion 78, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 21:18:40,768 TADA INFO assertion 79, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:40,768 __main__ INFO 12356
2022-10-27 21:18:40,768 __main__ INFO 12356
2022-10-27 21:18:40,768 TADA INFO assertion 80, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,769 TADA INFO assertion 81, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-27 21:18:40,769 TADA INFO assertion 82, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,769 TADA INFO assertion 83, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,769 TADA INFO assertion 84, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,769 TADA INFO assertion 85, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,769 TADA INFO assertion 86, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,770 TADA INFO assertion 87, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,770 TADA INFO assertion 88, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,770 TADA INFO assertion 89, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,908 TADA INFO assertion 90, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:40,909 __main__ INFO 12356
2022-10-27 21:18:40,909 __main__ INFO 12356
2022-10-27 21:18:40,909 TADA INFO assertion 91, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,909 TADA INFO assertion 92, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-27 21:18:40,910 TADA INFO assertion 93, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,910 TADA INFO assertion 94, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,910 TADA INFO assertion 95, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,910 TADA INFO assertion 96, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,910 TADA INFO assertion 97, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,910 TADA INFO assertion 98, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,911 TADA INFO assertion 99, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:40,911 TADA INFO assertion 100, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 21:18:41,029 TADA INFO assertion 101, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:41,029 __main__ INFO 12357
2022-10-27 21:18:41,029 __main__ INFO 12357
2022-10-27 21:18:41,029 TADA INFO assertion 102, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,030 TADA INFO assertion 103, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-27 21:18:41,030 TADA INFO assertion 104, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,030 TADA INFO assertion 105, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,030 TADA INFO assertion 106, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,030 TADA INFO assertion 107, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,030 TADA INFO assertion 108, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,031 TADA INFO assertion 109, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,031 TADA INFO assertion 110, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,031 TADA INFO assertion 111, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,158 TADA INFO assertion 112, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:41,158 __main__ INFO 12357
2022-10-27 21:18:41,159 __main__ INFO 12357
2022-10-27 21:18:41,159 TADA INFO assertion 113, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,159 TADA INFO assertion 114, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-27 21:18:41,160 TADA INFO assertion 115, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,160 TADA INFO assertion 116, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,160 TADA INFO assertion 117, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,160 TADA INFO assertion 118, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,160 TADA INFO assertion 119, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,160 TADA INFO assertion 120, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,161 TADA INFO assertion 121, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,161 TADA INFO assertion 122, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 21:18:41,265 TADA INFO assertion 123, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:41,266 __main__ INFO 12358
2022-10-27 21:18:41,266 __main__ INFO 12358
2022-10-27 21:18:41,266 TADA INFO assertion 124, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,266 TADA INFO assertion 125, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-27 21:18:41,266 TADA INFO assertion 126, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,266 TADA INFO assertion 127, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,266 TADA INFO assertion 128, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,267 TADA INFO assertion 129, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,267 TADA INFO assertion 130, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,267 TADA INFO assertion 131, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,267 TADA INFO assertion 132, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,267 TADA INFO assertion 133, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,373 TADA INFO assertion 134, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 21:18:41,373 __main__ INFO 12358
2022-10-27 21:18:41,373 __main__ INFO 12358
2022-10-27 21:18:41,373 TADA INFO assertion 135, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,374 TADA INFO assertion 136, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-27 21:18:41,374 TADA INFO assertion 137, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,374 TADA INFO assertion 138, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,374 TADA INFO assertion 139, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,374 TADA INFO assertion 140, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,374 TADA INFO assertion 141, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,375 TADA INFO assertion 142, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,375 TADA INFO assertion 143, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:41,375 TADA INFO assertion 144, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 21:18:43,451 TADA INFO assertion 145, new job correctly replaces oldest slot: correct job_id fills next slot, passed
2022-10-27 21:18:43,451 __main__ INFO 12353
2022-10-27 21:18:43,452 __main__ INFO 12353
2022-10-27 21:18:43,452 TADA INFO assertion 146, new job_start correctly represented in metric set: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,452 TADA INFO assertion 147, new job_end correctly represented in metric set: with mutl jobs running, for Job 12353, passed
2022-10-27 21:18:43,452 TADA INFO assertion 148, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,452 TADA INFO assertion 149, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,452 TADA INFO assertion 150, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,452 TADA INFO assertion 151, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,453 TADA INFO assertion 152, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,453 TADA INFO assertion 153, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,453 TADA INFO assertion 154, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,453 TADA INFO assertion 155, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 21:18:43,453 __main__ INFO -- Test Finished --
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
2022-10-27 21:18:43,454 TADA INFO test slurm_stream_test ended
2022-10-27 21:18:54 INFO: ----------------------------------------------
2022-10-27 21:18:55 INFO: ======== spank_notifier_test ========
2022-10-27 21:18:55 INFO: CMD: python3 spank_notifier_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/spank_notifier_test
2022-10-27 21:18:56,430 TADA INFO starting test `spank_notifier_test`
2022-10-27 21:18:56,430 TADA INFO   test-id: 596b45bc4da3b96c35390041080b9cd2aa40de4aea549a72c7c672084979d075
2022-10-27 21:18:56,430 TADA INFO   test-suite: Slurm_Plugins
2022-10-27 21:18:56,430 TADA INFO   test-name: spank_notifier_test
2022-10-27 21:18:56,430 TADA INFO   test-user: narate
2022-10-27 21:18:56,431 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:18:56,431 __main__ INFO -- Create the cluster --
2022-10-27 21:19:21,926 __main__ INFO -- Cleanup output --
2022-10-27 21:19:22,267 __main__ INFO -- Test bad plugstack config --
2022-10-27 21:19:22,267 __main__ INFO Starting slurm ...
2022-10-27 21:19:36,706 __main__ INFO Starting slurm ... OK
2022-10-27 21:19:57,191 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 21:19:57,314 __main__ INFO   jobid = 1
2022-10-27 21:19:57,510 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 21:19:57,621 __main__ INFO   jobid = 2
2022-10-27 21:19:57,823 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 21:19:57,929 __main__ INFO   jobid = 3
2022-10-27 21:19:58,160 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 21:19:58,295 __main__ INFO   jobid = 4
2022-10-27 21:20:07,927 TADA INFO assertion 60, Bad config does not affect jobs: jobs verified, passed
2022-10-27 21:20:07,927 __main__ INFO Killin slurm ...
2022-10-27 21:20:10,883 __main__ INFO Killin slurm ... OK
2022-10-27 21:20:30,897 __main__ INFO -- Start daemons --
2022-10-27 21:20:41,818 __main__ INFO Starting slurm ... OK
2022-10-27 21:21:02,082 __main__ INFO -- Submitting job with no stream listener --
2022-10-27 21:21:02,286 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-27 21:21:02,396 __main__ INFO   jobid = 5
2022-10-27 21:21:18,379 TADA INFO assertion 0, Missing stream listener on node-1 does not affect job execution: job output file created, passed
2022-10-27 21:21:18,380 TADA INFO assertion 1, Missing stream listener on node-2 does not affect job execution: job output file created, passed
2022-10-27 21:21:24,287 __main__ INFO -- Submitting job with listener --
2022-10-27 21:21:24,481 __main__ INFO -- Submitting job with num_tasks 1 --
2022-10-27 21:21:24,589 __main__ INFO   jobid = 6
2022-10-27 21:21:24,793 __main__ INFO -- Submitting job with num_tasks 2 --
2022-10-27 21:21:24,907 __main__ INFO   jobid = 7
2022-10-27 21:21:25,121 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 21:21:25,244 __main__ INFO   jobid = 8
2022-10-27 21:21:25,451 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-27 21:21:25,567 __main__ INFO   jobid = 9
2022-10-27 21:21:25,791 __main__ INFO -- Submitting job with num_tasks 27 --
2022-10-27 21:21:25,902 __main__ INFO   jobid = 10
2022-10-27 21:21:47,635 __main__ INFO -- Verifying Events --
2022-10-27 21:21:47,636 TADA INFO assertion 2, 1-task job: first event is 'init': step_init == init, failed
Traceback (most recent call last):
  File "spank_notifier_test", line 492, in <module>
    verify_jobinfo(cluster, test, node_events, jobinfo)
  File "spank_notifier_test", line 154, in verify_jobinfo
    test.assert_test(assert_no, False, '{0} == {1}'.format(ev['event'], 'init'))
  File "/home/narate/cron/ldms-test/TADA.py", line 157, in assert_test
    raise AssertionException(self.test_desc + ", " + cond_str + ": FAILED")
TADA.AssertionException: The test to verify ldmsd-stream SPANK notifier., step_init == init: FAILED
2022-10-27 21:21:47,637 TADA INFO assertion 3, 1-task job: 'step_init' event contains subscriber data: skipped
2022-10-27 21:21:47,637 TADA INFO assertion 4, 1-task job: second event is 'task_init_priv': skipped
2022-10-27 21:21:47,637 TADA INFO assertion 5, 1-task job: third event is 'task_exit': skipped
2022-10-27 21:21:47,637 TADA INFO assertion 6, 1-task job: fourth event is 'exit': skipped
2022-10-27 21:21:47,638 TADA INFO assertion 7, 2-task job: first event is 'init': skipped
2022-10-27 21:21:47,638 TADA INFO assertion 8, 2-task job: 'step_init' event contains subscriber data: skipped
2022-10-27 21:21:47,638 TADA INFO assertion 9, 2-task job: second event is 'task_init_priv': skipped
2022-10-27 21:21:47,638 TADA INFO assertion 10, 2-task job: third event is 'task_exit': skipped
2022-10-27 21:21:47,638 TADA INFO assertion 11, 2-task job: fourth event is 'exit': skipped
2022-10-27 21:21:47,638 TADA INFO assertion 12, 4-task job: first event is 'init': skipped
2022-10-27 21:21:47,638 TADA INFO assertion 13, 4-task job: 'step_init' event contains subscriber data: skipped
2022-10-27 21:21:47,639 TADA INFO assertion 14, 4-task job: second event is 'task_init_priv': skipped
2022-10-27 21:21:47,639 TADA INFO assertion 15, 4-task job: third event is 'task_exit': skipped
2022-10-27 21:21:47,639 TADA INFO assertion 16, 4-task job: fourth event is 'exit': skipped
2022-10-27 21:21:47,639 TADA INFO assertion 17, 8-task job: first event is 'init': skipped
2022-10-27 21:21:47,639 TADA INFO assertion 18, 8-task job: 'step_init' event contains subscriber data: skipped
2022-10-27 21:21:47,639 TADA INFO assertion 19, 8-task job: second event is 'task_init_priv': skipped
2022-10-27 21:21:47,639 TADA INFO assertion 20, 8-task job: third event is 'task_exit': skipped
2022-10-27 21:21:47,640 TADA INFO assertion 21, 8-task job: fourth event is 'exit': skipped
2022-10-27 21:21:47,640 TADA INFO assertion 22, 27-task job: first event is 'init': skipped
2022-10-27 21:21:47,640 TADA INFO assertion 23, 27-task job: 'step_init' event contains subscriber data: skipped
2022-10-27 21:21:47,640 TADA INFO assertion 24, 27-task job: second event is 'task_init_priv': skipped
2022-10-27 21:21:47,640 TADA INFO assertion 25, 27-task job: third event is 'task_exit': skipped
2022-10-27 21:21:47,640 TADA INFO assertion 26, 27-task job: fourth event is 'exit': skipped
2022-10-27 21:21:47,640 TADA INFO assertion 50, Multi-tenant verification: skipped
2022-10-27 21:21:47,641 TADA INFO assertion 51, Killing stream listener does not affect job execution on node-1: skipped
2022-10-27 21:21:47,641 TADA INFO assertion 52, Killing stream listener does not affect job execution on node-2: skipped
2022-10-27 21:21:47,641 TADA INFO test spank_notifier_test ended
2022-10-27 21:22:04 INFO: ----------------------------------------------
2022-10-27 21:22:05 INFO: ======== ldms_list_test ========
2022-10-27 21:22:05 INFO: CMD: python3 ldms_list_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldms_list_test
2022-10-27 21:22:05,815 TADA INFO starting test `ldms_list_test`
2022-10-27 21:22:05,815 TADA INFO   test-id: 522c612d17c01ade8633a4baac6dea595d9efeb327cf5f4655820fade2b34a31
2022-10-27 21:22:05,815 TADA INFO   test-suite: LDMSD
2022-10-27 21:22:05,815 TADA INFO   test-name: ldms_list_test
2022-10-27 21:22:05,815 TADA INFO   test-user: narate
2022-10-27 21:22:05,815 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:22:05,816 __main__ INFO -- Get or create the cluster --
2022-10-27 21:22:08,911 __main__ INFO -- Start daemons --
2022-10-27 21:22:15,257 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:22:17,259 __main__ INFO start list_samp.py and list_agg.py interactive sessions
2022-10-27 21:22:23,295 TADA INFO assertion 1, check list_sampler on list_agg.py: OK, passed
2022-10-27 21:22:23,295 TADA INFO assertion 2, (1st update) check set1 on list_samp.py: OK, passed
2022-10-27 21:22:23,296 TADA INFO assertion 3, (1st update) check set3_p on list_samp.py: OK, passed
2022-10-27 21:22:23,296 TADA INFO assertion 4, (1st update)check set3_c on list_samp.py: OK, passed
2022-10-27 21:22:23,296 TADA INFO assertion 5, (1st update)check set1 on list_agg.py: OK, passed
2022-10-27 21:22:23,296 TADA INFO assertion 6, (1st update)check set3_p on list_agg.py: OK, passed
2022-10-27 21:22:23,297 TADA INFO assertion 7, (1st update)check set3_c on list_agg.py: OK, passed
2022-10-27 21:22:23,297 __main__ INFO 2nd sampling on the sampler...
2022-10-27 21:22:30,506 TADA INFO assertion 8, (2nd update) check set1 on list_samp.py: OK, passed
2022-10-27 21:22:30,507 TADA INFO assertion 9, (2nd update) check set3_p on list_samp.py: OK, passed
2022-10-27 21:22:30,507 TADA INFO assertion 10, (2nd update) check set3_c on list_samp.py: OK, passed
2022-10-27 21:22:30,507 __main__ INFO 2nd update on the aggregator...
2022-10-27 21:22:37,717 TADA INFO assertion 11, (2nd update) check set1 on list_agg.py: OK, passed
2022-10-27 21:22:37,717 TADA INFO assertion 12, (2nd update) check set3_p on list_agg.py: OK, passed
2022-10-27 21:22:37,717 TADA INFO assertion 13, (2nd update) check set3_c on list_agg.py: OK, passed
2022-10-27 21:22:37,718 __main__ INFO 3rd sampling on the sampler...
2022-10-27 21:22:44,927 TADA INFO assertion 14, (3rd update) check set1 on list_samp.py: OK, passed
2022-10-27 21:22:44,927 TADA INFO assertion 15, (3rd update) check set3_p on list_samp.py: OK, passed
2022-10-27 21:22:44,927 TADA INFO assertion 16, (3rd update) check set3_c on list_samp.py: OK, passed
2022-10-27 21:22:44,928 __main__ INFO 3rd update on the aggregator...
2022-10-27 21:22:52,137 TADA INFO assertion 17, (3rd update) check set1 on list_agg.py: OK, passed
2022-10-27 21:22:52,137 TADA INFO assertion 18, (3rd update) check set3_p on list_agg.py: OK, passed
2022-10-27 21:22:52,138 TADA INFO assertion 19, (3rd update) check set3_c on list_agg.py: OK, passed
2022-10-27 21:22:52,138 __main__ INFO 4th sampling on the sampler...
2022-10-27 21:22:59,347 TADA INFO assertion 20, (4th update; list uncahnged) check set1 on list_samp.py: OK, passed
2022-10-27 21:22:59,348 TADA INFO assertion 21, (4th update; list uncahnged) check set3_p on list_samp.py: OK, passed
2022-10-27 21:22:59,348 TADA INFO assertion 22, (4th update; list uncahnged) check set3_c on list_samp.py: OK, passed
2022-10-27 21:22:59,348 __main__ INFO 4th update on the aggregator...
2022-10-27 21:23:06,557 TADA INFO assertion 23, (4th update; list uncahnged) check set1 on list_agg.py: OK, passed
2022-10-27 21:23:06,558 TADA INFO assertion 24, (4th update; list uncahnged) check set3_p on list_agg.py: OK, passed
2022-10-27 21:23:06,558 TADA INFO assertion 25, (4th update; list uncahnged) check set3_c on list_agg.py: OK, passed
2022-10-27 21:23:06,558 __main__ INFO 5th sampling on the sampler...
2022-10-27 21:23:13,768 TADA INFO assertion 26, (5th update; list del) check set1 on list_samp.py: OK, passed
2022-10-27 21:23:13,768 TADA INFO assertion 27, (5th update; list del) check set3_p on list_samp.py: OK, passed
2022-10-27 21:23:13,768 TADA INFO assertion 28, (5th update; list del) check set3_c on list_samp.py: OK, passed
2022-10-27 21:23:13,768 __main__ INFO 5th update on the aggregator...
2022-10-27 21:23:20,978 TADA INFO assertion 29, (5th update; list del) check set1 on list_agg.py: OK, passed
2022-10-27 21:23:20,978 TADA INFO assertion 30, (5th update; list del) check set3_p on list_agg.py: OK, passed
2022-10-27 21:23:20,978 TADA INFO assertion 31, (5th update; list del) check set3_c on list_agg.py: OK, passed
2022-10-27 21:23:20,979 __main__ INFO 6th sampling on the sampler...
2022-10-27 21:23:28,187 TADA INFO assertion 32, (6th update; list unchanged) check set1 on list_samp.py: OK, passed
2022-10-27 21:23:28,187 TADA INFO assertion 33, (6th update; list unchanged) check set3_p on list_samp.py: OK, passed
2022-10-27 21:23:28,188 TADA INFO assertion 34, (6th update; list unchanged) check set3_c on list_samp.py: OK, passed
2022-10-27 21:23:28,188 __main__ INFO 6th update on the updator...
2022-10-27 21:23:35,397 TADA INFO assertion 35, (6th update; list unchanged) check set1 on list_agg.py: OK, passed
2022-10-27 21:23:35,398 TADA INFO assertion 36, (6th update; list unchanged) check set3_p on list_agg.py: OK, passed
2022-10-27 21:23:35,398 TADA INFO assertion 37, (6th update; list unchanged) check set3_c on list_agg.py: OK, passed
2022-10-27 21:23:35,398 TADA INFO test ldms_list_test ended
2022-10-27 21:23:46 INFO: ----------------------------------------------
2022-10-27 21:23:46 INFO: ======== quick_set_add_rm_test ========
2022-10-27 21:23:46 INFO: CMD: python3 quick_set_add_rm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/quick_set_add_rm_test
2022-10-27 21:23:47,678 TADA INFO starting test `quick_set_add_rm_test`
2022-10-27 21:23:47,678 TADA INFO   test-id: 429eb03c295b3d1948051721dc69d7bc6c2026fea0843137ce2f19bc3021843c
2022-10-27 21:23:47,678 TADA INFO   test-suite: LDMSD
2022-10-27 21:23:47,679 TADA INFO   test-name: quick_set_add_rm_test
2022-10-27 21:23:47,679 TADA INFO   test-user: narate
2022-10-27 21:23:47,679 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:23:47,679 __main__ INFO -- Get or create the cluster --
2022-10-27 21:23:54,832 __main__ INFO -- Start samp.py --
2022-10-27 21:23:59,948 TADA INFO assertion 1, start samp.py: prompt checked, passed
2022-10-27 21:23:59,948 __main__ INFO -- Start daemons --
2022-10-27 21:24:07,529 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:24:13,107 TADA INFO assertion 2, verify data: verified, passed
2022-10-27 21:24:17,699 TADA INFO assertion 3, samp.py adds set1 / verify data: verified, passed
2022-10-27 21:24:22,290 TADA INFO assertion 4, samp.py removes set1 / verify data: verified, passed
2022-10-27 21:24:26,882 TADA INFO assertion 5, samp.py quickly adds and removes set2 / verify data: verified, passed
2022-10-27 21:24:32,010 TADA INFO assertion 6, agg-1 log stays empty: verified, passed
2022-10-27 21:24:32,010 TADA INFO test quick_set_add_rm_test ended
2022-10-27 21:24:44 INFO: ----------------------------------------------
2022-10-27 21:24:45 INFO: ======== set_array_hang_test ========
2022-10-27 21:24:45 INFO: CMD: python3 set_array_hang_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/set_array_hang_test
2022-10-27 21:24:45,804 TADA INFO starting test `set_array_hang_test`
2022-10-27 21:24:45,804 TADA INFO   test-id: 968179d03a958fe4f1b4d0c957920dff40b8eba42a5417cfabcebf4228930801
2022-10-27 21:24:45,804 TADA INFO   test-suite: LDMSD
2022-10-27 21:24:45,804 TADA INFO   test-name: set_array_hang_test
2022-10-27 21:24:45,804 TADA INFO   test-user: narate
2022-10-27 21:24:45,804 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:24:45,805 __main__ INFO -- Get or create the cluster --
2022-10-27 21:24:48,865 __main__ INFO -- Start processes --
2022-10-27 21:24:48,865 __main__ INFO starting interactive set_array_samp.py
2022-10-27 21:24:51,879 TADA INFO assertion 1, start set_array_samp.py: data verified, passed
2022-10-27 21:24:54,896 TADA INFO assertion 2, start set_array_agg.py: data verified, passed
2022-10-27 21:25:02,105 TADA INFO assertion 3, agg update before the 1st sample: data verified, passed
2022-10-27 21:25:09,314 TADA INFO assertion 4, sampling 2 times then agg update: data verified, passed
2022-10-27 21:25:12,919 TADA INFO assertion 5, agg update w/o new sampling: data verified, passed
2022-10-27 21:25:20,127 TADA INFO assertion 6, sampling 5 times then agg update: data verified, passed
2022-10-27 21:25:20,128 TADA INFO test set_array_hang_test ended
2022-10-27 21:25:30 INFO: ----------------------------------------------
2022-10-27 21:25:31 INFO: ======== ldmsd_autointerval_test ========
2022-10-27 21:25:31 INFO: CMD: python3 ldmsd_autointerval_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldmsd_autointerval_test
2022-10-27 21:25:32,395 TADA INFO starting test `ldmsd_autointerval_test`
2022-10-27 21:25:32,396 TADA INFO   test-id: 889595027664422a444ea506bf7f7c54a16d8af21ea7c4b4c2c03e344e918a01
2022-10-27 21:25:32,396 TADA INFO   test-suite: LDMSD
2022-10-27 21:25:32,396 TADA INFO   test-name: ldmsd_autointerval_test
2022-10-27 21:25:32,396 TADA INFO   test-user: narate
2022-10-27 21:25:32,396 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:25:32,397 __main__ INFO -- Get or create the cluster --
2022-10-27 21:25:39,857 __main__ INFO -- Start daemons --
2022-10-27 21:25:43,612 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:25:50,132 TADA INFO assertion 1, start all daemons and interactive controller: OK, passed
2022-10-27 21:25:52,346 TADA INFO assertion 2, verify sampling interval and update hints: verified, passed
2022-10-27 21:25:52,347 __main__ INFO Let them run for a while to collect data ...
2022-10-27 21:26:02,352 __main__ INFO Setting sample interval to 1000000 ...
2022-10-27 21:26:10,630 TADA INFO assertion 3, set and verify 2nd sampling interval / update hints: verified, passed
2022-10-27 21:26:10,631 __main__ INFO Let them run for a while to collect data ...
2022-10-27 21:26:20,641 __main__ INFO Setting sample interval to 2000000 ...
2022-10-27 21:26:28,877 TADA INFO assertion 4, set and verify 3rd sampling interval / update hints: verified, passed
2022-10-27 21:26:28,877 __main__ INFO Let them run for a while to collect data ...
2022-10-27 21:26:39,120 TADA INFO assertion 5, verify SOS data: timestamp differences in SOS show all 3 intervals, passed
2022-10-27 21:26:39,237 TADA INFO assertion 6, verify 'oversampled' in the agg2 log: OK, passed
2022-10-27 21:26:39,237 TADA INFO test ldmsd_autointerval_test ended
2022-10-27 21:26:51 INFO: ----------------------------------------------
2022-10-27 21:26:52 INFO: ======== ldms_record_test ========
2022-10-27 21:26:52 INFO: CMD: python3 ldms_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldms_record_test
2022-10-27 21:26:52,863 TADA INFO starting test `ldms_record_test`
2022-10-27 21:26:52,864 TADA INFO   test-id: 5e33c2838d257777da57128a318f898925a021633e7d4f42c11b02774f18819d
2022-10-27 21:26:52,864 TADA INFO   test-suite: LDMSD
2022-10-27 21:26:52,864 TADA INFO   test-name: ldms_record_test
2022-10-27 21:26:52,864 TADA INFO   test-user: narate
2022-10-27 21:26:52,864 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:26:52,865 __main__ INFO -- Get or create the cluster --
2022-10-27 21:26:55,992 __main__ INFO -- Start daemons --
2022-10-27 21:27:02,334 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:27:04,336 __main__ INFO start record_samp.py and record_agg.py interactive sessions
2022-10-27 21:27:10,375 TADA INFO assertion 1, check record_sampler on record_agg.py: OK, passed
2022-10-27 21:27:10,376 TADA INFO assertion 2, (1st update) check set1 on record_samp.py: OK, passed
2022-10-27 21:27:10,376 TADA INFO assertion 3, (1st update) check set3_p on record_samp.py: OK, passed
2022-10-27 21:27:10,376 TADA INFO assertion 4, (1st update) check set3_c on record_samp.py: OK, passed
2022-10-27 21:27:10,376 TADA INFO assertion 5, (1st update) check set1 on record_agg.py: OK, passed
2022-10-27 21:27:10,377 TADA INFO assertion 6, (1st update) check set3_p on record_agg.py: OK, passed
2022-10-27 21:27:10,377 TADA INFO assertion 7, (1st update) check set3_c on record_agg.py: OK, passed
2022-10-27 21:27:10,377 __main__ INFO 2nd sampling on the sampler...
2022-10-27 21:27:17,587 TADA INFO assertion 8, (2nd update) check set1 on record_samp.py: OK, passed
2022-10-27 21:27:17,587 TADA INFO assertion 9, (2nd update) check set3_p on record_samp.py: OK, passed
2022-10-27 21:27:17,587 TADA INFO assertion 10, (2nd update) check set3_c on record_samp.py: OK, passed
2022-10-27 21:27:17,587 __main__ INFO 2nd update on the aggregator...
2022-10-27 21:27:24,797 TADA INFO assertion 11, (2nd update) check set1 on record_agg.py: OK, passed
2022-10-27 21:27:24,797 TADA INFO assertion 12, (2nd update) check set3_p on record_agg.py: OK, passed
2022-10-27 21:27:24,797 TADA INFO assertion 13, (2nd update) check set3_c on record_agg.py: OK, passed
2022-10-27 21:27:24,797 __main__ INFO 3rd sampling on the sampler...
2022-10-27 21:27:32,007 TADA INFO assertion 14, (3rd update) check set1 on record_samp.py: OK, passed
2022-10-27 21:27:32,007 TADA INFO assertion 15, (3rd update) check set3_p on record_samp.py: OK, passed
2022-10-27 21:27:32,008 TADA INFO assertion 16, (3rd update) check set3_c on record_samp.py: OK, passed
2022-10-27 21:27:32,008 __main__ INFO 3rd update on the aggregator...
2022-10-27 21:27:39,217 TADA INFO assertion 17, (3rd update) check set1 on record_agg.py: OK, passed
2022-10-27 21:27:39,217 TADA INFO assertion 18, (3rd update) check set3_p on record_agg.py: OK, passed
2022-10-27 21:27:39,218 TADA INFO assertion 19, (3rd update) check set3_c on record_agg.py: OK, passed
2022-10-27 21:27:39,218 __main__ INFO 4th sampling on the sampler...
2022-10-27 21:27:46,427 TADA INFO assertion 20, (4th update; record uncahnged) check set1 on record_samp.py: OK, passed
2022-10-27 21:27:46,428 TADA INFO assertion 21, (4th update; record uncahnged) check set3_p on record_samp.py: OK, passed
2022-10-27 21:27:46,428 TADA INFO assertion 22, (4th update; record uncahnged) check set3_c on record_samp.py: OK, passed
2022-10-27 21:27:46,428 __main__ INFO 4th update on the aggregator...
2022-10-27 21:27:53,637 TADA INFO assertion 23, (4th update; record uncahnged) check set1 on record_agg.py: OK, passed
2022-10-27 21:27:53,638 TADA INFO assertion 24, (4th update; record uncahnged) check set3_p on record_agg.py: OK, passed
2022-10-27 21:27:53,638 TADA INFO assertion 25, (4th update; record uncahnged) check set3_c on record_agg.py: OK, passed
2022-10-27 21:27:53,638 __main__ INFO 5th sampling on the sampler...
2022-10-27 21:28:00,848 TADA INFO assertion 26, (5th update; record del) check set1 on record_samp.py: OK, passed
2022-10-27 21:28:00,848 TADA INFO assertion 27, (5th update; record del) check set3_p on record_samp.py: OK, passed
2022-10-27 21:28:00,848 TADA INFO assertion 28, (5th update; record del) check set3_c on record_samp.py: OK, passed
2022-10-27 21:28:00,848 __main__ INFO 5th update on the aggregator...
2022-10-27 21:28:08,058 TADA INFO assertion 29, (5th update; record del) check set1 on record_agg.py: OK, passed
2022-10-27 21:28:08,058 TADA INFO assertion 30, (5th update; record del) check set3_p on record_agg.py: OK, passed
2022-10-27 21:28:08,058 TADA INFO assertion 31, (5th update; record del) check set3_c on record_agg.py: OK, passed
2022-10-27 21:28:08,058 __main__ INFO 6th sampling on the sampler...
2022-10-27 21:28:15,268 TADA INFO assertion 32, (6th update; record unchanged) check set1 on record_samp.py: OK, passed
2022-10-27 21:28:15,268 TADA INFO assertion 33, (6th update; record unchanged) check set3_p on record_samp.py: OK, passed
2022-10-27 21:28:15,269 TADA INFO assertion 34, (6th update; record unchanged) check set3_c on record_samp.py: OK, passed
2022-10-27 21:28:15,269 __main__ INFO 6th update on the updator...
2022-10-27 21:28:22,478 TADA INFO assertion 35, (6th update; record unchanged) check set1 on record_agg.py: OK, passed
2022-10-27 21:28:22,478 TADA INFO assertion 36, (6th update; record unchanged) check set3_p on record_agg.py: OK, passed
2022-10-27 21:28:22,479 TADA INFO assertion 37, (6th update; record unchanged) check set3_c on record_agg.py: OK, passed
2022-10-27 21:28:22,479 TADA INFO test ldms_record_test ended
2022-10-27 21:28:33 INFO: ----------------------------------------------
2022-10-27 21:28:34 INFO: ======== ldms_schema_digest_test ========
2022-10-27 21:28:34 INFO: CMD: python3 ldms_schema_digest_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldms_schema_digest_test
2022-10-27 21:28:34,720 TADA INFO starting test `ldms_schema_digest_test`
2022-10-27 21:28:34,720 TADA INFO   test-id: ca255b63eb0cfa013a0627f05e84954b8f0c29377bf630bcdbef9d7ad850b4b3
2022-10-27 21:28:34,720 TADA INFO   test-suite: LDMSD
2022-10-27 21:28:34,721 TADA INFO   test-name: ldms_schema_digest_test
2022-10-27 21:28:34,721 TADA INFO   test-user: narate
2022-10-27 21:28:34,721 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:28:34,721 __main__ INFO -- Get or create the cluster --
2022-10-27 21:28:42,058 __main__ INFO -- Start daemons --
2022-10-27 21:28:45,286 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:28:50,412 TADA INFO assertion 1, No schema digest from ldms_ls -v sampler: verified, passed
2022-10-27 21:28:50,534 TADA INFO assertion 2, Schema digest from ldms_ls -vv sampler is not empty: verified, passed
2022-10-27 21:28:50,656 TADA INFO assertion 3, Schema digest from ldms_ls -vv agg-1 is not empty: verified, passed
2022-10-27 21:28:50,837 TADA INFO assertion 4, Schema digest from Python ldms dir agg-1 is not empty: verified, passed
2022-10-27 21:28:50,838 TADA INFO assertion 5, Schema digest from Python ldms lokoup agg-1 is not empty: verified, passed
2022-10-27 21:28:50,838 TADA INFO assertion 6, All digests of the same set are the same: , passed
2022-10-27 21:28:53,261 TADA INFO assertion 7, Sets of same schema yield the same digest: check, passed
2022-10-27 21:28:53,261 TADA INFO assertion 8, Different schema (1-off metric) yield different digest: check, passed
2022-10-27 21:28:53,262 TADA INFO test ldms_schema_digest_test ended
2022-10-27 21:29:05 INFO: ----------------------------------------------
2022-10-27 21:29:06 INFO: ======== ldmsd_decomp_test ========
2022-10-27 21:29:06 INFO: CMD: python3 ldmsd_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldmsd_decomp_test
2022-10-27 21:29:06,993 TADA INFO starting test `ldmsd_decomp_test`
2022-10-27 21:29:06,993 TADA INFO   test-id: 679c44a5af05fdfb24fd4d4f040f124cbd4bc36c514ab0b51115f3b6c83da831
2022-10-27 21:29:06,993 TADA INFO   test-suite: LDMSD
2022-10-27 21:29:06,993 TADA INFO   test-name: ldmsd_decomp_test
2022-10-27 21:29:06,993 TADA INFO   test-user: narate
2022-10-27 21:29:06,993 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:29:06,994 __main__ INFO -- Get or create the cluster --
2022-10-27 21:29:22,802 __main__ INFO -- Start daemons --
2022-10-27 21:29:32,968 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:30:27,746 TADA INFO assertion 1, `as_is` decomposition, test_sampler_8d2b8bd sos schema check: OK, passed
2022-10-27 21:30:27,746 TADA INFO assertion 2, `as_is` decomposition, test_sampler_95772b6 sos schema check: OK, passed
2022-10-27 21:30:27,747 TADA INFO assertion 3, `as_is` decomposition, record_sampler_e1f021f sos schema check: OK, passed
2022-10-27 21:30:27,747 TADA INFO assertion 4, `static` decomposition, fill sos schema check: OK, passed
2022-10-27 21:30:27,747 TADA INFO assertion 5, `static` decomposition, filter sos schema check: OK, passed
2022-10-27 21:30:27,747 TADA INFO assertion 6, `static` decomposition, record sos schema check: OK, passed
2022-10-27 21:30:27,747 TADA INFO assertion 7, `as_is` decomposition, test_sampler_8d2b8bd csv schema check: OK, passed
2022-10-27 21:30:27,747 TADA INFO assertion 8, `as_is` decomposition, test_sampler_95772b6 csv schema check: OK, passed
2022-10-27 21:30:27,748 TADA INFO assertion 9, `as_is` decomposition, record_sampler_e1f021f csv schema check: OK, passed
2022-10-27 21:30:27,748 TADA INFO assertion 10, `static` decomposition, fill csv schema check: OK, passed
2022-10-27 21:30:27,748 TADA INFO assertion 11, `static` decomposition, filter csv schema check: OK, passed
2022-10-27 21:30:27,748 TADA INFO assertion 12, `static` decomposition, record csv schema check: OK, passed
2022-10-27 21:30:27,748 TADA INFO assertion 13, `as_is` decomposition, test_sampler_8d2b8bd kafka schema check: OK, passed
2022-10-27 21:30:27,748 TADA INFO assertion 14, `as_is` decomposition, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-27 21:30:27,749 TADA INFO assertion 15, `as_is` decomposition, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-27 21:30:27,749 TADA INFO assertion 16, `static` decomposition, fill kafka schema check: OK, passed
2022-10-27 21:30:27,749 TADA INFO assertion 17, `static` decomposition, filter kafka schema check: OK, passed
2022-10-27 21:30:27,749 TADA INFO assertion 18, `static` decomposition, record kafka schema check: OK, passed
2022-10-27 21:30:27,751 TADA INFO assertion 19, `as_is` decomposition, test_sampler_8d2b8bd sos data check: OK, passed
2022-10-27 21:30:27,753 TADA INFO assertion 20, `as_is` decomposition, test_sampler_95772b6 sos data check: OK, passed
2022-10-27 21:30:27,825 TADA INFO assertion 21, `as_is` decomposition, record_sampler_e1f021f sos data check: OK, passed
2022-10-27 21:30:27,829 TADA INFO assertion 22, `static` decomposition, fill sos data check: OK, passed
2022-10-27 21:30:27,832 TADA INFO assertion 23, `static` decomposition, filter sos data check: OK, passed
2022-10-27 21:30:27,840 TADA INFO assertion 24, `static` decomposition, record sos data check: OK, passed
2022-10-27 21:30:27,842 TADA INFO assertion 25, `as_is` decomposition, test_sampler_8d2b8bd csv data check: OK, passed
2022-10-27 21:30:27,843 TADA INFO assertion 26, `as_is` decomposition, test_sampler_95772b6 csv data check: OK, passed
2022-10-27 21:30:27,917 TADA INFO assertion 27, `as_is` decomposition, record_sampler_e1f021f csv data check: OK, passed
2022-10-27 21:30:27,921 TADA INFO assertion 28, `static` decomposition, fill csv data check: OK, passed
2022-10-27 21:30:27,924 TADA INFO assertion 29, `static` decomposition, filter csv data check: OK, passed
2022-10-27 21:30:27,932 TADA INFO assertion 30, `static` decomposition, record csv data check: OK, passed
2022-10-27 21:30:27,933 TADA INFO assertion 31, `as_is` decomposition, test_sampler_8d2b8bd kafka data check: OK, passed
2022-10-27 21:30:27,934 TADA INFO assertion 32, `as_is` decomposition, test_sampler_95772b6 kafka data check: OK, passed
2022-10-27 21:30:27,963 TADA INFO assertion 33, `as_is` decomposition, record_sampler_e1f021f kafka data check: OK, passed
2022-10-27 21:30:27,965 TADA INFO assertion 34, `static` decomposition, fill kafka data check: OK, passed
2022-10-27 21:30:27,967 TADA INFO assertion 35, `static` decomposition, filter kafka data check: OK, passed
2022-10-27 21:30:27,971 TADA INFO assertion 36, `static` decomposition, record kafka data check: OK, passed
2022-10-27 21:30:27,971 TADA INFO test ldmsd_decomp_test ended
2022-10-27 21:30:27,972 TADA INFO test ldmsd_decomp_test ended
2022-10-27 21:30:43 INFO: ----------------------------------------------
2022-10-27 21:30:44 INFO: ======== ldmsd_stream_dir_test ========
2022-10-27 21:30:44 INFO: CMD: python3 ldmsd_stream_dir_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldmsd_stream_dir_test
2022-10-27 21:30:44,862 __main__ INFO -- Get or create the cluster --
2022-10-27 21:30:44,862 TADA INFO starting test `ldmsd_stream_dir`
2022-10-27 21:30:44,862 TADA INFO   test-id: 7011293af697ea730c169a9282f12ce00a552bf49ca4014af1854364f3fe1dc4
2022-10-27 21:30:44,862 TADA INFO   test-suite: LDMSD
2022-10-27 21:30:44,862 TADA INFO   test-name: ldmsd_stream_dir
2022-10-27 21:30:44,862 TADA INFO   test-user: narate
2022-10-27 21:30:44,862 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:30:53,484 __main__ INFO -- Start daemons --
2022-10-27 21:30:57,292 __main__ INFO waiting ... for all LDMSDs to start
2022-10-27 21:30:57,603 __main__ INFO All LDMSDs are up.
2022-10-27 21:30:58,811 TADA INFO assertion 1, No Stream data: {} == {}, passed
2022-10-27 21:31:00,134 TADA INFO assertion 2, stream_dir -- one stream message: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666924258, 'last_ts': 1666924258, 'count': 1, 'total_bytes': 6}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666924258, 'last_ts': 1666924258, 'count': 1, 'total_bytes': 6}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1666924258, 'last_ts': 1666924258}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1666924258, 'last_ts': 1666924258}}}, passed
2022-10-27 21:31:02,615 TADA INFO assertion 3, stream_dir --  multiple stream messages: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666924258, 'last_ts': 1666924261, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666924258, 'last_ts': 1666924261, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.0, 'bytes/sec': 6.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666924258, 'last_ts': 1666924261, 'bytes/sec': 6.0, 'msg/sec': 1.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666924258, 'last_ts': 1666924261, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, passed
2022-10-27 21:31:03,846 TADA INFO assertion 4, prdcr_stream_dir to agg -- one producer: {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666924261, 'first_ts': 1666924258, 'bytes/sec': 6.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666924261, 'first_ts': 1666924258, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666924258, 'last_ts': 1666924261, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666924258, 'last_ts': 1666924261, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}}, passed
2022-10-27 21:31:07,642 TADA INFO assertion 5, stream_dir -- mulitple streams: {'bar': {'mode': 'not subscribed', 'info': {'first_ts': 1666924265, 'last_ts': 1666924266, 'count': 3, 'total_bytes': 48, 'msg/sec': 3.0, 'bytes/sec': 48.0}, 'publishers': {}}, 'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666924263, 'last_ts': 1666924265, 'count': 2, 'total_bytes': 12, 'msg/sec': 1.0, 'bytes/sec': 6.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666924263, 'last_ts': 1666924266, 'count': 5, 'total_bytes': 60, 'msg/sec': 1.666667, 'bytes/sec': 20.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666924263, 'last_ts': 1666924265, 'bytes/sec': 6.0, 'msg/sec': 1.0}, 'publishers': {}}, 'bar': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1666924265, 'last_ts': 1666924266, 'bytes/sec': 48.0, 'msg/sec': 3.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1666924263, 'last_ts': 1666924266, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}, passed
2022-10-27 21:31:08,854 TADA INFO assertion 6, prdcr_stream_dir to agg -- two producers: {'foo': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 12, 'last_ts': 1666924265, 'first_ts': 1666924263, 'bytes/sec': 6.0, 'count': 2}}, 'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666924261, 'first_ts': 1666924258, 'bytes/sec': 6.0, 'count': 3}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 3.0, 'total_bytes': 48, 'last_ts': 1666924266, 'first_ts': 1666924265, 'bytes/sec': 48.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-2': {'info': {'msg/sec': 1.666667, 'total_bytes': 60, 'last_ts': 1666924266, 'first_ts': 1666924263, 'bytes/sec': 20.0, 'count': 5}}, 'samplerd-1': {'info': {'msg/sec': 1.0, 'total_bytes': 18, 'last_ts': 1666924261, 'first_ts': 1666924258, 'bytes/sec': 6.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666924258, 'last_ts': 1666924261, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666924263, 'last_ts': 1666924265, 'bytes/sec': 6.0, 'msg/sec': 1.0}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1666924265, 'last_ts': 1666924266, 'bytes/sec': 48.0, 'msg/sec': 3.0}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666924258, 'last_ts': 1666924261, 'bytes/sec': 6.0, 'msg/sec': 1.0}}, 'samplerd-2': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1666924263, 'last_ts': 1666924266, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}}, passed
2022-10-27 21:31:12,522 TADA INFO assertion 7, stream_dir to agg after one producer republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666924270, 'last_ts': 1666924271, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1666924270, 'last_ts': 1666924271, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}}}, '_AGGREGATED_': {'info': {'first_ts': 1666924270, 'last_ts': 1666924271, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666924270, 'last_ts': 1666924271, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666924270, 'last_ts': 1666924271, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}}, '_AGGREGATED_': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666924270, 'last_ts': 1666924271, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, passed
2022-10-27 21:31:14,119 TADA INFO assertion 8, stream_dir to agg after two producers republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666924270, 'last_ts': 1666924272, 'count': 5, 'total_bytes': 30, 'msg/sec': 2.5, 'bytes/sec': 15.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1666924270, 'last_ts': 1666924271, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}, 'samplerd-2': {'info': {'first_ts': 1666924272, 'last_ts': 1666924272, 'count': 3, 'total_bytes': 18}}}}, '_AGGREGATED_': {'info': {'first_ts': 1666924270, 'last_ts': 1666924272, 'count': 5, 'total_bytes': 30, 'msg/sec': 2.5, 'bytes/sec': 15.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1666924270, 'last_ts': 1666924272, 'bytes/sec': 15.0, 'msg/sec': 2.5}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666924270, 'last_ts': 1666924271, 'bytes/sec': 12.0, 'msg/sec': 2.0}}, 'samplerd-2': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666924272, 'last_ts': 1666924272}}}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1666924270, 'last_ts': 1666924272, 'bytes/sec': 15.0, 'msg/sec': 2.5}}}, passed
2022-10-27 21:31:14,119 TADA INFO test ldmsd_stream_dir ended
2022-10-27 21:31:26 INFO: ----------------------------------------------
2022-10-27 21:31:27 INFO: ======== store_list_record_test ========
2022-10-27 21:31:27 INFO: CMD: python3 store_list_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/store_list_record_test
2022-10-27 21:31:27,778 __main__ INFO -- Get or create the cluster --
2022-10-27 21:31:27,778 TADA INFO starting test `store_sos_lists_test`
2022-10-27 21:31:27,778 TADA INFO   test-id: d42107096a0825d248efde054474eddbb7cedc3546c7f0e68070edd6c99545cb
2022-10-27 21:31:27,778 TADA INFO   test-suite: LDMSD
2022-10-27 21:31:27,779 TADA INFO   test-name: store_sos_lists_test
2022-10-27 21:31:27,779 TADA INFO   test-user: narate
2022-10-27 21:31:27,779 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:31:35,337 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:31:39,175 __main__ INFO All sampler daemons are up.
2022-10-27 21:31:39,292 TADA INFO assertion 1, aggregator with store_sos has started properly.: agg_sos.check_ldmsd(), passed
2022-10-27 21:31:39,408 TADA INFO assertion 2, aggregator with store_csv has started properly.: agg_csv.check_ldmsd(), passed
2022-10-27 21:31:52,317 TADA INFO assertion 3, store_sos is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-27 21:31:55,667 TADA INFO assertion 4, store_sos stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-27 21:32:04,526 TADA INFO assertion 5, store_sos stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-27 21:32:05,944 TADA INFO assertion 6, store_csv is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-27 21:32:17,119 TADA INFO assertion 7, store_csv stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-27 21:32:26,671 TADA INFO assertion 8, store_csv stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-27 21:32:26,672 TADA INFO test store_sos_lists_test ended
2022-10-27 21:32:39 INFO: ----------------------------------------------
2022-10-27 21:32:40 INFO: ======== maestro_raft_test ========
2022-10-27 21:32:40 INFO: CMD: python3 maestro_raft_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/maestro_raft_test
2022-10-27 21:32:40,992 TADA INFO starting test `maestro_raft_test`
2022-10-27 21:32:40,993 TADA INFO   test-id: 6644c44a486a4c5593e6c96651635e970e650f2fce604daa934253e447461235
2022-10-27 21:32:40,993 TADA INFO   test-suite: LDMSD
2022-10-27 21:32:40,993 TADA INFO   test-name: maestro_raft_test
2022-10-27 21:32:40,993 TADA INFO   test-user: narate
2022-10-27 21:32:40,993 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:32:51,003 __main__ INFO -- Get or create cluster --
2022-10-27 21:33:25,523 __main__ INFO -- Start daemons --
2022-10-27 21:34:36,772 __main__ INFO -- making known hosts (ssh) --
2022-10-27 21:34:43,696 __main__ INFO ... make sure ldmsd's are up
2022-10-27 21:34:58,147 TADA INFO assertion 1, Statuses of maestros, 1 leader + 2 followers: [('FOLLOWER', 2), ('LEADER', 1)], passed
2022-10-27 21:35:10,526 TADA INFO assertion 2, All ldmsds are up and configured: sets verified, passed
2022-10-27 21:35:10,803 TADA INFO assertion 3, Data are being stored: data check, passed
2022-10-27 21:35:15,726 TADA INFO assertion 4, New leader elected: checked, passed
2022-10-27 21:35:27,545 TADA INFO assertion 5, Restarted ldmsd is configured: sets verified, passed
2022-10-27 21:35:27,870 TADA INFO assertion 6, New data are presented in the store: data check, passed
2022-10-27 21:35:38,871 TADA INFO assertion 7, The restarted maestro becomes a follower: checked, passed
---Wait for config to write to file---
2022-10-27 21:35:38,871 TADA INFO test maestro_raft_test ended
2022-10-27 21:36:00 INFO: ----------------------------------------------
2022-10-27 21:36:01 INFO: ======== ovis_json_test ========
2022-10-27 21:36:01 INFO: CMD: python3 ovis_json_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ovis_json_test
2022-10-27 21:36:01,718 __main__ INFO -- Create the cluster -- 
2022-10-27 21:36:07,021 TADA INFO starting test `ovis_json_test`
2022-10-27 21:36:07,022 TADA INFO   test-id: ca8ae96804fc4a6f72dc200aa9a6a49590754c0ebb11f01ba94acfba97159fe9
2022-10-27 21:36:07,022 TADA INFO   test-suite: OVIS-LIB
2022-10-27 21:36:07,022 TADA INFO   test-name: ovis_json_test
2022-10-27 21:36:07,022 TADA INFO   test-user: narate
2022-10-27 21:36:07,022 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:36:07,023 TADA INFO assertion 1, Test creating a JSON integer entity: (type is JSON_INT_VALUE) && (1 == e->value.int_), passed
2022-10-27 21:36:07,023 TADA INFO assertion 2, Test creating a JSON boolean entity: (type is JSON_BOOL_VALUE) && (1 == e->value.bool_), passed
2022-10-27 21:36:07,023 TADA INFO assertion 3, Test creating a JSON float entity: (type is JSON_FLOAT_VALUE) && (1.1 == e->value.double_), passed
2022-10-27 21:36:07,023 TADA INFO assertion 4, Test creating a JSON string entity: (type is JSON_STRING_VALUE) && (foo == e->value.str_->str), passed
2022-10-27 21:36:07,023 TADA INFO assertion 5, Test creating a JSON attribute entity: (type is JSON_ATTR_VALUE) && (name == <attr name>) && (value == <attr value>), passed
2022-10-27 21:36:07,024 TADA INFO assertion 6, Test creating a JSON list entity: (type is JSON_LIST_VALUE) && (0 == Number of elements) && (list is empty), passed
2022-10-27 21:36:07,024 TADA INFO assertion 7, Test creating a JSON dictionary entity: (type is JSON_DICT_VALUE) && (dict table is empty), passed
2022-10-27 21:36:07,024 TADA INFO assertion 8, Test creating a JSON null entity: (type is JSON_NULL_VALUE) && (0 == e->value.int_), passed
2022-10-27 21:36:07,024 TADA INFO assertion 9, Test parsing a JSON integer string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 21:36:07,024 TADA INFO assertion 10, Test parsing a JSON false boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 21:36:07,024 TADA INFO assertion 11, Test parsing a JSON true boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 21:36:07,024 TADA INFO assertion 12, Test parsing a JSON float string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 21:36:07,025 TADA INFO assertion 13, Test parsing a JSON string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 21:36:07,025 TADA INFO assertion 15, Test parsing a JSON dict string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 21:36:07,025 TADA INFO assertion 16, Test parsing a JSON null string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 21:36:07,025 TADA INFO assertion 17, Test parsing an invalid string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 21:36:07,025 TADA INFO assertion 17, Test parsing an invalid string: 0 != json_parse_buffer(), passed
2022-10-27 21:36:07,025 TADA INFO assertion 18, Test dumping a JSON integer entity: 1 == 1, passed
2022-10-27 21:36:07,025 TADA INFO assertion 19, Test dumping a JSON false boolean entity: false == false, passed
2022-10-27 21:36:07,026 TADA INFO assertion 20, Test dumping a JSON true boolean entity: true == true, passed
2022-10-27 21:36:07,026 TADA INFO assertion 21, Test dumping a JSON float entity: 1.100000 == 1.100000, passed
2022-10-27 21:36:07,026 TADA INFO assertion 22, Test dumping a JSON string entity: "foo" == "foo", passed
2022-10-27 21:36:07,026 TADA INFO assertion 23, Test dumping a JSON attr entity: "name":"foo" == jb->buf, passed
2022-10-27 21:36:07,026 TADA INFO assertion 24, Test dumping a JSON list entity: [1,false,1.100000,"foo",[],{},null] == [1,false,1.100000,"foo",[],{},null], passed
2022-10-27 21:36:07,026 TADA INFO assertion 25, Test dumping a JSON dict entity: {"int":1,"bool":true,"float":1.100000,"string":"foo","list":[1,false,1.100000,"foo",[],{},null],"dict":{"attr_1":"value_1"},"null":null} == {"null":null,"list":[1,false,1.100000,"foo",[],{},null],"string":"foo","float":1.100000,"bool":true,"dict":{"attr_1":"value_1"},"int":1}, passed
2022-10-27 21:36:07,027 TADA INFO assertion 26, Test dumping a JSON null entity: null == null, passed
2022-10-27 21:36:07,027 TADA INFO assertion 27, Test dumping a JSON entity to a non-empty jbuf: This is a book."FOO" == This is a book."FOO", passed
2022-10-27 21:36:07,027 TADA INFO assertion 28, Test copying a JSON integer entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,027 TADA INFO assertion 29, Test copying a JSON false boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,027 TADA INFO assertion 30, Test copying a JSON true boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,027 TADA INFO assertion 31, Test copying a JSON float entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,027 TADA INFO assertion 32, Test copying a JSON string entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,028 TADA INFO assertion 33, Test copying a JSON attribute entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,028 TADA INFO assertion 34, Test copying a JSON list entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,028 TADA INFO assertion 35, Test copying a JSON dict entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,028 TADA INFO assertion 36, Test copying a JSON null entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 21:36:07,028 TADA INFO assertion 37, Test obtaining the number of attributes: 7 == json_attr_count(dict), passed
2022-10-27 21:36:07,028 TADA INFO assertion 38, Test finding an existing attribute: 0 != json_attr_find(), passed
2022-10-27 21:36:07,028 TADA INFO assertion 39, Test finding a non-existng attribute: 0 == json_attr_find(), passed
2022-10-27 21:36:07,029 TADA INFO assertion 40, Test finding the value of an existing attribute: 0 != json_value_find(), passed
2022-10-27 21:36:07,029 TADA INFO assertion 41, Test finding the value of a non-existing attribute: 0 == json_value_find(), passed
2022-10-27 21:36:07,029 TADA INFO assertion 42, Test adding a new attribute to a dictionary: (0 == json_attr_add() && (0 != json_attr_find()), passed
2022-10-27 21:36:07,029 TADA INFO assertion 43, Test replacing the value of an existing attribute: (0 == json_attr_add()) && (0 != json_value_find()) && (is_same_entity(old_v, new_v)), passed
2022-10-27 21:36:07,029 TADA INFO assertion 44, Test removing an existing attribute: (0 = json_attr_rem()) && (0 == json_attr_find()), passed
2022-10-27 21:36:07,029 TADA INFO assertion 45, Test removing a non-existing attribute: (ENOENT == json_attr_rem()), passed
2022-10-27 21:36:07,029 TADA INFO assertion 46, Test creating a dictionary by json_dict_build: expected == json_dict_build(...), passed
2022-10-27 21:36:07,030 TADA INFO assertion 47, Test adding attributes and replacing attribute values by json_dict_build: expected == json_dict_build(d, ...), passed
2022-10-27 21:36:07,030 TADA INFO assertion 48, Test json_dict_merge(): The merged dictionary is correct., passed
2022-10-27 21:36:07,030 TADA INFO assertion 49, Test json_list_len(): 7 == json_list_len(), passed
2022-10-27 21:36:07,030 TADA INFO assertion 50, Test adding items to a list: 0 == strcmp(exp_str, json_entity_dump(l)->buf, passed
2022-10-27 21:36:07,030 TADA INFO assertion 51, Test removing an existing item by json_item_rem(): 0 == json_item_rem(), passed
2022-10-27 21:36:07,030 TADA INFO assertion 52, Test removing a non-existing item by json_item_rem(): ENOENT == json_item_rem(), passed
2022-10-27 21:36:07,030 TADA INFO assertion 53, Test popping an existing item from a list by json_item_pop(): NULL == json_item_pop(len + 3), passed
2022-10-27 21:36:07,031 TADA INFO assertion 54, Test popping a non-existing item from a list by json_item_pop(): NULL != json_item_pop(len - 1), passed
2022-10-27 21:36:07,031 TADA INFO test ovis_json_test ended
2022-10-27 21:36:17 INFO: ----------------------------------------------
2022-10-27 21:36:18 INFO: ======== updtr_add_test ========
2022-10-27 21:36:18 INFO: CMD: python3 updtr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/updtr_add_test
2022-10-27 21:36:19,359 __main__ INFO -- Get or create the cluster --
2022-10-27 21:36:19,359 TADA INFO starting test `updtr_add test`
2022-10-27 21:36:19,359 TADA INFO   test-id: 55111600e3d0d34977de2603bada9c5cd91ca896e185100a0f8cf9d75a5aff92
2022-10-27 21:36:19,359 TADA INFO   test-suite: LDMSD
2022-10-27 21:36:19,359 TADA INFO   test-name: updtr_add test
2022-10-27 21:36:19,359 TADA INFO   test-user: narate
2022-10-27 21:36:19,360 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:36:27,581 __main__ INFO -- Start daemons --
2022-10-27 21:36:31,286 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:36:31,596 __main__ INFO All LDMSDs are up.
2022-10-27 21:36:32,829 TADA INFO assertion 1, Add an updater with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:36:34,055 TADA INFO assertion 2, Add an updater with a zero interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:36:35,270 TADA INFO assertion 3, Add an updater with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:36:36,478 TADA INFO assertion 4, Add an updater with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-27 21:36:37,694 TADA INFO assertion 5, Add an updater with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:36:40,138 TADA INFO assertion 6, Add an updater without an offset: report(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 21:36:42,554 TADA INFO assertion 7, Add an updater with a valid offset: report(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 21:36:43,783 TADA INFO assertion 8, Add an updater with an existing name: report(rc = 17) == expect(rc = 17), passed
2022-10-27 21:36:43,783 __main__ INFO --- done ---
2022-10-27 21:36:43,784 TADA INFO test updtr_add test ended
2022-10-27 21:36:55 INFO: ----------------------------------------------
2022-10-27 21:36:56 INFO: ======== updtr_del_test ========
2022-10-27 21:36:56 INFO: CMD: python3 updtr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/updtr_del_test
2022-10-27 21:36:57,395 __main__ INFO -- Get or create the cluster --
2022-10-27 21:36:57,395 TADA INFO starting test `updtr_add test`
2022-10-27 21:36:57,395 TADA INFO   test-id: fce41993a3ae8117658a9dcb52177e4dcc4f00f0b32e1655228c425570e8ef26
2022-10-27 21:36:57,395 TADA INFO   test-suite: LDMSD
2022-10-27 21:36:57,395 TADA INFO   test-name: updtr_add test
2022-10-27 21:36:57,396 TADA INFO   test-user: narate
2022-10-27 21:36:57,396 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:37:05,122 __main__ INFO -- Start daemons --
2022-10-27 21:37:08,719 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:37:09,051 __main__ INFO All LDMSDs are up.
2022-10-27 21:37:10,264 TADA INFO assertion 1, updtr_del a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 21:37:11,496 TADA INFO assertion 2, updtr_del a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 21:37:12,698 TADA INFO assertion 3, updtr_del a stopped updater: report(rc = 0) == expect(rc = 0), passed
2022-10-27 21:37:13,923 TADA INFO assertion 4, updtr_del a just-added updater: report(rc = 0) == expect(rc = 0), passed
2022-10-27 21:37:13,923 __main__ INFO --- done ---
2022-10-27 21:37:13,923 TADA INFO test updtr_add test ended
2022-10-27 21:37:25 INFO: ----------------------------------------------
2022-10-27 21:37:26 INFO: ======== updtr_match_add_test ========
2022-10-27 21:37:26 INFO: CMD: python3 updtr_match_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/updtr_match_add_test
2022-10-27 21:37:27,516 __main__ INFO -- Get or create the cluster --
2022-10-27 21:37:27,516 TADA INFO starting test `updtr_add test`
2022-10-27 21:37:27,516 TADA INFO   test-id: 2d88907caad67aef801e39f937ba873eb7a5c3c07a2b334828972bc6a98dca5d
2022-10-27 21:37:27,516 TADA INFO   test-suite: LDMSD
2022-10-27 21:37:27,517 TADA INFO   test-name: updtr_add test
2022-10-27 21:37:27,517 TADA INFO   test-user: narate
2022-10-27 21:37:27,517 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:37:35,282 __main__ INFO -- Start daemons --
2022-10-27 21:37:38,958 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:37:39,284 __main__ INFO All LDMSDs are up.
2022-10-27 21:37:40,510 TADA INFO assertion 1, updtr_match_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:37:41,712 TADA INFO assertion 2, updtr_match_add with an invalid match: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:37:42,921 TADA INFO assertion 3, updtr_match_add of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 21:37:44,125 TADA INFO assertion 4, A success updtr_match_add: report(rc = 0) == expect(rc = 0), passed
2022-10-27 21:37:45,337 TADA INFO assertion 5, updtr_match_add of a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 21:37:45,338 __main__ INFO --- done ---
2022-10-27 21:37:45,338 TADA INFO test updtr_add test ended
2022-10-27 21:37:57 INFO: ----------------------------------------------
2022-10-27 21:37:58 INFO: ======== updtr_match_del_test ========
2022-10-27 21:37:58 INFO: CMD: python3 updtr_match_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/updtr_match_del_test
2022-10-27 21:37:59,130 __main__ INFO -- Get or create the cluster --
2022-10-27 21:37:59,130 TADA INFO starting test `updtr_add test`
2022-10-27 21:37:59,130 TADA INFO   test-id: 7583e3d26eb53989a5e2706ff48d90e0102361bb6b46e1ffe390fce73dcfbdb6
2022-10-27 21:37:59,130 TADA INFO   test-suite: LDMSD
2022-10-27 21:37:59,131 TADA INFO   test-name: updtr_add test
2022-10-27 21:37:59,131 TADA INFO   test-user: narate
2022-10-27 21:37:59,131 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:38:06,884 __main__ INFO -- Start daemons --
2022-10-27 21:38:10,591 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:38:10,930 __main__ INFO All LDMSDs are up.
2022-10-27 21:38:12,145 TADA INFO assertion 1, Send updtr_match_del with an invalid regex: report(rc = 2) == expect(rc = 22), passed
2022-10-27 21:38:13,380 TADA INFO assertion 2, Send updtr_match_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 21:38:14,604 TADA INFO assertion 3, Send updtr_match_del with a non-existing inst match: report(rc = 2) == expect(rc = 2), passed
2022-10-27 21:38:15,812 TADA INFO assertion 4, Send updtr_match_del with a non-existing schema match: report(rc = 2) == expect(rc = 2), passed
2022-10-27 21:38:17,024 TADA INFO assertion 5, Send updater_match_del with an invalid match type: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:38:18,245 TADA INFO assertion 6, Send updater_match_del with a valid regex of the inst type: report(rc = 0) == expect(rc = 0), passed
2022-10-27 21:38:19,456 TADA INFO assertion 7, Send updater_match_del with a valid regex of the schema type: report(rc = 0) == expect(rc = 0), passed
2022-10-27 21:38:19,456 __main__ INFO --- done ---
2022-10-27 21:38:19,457 TADA INFO test updtr_add test ended
2022-10-27 21:38:31 INFO: ----------------------------------------------
2022-10-27 21:38:32 INFO: ======== updtr_prdcr_add_test ========
2022-10-27 21:38:32 INFO: CMD: python3 updtr_prdcr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/updtr_prdcr_add_test
2022-10-27 21:38:33,132 __main__ INFO -- Get or create the cluster --
2022-10-27 21:38:33,133 TADA INFO starting test `updtr_add test`
2022-10-27 21:38:33,133 TADA INFO   test-id: f9392cb1a16e9901e643c1f2c286c9a638875d5d17d03b9f3e127b2cbcfb9feb
2022-10-27 21:38:33,133 TADA INFO   test-suite: LDMSD
2022-10-27 21:38:33,133 TADA INFO   test-name: updtr_add test
2022-10-27 21:38:33,133 TADA INFO   test-user: narate
2022-10-27 21:38:33,133 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:38:40,824 __main__ INFO -- Start daemons --
2022-10-27 21:38:44,510 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:38:44,828 __main__ INFO All LDMSDs are up.
2022-10-27 21:38:46,055 TADA INFO assertion 1, Send updtr_prdcr_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:38:48,510 TADA INFO assertion 2, Send updtr_prdcr_add with a regex matching no prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 21:38:50,946 TADA INFO assertion 3, Send updtr_prdcdr_add with a regex matching some prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 21:38:52,162 TADA INFO assertion 4, Send updtr_prdcdr_add to a running updtr: report(rc = 16) == expect(rc = 16), passed
2022-10-27 21:38:53,384 TADA INFO assertion 5, Send updtr_prdcr_add to a not-existing updtr: report(rc = 2) == expect(rc = 2), passed
2022-10-27 21:38:53,385 __main__ INFO --- done ---
2022-10-27 21:38:53,385 TADA INFO test updtr_add test ended
2022-10-27 21:39:05 INFO: ----------------------------------------------
2022-10-27 21:39:06 INFO: ======== updtr_prdcr_del_test ========
2022-10-27 21:39:06 INFO: CMD: python3 updtr_prdcr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/updtr_prdcr_del_test
2022-10-27 21:39:07,252 __main__ INFO -- Get or create the cluster --
2022-10-27 21:39:07,253 TADA INFO starting test `updtr_add test`
2022-10-27 21:39:07,253 TADA INFO   test-id: 2a7b52e1dde48f3097d99f5c46d8b5edbc914dc2f200c52275f164bd587bc4e7
2022-10-27 21:39:07,253 TADA INFO   test-suite: LDMSD
2022-10-27 21:39:07,253 TADA INFO   test-name: updtr_add test
2022-10-27 21:39:07,253 TADA INFO   test-user: narate
2022-10-27 21:39:07,253 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:39:14,911 __main__ INFO -- Start daemons --
2022-10-27 21:39:18,556 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:39:18,859 __main__ INFO All LDMSDs are up.
2022-10-27 21:39:20,073 TADA INFO assertion 1, Send updtr_prdcr_del with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:39:21,294 TADA INFO assertion 2, Send updtr_prdcr_del to a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 21:39:22,513 TADA INFO assertion 3, Send updtr_prdcr_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 21:39:24,951 TADA INFO assertion 4, Send updtr_prdcr_del successfully: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}], passed
2022-10-27 21:39:24,951 __main__ INFO --- done ---
2022-10-27 21:39:24,951 TADA INFO test updtr_add test ended
2022-10-27 21:39:36 INFO: ----------------------------------------------
2022-10-27 21:39:37 INFO: ======== updtr_start_test ========
2022-10-27 21:39:37 INFO: CMD: python3 updtr_start_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/updtr_start_test
2022-10-27 21:39:38,569 __main__ INFO -- Get or create the cluster --
2022-10-27 21:39:38,569 TADA INFO starting test `updtr_add test`
2022-10-27 21:39:38,569 TADA INFO   test-id: f0b6092bb4d4d7f1c7e57d14851cac5034a6cf069c95e88ff8184c606addad3f
2022-10-27 21:39:38,569 TADA INFO   test-suite: LDMSD
2022-10-27 21:39:38,569 TADA INFO   test-name: updtr_add test
2022-10-27 21:39:38,570 TADA INFO   test-user: narate
2022-10-27 21:39:38,570 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:39:46,359 __main__ INFO -- Start daemons --
2022-10-27 21:39:50,039 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:39:50,377 __main__ INFO All LDMSDs are up.
2022-10-27 21:39:51,606 TADA INFO assertion 1, updtr_start with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:39:52,842 TADA INFO assertion 2, updtr_start with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:39:54,072 TADA INFO assertion 3, updtr_start with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-27 21:39:55,284 TADA INFO assertion 4, updtr_start with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:39:56,511 TADA INFO assertion 5, updtr_start without an offset larger than interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 21:39:58,978 TADA INFO assertion 6, updtr_start that changes offset to no offset: report(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 21:40:00,205 TADA INFO assertion 7, updtr_start of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 21:40:02,619 TADA INFO assertion 8, updtr_start with a valid interval: report(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 21:40:05,065 TADA INFO assertion 9, updtr_start with a valid offset: report(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 21:40:07,505 TADA INFO assertion 10, updtr_start without giving interval and offset: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 21:40:08,718 TADA INFO assertion 11, updtr_start a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 21:40:08,718 __main__ INFO --- done ---
2022-10-27 21:40:08,718 TADA INFO test updtr_add test ended
2022-10-27 21:40:20 INFO: ----------------------------------------------
2022-10-27 21:40:21 INFO: ======== updtr_status_test ========
2022-10-27 21:40:21 INFO: CMD: python3 updtr_status_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/updtr_status_test
2022-10-27 21:40:22,328 __main__ INFO -- Get or create the cluster --
2022-10-27 21:40:22,328 TADA INFO starting test `updtr_status test`
2022-10-27 21:40:22,328 TADA INFO   test-id: 8b087475d49d3f29c2c4f9493a792be8b1646bfe7840419b5a763354deeb8479
2022-10-27 21:40:22,328 TADA INFO   test-suite: LDMSD
2022-10-27 21:40:22,328 TADA INFO   test-name: updtr_status test
2022-10-27 21:40:22,328 TADA INFO   test-user: narate
2022-10-27 21:40:22,329 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:40:32,536 __main__ INFO -- Start daemons --
2022-10-27 21:40:37,411 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 21:40:37,812 __main__ INFO All LDMSDs are up.
2022-10-27 21:40:39,032 TADA INFO assertion 1, Send 'updtr_status' to an LDMSD without any Updaters: [], passed
2022-10-27 21:40:40,241 TADA INFO assertion 2, Send 'updtr_status name=foo', where updtr 'foo' doesn't exist.: report(updtr 'foo' doesn't exist.) == expect(updtr 'foo' doesn't exist.), passed
2022-10-27 21:40:41,470 TADA INFO assertion 3, Send 'updtr_status name=all', where 'all' exists.: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 21:40:42,681 TADA INFO assertion 4, Send 'updtr_status' to an LDMSD with a single Updater: report([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 21:40:43,905 TADA INFO assertion 5, Send 'updtr_status' to an LDMSD with 2 updaters: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 21:40:43,905 __main__ INFO --- done ---
2022-10-27 21:40:43,906 TADA INFO test updtr_status test ended
2022-10-27 21:40:56 INFO: ----------------------------------------------
2022-10-27 21:40:57 INFO: ======== ldmsd_flex_decomp_test ========
2022-10-27 21:40:57 INFO: CMD: python3 ldmsd_flex_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldmsd_flex_decomp_test
2022-10-27 21:40:58,317 TADA INFO starting test `ldmsd_flex_decomp_test`
2022-10-27 21:40:58,318 TADA INFO   test-id: f0094b48ba2fbf236ea41b20f23d519727d9c9d3409efd419bb877d5aa443537
2022-10-27 21:40:58,318 TADA INFO   test-suite: LDMSD
2022-10-27 21:40:58,318 TADA INFO   test-name: ldmsd_flex_decomp_test
2022-10-27 21:40:58,318 TADA INFO   test-user: narate
2022-10-27 21:40:58,318 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:40:58,319 __main__ INFO -- Get or create the cluster --
2022-10-27 21:41:14,037 __main__ INFO -- Start daemons --
2022-10-27 21:41:24,233 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 21:42:13,330 TADA INFO assertion 1, test_sampler_95772b6 sos schema check: OK, passed
2022-10-27 21:42:13,330 TADA INFO assertion 2, record_sampler_e1f021f sos schema check: OK, passed
2022-10-27 21:42:13,330 TADA INFO assertion 3, fill sos schema check: OK, passed
2022-10-27 21:42:13,331 TADA INFO assertion 4, filter sos schema check: OK, passed
2022-10-27 21:42:13,331 TADA INFO assertion 5, record sos schema check: OK, passed
2022-10-27 21:42:13,331 TADA INFO assertion 6, test_sampler_95772b6 csv schema check: OK, passed
2022-10-27 21:42:13,331 TADA INFO assertion 7, record_sampler_e1f021f csv schema check: OK, passed
2022-10-27 21:42:13,331 TADA INFO assertion 8, fill csv schema check: OK, passed
2022-10-27 21:42:13,331 TADA INFO assertion 9, filter csv schema check: OK, passed
2022-10-27 21:42:13,332 TADA INFO assertion 10, record csv schema check: OK, passed
2022-10-27 21:42:13,332 TADA INFO assertion 11, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-27 21:42:13,332 TADA INFO assertion 12, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-27 21:42:13,332 TADA INFO assertion 13, fill kafka schema check: OK, passed
2022-10-27 21:42:13,332 TADA INFO assertion 14, filter kafka schema check: OK, passed
2022-10-27 21:42:13,332 TADA INFO assertion 15, record kafka schema check: OK, passed
2022-10-27 21:42:13,334 TADA INFO assertion 16, test_sampler_95772b6 sos data check: OK, passed
2022-10-27 21:42:13,400 TADA INFO assertion 17, record_sampler_e1f021f sos data check: OK, passed
2022-10-27 21:42:13,403 TADA INFO assertion 18, fill sos data check: OK, passed
2022-10-27 21:42:13,404 TADA INFO assertion 19, filter sos data check: OK, passed
2022-10-27 21:42:13,411 TADA INFO assertion 20, record sos data check: OK, passed
2022-10-27 21:42:13,412 TADA INFO assertion 21, test_sampler_95772b6 csv data check: OK, passed
2022-10-27 21:42:13,473 TADA INFO assertion 22, record_sampler_e1f021f csv data check: OK, passed
2022-10-27 21:42:13,476 TADA INFO assertion 23, fill csv data check: OK, passed
2022-10-27 21:42:13,477 TADA INFO assertion 24, filter csv data check: OK, passed
2022-10-27 21:42:13,485 TADA INFO assertion 25, record csv data check: OK, passed
2022-10-27 21:42:13,486 TADA INFO assertion 26, test_sampler_95772b6 kafka data check: OK, passed
2022-10-27 21:42:13,509 TADA INFO assertion 27, record_sampler_e1f021f kafka data check: OK, passed
2022-10-27 21:42:13,510 TADA INFO assertion 28, fill kafka data check: OK, passed
2022-10-27 21:42:13,511 TADA INFO assertion 29, filter kafka data check: OK, passed
2022-10-27 21:42:13,515 TADA INFO assertion 30, record kafka data check: OK, passed
2022-10-27 21:42:13,515 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-27 21:42:13,515 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-27 21:42:28 INFO: ----------------------------------------------
2022-10-27 21:42:29 INFO: ======== ldms_set_info_test ========
2022-10-27 21:42:29 INFO: CMD: python3 ldms_set_info_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/ldms_set_info_test
2022-10-27 21:42:40,061 TADA INFO starting test `ldms_set_info_test`
2022-10-27 21:42:40,061 TADA INFO   test-id: de38efc29214739456a35c0a9fc35ad04efed7cf2e44b5bb5c26c87056adf601
2022-10-27 21:42:40,061 TADA INFO   test-suite: LDMSD
2022-10-27 21:42:40,062 TADA INFO   test-name: ldms_set_info_test
2022-10-27 21:42:40,062 TADA INFO   test-user: narate
2022-10-27 21:42:40,062 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:42:40,062 TADA INFO assertion 1, Adding set info key value pairs : -, passed
2022-10-27 21:42:40,063 TADA INFO assertion 2, Reset value of an existing pair : -, passed
2022-10-27 21:42:40,063 TADA INFO assertion 3, Get a value : -, passed
2022-10-27 21:42:40,063 TADA INFO assertion 4, Unset a pair : -, passed
2022-10-27 21:42:40,063 TADA INFO assertion 5, Traverse the local set info : -, passed
2022-10-27 21:42:40,063 TADA INFO assertion 6, Verifying the set info at the 1st level : -, passed
2022-10-27 21:42:40,063 TADA INFO assertion 7, Server resetting a key : -, passed
2022-10-27 21:42:40,063 TADA INFO assertion 8, Server unset a key : -, passed
2022-10-27 21:42:40,064 TADA INFO assertion 9, Server add a key : -, passed
2022-10-27 21:42:40,064 TADA INFO assertion 10, Adding a key : -, passed
2022-10-27 21:42:40,064 TADA INFO assertion 11, Add a key that is already in the remote list : -, passed
2022-10-27 21:42:40,064 TADA INFO assertion 12, Unset a key that appears in both local and remote list : -, passed
2022-10-27 21:42:40,064 TADA INFO assertion 13, Verifying the set_info at the 2nd level : -, passed
2022-10-27 21:42:40,064 TADA INFO assertion 14, Test set info propagation: resetting a key on the set origin : -, passed
2022-10-27 21:42:40,064 TADA INFO assertion 15, Test set info propagation: unsetting a key on the set origin : -, passed
2022-10-27 21:42:40,065 TADA INFO assertion 16, Test set info propagation: adding a key on the set origin : -, passed
2022-10-27 21:42:40,065 TADA INFO test ldms_set_info_test ended
2022-10-27 21:42:50 INFO: ----------------------------------------------
2022-10-27 21:42:51 INFO: ======== slurm_sampler2_test ========
2022-10-27 21:42:51 INFO: CMD: python3 slurm_sampler2_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-204339/data/slurm_sampler2_test
2022-10-27 21:42:52,279 TADA INFO starting test `slurm_sampler2_test`
2022-10-27 21:42:52,279 TADA INFO   test-id: c9f1327b44191a0020559d8bbccb70fb013551e50d0de4467897ae41e314305f
2022-10-27 21:42:52,279 TADA INFO   test-suite: LDMSD
2022-10-27 21:42:52,280 TADA INFO   test-name: slurm_sampler2_test
2022-10-27 21:42:52,280 TADA INFO   test-user: narate
2022-10-27 21:42:52,280 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 21:42:52,280 __main__ INFO -- Get or create the cluster --
2022-10-27 21:43:06,078 __main__ INFO -- Add users --
2022-10-27 21:43:11,359 __main__ INFO -- Preparing job script & programs --
2022-10-27 21:43:12,057 __main__ INFO -- Start daemons --
2022-10-27 21:43:33,965 TADA INFO assertion 1, Processing the stream data from slurm_notifier: The metric values are as expected on all nodes., passed
2022-10-27 21:43:37,617 TADA INFO assertion 2.1, Deleting completed jobs -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 21:43:39,251 TADA INFO assertion 2.2, Deleting completed jobs -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 21:43:40,904 TADA INFO assertion 2.3, Deleting completed jobs -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 21:43:42,553 TADA INFO assertion 2.4, Deleting completed jobs -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 21:43:44,226 TADA INFO assertion 2.5, Deleting completed jobs -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 21:43:47,863 TADA INFO assertion 3.1, Expanding the set heap -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 21:43:49,509 TADA INFO assertion 3.2, Expanding the set heap -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 21:43:52,524 TADA INFO assertion 3.3, Expanding the set heap -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 21:43:55,517 TADA INFO assertion 3.4, Expanding the set heap -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 21:43:57,152 TADA INFO assertion 3.5, Expanding the set heap -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 21:44:03,437 TADA INFO assertion 4.1, Multi-tenant -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 21:44:05,027 TADA INFO assertion 4.2, Multi-tenant -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 21:44:07,631 TADA INFO assertion 4.3, Multi-tenant -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 21:44:10,119 TADA INFO assertion 4.4, Multi-tenant -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 21:44:11,808 TADA INFO assertion 4.5, Multi-tenant -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 21:44:11,808 TADA INFO test slurm_sampler2_test ended
2022-10-27 21:44:25 INFO: ----------------------------------------------
2022-10-27 21:44:26 INFO: ======== test-ldms ========
2022-10-27 21:44:26 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-ldms/test.sh
2022-10-27T21:44:26-05:00 INFO: starting test-samp-1
93b7130a9a3039fd34c7a6a448674b276061c0aaa7d1178794741f0bab6d0f0d
2022-10-27T21:44:29-05:00 INFO: starting test-samp-2
da2b4268d8c99e1f3a8bf0e64ed2cba189812c1f73ccdd34ca01c9d1aa9a2cae
2022-10-27T21:44:31-05:00 INFO: starting test-samp-3
b36f1db2304ca03863d4cdfb260b13208f67cd3aa284ab9cb0108b83db75a874
2022-10-27T21:44:33-05:00 INFO: starting test-samp-4
06a3234bcd511f3a36b6626329ffaeb28d01a863bff256a2167f1de68c677a1c
2022-10-27T21:44:35-05:00 INFO: test-samp-1 is running
2022-10-27T21:44:35-05:00 INFO: test-samp-2 is running
2022-10-27T21:44:35-05:00 INFO: test-samp-3 is running
2022-10-27T21:44:35-05:00 INFO: test-samp-4 is running
2022-10-27T21:44:35-05:00 INFO: starting test-agg-11
2809b2d5d6d2268d2306bdc55da52761aedc5df564fbb24c9a489694b16e6200
2022-10-27T21:44:37-05:00 INFO: starting test-agg-12
ac9c1d45ef0c32bdd2c52128acabc9ea7162a6465d6cc6f9b18509ef2d9fb038
2022-10-27T21:44:39-05:00 INFO: test-agg-11 is running
2022-10-27T21:44:39-05:00 INFO: test-agg-12 is running
2022-10-27T21:44:39-05:00 INFO: starting test-agg-2
e984b8de61ccd8c087592bcb55cf444d51e84fc9c7c470b460ab8551cd273725
2022-10-27T21:44:40-05:00 INFO: test-agg-2 is running
2022-10-27T21:44:40-05:00 INFO: Collecting data (into SOS)
2022-10-27T21:44:50-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T21:44:53-05:00 INFO: check rc: 0
2022-10-27T21:44:53-05:00 INFO: Cleaning up ...
test-samp-1
test-samp-2
test-samp-3
test-samp-4
test-agg-11
test-agg-12
test-agg-2
2022-10-27T21:44:57-05:00 INFO: DONE
2022-10-27 21:45:07 INFO: ----------------------------------------------
2022-10-27 21:45:07 INFO: ======== test-maestro ========
2022-10-27 21:45:07 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro/test.sh
2022-10-27T21:45:07-05:00 INFO: starting mtest-maestro
bf03b0d6435fda913b3a4bb22c8d5d4e39d60dd921353e4cd3f45793bdd65094
2022-10-27T21:45:09-05:00 INFO: starting mtest-samp-1
225dd1f04a098d7ecaaf01121b31275fdd36948b5c288d9e23020a996ba65b1e
2022-10-27T21:45:11-05:00 INFO: starting mtest-samp-2
101b60126355b6446d04e0bf6f63e374b72a859d3f629e4faa8356a5b32a8817
2022-10-27T21:45:13-05:00 INFO: starting mtest-samp-3
8ab44a37752a147b64ac559caf0702ffca17b46ee71b5080792cd95016f66721
2022-10-27T21:45:14-05:00 INFO: starting mtest-samp-4
7bcc8be47d8a40d34ec2ed32211eb93a249032de6ea59d480db371e637c87e9e
2022-10-27T21:45:16-05:00 INFO: mtest-samp-1 is running
2022-10-27T21:45:16-05:00 INFO: mtest-samp-2 is running
2022-10-27T21:45:16-05:00 INFO: mtest-samp-3 is running
2022-10-27T21:45:16-05:00 INFO: mtest-samp-4 is running
2022-10-27T21:45:16-05:00 INFO: starting mtest-agg-11
610ae337a37f96fb24313ba06331e30203d26e1cc57d2bf4f4681efe1045f5f7
2022-10-27T21:45:17-05:00 INFO: starting mtest-agg-12
ea5770ed58da279bee641ed26270de176b80a8a063fbe8f761f919f9d8c9d1d5
2022-10-27T21:45:19-05:00 INFO: mtest-agg-11 is running
2022-10-27T21:45:19-05:00 INFO: mtest-agg-12 is running
2022-10-27T21:45:19-05:00 INFO: starting mtest-agg-2
517c0599a20e3c372e13bc27d1bb8b1d7fcc542bf2dc72952c7bcf4689ac0c65
2022-10-27T21:45:20-05:00 INFO: mtest-agg-2 is running
2022-10-27T21:45:20-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T21:45:32-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T21:45:34-05:00 INFO: sos check rc: 0
2022-10-27T21:45:35-05:00 INFO: starting mtest-ui
ec3bdd4804bf2f0d94b2ea17cd6ba9cdf57ae93e6f49b2bd43941782a54cb7e4
2022-10-27T21:45:42-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4366484, 1666925124000.811], [4366484, 1666925124001.615], [4366484, 1666925124001.616], [4366484, 1666925124001.627], [4366856, 1666925125001.303], [4366856, 1666925125001.311], [4366856, 1666925125001.7422], [4366856, 1666925125001.78], [4366856, 1666925126001.462], [4366856, 1666925126001.465], [4366856, 1666925126001.466], [4366856, 1666925126001.593], [4366856, 1666925127000.98], [4366856, 1666925127001.581], [4366856, 1666925127001.625], [4366856, 1666925127001.6262], [4366856, 1666925128001.494], [4366856, 1666925128001.7222], [4366856, 1666925128001.75], [4366856, 1666925128001.7632], [4366856, 1666925129001.684], [4366856, 1666925129001.695], [4366856, 1666925129001.8691], [4366856, 1666925129001.897], [4366856, 1666925130001.842], [4366856, 1666925130001.847], [4366856, 1666925130001.8481], [4366856, 1666925130002.043]]}, {"target": "component_id", "datapoints": [[1, 1666925124000.811], [2, 1666925124001.615], [3, 1666925124001.616], [4, 1666925124001.627], [4, 1666925125001.303], [3, 1666925125001.311], [2, 1666925125001.7422], [1, 1666925125001.78], [4, 1666925126001.462], [2, 1666925126001.465], [3, 1666925126001.466], [1, 1666925126001.593], [3, 1666925127000.98], [4, 1666925127001.581], [2, 1666925127001.625], [1, 1666925127001.6262], [2, 1666925128001.494], [3, 1666925128001.7222], [4, 1666925128001.75], [1, 1666925128001.7632], [3, 1666925129001.684], [2, 1666925129001.695], [4, 1666925129001.8691], [1, 1666925129001.897], [2, 1666925130001.842], [3, 1666925130001.847], [4, 1666925130001.8481], [1, 1666925130002.043]]}, {"target": "job_id", "datapoints": [[0, 1666925124000.811], [0, 1666925124001.615], [0, 1666925124001.616], [0, 1666925124001.627], [0, 1666925125001.303], [0, 1666925125001.311], [0, 1666925125001.7422], [0, 1666925125001.78], [0, 1666925126001.462], [0, 1666925126001.465], [0, 1666925126001.466], [0, 1666925126001.593], [0, 1666925127000.98], [0, 1666925127001.581], [0, 1666925127001.625], [0, 1666925127001.6262], [0, 1666925128001.494], [0, 1666925128001.7222], [0, 1666925128001.75], [0, 1666925128001.7632], [0, 1666925129001.684], [0, 1666925129001.695], [0, 1666925129001.8691], [0, 1666925129001.897], [0, 1666925130001.842], [0, 1666925130001.847], [0, 1666925130001.8481], [0, 1666925130002.043]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T21:45:44-05:00 INFO: query check RC: 0
14bb8b623a5db63c39982e19681c6da1c8c0f56d2ac1c64c6537cf6b3a28cf65
2022-10-27T21:46:15-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2407    743 --:--:-- --:--:-- --:--:--  3172
{"datasource":{"id":1,"uid":"cGb660NVk","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T21:46:17-05:00 INFO: Checking grafana data
2022-10-27T21:46:17-05:00 INFO: Grafana data check, rc: 0
2022-10-27T21:46:17-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T21:46:22-05:00 INFO: DONE
2022-10-27 21:46:32 INFO: ----------------------------------------------
2022-10-27 21:46:32 INFO: ======== test-maestro-hostmunge ========
2022-10-27 21:46:32 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-hostmunge/test.sh
2022-10-27T21:46:32-05:00 INFO: Checking munge on localhost
2022-10-27T21:46:32-05:00 INFO: munge encode/decode successfully
2022-10-27T21:46:32-05:00 INFO: starting mtest-maestro
32285c5c57f625b81b5c4174f8d17bee2efe0a6a655e64b8b418b8892b9bba9e
2022-10-27T21:46:34-05:00 INFO: starting mtest-samp-1
2dd20b885880583c88dea2b254d8166f8d768af520a5dda347619e17a86f1830
2022-10-27T21:46:36-05:00 INFO: starting mtest-samp-2
2be43df9b19511e6d1cfcaad264cb8a2410a8c777ac776b389be70a446ba00c6
2022-10-27T21:46:38-05:00 INFO: starting mtest-samp-3
a5af20b98ff704cf03dd2eff6e1ebd147be1ebdeb0a85a673b8f3413b59f8447
2022-10-27T21:46:40-05:00 INFO: starting mtest-samp-4
54749a6eb404b3c7ec4d78958b5f737b9dd8743e02f01510c5f0eb7162c96c60
2022-10-27T21:46:41-05:00 INFO: mtest-samp-1 is running
2022-10-27T21:46:41-05:00 INFO: mtest-samp-2 is running
2022-10-27T21:46:41-05:00 INFO: mtest-samp-3 is running
2022-10-27T21:46:41-05:00 INFO: mtest-samp-4 is running
2022-10-27T21:46:41-05:00 INFO: starting mtest-agg-11
ccd0dcf6fa02f6528d82ff6974c98a813ab7fe7f4c633f59f3674694508d36c3
2022-10-27T21:46:43-05:00 INFO: starting mtest-agg-12
7d6309089841dc1c3b87b62d2263123b2d58f791a1d8da9ba9fca6e1bd7ab9cc
2022-10-27T21:46:44-05:00 INFO: mtest-agg-11 is running
2022-10-27T21:46:44-05:00 INFO: mtest-agg-12 is running
2022-10-27T21:46:44-05:00 INFO: starting mtest-agg-2
622c18077386b5c76359659b41d76e1619ed9895343f0b6e2714bc1cbeafe5a8
2022-10-27T21:46:46-05:00 INFO: mtest-agg-2 is running
2022-10-27T21:46:46-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T21:46:57-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T21:46:59-05:00 INFO: sos check rc: 0
2022-10-27T21:47:00-05:00 INFO: starting mtest-ui
df21462089036719a03de78ad2b3e4d325d2d0650dccbbc33e84a1a9cf672ade
2022-10-27T21:47:02-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4366940, 1666925210001.147], [4366940, 1666925210001.248], [4366940, 1666925210001.3179], [4366940, 1666925210001.7148], [4367312, 1666925211000.701], [4367312, 1666925211000.7092], [4367312, 1666925211000.719], [4367312, 1666925211001.771], [4367312, 1666925212001.85], [4367312, 1666925212001.8591], [4367312, 1666925212001.864], [4367312, 1666925212001.866], [4367312, 1666925213001.071], [4367312, 1666925213001.974], [4367312, 1666925213002.009], [4367312, 1666925213002.02], [4367312, 1666925214000.3352], [4367312, 1666925214001.164], [4367312, 1666925214001.205], [4367312, 1666925214001.233], [4367312, 1666925215000.5918], [4367312, 1666925215000.8289], [4367312, 1666925215000.835], [4367312, 1666925215001.331]]}, {"target": "component_id", "datapoints": [[3, 1666925210001.147], [2, 1666925210001.248], [4, 1666925210001.3179], [1, 1666925210001.7148], [3, 1666925211000.701], [2, 1666925211000.7092], [4, 1666925211000.719], [1, 1666925211001.771], [3, 1666925212001.85], [2, 1666925212001.8591], [1, 1666925212001.864], [4, 1666925212001.866], [4, 1666925213001.071], [1, 1666925213001.974], [2, 1666925213002.009], [3, 1666925213002.02], [2, 1666925214000.3352], [3, 1666925214001.164], [4, 1666925214001.205], [1, 1666925214001.233], [1, 1666925215000.5918], [4, 1666925215000.8289], [2, 1666925215000.835], [3, 1666925215001.331]]}, {"target": "job_id", "datapoints": [[0, 1666925210001.147], [0, 1666925210001.248], [0, 1666925210001.3179], [0, 1666925210001.7148], [0, 1666925211000.701], [0, 1666925211000.7092], [0, 1666925211000.719], [0, 1666925211001.771], [0, 1666925212001.85], [0, 1666925212001.8591], [0, 1666925212001.864], [0, 1666925212001.866], [0, 1666925213001.071], [0, 1666925213001.974], [0, 1666925213002.009], [0, 1666925213002.02], [0, 1666925214000.3352], [0, 1666925214001.164], [0, 1666925214001.205], [0, 1666925214001.233], [0, 1666925215000.5918], [0, 1666925215000.8289], [0, 1666925215000.835], [0, 1666925215001.331]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T21:47:04-05:00 INFO: query check RC: 0
def05d92fddbeb4b4ba555bbba412092f3094cdffb5233a06a4e5f6ebc0cb651
2022-10-27T21:47:35-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   1242    383 --:--:-- --:--:-- --:--:--  1629
{"datasource":{"id":1,"uid":"N4RmRJN4z","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T21:47:37-05:00 INFO: Checking grafana data
2022-10-27T21:47:37-05:00 INFO: Grafana data check, rc: 0
2022-10-27T21:47:37-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T21:47:42-05:00 INFO: DONE
2022-10-27 21:47:52 INFO: ----------------------------------------------
2022-10-27 21:47:52 INFO: ======== test-maestro-munge ========
2022-10-27 21:47:52 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-munge/test.sh
1+0 records in
1+0 records out
4096 bytes (4.1 kB, 4.0 KiB) copied, 0.000390164 s, 10.5 MB/s
2022-10-27T21:47:53-05:00 INFO: starting mtest-maestro
4ca1d89db16ab0944c3ba07e9e39b9201edbf9ee7f891f0476f5184bad3f4e7b
2022-10-27T21:47:55-05:00 INFO: starting mtest-samp-1
ca16123b285fca969c6503c3aae9d8b0cd2bc46ae6245878cdbc1aaadc82b31a
2022-10-27T21:47:57-05:00 INFO: starting mtest-samp-2
f3e71879527a03c081a88cfb29043bdbae2ff63d9188d8719fea74aa19ed2404
2022-10-27T21:47:59-05:00 INFO: starting mtest-samp-3
49c2af26953da924ba0ac1fd36cfcf2461a57311356fb4e15ba8dfe1577dcb5d
2022-10-27T21:48:00-05:00 INFO: starting mtest-samp-4
42bd64027b1b3cb34adf16755d0dc930600d72e496ee1f1a4a6fb7657c09d9db
2022-10-27T21:48:02-05:00 INFO: mtest-samp-1 is running
2022-10-27T21:48:02-05:00 INFO: mtest-samp-2 is running
2022-10-27T21:48:02-05:00 INFO: mtest-samp-3 is running
2022-10-27T21:48:02-05:00 INFO: mtest-samp-4 is running
2022-10-27T21:48:02-05:00 INFO: starting mtest-agg-11
4bcc7e52843052a16bdd6bf0dab8f3aeef32760a38813f958e2b04bbea9009c5
2022-10-27T21:48:03-05:00 INFO: starting mtest-agg-12
c78586537b42dc5e632cd39bfffa1f274940d534e952aca0e7e1fc10ecddddfb
2022-10-27T21:48:05-05:00 INFO: mtest-agg-11 is running
2022-10-27T21:48:05-05:00 INFO: mtest-agg-12 is running
2022-10-27T21:48:05-05:00 INFO: starting mtest-agg-2
372230ec32f6d14c263e52d72c8bb5ed7b4ec8febaa0c4bc572c6a48a1e3416e
2022-10-27T21:48:07-05:00 INFO: mtest-agg-2 is running
2022-10-27T21:48:07-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T21:48:18-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T21:48:20-05:00 INFO: sos check rc: 0
2022-10-27T21:48:21-05:00 INFO: starting mtest-ui
26588ae24a39a45e4bfc87761d87253ac6c97a0b27aa9e8424fe169857b642ba
2022-10-27T21:48:23-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4367296, 1666925291001.023], [4367296, 1666925291001.77], [4367296, 1666925291001.772], [4367296, 1666925291001.867], [4367668, 1666925292001.212], [4367668, 1666925292001.2249], [4367668, 1666925292001.3152], [4367668, 1666925292001.581], [4367668, 1666925293001.37], [4367668, 1666925293001.376], [4367668, 1666925293001.3801], [4367668, 1666925293001.507], [4367668, 1666925294000.827], [4367668, 1666925294001.506], [4367668, 1666925294001.513], [4367668, 1666925294001.535], [4367668, 1666925295001.502], [4367668, 1666925295001.525], [4367668, 1666925295001.5989], [4367668, 1666925295001.684], [4367668, 1666925296001.149], [4367668, 1666925296001.156], [4367668, 1666925296001.2852], [4367668, 1666925296001.834]]}, {"target": "component_id", "datapoints": [[3, 1666925291001.023], [4, 1666925291001.77], [1, 1666925291001.772], [2, 1666925291001.867], [2, 1666925292001.212], [3, 1666925292001.2249], [4, 1666925292001.3152], [1, 1666925292001.581], [4, 1666925293001.37], [1, 1666925293001.376], [2, 1666925293001.3801], [3, 1666925293001.507], [4, 1666925294000.827], [2, 1666925294001.506], [1, 1666925294001.513], [3, 1666925294001.535], [2, 1666925295001.502], [4, 1666925295001.525], [1, 1666925295001.5989], [3, 1666925295001.684], [2, 1666925296001.149], [1, 1666925296001.156], [4, 1666925296001.2852], [3, 1666925296001.834]]}, {"target": "job_id", "datapoints": [[0, 1666925291001.023], [0, 1666925291001.77], [0, 1666925291001.772], [0, 1666925291001.867], [0, 1666925292001.212], [0, 1666925292001.2249], [0, 1666925292001.3152], [0, 1666925292001.581], [0, 1666925293001.37], [0, 1666925293001.376], [0, 1666925293001.3801], [0, 1666925293001.507], [0, 1666925294000.827], [0, 1666925294001.506], [0, 1666925294001.513], [0, 1666925294001.535], [0, 1666925295001.502], [0, 1666925295001.525], [0, 1666925295001.5989], [0, 1666925295001.684], [0, 1666925296001.149], [0, 1666925296001.156], [0, 1666925296001.2852], [0, 1666925296001.834]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T21:48:25-05:00 INFO: query check RC: 0
afdb10c9c3f101eb9390a0664fb3dd218c5c3715e2e3c6229b2d8a1580082a27
2022-10-27T21:48:56-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2565    791 --:--:-- --:--:-- --:--:--  3373
{"datasource":{"id":1,"uid":"hVTGRJN4z","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T21:48:57-05:00 INFO: Checking grafana data
2022-10-27T21:48:58-05:00 INFO: Grafana data check, rc: 0
2022-10-27T21:48:58-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T21:49:02-05:00 INFO: DONE
2022-10-27 21:49:12 INFO: ----------------------------------------------
2022-10-27 21:49:12 INFO: ==== Summary ====
ldmsd_ctrl_test: [01;32mPASSED[0m
papi_store_test: [01;32mPASSED[0m
updtr_status_test: [01;32mPASSED[0m
ldmsd_auth_ovis_test: [01;32mPASSED[0m
store_app_test: [01;32mPASSED[0m
store_list_record_test: [01;32mPASSED[0m
set_array_test: [01;32mPASSED[0m
ovis_ev_test: [01;32mPASSED[0m
setgroup_test: [01;32mPASSED[0m
ldms_list_test: [01;32mPASSED[0m
slurm_stream_test: [01;32mPASSED[0m
maestro_cfg_test: [01;32mPASSED[0m
ldms_set_info_test: [01;32mPASSED[0m
spank_notifier_test: [01;31mFAILED[0m
agg_slurm_test: [01;32mPASSED[0m
updtr_match_add_test: [01;32mPASSED[0m
updtr_match_del_test: [01;32mPASSED[0m
ldmsd_stream_dir_test: [01;32mPASSED[0m
direct_prdcr_subscribe_test: [01;32mPASSED[0m
ldmsd_auth_test: [01;32mPASSED[0m
cont-test-maestro-munge: [01;32mPASSED[0m
cont-test-ldms: [01;32mPASSED[0m
prdcr_subscribe_test: [01;32mPASSED[0m
cont-test-maestro-hostmunge: [01;32mPASSED[0m
maestro_raft_test: [01;32mPASSED[0m
updtr_start_test: [01;32mPASSED[0m
failover_test: [01;32mPASSED[0m
ldms_record_test: [01;32mPASSED[0m
cont-test-maestro: [01;32mPASSED[0m
ldmsd_decomp_test: [01;32mPASSED[0m
ldmsd_flex_decomp_test: [01;32mPASSED[0m
quick_set_add_rm_test: [01;32mPASSED[0m
updtr_prdcr_del_test: [01;32mPASSED[0m
updtr_prdcr_add_test: [01;32mPASSED[0m
mt-slurm-test: [01;32mPASSED[0m
ovis_json_test: [01;32mPASSED[0m
papi_sampler_test: [01;32mPASSED[0m
syspapi_test: [01;32mPASSED[0m
updtr_del_test: [01;32mPASSED[0m
ldmsd_autointerval_test: [01;32mPASSED[0m
updtr_add_test: [01;32mPASSED[0m
ldmsd_stream_test: [01;32mPASSED[0m
direct_ldms_ls_conn_test: [01;32mPASSED[0m
set_array_hang_test: [01;32mPASSED[0m
slurm_sampler2_test: [01;32mPASSED[0m
ldms_schema_digest_test: [01;32mPASSED[0m
agg_test: [01;32mPASSED[0m
------------------------------------------
Total tests passed: 46/47
------------------------------------------
