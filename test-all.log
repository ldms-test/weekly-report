2022-10-27 15:45:35 INFO: WORK_DIR: /mnt/300G/data/2022-10-27-154535
2022-10-27 15:45:35 INFO: LOG: /mnt/300G/data/2022-10-27-154535/cygnus-weekly.log
~/cron/ldms-test ~/cron/ldms-test
/mnt/300G/data/2022-10-27-154535 ~/cron/ldms-test ~/cron/ldms-test
2022-10-27 15:45:36 INFO: Skip building on host because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:45:36 INFO: Skip building containerized binary because GIT SHA has not changed: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:45:36 INFO: -- Installation process succeeded --
2022-10-27 15:45:36 INFO: ---------------------------------------------------------------
~/cron/ldms-test /mnt/300G/data/2022-10-27-154535
~/cron/ldms-test/weekly-report ~/cron/ldms-test /mnt/300G/data/2022-10-27-154535
HEAD is now at 0c06d3f 2022-10-27-102619
[master 17dba71] 2022-10-27-154535
 2 files changed, 14 insertions(+), 2030 deletions(-)
 rewrite test-all.log (99%)
To github.com:ldms-test/weekly-report
   0c06d3f..17dba71  master -> master
~/cron/ldms-test /mnt/300G/data/2022-10-27-154535
2022-10-27 15:45:38 INFO: ==== OVIS+SOS Installation Completed ====
2022-10-27 15:45:38 INFO: ==== Start batch testing ====
~/cron/ldms-test /mnt/300G/data/2022-10-27-154535 ~/cron/ldms-test ~/cron/ldms-test
2022-10-27 15:45:38 INFO: ======== direct_ldms_ls_conn_test ========
2022-10-27 15:45:38 INFO: CMD: python3 direct_ldms_ls_conn_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/direct_ldms_ls_conn_test
2022-10-27 15:45:38,800 TADA INFO starting test `direct_ldms_ls_conn_test`
2022-10-27 15:45:38,800 TADA INFO   test-id: 724b025acf1392586b17b05770c798f4c9c9aff73c24271598e81aaa4de5c099
2022-10-27 15:45:38,800 TADA INFO   test-suite: LDMSD
2022-10-27 15:45:38,800 TADA INFO   test-name: direct_ldms_ls_conn_test
2022-10-27 15:45:38,800 TADA INFO   test-user: narate
2022-10-27 15:45:38,800 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:45:39,258 __main__ INFO starting munged on cygnus-01-iw
2022-10-27 15:45:39,649 __main__ INFO starting munged on localhost
2022-10-27 15:45:39,884 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-27 15:45:40,190 TADA INFO assertion 0, Start ldmsd sampler and munged: OK, passed
2022-10-27 15:45:45,387 TADA INFO assertion 1, ldms_ls to the sampler: OK, passed
2022-10-27 15:45:45,387 __main__ INFO Stopping sampler daemon ...
2022-10-27 15:45:50,808 TADA INFO assertion 2, Kill the sampler: OK, passed
2022-10-27 15:45:50,848 TADA INFO assertion 3, ldms_ls to the dead sampler: got expected output, passed
2022-10-27 15:45:50,880 TADA INFO assertion 4, ldms_ls to a dead host: got expected output, passed
2022-10-27 15:45:50,882 TADA INFO test direct_ldms_ls_conn_test ended
2022-10-27 15:45:51,095 __main__ INFO stopping munged on cygnus-01-iw
2022-10-27 15:45:51,501 __main__ INFO stopping munged on localhost
2022-10-27 15:45:51 INFO: ----------------------------------------------
2022-10-27 15:45:51 INFO: ======== direct_prdcr_subscribe_test ========
2022-10-27 15:45:51 INFO: CMD: python3 direct_prdcr_subscribe_test --prefix /opt/ovis --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/direct_prdcr_subscribe_test
2022-10-27 15:45:52,332 TADA INFO starting test `direct_prdcr_subscribe_test`
2022-10-27 15:45:52,332 TADA INFO   test-id: efbc53ceb0c4461a7473a38d572202ffe50a08254fbb3498d88f7693d8d5a9c8
2022-10-27 15:45:52,332 TADA INFO   test-suite: LDMSD
2022-10-27 15:45:52,333 TADA INFO   test-name: direct_prdcr_subscribe_test
2022-10-27 15:45:52,333 TADA INFO   test-user: narate
2022-10-27 15:45:52,333 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:45:54,245 __main__ INFO starting munged on cygnus-01-iw
2022-10-27 15:45:55,021 __main__ INFO starting munged on cygnus-02-iw
2022-10-27 15:45:55,753 __main__ INFO starting munged on cygnus-03-iw
2022-10-27 15:45:56,510 __main__ INFO starting munged on cygnus-04-iw
2022-10-27 15:45:56,818 __main__ INFO starting munged on localhost
2022-10-27 15:45:57,057 __main__ INFO starting ldmsd on cygnus-01-iw
2022-10-27 15:45:57,552 __main__ INFO starting ldmsd on cygnus-02-iw
2022-10-27 15:45:58,076 __main__ INFO starting ldmsd on cygnus-03-iw
2022-10-27 15:45:58,581 __main__ INFO starting ldmsd on cygnus-04-iw
2022-10-27 15:46:05,473 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-27 15:46:05,473 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-27 15:46:05,474 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-27 15:46:05,474 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-27 15:46:05,475 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verified, passed
2022-10-27 15:46:05,517 TADA INFO assertion 5, Stopping the producers succeeds: agg-1 producers stopped, passed
2022-10-27 15:46:06,519 TADA INFO assertion 6, Restarting the producers succeeds: agg-1 producers started, passed
2022-10-27 15:46:13,099 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-27 15:46:13,100 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-27 15:46:13,100 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-27 15:46:13,101 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-27 15:46:13,102 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verified, passed
2022-10-27 15:46:13,102 __main__ INFO stopping sampler-1
2022-10-27 15:46:14,520 TADA INFO assertion 12, stream-sampler-1 is not running: sampler-1 stopped, passed
2022-10-27 15:46:14,521 __main__ INFO starting sampler-1
2022-10-27 15:46:15,787 TADA INFO assertion 13, stream-sampler-1 has restarted: sampler-1 running, passed
2022-10-27 15:46:15,787 __main__ INFO allow some time for prdcr to reconnect ...
2022-10-27 15:46:21,704 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-27 15:46:21,705 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-27 15:46:21,705 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verified, passed
2022-10-27 15:46:21,707 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: unsubscribed, passed
2022-10-27 15:46:23,883 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-27 15:46:23,888 __main__ INFO stopping agg-1
2022-10-27 15:46:29,106 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-27 15:46:29,107 TADA INFO test direct_prdcr_subscribe_test ended
2022-10-27 15:46:29,319 __main__ INFO stopping munged on cygnus-01-iw
2022-10-27 15:46:29,730 __main__ INFO stopping ldmsd on cygnus-01-iw
2022-10-27 15:46:30,144 __main__ INFO stopping munged on cygnus-02-iw
2022-10-27 15:46:30,559 __main__ INFO stopping ldmsd on cygnus-02-iw
2022-10-27 15:46:30,976 __main__ INFO stopping munged on cygnus-03-iw
2022-10-27 15:46:31,614 __main__ INFO stopping munged on cygnus-04-iw
2022-10-27 15:46:32,038 __main__ INFO stopping ldmsd on cygnus-04-iw
2022-10-27 15:46:32,287 __main__ INFO stopping munged on localhost
2022-10-27 15:46:32 INFO: ----------------------------------------------
2022-10-27 15:46:32 INFO: ======== agg_slurm_test ========
2022-10-27 15:46:32 INFO: CMD: python3 agg_slurm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/agg_slurm_test
2022-10-27 15:46:33,162 TADA INFO starting test `agg_slurm_test`
2022-10-27 15:46:33,162 TADA INFO   test-id: ed0c7aef778a104aac46890bd2ea6a8002daa7a8a9d4ad3f9a74e0cb25b21d32
2022-10-27 15:46:33,162 TADA INFO   test-suite: LDMSD
2022-10-27 15:46:33,163 TADA INFO   test-name: agg_slurm_test
2022-10-27 15:46:33,163 TADA INFO   test-user: narate
2022-10-27 15:46:33,163 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:46:33,164 __main__ INFO -- Get or create the cluster --
2022-10-27 15:46:47,209 __main__ INFO -- Preparing syspapi JSON file --
2022-10-27 15:46:47,320 __main__ INFO -- Preparing jobpapi JSON file --
2022-10-27 15:46:47,418 __main__ INFO -- Preparing job script & programs --
2022-10-27 15:46:48,699 __main__ INFO -- Start daemons --
2022-10-27 15:47:00,934 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 15:47:05,938 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 15:47:06,041 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-27 15:47:06,154 __main__ INFO -- Give syspapi some time to work before submitting job --
2022-10-27 15:47:11,158 __main__ INFO -- Submitting jobs --
2022-10-27 15:47:11,285 __main__ INFO job_one: 1
2022-10-27 15:47:11,406 __main__ INFO job_two: 2
2022-10-27 15:47:21,417 __main__ INFO -- Cancelling jobs --
2022-10-27 15:47:21,417 __main__ INFO job_one: 1
2022-10-27 15:47:21,539 __main__ INFO job_two: 2
2022-10-27 15:48:28,690 TADA INFO assertion 2, slurm data verification: get expected data from store, passed
2022-10-27 15:48:28,690 TADA INFO assertion 3, meminfo data verification: No data missing, passed
2022-10-27 15:48:28,691 TADA INFO assertion 4, (SYS/JOB) PAPI data verification: No data missing, passed
2022-10-27 15:48:28,691 TADA INFO test agg_slurm_test ended
2022-10-27 15:48:42 INFO: ----------------------------------------------
2022-10-27 15:48:43 INFO: ======== papi_sampler_test ========
2022-10-27 15:48:43 INFO: CMD: python3 papi_sampler_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/papi_sampler_test
2022-10-27 15:48:44,496 TADA INFO starting test `papi_sampler_test`
2022-10-27 15:48:44,496 TADA INFO   test-id: 1de29465fdaa3b51730bb109d41c1f7e88f88db828ce733cfce852a37359bb54
2022-10-27 15:48:44,496 TADA INFO   test-suite: LDMSD
2022-10-27 15:48:44,496 TADA INFO   test-name: papi_sampler_test
2022-10-27 15:48:44,496 TADA INFO   test-user: narate
2022-10-27 15:48:44,497 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:48:44,497 __main__ INFO -- Get or create the cluster --
2022-10-27 15:48:49,719 __main__ INFO -- Start daemons --
2022-10-27 15:48:59,794 TADA INFO assertion 0, ldmsd has started: verified, passed
2022-10-27 15:49:00,034 TADA INFO assertion 1.1, Non-papi job is submitted: jobid(1) > 0, passed
2022-10-27 15:49:05,148 TADA INFO assertion 1.2, Non-papi job is running before ldms_ls: STATE = RUNNING, passed
2022-10-27 15:49:05,327 TADA INFO assertion 1.3, Non-papi job is running after ldms_ls: STATE = RUNNING, passed
2022-10-27 15:49:05,327 TADA INFO assertion 1, Non-papi job does not create set: verified, passed
2022-10-27 15:49:19,172 TADA INFO assertion 2, papi job creates set: PAPI set created, passed
2022-10-27 15:49:19,173 TADA INFO assertion 2.2, Schema name is set accordingly: schema name == papi0, passed
2022-10-27 15:49:19,173 TADA INFO assertion 2.1, Events in papi job set created according to config file: {'PAPI_TOT_INS'} == {'PAPI_TOT_INS'}, passed
2022-10-27 15:49:19,173 TADA INFO assertion 2.3, PAPI set has correct job_id: 2 == 2, passed
2022-10-27 15:49:19,382 TADA INFO assertion 2.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-27 15:49:25,195 TADA INFO assertion 3, papi job creates set: PAPI set created, passed
2022-10-27 15:49:25,195 TADA INFO assertion 3.2, Schema name is set accordingly: schema name == papi1, passed
2022-10-27 15:49:25,195 TADA INFO assertion 3.1, Events in papi job set created according to config file: {'PAPI_BR_MSP', 'PAPI_TOT_INS'} == {'PAPI_BR_MSP', 'PAPI_TOT_INS'}, passed
2022-10-27 15:49:25,195 TADA INFO assertion 3.3, PAPI set has correct job_id: 3 == 3, passed
2022-10-27 15:49:25,420 TADA INFO assertion 3.4, PAPI set has correct task_pids: jobid/ranks/pids verified, passed
2022-10-27 15:49:25,421 TADA INFO assertion 4, Multiple, concurrent jobs results in concurrent, multiple sets: LDMS sets ({'node-1/papi0/2.0', 'node-1/meminfo', 'node-1/papi1/3.0'}), passed
2022-10-27 15:49:35,947 TADA INFO assertion 6, PAPI set persists within `job_expiry` after job exited: verified, passed
2022-10-27 15:50:16,282 TADA INFO assertion 7, PAPI set is deleted after `2.2 x job_expiry` since job exited: node-1/meminfo deleted, passed
2022-10-27 15:50:18,628 TADA INFO assertion 8, Missing config file attribute is logged: : papi_sampler[519]: papi_config object must contain either the 'file' or 'config' attribute., passed
2022-10-27 15:50:24,080 TADA INFO assertion 9, Bad config file is logged: : papi_sampler: configuration file syntax error., passed
2022-10-27 15:50:29,528 TADA INFO assertion 10, Unsupported events are logged: : papi_sampler: PAPI error 'Event does not exist' translating event code 'FOO', passed
2022-10-27 15:50:29,529 __main__ INFO -- Finishing Test --
2022-10-27 15:50:29,529 TADA INFO test papi_sampler_test ended
2022-10-27 15:50:29,529 __main__ INFO -- Cleaning up files --
2022-10-27 15:50:29,530 __main__ INFO -- Removing the virtual cluster --
2022-10-27 15:50:40 INFO: ----------------------------------------------
2022-10-27 15:50:41 INFO: ======== papi_store_test ========
2022-10-27 15:50:41 INFO: CMD: python3 papi_store_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/papi_store_test
2022-10-27 15:50:42,492 TADA INFO starting test `papi_store_test`
2022-10-27 15:50:42,492 TADA INFO   test-id: cc51fa7a646aeccdfe6a4607118f0f22e3015eb0c122a4e15b7592a79aa17ca2
2022-10-27 15:50:42,493 TADA INFO   test-suite: LDMSD
2022-10-27 15:50:42,493 TADA INFO   test-name: papi_store_test
2022-10-27 15:50:42,493 TADA INFO   test-user: narate
2022-10-27 15:50:42,493 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:50:42,494 __main__ INFO -- Get or create the cluster --
2022-10-27 15:50:50,322 __main__ INFO -- Start daemons --
2022-10-27 15:51:23,018 TADA INFO assertion 1, Every job in the input data is represented in the output: {1, 2, 3, 4} = {1, 2, 3, 4}, passed
2022-10-27 15:51:23,019 TADA INFO assertion 2, Every event in every job results in a separate row in the output: verified, passed
2022-10-27 15:51:23,019 TADA INFO assertion 3, The schema name in the output matches the event name: verified, passed
2022-10-27 15:51:23,019 TADA INFO assertion 4, Each rank in the job results in a row per event in the output: verified, passed
2022-10-27 15:51:23,019 TADA INFO test papi_store_test ended
2022-10-27 15:51:35 INFO: ----------------------------------------------
2022-10-27 15:51:36 INFO: ======== store_app_test ========
2022-10-27 15:51:36 INFO: CMD: python3 store_app_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/store_app_test
2022-10-27 15:51:36,852 TADA INFO starting test `store_app_test`
2022-10-27 15:51:36,853 TADA INFO   test-id: 69cfc94b3871122621175546bf0100ae8662616e9c7fe4d5888c8f2cb6ccea9c
2022-10-27 15:51:36,853 TADA INFO   test-suite: LDMSD
2022-10-27 15:51:36,853 TADA INFO   test-name: store_app_test
2022-10-27 15:51:36,853 TADA INFO   test-user: narate
2022-10-27 15:51:36,853 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:51:36,854 __main__ INFO -- Get or create the cluster --
2022-10-27 15:51:51,371 __main__ INFO -- Preparing job script & programs --
2022-10-27 15:51:51,763 __main__ INFO -- Start daemons --
2022-10-27 15:52:03,913 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 15:52:08,920 __main__ INFO -- Submitting jobs --
2022-10-27 15:52:09,144 __main__ INFO job_one: 1
2022-10-27 15:52:14,268 __main__ INFO job_two: 2
2022-10-27 15:52:23,809 __main__ INFO Verifying data ...
2022-10-27 15:54:20,659 TADA INFO assertion 1, Verify data: sos data is not empty and sos data < ldms_ls data, passed
2022-10-27 15:54:20,659 TADA INFO test store_app_test ended
2022-10-27 15:54:34 INFO: ----------------------------------------------
2022-10-27 15:54:35 INFO: ======== syspapi_test ========
2022-10-27 15:54:35 INFO: CMD: python3 syspapi_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/syspapi_test
2022-10-27 15:54:36,202 TADA INFO starting test `syspapi_test`
2022-10-27 15:54:36,202 TADA INFO   test-id: d8a821ffbcfe6dffb2b4031c0b9fa576e36f4c125fb32f364edda734d162be9d
2022-10-27 15:54:36,202 TADA INFO   test-suite: LDMSD
2022-10-27 15:54:36,202 TADA INFO   test-name: syspapi_test
2022-10-27 15:54:36,202 TADA INFO   test-user: narate
2022-10-27 15:54:36,202 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:54:36,203 __main__ INFO -- Get or create the cluster --
2022-10-27 15:54:47,423 __main__ INFO -- Write syspapi JSON config files --
2022-10-27 15:54:47,423 __main__ INFO    - db/syspapi-1.json
2022-10-27 15:54:47,424 __main__ INFO    - db/syspapi-bad.json
2022-10-27 15:54:47,425 __main__ INFO -- Start daemons --
2022-10-27 15:54:55,803 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 15:55:00,806 __main__ INFO -- Verifying --
2022-10-27 15:55:00,941 TADA INFO assertion 1, verify set creation by cfg_file: set existed (with correct instance name), passed
2022-10-27 15:55:00,941 TADA INFO assertion 2, verify schema name by cfg_file: verify schema name, passed
2022-10-27 15:55:01,067 TADA INFO assertion 3, verify metrics (events) by cfg_file: verify events (metrics), passed
2022-10-27 15:55:03,205 TADA INFO assertion 4, verify increment counters: verify increment of supported counters, passed
2022-10-27 15:55:03,317 TADA INFO assertion 5, verify cfg_file syntax error report: verify JSON parse error, passed
2022-10-27 15:55:03,435 TADA INFO assertion 6, verify cfg_file unsupported events report: verify unsupported event report, passed
2022-10-27 15:55:24,960 TADA INFO assertion 7, verify cfg_file for many events: each event has either 'sucees' or 'failed' report, passed
2022-10-27 15:55:24,960 __main__ INFO  events succeeded: 77
2022-10-27 15:55:24,960 __main__ INFO  events failed: 114
2022-10-27 15:55:24,960 TADA INFO test syspapi_test ended
2022-10-27 15:55:38 INFO: ----------------------------------------------
2022-10-27 15:55:39 INFO: ======== agg_test ========
2022-10-27 15:55:39 INFO: CMD: python3 agg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/agg_test
2022-10-27 15:55:39,824 TADA INFO starting test `agg_test`
2022-10-27 15:55:39,824 TADA INFO   test-id: 89a08b7c67f025db4213db3692877df957b240c9221e0f66e84653fa67c0919c
2022-10-27 15:55:39,825 TADA INFO   test-suite: LDMSD
2022-10-27 15:55:39,825 TADA INFO   test-name: agg_test
2022-10-27 15:55:39,825 TADA INFO   test-user: narate
2022-10-27 15:55:39,825 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:55:39,825 __main__ INFO -- Get or create the cluster --
2022-10-27 15:55:57,515 __main__ INFO -- Start daemons --
2022-10-27 15:56:06,732 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 15:56:11,738 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 15:56:11,868 TADA INFO assertion 1, ldms_ls agg-2: dir result verified, passed
2022-10-27 15:56:12,630 TADA INFO assertion 2, meminfo data verification: data verified, passed
2022-10-27 15:56:12,630 __main__ INFO -- Terminating ldmsd on node-1 --
2022-10-27 15:56:15,008 TADA INFO assertion 3, node-1 ldmsd terminated, sets removed from agg-11: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 15:56:15,259 TADA INFO assertion 4, node-1 ldmsd terminated, sets removed from agg-2: list({'node-2/meminfo', 'node-4/meminfo', 'node-3/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo', 'node-3/meminfo'}), passed
2022-10-27 15:56:15,260 __main__ INFO -- Resurrecting ldmsd on node-1 --
2022-10-27 15:56:20,923 TADA INFO assertion 5, node-1 ldmsd revived, sets added to agg-11: list({'node-1/meminfo', 'node-3/meminfo'}) == expect({'node-1/meminfo', 'node-3/meminfo'}), passed
2022-10-27 15:56:21,035 TADA INFO assertion 6, node-1 ldmsd revived, sets added to agg-2: list({'node-1/meminfo', 'node-2/meminfo', 'node-4/meminfo', 'node-3/meminfo'}) == expect({'node-2/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-3/meminfo'}), passed
2022-10-27 15:56:21,036 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-27 15:56:23,373 TADA INFO assertion 7, agg-11 ldmsd terminated, sets removed from agg-2: list({'node-2/meminfo', 'node-4/meminfo'}) == expect({'node-2/meminfo', 'node-4/meminfo'}), passed
2022-10-27 15:56:23,502 TADA INFO assertion 8, agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-27 15:56:23,618 TADA INFO assertion 9, agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 15:56:23,618 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-27 15:56:29,274 TADA INFO assertion 10, agg-11 ldmsd revived, sets added to agg-2: list({'node-1/meminfo', 'node-2/meminfo', 'node-4/meminfo', 'node-3/meminfo'}) == expect({'node-2/meminfo', 'node-1/meminfo', 'node-4/meminfo', 'node-3/meminfo'}), passed
2022-10-27 15:56:29,274 TADA INFO test agg_test ended
2022-10-27 15:56:44 INFO: ----------------------------------------------
2022-10-27 15:56:45 INFO: ======== failover_test ========
2022-10-27 15:56:45 INFO: CMD: python3 failover_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/failover_test
2022-10-27 15:56:46,219 TADA INFO starting test `failover_test`
2022-10-27 15:56:46,219 TADA INFO   test-id: 22d7427b93c03c1b9af91e981f8638f4d2e052a060c5ea769170c4824af4c115
2022-10-27 15:56:46,220 TADA INFO   test-suite: LDMSD
2022-10-27 15:56:46,220 TADA INFO   test-name: failover_test
2022-10-27 15:56:46,220 TADA INFO   test-user: narate
2022-10-27 15:56:46,220 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:56:46,220 __main__ INFO -- Get or create the cluster --
2022-10-27 15:57:03,920 __main__ INFO -- Start daemons --
2022-10-27 15:57:13,169 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 15:57:28,185 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 15:57:28,308 TADA INFO assertion 1, 
ldms_ls agg-2: dir result verified, passed
2022-10-27 15:57:29,101 TADA INFO assertion 2, 
meminfo data verification: data verified, passed
2022-10-27 15:57:29,101 __main__ INFO -- Terminating ldmsd on agg-11 --
2022-10-27 15:57:34,428 TADA INFO assertion 3, 
agg-11 ldmsd terminated, sets added to agg-12: list({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 15:57:34,559 TADA INFO assertion 4, 
agg-11 ldmsd terminated, all sets running on agg-2: list({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 15:57:34,671 TADA INFO assertion 5, 
agg-11 ldmsd terminated, node-1 ldmsd is still running: list({'node-1/meminfo'}) == expect({'node-1/meminfo'}), passed
2022-10-27 15:57:34,789 TADA INFO assertion 6, 
agg-11 ldmsd terminated, node-3 ldmsd is still running: list({'node-3/meminfo'}) == expect({'node-3/meminfo'}), passed
2022-10-27 15:57:34,790 __main__ INFO -- Resurrecting ldmsd on agg-11 --
2022-10-27 15:57:55,473 TADA INFO assertion 7, 
agg-11 ldmsd revived, sets removed from agg-12: list({'node-4/meminfo', 'node-2/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo'}), passed
2022-10-27 15:57:55,585 TADA INFO assertion 8, 
agg-11 ldmsd revived, all sets running on agg-2: list({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 15:57:55,585 __main__ INFO -- Terminating ldmsd on agg-12 --
2022-10-27 15:58:00,941 TADA INFO assertion 9, 
agg-12 ldmsd terminated, sets added to agg-11: list({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 15:58:01,053 TADA INFO assertion 10, 
agg-12 ldmsd terminated, all sets running on agg-2: list({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 15:58:01,166 TADA INFO assertion 11, 
agg-12 ldmsd terminated, node-2 ldmsd is still running: list({'node-2/meminfo'}) == expect({'node-2/meminfo'}), passed
2022-10-27 15:58:01,281 TADA INFO assertion 12, 
agg-12 ldmsd terminated, node-4 ldmsd is still running: list({'node-4/meminfo'}) == expect({'node-4/meminfo'}), passed
2022-10-27 15:58:01,281 __main__ INFO -- Resurrecting ldmsd on agg-12 --
2022-10-27 15:58:21,964 TADA INFO assertion 13, 
agg-12 ldmsd revived, sets removed from agg-11: list({'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 15:58:22,082 TADA INFO assertion 14, 
agg-12 ldmsd revived, all sets running on agg-2: list({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}) == expect({'node-4/meminfo', 'node-2/meminfo', 'node-3/meminfo', 'node-1/meminfo'}), passed
2022-10-27 15:58:22,083 TADA INFO test failover_test ended
2022-10-27 15:58:37 INFO: ----------------------------------------------
2022-10-27 15:58:38 INFO: ======== ldmsd_auth_ovis_test ========
2022-10-27 15:58:38 INFO: CMD: python3 ldmsd_auth_ovis_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldmsd_auth_ovis_test
2022-10-27 15:58:39,239 TADA INFO starting test `ldmsd_auth_ovis_test`
2022-10-27 15:58:39,240 TADA INFO   test-id: 63f311896064a9ac9b1094081fafb0a95e43788d0845ecf26cdd9bcb295a6998
2022-10-27 15:58:39,240 TADA INFO   test-suite: LDMSD
2022-10-27 15:58:39,240 TADA INFO   test-name: ldmsd_auth_ovis_test
2022-10-27 15:58:39,240 TADA INFO   test-user: narate
2022-10-27 15:58:39,240 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:58:39,241 __main__ INFO -- Get or create the cluster --
2022-10-27 15:58:44,354 __main__ INFO -- Start daemons --
2022-10-27 15:58:46,354 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 15:58:51,486 TADA INFO assertion 1, ldms_ls with auth none: verified, passed
2022-10-27 15:58:51,634 TADA INFO assertion 2, ldms_ls with wrong secret: verified, passed
2022-10-27 15:58:51,765 TADA INFO assertion 3, ldms_ls 'dir' with right secret: verified, passed
2022-10-27 15:58:52,071 TADA INFO assertion 4, ldms_ls 'read' with right secret: verified, passed
2022-10-27 15:58:52,071 TADA INFO test ldmsd_auth_ovis_test ended
2022-10-27 15:59:03 INFO: ----------------------------------------------
2022-10-27 15:59:04 INFO: ======== ldmsd_auth_test ========
2022-10-27 15:59:04 INFO: CMD: python3 ldmsd_auth_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldmsd_auth_test
2022-10-27 15:59:05,019 TADA INFO starting test `ldmsd_auth_test`
2022-10-27 15:59:05,019 TADA INFO   test-id: 50d5161cd0d9f1253e404b2fa0712f3b819c3523f073fa50bb289911d43a3433
2022-10-27 15:59:05,019 TADA INFO   test-suite: LDMSD
2022-10-27 15:59:05,019 TADA INFO   test-name: ldmsd_auth_test
2022-10-27 15:59:05,019 TADA INFO   test-user: narate
2022-10-27 15:59:05,019 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 15:59:05,020 __main__ INFO -- Get or create the cluster --
2022-10-27 15:59:22,887 __main__ INFO -- Start daemons --
2022-10-27 15:59:41,761 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 15:59:46,892 TADA INFO assertion 1, root@agg-2(dom3) ldms_ls to agg-2:10000: see all sets, passed
2022-10-27 15:59:47,019 TADA INFO assertion 2, user@agg-2(dom3) ldms_ls to agg-2:10000: see only meminfo, passed
2022-10-27 15:59:47,151 TADA INFO assertion 3, root@headnode(dom4) ldms_ls to agg-2:10001: see all sets, passed
2022-10-27 15:59:47,254 TADA INFO assertion 4, user@headnode(dom4) ldms_ls to agg-2:10001: see only meminfo, passed
2022-10-27 15:59:47,366 TADA INFO assertion 5, root@headnode(dom4) ldms_ls to agg-11:10000: connection rejected, passed
2022-10-27 15:59:47,366 TADA INFO test ldmsd_auth_test ended
2022-10-27 16:00:03 INFO: ----------------------------------------------
2022-10-27 16:00:03 INFO: ======== ldmsd_ctrl_test ========
2022-10-27 16:00:03 INFO: CMD: python3 ldmsd_ctrl_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldmsd_ctrl_test
2022-10-27 16:00:04,620 TADA INFO starting test `ldmsd_ctrl_test`
2022-10-27 16:00:04,620 TADA INFO   test-id: 010580096e39786bae1bc24c66ceaf15cd9a971ffe488814a85aed3f61ecea6a
2022-10-27 16:00:04,620 TADA INFO   test-suite: LDMSD
2022-10-27 16:00:04,620 TADA INFO   test-name: ldmsd_ctrl_test
2022-10-27 16:00:04,620 TADA INFO   test-user: narate
2022-10-27 16:00:04,620 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:00:04,621 __main__ INFO -- Get or create the cluster --
2022-10-27 16:00:13,859 __main__ INFO -- Start daemons --
2022-10-27 16:00:18,256 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:00:24,377 TADA INFO assertion 1, ldmsd_controller interactive session: connected, passed
2022-10-27 16:00:25,494 TADA INFO assertion 2, ldmsctl interactive session: connected, passed
2022-10-27 16:00:26,096 TADA INFO assertion 3, ldmsd_controller start bogus producer: expected output verified, passed
2022-10-27 16:00:26,698 TADA INFO assertion 4, ldmsctl start bogus producer: expected output verified, passed
2022-10-27 16:00:27,299 TADA INFO assertion 5, ldmsd_controller bogus command: expected output verified, passed
2022-10-27 16:00:27,901 TADA INFO assertion 6, ldmsctl bogus command: expected output verified, passed
2022-10-27 16:00:28,502 TADA INFO assertion 7, ldmsd_controller load bogus plugin: expected output verified, passed
2022-10-27 16:00:29,104 TADA INFO assertion 8, ldmsctl load bogus plugin: expected output verified, passed
2022-10-27 16:00:46,311 TADA INFO assertion 9, ldmsd_controller prdcr/updtr: verified, passed
2022-10-27 16:01:03,517 TADA INFO assertion 10, ldmsctl prdcr/updtr: verified, passed
2022-10-27 16:01:03,517 TADA INFO test ldmsd_ctrl_test ended
2022-10-27 16:01:16 INFO: ----------------------------------------------
2022-10-27 16:01:17 INFO: ======== ldmsd_stream_test ========
2022-10-27 16:01:17 INFO: CMD: python3 ldmsd_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldmsd_stream_test
2022-10-27 16:01:17,744 TADA INFO starting test `ldmsd_stream_test`
2022-10-27 16:01:17,744 TADA INFO   test-id: 31491391e325e7b0aba0b5feb8c57bc36a4452b7b72a548ae355307381e1cfb2
2022-10-27 16:01:17,744 TADA INFO   test-suite: LDMSD
2022-10-27 16:01:17,744 TADA INFO   test-name: ldmsd_stream_test
2022-10-27 16:01:17,744 TADA INFO   test-user: narate
2022-10-27 16:01:17,744 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:01:28,774 __main__ INFO waiting for libraries to be available across all containers...
2022-10-27 16:01:29,677 __main__ INFO _lib_avail: True
2022-10-27 16:02:37,100 __main__ INFO test ldmsd_stream_subscribe with large json streams
2022-10-27 16:02:43,211 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 16:02:56,818 __main__ INFO --- Verifying the received streams
2022-10-27 16:02:58,438 TADA INFO assertion 1, ldmsd_stream_subscribe receives large json streams: Verify all streams were received correctly, passed
2022-10-27 16:02:58,660 __main__ INFO test LDMSD with large json streams
2022-10-27 16:03:04,747 __main__ INFO --- Sending stream to samplerd
2022-10-27 16:03:23,721 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 16:03:26,116 TADA INFO assertion 2, samplerd receives large json streams: Verify all streams were received correctly, passed
2022-10-27 16:03:26,116 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 16:03:28,504 TADA INFO assertion 3, agg receives large json streams: Verify all streams were received correctly, passed
2022-10-27 16:03:28,504 __main__ INFO test ldmsd_stream_subscribe with small json streams
2022-10-27 16:03:34,621 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 16:05:30,823 __main__ INFO --- Verifying the received streams
2022-10-27 16:05:32,644 TADA INFO assertion 4, ldmsd_stream_subscribe receives small json streams: Verify all streams were received correctly, passed
2022-10-27 16:05:32,870 __main__ INFO test LDMSD with small json streams
2022-10-27 16:05:38,925 __main__ INFO --- Sending stream to samplerd
2022-10-27 16:07:40,245 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 16:07:43,299 TADA INFO assertion 5, samplerd receives small json streams: Verify all streams were received correctly, passed
2022-10-27 16:07:43,299 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 16:07:46,135 TADA INFO assertion 6, agg receives small json streams: Verify all streams were received correctly, passed
2022-10-27 16:07:46,135 __main__ INFO test ldmsd_stream_subscribe with large string streams
2022-10-27 16:07:52,250 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 16:08:05,608 __main__ INFO --- Verifying the received streams
2022-10-27 16:08:07,214 TADA INFO assertion 7, ldmsd_stream_subscribe receives large string streams: Verify all streams were received correctly, passed
2022-10-27 16:08:07,420 __main__ INFO test LDMSD with large string streams
2022-10-27 16:08:13,431 __main__ INFO --- Sending stream to samplerd
2022-10-27 16:08:32,393 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 16:08:33,555 TADA INFO assertion 8, samplerd receives large string streams: Verify all streams were received correctly, passed
2022-10-27 16:08:33,556 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 16:08:34,690 TADA INFO assertion 9, agg receives large string streams: Verify all streams were received correctly, passed
2022-10-27 16:08:34,691 __main__ INFO test ldmsd_stream_subscribe with small string streams
2022-10-27 16:08:40,814 __main__ INFO --- Sending stream to ldmsd_stream_subscriber
2022-10-27 16:10:36,886 __main__ INFO --- Verifying the received streams
2022-10-27 16:10:38,834 TADA INFO assertion 10, ldmsd_stream_subscribe receives small string streams: Verify all streams were received correctly, passed
2022-10-27 16:10:39,078 __main__ INFO test LDMSD with small string streams
2022-10-27 16:10:45,073 __main__ INFO --- Sending stream to samplerd
2022-10-27 16:12:46,776 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 16:12:47,948 TADA INFO assertion 11, samplerd receives small string streams: Verify all streams were received correctly, passed
2022-10-27 16:12:47,949 __main__ INFO --- Verifying the streams received by samplerd
2022-10-27 16:12:49,133 TADA INFO assertion 12, agg receives small string streams: Verify all streams were received correctly, passed
2022-10-27 16:12:49,133 TADA INFO test ldmsd_stream_test ended
2022-10-27 16:13:03 INFO: ----------------------------------------------
2022-10-27 16:13:05 INFO: ======== maestro_cfg_test ========
2022-10-27 16:13:05 INFO: CMD: python3 maestro_cfg_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/maestro_cfg_test
2022-10-27 16:13:05,709 TADA INFO starting test `maestro_cfg_test`
2022-10-27 16:13:05,709 TADA INFO   test-id: 973eefca58593f11ac801833adb2d692cf07c4ce08e9a8ef3b5c440b01552456
2022-10-27 16:13:05,709 TADA INFO   test-suite: LDMSD
2022-10-27 16:13:05,709 TADA INFO   test-name: maestro_cfg_test
2022-10-27 16:13:05,709 TADA INFO   test-user: narate
2022-10-27 16:13:05,709 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:13:15,720 __main__ INFO -- Get or create cluster --
2022-10-27 16:13:41,991 __main__ INFO -- Start daemons --
2022-10-27 16:13:56,713 __main__ INFO ... make sure ldmsd's are up
2022-10-27 16:14:04,152 TADA INFO assertion 1, load maestro etcd cluster: etcd cluster loaded successfully, passed
2022-10-27 16:14:44,181 TADA INFO assertion 2, config ldmsd cluster with maestro: Maestro ldmsd configuration successful, passed
2022-10-27 16:14:45,759 TADA INFO assertion 3, verify sampler daemons: OK, passed
2022-10-27 16:14:46,360 TADA INFO assertion 4, verify L1 aggregator daemons: OK, passed
2022-10-27 16:14:46,611 TADA INFO assertion 5, verify L2 aggregator daemon: OK, passed
2022-10-27 16:14:46,936 TADA INFO assertion 6, verify data storage: OK, passed
---Wait for config to write to file---
2022-10-27 16:14:46,937 TADA INFO test maestro_cfg_test ended
2022-10-27 16:15:05 INFO: ----------------------------------------------
2022-10-27 16:15:06 INFO: ======== mt-slurm-test ========
2022-10-27 16:15:06 INFO: CMD: python3 mt-slurm-test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/mt-slurm-test
-- Get or create the cluster --
-- Start daemons --
... wait a bit to make sure ldmsd's are up
Every job in input data represented in output: : Passed
['# task_rank,timestamp', '0,1666905346.935611', '1,1666905346.935611', '2,1666905346.935611', '3,1666905346.935611', '4,1666905346.935611', '5,1666905346.935611', '6,1666905346.935611', '7,1666905347.950138', '8,1666905347.950138', '9,1666905348.946308', '10,1666905348.946308', '11,1666905348.946308', '12,1666905348.946308', '13,1666905348.946308', '14,1666905349.939444', '15,1666905349.939444', '16,1666905349.939444', '17,1666905349.939444', '18,1666905350.959426', '19,1666905350.959426', '20,1666905351.990448', '21,1666905351.990448', '22,1666905351.990448', '23,1666905351.990448', '24,1666905351.990448', '25,1666905351.990448', '26,1666905351.990448', '# Records 27/27.', '']
Job 10000 has 27 rank: : Passed
Job 10100 has 64 rank: : Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_size in metric set matches database: job_size input match 27: Passed
27
27
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10000 job_id in metric set matches database: job_id match: Passed
For Job 10000 task_rank in metric set matches database: task_rank match: Passed
For Job 10000 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_size in metric set matches database: job_size input match 64: Passed
64
64
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
For Job 10100 job_id in metric set matches database: job_id match: Passed
For Job 10100 task_rank in metric set matches database: task_rank match: Passed
For Job 10100 job_pid in metric set matches database: task_pid match: Passed
Job 10000 has 3 nodes: node count 3 correct: Passed
Job 10100 has 4 nodes: node count 4 correct: Passed
2022-10-27 16:16:25 INFO: ----------------------------------------------
2022-10-27 16:16:26 INFO: ======== ovis_ev_test ========
2022-10-27 16:16:26 INFO: CMD: python3 ovis_ev_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ovis_ev_test
2022-10-27 16:16:27,426 __main__ INFO -- Create the cluster -- 
2022-10-27 16:16:36,700 TADA INFO starting test `ovis_ev_test`
2022-10-27 16:16:36,700 TADA INFO   test-id: f25bd118efcfc1ce306f70e1ae326085a482cbd0dd5f5e35be44a8942619ec8e
2022-10-27 16:16:36,700 TADA INFO   test-suite: test_ovis_ev
2022-10-27 16:16:36,700 TADA INFO   test-name: ovis_ev_test
2022-10-27 16:16:36,700 TADA INFO   test-user: narate
2022-10-27 16:16:36,700 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:16:36,701 TADA INFO assertion 1, Test posting an event without timeout: ovis_ev delivered the expected event., passed
2022-10-27 16:16:36,701 TADA INFO assertion 2, Test posting an event with a current timeout: ovis_ev delivered the expected event., passed
2022-10-27 16:16:36,701 TADA INFO assertion 3, Test posting an event with a future timeout: ovis_ev delivered the expected event., passed
2022-10-27 16:16:36,701 TADA INFO assertion 4, Test reposting a posted event: ev_post returned EBUSY when posted an already posted event, passed
2022-10-27 16:16:36,702 TADA INFO assertion 5, Test canceling a posted event: ovis_ev delivered the expected event., passed
2022-10-27 16:16:36,702 TADA INFO assertion 6, Test rescheduling a posted event: ovis_ev delivered the expected event., passed
2022-10-27 16:16:36,702 TADA INFO assertion 7, Test event deliver order: The event delivery order was correct., passed
2022-10-27 16:16:36,702 TADA INFO assertion 8, Test flushing events: Expected status (1) == delivered status (1), passed
2022-10-27 16:16:36,702 TADA INFO assertion 9, Test posting event on a flushed worker: Expected status (0) == delivered status (0), passed
2022-10-27 16:16:36,702 TADA INFO assertion 10, Test the case that multiple threads post the same event: ev_post returned the expected return code., passed
2022-10-27 16:16:36,702 TADA INFO test ovis_ev_test ended
2022-10-27 16:16:47 INFO: ----------------------------------------------
2022-10-27 16:16:48 INFO: ======== prdcr_subscribe_test ========
2022-10-27 16:16:48 INFO: CMD: python3 prdcr_subscribe_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/prdcr_subscribe_test
2022-10-27 16:16:49,026 TADA INFO starting test `prdcr_subscribe_test`
2022-10-27 16:16:49,026 TADA INFO   test-id: fd2a19a7f78bb34c6e6f5baca51f7532eb381fc7943949ec96e5637f600159c1
2022-10-27 16:16:49,026 TADA INFO   test-suite: LDMSD
2022-10-27 16:16:49,026 TADA INFO   test-name: prdcr_subscribe_test
2022-10-27 16:16:49,026 TADA INFO   test-user: narate
2022-10-27 16:16:49,026 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:17:24,834 TADA INFO assertion 0, ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds: verify JSON data, passed
2022-10-27 16:17:24,835 TADA INFO assertion 1, ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds: verify STRING data, passed
2022-10-27 16:17:24,835 TADA INFO assertion 2, ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds: verify JSON data, passed
2022-10-27 16:17:24,836 TADA INFO assertion 3, ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds: verify STRING data, passed
2022-10-27 16:17:24,836 TADA INFO assertion 4, ldmsd_stream data check on agg-2: agg2 stream data verification, passed
2022-10-27 16:17:25,197 TADA INFO assertion 5, Stopping the producers succeeds: , passed
2022-10-27 16:17:25,555 TADA INFO assertion 6, Restarting the producers succeeds: , passed
2022-10-27 16:17:33,535 TADA INFO assertion 7, JSON stream data resumes after producer restart on stream-sampler-1: verify JSON data, passed
2022-10-27 16:17:33,536 TADA INFO assertion 8, STRING stream data resumes after producer rerestart on stream-sampler-1: verify STRING data, passed
2022-10-27 16:17:33,536 TADA INFO assertion 9, JSON stream data resumes after producer restart on stream-sampler-2: verify JSON data, passed
2022-10-27 16:17:33,537 TADA INFO assertion 10, STRING stream data resumes after producer rerestart on stream-sampler-2: verify STRING data, passed
2022-10-27 16:17:33,537 TADA INFO assertion 11, ldmsd_stream data resume check on agg-2: agg2 stream data verification, passed
2022-10-27 16:17:34,773 TADA INFO assertion 12, stream-sampler-1 is not running: (running == False), passed
2022-10-27 16:17:36,304 TADA INFO assertion 13, stream-sampler-1 has restarted: (running == True), passed
2022-10-27 16:17:43,871 TADA INFO assertion 14, JSON stream data resumes after stream-sampler-1 restart: verify JSON data, passed
2022-10-27 16:17:43,871 TADA INFO assertion 15, STRING stream data resumes after stream-sampler-1 restart: verify STRING data, passed
2022-10-27 16:17:43,872 TADA INFO assertion 16, ldmsd_stream data check on agg-2 after stream-sampler-1 restart: agg2 stream data verification, passed
2022-10-27 16:17:44,229 TADA INFO assertion 17, agg-1 unsubscribes stream-sampler-1: , passed
2022-10-27 16:17:47,540 TADA INFO assertion 18, agg-1 receives data only from stream-sampler-2: data verified, passed
2022-10-27 16:17:53,331 TADA INFO assertion 19, stream-sampler-2 removes agg-1 stream client after disconnected: verified, passed
2022-10-27 16:17:53,331 TADA INFO test prdcr_subscribe_test ended
2022-10-27 16:18:06 INFO: ----------------------------------------------
2022-10-27 16:18:06 INFO: ======== set_array_test ========
2022-10-27 16:18:06 INFO: CMD: python3 set_array_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/set_array_test
2022-10-27 16:18:07,610 TADA INFO starting test `set_array_test`
2022-10-27 16:18:07,610 TADA INFO   test-id: fb899d9179e1ea3f9e6d314e2661010aea070b9bc27d3c279c5143e0a6aad650
2022-10-27 16:18:07,610 TADA INFO   test-suite: LDMSD
2022-10-27 16:18:07,610 TADA INFO   test-name: set_array_test
2022-10-27 16:18:07,610 TADA INFO   test-user: narate
2022-10-27 16:18:07,610 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:18:07,611 __main__ INFO -- Get or create the cluster --
2022-10-27 16:18:12,824 __main__ INFO -- Start daemons --
2022-10-27 16:18:14,790 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:18:40,534 TADA INFO assertion 1, 1st update got some callbacks: verified hunk of 7 snapshots, passed
2022-10-27 16:18:40,535 TADA INFO assertion 2, 2nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-27 16:18:40,535 TADA INFO assertion 3, 3nd update got N callbacks: verified hunk of 5 snapshots, passed
2022-10-27 16:18:40,535 TADA INFO test set_array_test ended
2022-10-27 16:18:51 INFO: ----------------------------------------------
2022-10-27 16:18:52 INFO: ======== setgroup_test ========
2022-10-27 16:18:52 INFO: CMD: python3 setgroup_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/setgroup_test
2022-10-27 16:18:53,460 TADA INFO starting test `setgroup_test`
2022-10-27 16:18:53,461 TADA INFO   test-id: c1c8ab7f18e0dc30f6bdbdf43b359c77ee8e28a7aae3cfddea7a6cb3d0d27cce
2022-10-27 16:18:53,461 TADA INFO   test-suite: LDMSD
2022-10-27 16:18:53,461 TADA INFO   test-name: setgroup_test
2022-10-27 16:18:53,461 TADA INFO   test-user: narate
2022-10-27 16:18:53,462 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:18:53,462 __main__ INFO -- Get or create the cluster --
2022-10-27 16:19:03,068 __main__ INFO -- Start daemons --
2022-10-27 16:19:07,503 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:19:12,508 __main__ INFO -- ldms_ls to agg-2 --
2022-10-27 16:19:12,623 TADA INFO assertion 1, ldms_ls grp on agg-2: dir result verified, passed
2022-10-27 16:19:14,882 TADA INFO assertion 2, members on agg-2 are being updated: data verified, passed
2022-10-27 16:19:14,882 __main__ INFO -- Removing test_2 from grp --
2022-10-27 16:19:15,394 TADA INFO assertion 3, test_2 is removed fom grp on sampler: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 16:19:19,529 TADA INFO assertion 4, test_2 is removed from grp on agg-1: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 16:19:23,661 TADA INFO assertion 5, test_2 is removed from grp on agg-2: expect {'node-1/test_1', 'node-1/grp'}, got {'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 16:19:27,665 __main__ INFO -- Adding test_2 back into grp --
2022-10-27 16:19:28,206 TADA INFO assertion 6, test_2 is added back to grp on sampler: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 16:19:32,332 TADA INFO assertion 7, test_2 is added back to grp on agg-1: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 16:19:34,457 TADA INFO assertion 8, test_2 is added back to grp on agg-2: expect {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, got {'node-1/test_2', 'node-1/test_1', 'node-1/grp'}, passed
2022-10-27 16:19:36,460 TADA INFO test setgroup_test ended
2022-10-27 16:19:49 INFO: ----------------------------------------------
2022-10-27 16:19:49 INFO: ======== slurm_stream_test ========
2022-10-27 16:19:49 INFO: CMD: python3 slurm_stream_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/slurm_stream_test
2022-10-27 16:19:50,630 TADA INFO starting test `slurm_stream_test`
2022-10-27 16:19:50,630 TADA INFO   test-id: 45bb2a48238461642a1e6abc29c35ba52c540f9c2a11de0bf889f04fdb98095d
2022-10-27 16:19:50,630 TADA INFO   test-suite: LDMSD
2022-10-27 16:19:50,630 TADA INFO   test-name: slurm_stream_test
2022-10-27 16:19:50,630 TADA INFO   test-user: narate
2022-10-27 16:19:50,630 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:19:50,631 __main__ INFO -- Get or create the cluster --
2022-10-27 16:19:57,483 __main__ INFO -- Start daemons --
2022-10-27 16:20:00,115 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:20:29,863 TADA INFO assertion 1, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:29,863 __main__ INFO 12345
2022-10-27 16:20:29,863 __main__ INFO 12345
2022-10-27 16:20:29,863 TADA INFO assertion 2, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,863 TADA INFO assertion 3, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-27 16:20:29,863 TADA INFO assertion 4, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,864 TADA INFO assertion 5, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,864 TADA INFO assertion 6, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,864 TADA INFO assertion 7, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,973 TADA INFO assertion 8, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:29,973 __main__ INFO 12345
2022-10-27 16:20:29,973 __main__ INFO 12345
2022-10-27 16:20:29,973 TADA INFO assertion 9, job_start correctly represented in metric set: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,973 TADA INFO assertion 10, job_end correctly represented in metric set: with mutl jobs running, for Job 12345, passed
2022-10-27 16:20:29,973 TADA INFO assertion 11, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,973 TADA INFO assertion 12, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,974 TADA INFO assertion 13, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 16:20:29,974 TADA INFO assertion 14, task_pid correctly represented: with mult jobs running for Job 12345, passed
2022-10-27 16:20:30,073 TADA INFO assertion 15, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,073 __main__ INFO 12346
2022-10-27 16:20:30,073 __main__ INFO 12346
2022-10-27 16:20:30,073 TADA INFO assertion 16, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,074 TADA INFO assertion 17, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-27 16:20:30,074 TADA INFO assertion 18, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,074 TADA INFO assertion 19, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,074 TADA INFO assertion 20, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,074 TADA INFO assertion 21, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,180 TADA INFO assertion 22, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,180 __main__ INFO 12346
2022-10-27 16:20:30,182 __main__ INFO 12346
2022-10-27 16:20:30,183 TADA INFO assertion 23, job_start correctly represented in metric set: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,183 TADA INFO assertion 24, job_end correctly represented in metric set: with mutl jobs running, for Job 12346, passed
2022-10-27 16:20:30,184 TADA INFO assertion 25, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,184 TADA INFO assertion 26, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,184 TADA INFO assertion 27, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,185 TADA INFO assertion 28, task_pid correctly represented: with mult jobs running for Job 12346, passed
2022-10-27 16:20:30,299 TADA INFO assertion 29, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,300 __main__ INFO 12347
2022-10-27 16:20:30,300 __main__ INFO 12347
2022-10-27 16:20:30,300 TADA INFO assertion 30, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,300 TADA INFO assertion 31, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-27 16:20:30,300 TADA INFO assertion 32, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,300 TADA INFO assertion 33, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,300 TADA INFO assertion 34, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,301 TADA INFO assertion 35, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,418 TADA INFO assertion 36, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,418 __main__ INFO 12347
2022-10-27 16:20:30,418 __main__ INFO 12347
2022-10-27 16:20:30,418 TADA INFO assertion 37, job_start correctly represented in metric set: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,418 TADA INFO assertion 38, job_end correctly represented in metric set: with mutl jobs running, for Job 12347, passed
2022-10-27 16:20:30,419 TADA INFO assertion 39, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,419 TADA INFO assertion 40, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,419 TADA INFO assertion 41, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,419 TADA INFO assertion 42, task_pid correctly represented: with mult jobs running for Job 12347, passed
2022-10-27 16:20:30,524 TADA INFO assertion 43, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,524 __main__ INFO 12348
2022-10-27 16:20:30,525 __main__ INFO 12348
2022-10-27 16:20:30,525 TADA INFO assertion 44, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,525 TADA INFO assertion 45, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-27 16:20:30,525 TADA INFO assertion 46, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,525 TADA INFO assertion 47, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,526 TADA INFO assertion 48, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,526 TADA INFO assertion 49, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,650 TADA INFO assertion 50, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,650 __main__ INFO 12348
2022-10-27 16:20:30,650 __main__ INFO 12348
2022-10-27 16:20:30,650 TADA INFO assertion 51, job_start correctly represented in metric set: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,650 TADA INFO assertion 52, job_end correctly represented in metric set: with mutl jobs running, for Job 12348, passed
2022-10-27 16:20:30,650 TADA INFO assertion 53, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,651 TADA INFO assertion 54, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,651 TADA INFO assertion 55, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,651 TADA INFO assertion 56, task_pid correctly represented: with mult jobs running for Job 12348, passed
2022-10-27 16:20:30,765 TADA INFO assertion 57, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,765 __main__ INFO 12355
2022-10-27 16:20:30,765 __main__ INFO 12355
2022-10-27 16:20:30,766 TADA INFO assertion 58, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,766 TADA INFO assertion 59, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-27 16:20:30,766 TADA INFO assertion 60, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,766 TADA INFO assertion 61, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,766 TADA INFO assertion 62, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,766 TADA INFO assertion 63, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,766 TADA INFO assertion 64, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,767 TADA INFO assertion 65, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,767 TADA INFO assertion 66, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,767 TADA INFO assertion 67, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,881 TADA INFO assertion 68, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,881 __main__ INFO 12355
2022-10-27 16:20:30,881 __main__ INFO 12355
2022-10-27 16:20:30,882 TADA INFO assertion 69, job_start correctly represented in metric set: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,882 TADA INFO assertion 70, job_end correctly represented in metric set: with mutl jobs running, for Job 12355, passed
2022-10-27 16:20:30,882 TADA INFO assertion 71, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,882 TADA INFO assertion 72, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,882 TADA INFO assertion 73, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,882 TADA INFO assertion 74, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,882 TADA INFO assertion 75, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,883 TADA INFO assertion 76, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,883 TADA INFO assertion 77, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,883 TADA INFO assertion 78, task_pid correctly represented: with mult jobs running for Job 12355, passed
2022-10-27 16:20:30,996 TADA INFO assertion 79, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:30,996 __main__ INFO 12356
2022-10-27 16:20:30,996 __main__ INFO 12356
2022-10-27 16:20:30,997 TADA INFO assertion 80, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-27 16:20:30,997 TADA INFO assertion 81, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-27 16:20:30,997 TADA INFO assertion 82, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:30,997 TADA INFO assertion 83, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:30,997 TADA INFO assertion 84, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:30,997 TADA INFO assertion 85, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:30,998 TADA INFO assertion 86, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:30,998 TADA INFO assertion 87, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:30,998 TADA INFO assertion 88, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:30,998 TADA INFO assertion 89, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,107 TADA INFO assertion 90, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:31,107 __main__ INFO 12356
2022-10-27 16:20:31,107 __main__ INFO 12356
2022-10-27 16:20:31,107 TADA INFO assertion 91, job_start correctly represented in metric set: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,108 TADA INFO assertion 92, job_end correctly represented in metric set: with mutl jobs running, for Job 12356, passed
2022-10-27 16:20:31,108 TADA INFO assertion 93, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,108 TADA INFO assertion 94, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,108 TADA INFO assertion 95, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,108 TADA INFO assertion 96, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,108 TADA INFO assertion 97, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,108 TADA INFO assertion 98, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,109 TADA INFO assertion 99, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,109 TADA INFO assertion 100, task_pid correctly represented: with mult jobs running for Job 12356, passed
2022-10-27 16:20:31,208 TADA INFO assertion 101, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:31,209 __main__ INFO 12357
2022-10-27 16:20:31,209 __main__ INFO 12357
2022-10-27 16:20:31,209 TADA INFO assertion 102, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,209 TADA INFO assertion 103, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-27 16:20:31,209 TADA INFO assertion 104, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,209 TADA INFO assertion 105, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,210 TADA INFO assertion 106, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,210 TADA INFO assertion 107, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,210 TADA INFO assertion 108, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,210 TADA INFO assertion 109, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,210 TADA INFO assertion 110, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,210 TADA INFO assertion 111, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,324 TADA INFO assertion 112, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:31,325 __main__ INFO 12357
2022-10-27 16:20:31,325 __main__ INFO 12357
2022-10-27 16:20:31,325 TADA INFO assertion 113, job_start correctly represented in metric set: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,325 TADA INFO assertion 114, job_end correctly represented in metric set: with mutl jobs running, for Job 12357, passed
2022-10-27 16:20:31,325 TADA INFO assertion 115, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,325 TADA INFO assertion 116, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,326 TADA INFO assertion 117, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,326 TADA INFO assertion 118, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,326 TADA INFO assertion 119, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,326 TADA INFO assertion 120, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,326 TADA INFO assertion 121, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,326 TADA INFO assertion 122, task_pid correctly represented: with mult jobs running for Job 12357, passed
2022-10-27 16:20:31,433 TADA INFO assertion 123, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:31,433 __main__ INFO 12358
2022-10-27 16:20:31,433 __main__ INFO 12358
2022-10-27 16:20:31,433 TADA INFO assertion 124, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,434 TADA INFO assertion 125, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-27 16:20:31,434 TADA INFO assertion 126, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,434 TADA INFO assertion 127, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,434 TADA INFO assertion 128, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,434 TADA INFO assertion 129, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,434 TADA INFO assertion 130, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,435 TADA INFO assertion 131, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,435 TADA INFO assertion 132, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,435 TADA INFO assertion 133, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,541 TADA INFO assertion 134, Job properly assigned to correct slot: correct job_id fills next slot, passed
2022-10-27 16:20:31,541 __main__ INFO 12358
2022-10-27 16:20:31,541 __main__ INFO 12358
2022-10-27 16:20:31,541 TADA INFO assertion 135, job_start correctly represented in metric set: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,541 TADA INFO assertion 136, job_end correctly represented in metric set: with mutl jobs running, for Job 12358, passed
2022-10-27 16:20:31,541 TADA INFO assertion 137, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,542 TADA INFO assertion 138, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,542 TADA INFO assertion 139, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,542 TADA INFO assertion 140, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,542 TADA INFO assertion 141, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,542 TADA INFO assertion 142, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,542 TADA INFO assertion 143, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:31,542 TADA INFO assertion 144, task_pid correctly represented: with mult jobs running for Job 12358, passed
2022-10-27 16:20:33,582 TADA INFO assertion 145, new job correctly replaces oldest slot: correct job_id fills next slot, passed
2022-10-27 16:20:33,583 __main__ INFO 12353
2022-10-27 16:20:33,583 __main__ INFO 12353
2022-10-27 16:20:33,583 TADA INFO assertion 146, new job_start correctly represented in metric set: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,583 TADA INFO assertion 147, new job_end correctly represented in metric set: with mutl jobs running, for Job 12353, passed
2022-10-27 16:20:33,583 TADA INFO assertion 148, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,583 TADA INFO assertion 149, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,584 TADA INFO assertion 150, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,584 TADA INFO assertion 151, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,584 TADA INFO assertion 152, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,584 TADA INFO assertion 153, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,584 TADA INFO assertion 154, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,584 TADA INFO assertion 155, new job's task replaces oldest slot: with mult jobs running for Job 12353, passed
2022-10-27 16:20:33,584 __main__ INFO -- Test Finished --
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
Delivering events...
2022-10-27 16:20:33,585 TADA INFO test slurm_stream_test ended
2022-10-27 16:20:44 INFO: ----------------------------------------------
2022-10-27 16:20:45 INFO: ======== spank_notifier_test ========
2022-10-27 16:20:45 INFO: CMD: python3 spank_notifier_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/spank_notifier_test
2022-10-27 16:20:46,549 TADA INFO starting test `spank_notifier_test`
2022-10-27 16:20:46,550 TADA INFO   test-id: 86cd5e1893652797c8b4d8077757736fc87ee73e11c50842014439f3f473d669
2022-10-27 16:20:46,550 TADA INFO   test-suite: Slurm_Plugins
2022-10-27 16:20:46,550 TADA INFO   test-name: spank_notifier_test
2022-10-27 16:20:46,550 TADA INFO   test-user: narate
2022-10-27 16:20:46,550 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:20:46,551 __main__ INFO -- Create the cluster --
2022-10-27 16:21:12,513 __main__ INFO -- Cleanup output --
2022-10-27 16:21:12,833 __main__ INFO -- Test bad plugstack config --
2022-10-27 16:21:12,833 __main__ INFO Starting slurm ...
2022-10-27 16:21:27,370 __main__ INFO Starting slurm ... OK
2022-10-27 16:21:47,839 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 16:21:47,946 __main__ INFO   jobid = 1
2022-10-27 16:21:48,139 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 16:21:48,250 __main__ INFO   jobid = 2
2022-10-27 16:21:48,462 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 16:21:48,581 __main__ INFO   jobid = 3
2022-10-27 16:21:48,825 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 16:21:48,948 __main__ INFO   jobid = 4
2022-10-27 16:21:58,571 TADA INFO assertion 60, Bad config does not affect jobs: jobs verified, passed
2022-10-27 16:21:58,571 __main__ INFO Killin slurm ...
2022-10-27 16:22:01,503 __main__ INFO Killin slurm ... OK
2022-10-27 16:22:21,519 __main__ INFO -- Start daemons --
2022-10-27 16:22:32,387 __main__ INFO Starting slurm ... OK
2022-10-27 16:22:52,656 __main__ INFO -- Submitting job with no stream listener --
2022-10-27 16:22:52,877 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-27 16:22:53,002 __main__ INFO   jobid = 5
2022-10-27 16:23:08,983 TADA INFO assertion 0, Missing stream listener on node-1 does not affect job execution: job output file created, passed
2022-10-27 16:23:08,983 TADA INFO assertion 1, Missing stream listener on node-2 does not affect job execution: job output file created, passed
2022-10-27 16:23:14,855 __main__ INFO -- Submitting job with listener --
2022-10-27 16:23:15,074 __main__ INFO -- Submitting job with num_tasks 1 --
2022-10-27 16:23:15,196 __main__ INFO   jobid = 6
2022-10-27 16:23:15,415 __main__ INFO -- Submitting job with num_tasks 2 --
2022-10-27 16:23:15,538 __main__ INFO   jobid = 7
2022-10-27 16:23:15,739 __main__ INFO -- Submitting job with num_tasks 4 --
2022-10-27 16:23:15,863 __main__ INFO   jobid = 8
2022-10-27 16:23:16,066 __main__ INFO -- Submitting job with num_tasks 8 --
2022-10-27 16:23:16,178 __main__ INFO   jobid = 9
2022-10-27 16:23:16,382 __main__ INFO -- Submitting job with num_tasks 27 --
2022-10-27 16:23:16,504 __main__ INFO   jobid = 10
2022-10-27 16:23:38,190 __main__ INFO -- Verifying Events --
2022-10-27 16:23:38,191 TADA INFO assertion 2, 1-task job: first event is 'init': `init` verified, passed
2022-10-27 16:23:38,191 TADA INFO assertion 3, 1-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 16:23:38,191 TADA INFO assertion 4, 1-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 16:23:38,191 TADA INFO assertion 5, 1-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 16:23:38,191 TADA INFO assertion 6, 1-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 16:23:38,192 TADA INFO assertion 7, 2-task job: first event is 'init': `init` verified, passed
2022-10-27 16:23:38,192 TADA INFO assertion 8, 2-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 16:23:38,192 TADA INFO assertion 9, 2-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 16:23:38,192 TADA INFO assertion 10, 2-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 16:23:38,192 TADA INFO assertion 11, 2-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 16:23:38,193 TADA INFO assertion 12, 4-task job: first event is 'init': `init` verified, passed
2022-10-27 16:23:38,193 TADA INFO assertion 13, 4-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 16:23:38,193 TADA INFO assertion 14, 4-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 16:23:38,193 TADA INFO assertion 15, 4-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 16:23:38,193 TADA INFO assertion 16, 4-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 16:23:38,194 TADA INFO assertion 17, 8-task job: first event is 'init': `init` verified, passed
2022-10-27 16:23:38,194 TADA INFO assertion 18, 8-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 16:23:38,194 TADA INFO assertion 19, 8-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 16:23:38,194 TADA INFO assertion 20, 8-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 16:23:38,194 TADA INFO assertion 21, 8-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 16:23:38,195 TADA INFO assertion 22, 27-task job: first event is 'init': `init` verified, passed
2022-10-27 16:23:38,195 TADA INFO assertion 23, 27-task job: 'step_init' event contains subscriber data: `init` subscriber_data verified, passed
2022-10-27 16:23:38,195 TADA INFO assertion 24, 27-task job: second event is 'task_init_priv': `task_init_priv` verified, passed
2022-10-27 16:23:38,195 TADA INFO assertion 25, 27-task job: third event is 'task_exit': `task_exit` verified, passed
2022-10-27 16:23:38,195 TADA INFO assertion 26, 27-task job: fourth event is 'exit': `exit` verified, passed
2022-10-27 16:23:38,196 __main__ INFO job 7 multi-tenant with dict_keys([6])
2022-10-27 16:23:38,196 __main__ INFO job 10 multi-tenant with dict_keys([6, 7])
2022-10-27 16:23:38,196 __main__ INFO job 10 multi-tenant with dict_keys([8])
2022-10-27 16:23:38,196 __main__ INFO job 10 multi-tenant with dict_keys([9])
2022-10-27 16:23:38,196 __main__ INFO job 10 multi-tenant with dict_keys([9])
2022-10-27 16:23:38,196 TADA INFO assertion 50, Multi-tenant verification: Multi-tenant jobs found, passed
2022-10-27 16:23:38,447 __main__ INFO -- Submitting job that crashes listener --
2022-10-27 16:23:38,574 __main__ INFO   jobid = 11
2022-10-27 16:23:48,812 TADA INFO assertion 51, Killing stream listener does not affect job execution on node-1: job output file created, passed
2022-10-27 16:23:48,907 TADA INFO assertion 52, Killing stream listener does not affect job execution on node-2: job output file created, passed
2022-10-27 16:23:48,907 TADA INFO test spank_notifier_test ended
2022-10-27 16:24:05 INFO: ----------------------------------------------
2022-10-27 16:24:06 INFO: ======== ldms_list_test ========
2022-10-27 16:24:06 INFO: CMD: python3 ldms_list_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldms_list_test
2022-10-27 16:24:06,862 TADA INFO starting test `ldms_list_test`
2022-10-27 16:24:06,863 TADA INFO   test-id: 229bd49099d3ca29bb9f7c1b4a169a955998747888e5d82f20bac85ce208c8af
2022-10-27 16:24:06,863 TADA INFO   test-suite: LDMSD
2022-10-27 16:24:06,863 TADA INFO   test-name: ldms_list_test
2022-10-27 16:24:06,863 TADA INFO   test-user: narate
2022-10-27 16:24:06,863 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:24:06,863 __main__ INFO -- Get or create the cluster --
2022-10-27 16:24:09,913 __main__ INFO -- Start daemons --
2022-10-27 16:24:16,282 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:24:18,284 __main__ INFO start list_samp.py and list_agg.py interactive sessions
2022-10-27 16:24:24,318 TADA INFO assertion 1, check list_sampler on list_agg.py: OK, passed
2022-10-27 16:24:24,319 TADA INFO assertion 2, (1st update) check set1 on list_samp.py: OK, passed
2022-10-27 16:24:24,319 TADA INFO assertion 3, (1st update) check set3_p on list_samp.py: OK, passed
2022-10-27 16:24:24,319 TADA INFO assertion 4, (1st update)check set3_c on list_samp.py: OK, passed
2022-10-27 16:24:24,320 TADA INFO assertion 5, (1st update)check set1 on list_agg.py: OK, passed
2022-10-27 16:24:24,320 TADA INFO assertion 6, (1st update)check set3_p on list_agg.py: OK, passed
2022-10-27 16:24:24,320 TADA INFO assertion 7, (1st update)check set3_c on list_agg.py: OK, passed
2022-10-27 16:24:24,320 __main__ INFO 2nd sampling on the sampler...
2022-10-27 16:24:31,530 TADA INFO assertion 8, (2nd update) check set1 on list_samp.py: OK, passed
2022-10-27 16:24:31,530 TADA INFO assertion 9, (2nd update) check set3_p on list_samp.py: OK, passed
2022-10-27 16:24:31,530 TADA INFO assertion 10, (2nd update) check set3_c on list_samp.py: OK, passed
2022-10-27 16:24:31,531 __main__ INFO 2nd update on the aggregator...
2022-10-27 16:24:38,740 TADA INFO assertion 11, (2nd update) check set1 on list_agg.py: OK, passed
2022-10-27 16:24:38,740 TADA INFO assertion 12, (2nd update) check set3_p on list_agg.py: OK, passed
2022-10-27 16:24:38,741 TADA INFO assertion 13, (2nd update) check set3_c on list_agg.py: OK, passed
2022-10-27 16:24:38,741 __main__ INFO 3rd sampling on the sampler...
2022-10-27 16:24:45,950 TADA INFO assertion 14, (3rd update) check set1 on list_samp.py: OK, passed
2022-10-27 16:24:45,950 TADA INFO assertion 15, (3rd update) check set3_p on list_samp.py: OK, passed
2022-10-27 16:24:45,951 TADA INFO assertion 16, (3rd update) check set3_c on list_samp.py: OK, passed
2022-10-27 16:24:45,951 __main__ INFO 3rd update on the aggregator...
2022-10-27 16:24:53,160 TADA INFO assertion 17, (3rd update) check set1 on list_agg.py: OK, passed
2022-10-27 16:24:53,161 TADA INFO assertion 18, (3rd update) check set3_p on list_agg.py: OK, passed
2022-10-27 16:24:53,161 TADA INFO assertion 19, (3rd update) check set3_c on list_agg.py: OK, passed
2022-10-27 16:24:53,161 __main__ INFO 4th sampling on the sampler...
2022-10-27 16:25:00,370 TADA INFO assertion 20, (4th update; list uncahnged) check set1 on list_samp.py: OK, passed
2022-10-27 16:25:00,371 TADA INFO assertion 21, (4th update; list uncahnged) check set3_p on list_samp.py: OK, passed
2022-10-27 16:25:00,371 TADA INFO assertion 22, (4th update; list uncahnged) check set3_c on list_samp.py: OK, passed
2022-10-27 16:25:00,371 __main__ INFO 4th update on the aggregator...
2022-10-27 16:25:07,580 TADA INFO assertion 23, (4th update; list uncahnged) check set1 on list_agg.py: OK, passed
2022-10-27 16:25:07,581 TADA INFO assertion 24, (4th update; list uncahnged) check set3_p on list_agg.py: OK, passed
2022-10-27 16:25:07,581 TADA INFO assertion 25, (4th update; list uncahnged) check set3_c on list_agg.py: OK, passed
2022-10-27 16:25:07,581 __main__ INFO 5th sampling on the sampler...
2022-10-27 16:25:14,790 TADA INFO assertion 26, (5th update; list del) check set1 on list_samp.py: OK, passed
2022-10-27 16:25:14,791 TADA INFO assertion 27, (5th update; list del) check set3_p on list_samp.py: OK, passed
2022-10-27 16:25:14,791 TADA INFO assertion 28, (5th update; list del) check set3_c on list_samp.py: OK, passed
2022-10-27 16:25:14,791 __main__ INFO 5th update on the aggregator...
2022-10-27 16:25:22,000 TADA INFO assertion 29, (5th update; list del) check set1 on list_agg.py: OK, passed
2022-10-27 16:25:22,001 TADA INFO assertion 30, (5th update; list del) check set3_p on list_agg.py: OK, passed
2022-10-27 16:25:22,001 TADA INFO assertion 31, (5th update; list del) check set3_c on list_agg.py: OK, passed
2022-10-27 16:25:22,001 __main__ INFO 6th sampling on the sampler...
2022-10-27 16:25:29,210 TADA INFO assertion 32, (6th update; list unchanged) check set1 on list_samp.py: OK, passed
2022-10-27 16:25:29,211 TADA INFO assertion 33, (6th update; list unchanged) check set3_p on list_samp.py: OK, passed
2022-10-27 16:25:29,211 TADA INFO assertion 34, (6th update; list unchanged) check set3_c on list_samp.py: OK, passed
2022-10-27 16:25:29,211 __main__ INFO 6th update on the updator...
2022-10-27 16:25:36,420 TADA INFO assertion 35, (6th update; list unchanged) check set1 on list_agg.py: OK, passed
2022-10-27 16:25:36,421 TADA INFO assertion 36, (6th update; list unchanged) check set3_p on list_agg.py: OK, passed
2022-10-27 16:25:36,421 TADA INFO assertion 37, (6th update; list unchanged) check set3_c on list_agg.py: OK, passed
2022-10-27 16:25:36,422 TADA INFO test ldms_list_test ended
2022-10-27 16:25:47 INFO: ----------------------------------------------
2022-10-27 16:25:47 INFO: ======== quick_set_add_rm_test ========
2022-10-27 16:25:47 INFO: CMD: python3 quick_set_add_rm_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/quick_set_add_rm_test
2022-10-27 16:25:48,687 TADA INFO starting test `quick_set_add_rm_test`
2022-10-27 16:25:48,688 TADA INFO   test-id: 7c4465e05c248a6b6f5b6a4432f6ee0f561d41c0b5d73740486b1c8e9b8890f4
2022-10-27 16:25:48,688 TADA INFO   test-suite: LDMSD
2022-10-27 16:25:48,688 TADA INFO   test-name: quick_set_add_rm_test
2022-10-27 16:25:48,688 TADA INFO   test-user: narate
2022-10-27 16:25:48,688 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:25:48,688 __main__ INFO -- Get or create the cluster --
2022-10-27 16:25:55,940 __main__ INFO -- Start samp.py --
2022-10-27 16:26:01,052 TADA INFO assertion 1, start samp.py: prompt checked, passed
2022-10-27 16:26:01,052 __main__ INFO -- Start daemons --
2022-10-27 16:26:08,679 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:26:14,268 TADA INFO assertion 2, verify data: verified, passed
2022-10-27 16:26:18,851 TADA INFO assertion 3, samp.py adds set1 / verify data: verified, passed
2022-10-27 16:26:23,447 TADA INFO assertion 4, samp.py removes set1 / verify data: verified, passed
2022-10-27 16:26:28,018 TADA INFO assertion 5, samp.py quickly adds and removes set2 / verify data: verified, passed
2022-10-27 16:26:33,140 TADA INFO assertion 6, agg-1 log stays empty: verified, passed
2022-10-27 16:26:33,141 TADA INFO test quick_set_add_rm_test ended
2022-10-27 16:26:45 INFO: ----------------------------------------------
2022-10-27 16:26:46 INFO: ======== set_array_hang_test ========
2022-10-27 16:26:46 INFO: CMD: python3 set_array_hang_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/set_array_hang_test
2022-10-27 16:26:46,789 TADA INFO starting test `set_array_hang_test`
2022-10-27 16:26:46,789 TADA INFO   test-id: 6d24648f85c1d1e450b031c63c80b18c4c760c0b6dd16b5fe4eb19d56be2fdf4
2022-10-27 16:26:46,789 TADA INFO   test-suite: LDMSD
2022-10-27 16:26:46,789 TADA INFO   test-name: set_array_hang_test
2022-10-27 16:26:46,789 TADA INFO   test-user: narate
2022-10-27 16:26:46,789 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:26:46,790 __main__ INFO -- Get or create the cluster --
2022-10-27 16:26:49,956 __main__ INFO -- Start processes --
2022-10-27 16:26:49,956 __main__ INFO starting interactive set_array_samp.py
2022-10-27 16:26:52,971 TADA INFO assertion 1, start set_array_samp.py: data verified, passed
2022-10-27 16:26:55,989 TADA INFO assertion 2, start set_array_agg.py: data verified, passed
2022-10-27 16:27:03,198 TADA INFO assertion 3, agg update before the 1st sample: data verified, passed
2022-10-27 16:27:10,408 TADA INFO assertion 4, sampling 2 times then agg update: data verified, passed
2022-10-27 16:27:14,013 TADA INFO assertion 5, agg update w/o new sampling: data verified, passed
2022-10-27 16:27:21,222 TADA INFO assertion 6, sampling 5 times then agg update: data verified, passed
2022-10-27 16:27:21,223 TADA INFO test set_array_hang_test ended
2022-10-27 16:27:31 INFO: ----------------------------------------------
2022-10-27 16:27:32 INFO: ======== ldmsd_autointerval_test ========
2022-10-27 16:27:32 INFO: CMD: python3 ldmsd_autointerval_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldmsd_autointerval_test
2022-10-27 16:27:33,502 TADA INFO starting test `ldmsd_autointerval_test`
2022-10-27 16:27:33,502 TADA INFO   test-id: 0f6b7f0c46155f5fad0b07069718b1f0c16f8d7d5169d3defbed507f005c4203
2022-10-27 16:27:33,502 TADA INFO   test-suite: LDMSD
2022-10-27 16:27:33,502 TADA INFO   test-name: ldmsd_autointerval_test
2022-10-27 16:27:33,502 TADA INFO   test-user: narate
2022-10-27 16:27:33,502 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:27:33,503 __main__ INFO -- Get or create the cluster --
2022-10-27 16:27:40,988 __main__ INFO -- Start daemons --
2022-10-27 16:27:44,711 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:27:51,235 TADA INFO assertion 1, start all daemons and interactive controller: OK, passed
2022-10-27 16:27:53,473 TADA INFO assertion 2, verify sampling interval and update hints: verified, passed
2022-10-27 16:27:53,474 __main__ INFO Let them run for a while to collect data ...
2022-10-27 16:28:03,484 __main__ INFO Setting sample interval to 1000000 ...
2022-10-27 16:28:11,726 TADA INFO assertion 3, set and verify 2nd sampling interval / update hints: verified, passed
2022-10-27 16:28:11,726 __main__ INFO Let them run for a while to collect data ...
2022-10-27 16:28:21,729 __main__ INFO Setting sample interval to 2000000 ...
2022-10-27 16:28:29,961 TADA INFO assertion 4, set and verify 3rd sampling interval / update hints: verified, passed
2022-10-27 16:28:29,961 __main__ INFO Let them run for a while to collect data ...
2022-10-27 16:28:40,162 TADA INFO assertion 5, verify SOS data: timestamp differences in SOS show all 3 intervals, passed
2022-10-27 16:28:40,288 TADA INFO assertion 6, verify 'oversampled' in the agg2 log: OK, passed
2022-10-27 16:28:40,289 TADA INFO test ldmsd_autointerval_test ended
2022-10-27 16:28:52 INFO: ----------------------------------------------
2022-10-27 16:28:53 INFO: ======== ldms_record_test ========
2022-10-27 16:28:53 INFO: CMD: python3 ldms_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldms_record_test
2022-10-27 16:28:54,019 TADA INFO starting test `ldms_record_test`
2022-10-27 16:28:54,019 TADA INFO   test-id: 6c97ed8cc381dc3a9ce1af2344bf1f5d38d29c2442f171e0900b3bb3d1005efc
2022-10-27 16:28:54,020 TADA INFO   test-suite: LDMSD
2022-10-27 16:28:54,020 TADA INFO   test-name: ldms_record_test
2022-10-27 16:28:54,020 TADA INFO   test-user: narate
2022-10-27 16:28:54,020 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:28:54,020 __main__ INFO -- Get or create the cluster --
2022-10-27 16:28:57,054 __main__ INFO -- Start daemons --
2022-10-27 16:29:03,332 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:29:05,334 __main__ INFO start record_samp.py and record_agg.py interactive sessions
2022-10-27 16:29:11,370 TADA INFO assertion 1, check record_sampler on record_agg.py: OK, passed
2022-10-27 16:29:11,370 TADA INFO assertion 2, (1st update) check set1 on record_samp.py: OK, passed
2022-10-27 16:29:11,371 TADA INFO assertion 3, (1st update) check set3_p on record_samp.py: OK, passed
2022-10-27 16:29:11,371 TADA INFO assertion 4, (1st update) check set3_c on record_samp.py: OK, passed
2022-10-27 16:29:11,371 TADA INFO assertion 5, (1st update) check set1 on record_agg.py: OK, passed
2022-10-27 16:29:11,371 TADA INFO assertion 6, (1st update) check set3_p on record_agg.py: OK, passed
2022-10-27 16:29:11,372 TADA INFO assertion 7, (1st update) check set3_c on record_agg.py: OK, passed
2022-10-27 16:29:11,372 __main__ INFO 2nd sampling on the sampler...
2022-10-27 16:29:18,581 TADA INFO assertion 8, (2nd update) check set1 on record_samp.py: OK, passed
2022-10-27 16:29:18,582 TADA INFO assertion 9, (2nd update) check set3_p on record_samp.py: OK, passed
2022-10-27 16:29:18,582 TADA INFO assertion 10, (2nd update) check set3_c on record_samp.py: OK, passed
2022-10-27 16:29:18,582 __main__ INFO 2nd update on the aggregator...
2022-10-27 16:29:25,791 TADA INFO assertion 11, (2nd update) check set1 on record_agg.py: OK, passed
2022-10-27 16:29:25,792 TADA INFO assertion 12, (2nd update) check set3_p on record_agg.py: OK, passed
2022-10-27 16:29:25,792 TADA INFO assertion 13, (2nd update) check set3_c on record_agg.py: OK, passed
2022-10-27 16:29:25,792 __main__ INFO 3rd sampling on the sampler...
2022-10-27 16:29:33,001 TADA INFO assertion 14, (3rd update) check set1 on record_samp.py: OK, passed
2022-10-27 16:29:33,002 TADA INFO assertion 15, (3rd update) check set3_p on record_samp.py: OK, passed
2022-10-27 16:29:33,002 TADA INFO assertion 16, (3rd update) check set3_c on record_samp.py: OK, passed
2022-10-27 16:29:33,002 __main__ INFO 3rd update on the aggregator...
2022-10-27 16:29:40,211 TADA INFO assertion 17, (3rd update) check set1 on record_agg.py: OK, passed
2022-10-27 16:29:40,212 TADA INFO assertion 18, (3rd update) check set3_p on record_agg.py: OK, passed
2022-10-27 16:29:40,212 TADA INFO assertion 19, (3rd update) check set3_c on record_agg.py: OK, passed
2022-10-27 16:29:40,212 __main__ INFO 4th sampling on the sampler...
2022-10-27 16:29:47,421 TADA INFO assertion 20, (4th update; record uncahnged) check set1 on record_samp.py: OK, passed
2022-10-27 16:29:47,421 TADA INFO assertion 21, (4th update; record uncahnged) check set3_p on record_samp.py: OK, passed
2022-10-27 16:29:47,421 TADA INFO assertion 22, (4th update; record uncahnged) check set3_c on record_samp.py: OK, passed
2022-10-27 16:29:47,422 __main__ INFO 4th update on the aggregator...
2022-10-27 16:29:54,631 TADA INFO assertion 23, (4th update; record uncahnged) check set1 on record_agg.py: OK, passed
2022-10-27 16:29:54,631 TADA INFO assertion 24, (4th update; record uncahnged) check set3_p on record_agg.py: OK, passed
2022-10-27 16:29:54,632 TADA INFO assertion 25, (4th update; record uncahnged) check set3_c on record_agg.py: OK, passed
2022-10-27 16:29:54,632 __main__ INFO 5th sampling on the sampler...
2022-10-27 16:30:01,840 TADA INFO assertion 26, (5th update; record del) check set1 on record_samp.py: OK, passed
2022-10-27 16:30:01,840 TADA INFO assertion 27, (5th update; record del) check set3_p on record_samp.py: OK, passed
2022-10-27 16:30:01,840 TADA INFO assertion 28, (5th update; record del) check set3_c on record_samp.py: OK, passed
2022-10-27 16:30:01,840 __main__ INFO 5th update on the aggregator...
2022-10-27 16:30:09,049 TADA INFO assertion 29, (5th update; record del) check set1 on record_agg.py: OK, passed
2022-10-27 16:30:09,050 TADA INFO assertion 30, (5th update; record del) check set3_p on record_agg.py: OK, passed
2022-10-27 16:30:09,050 TADA INFO assertion 31, (5th update; record del) check set3_c on record_agg.py: OK, passed
2022-10-27 16:30:09,050 __main__ INFO 6th sampling on the sampler...
2022-10-27 16:30:16,260 TADA INFO assertion 32, (6th update; record unchanged) check set1 on record_samp.py: OK, passed
2022-10-27 16:30:16,260 TADA INFO assertion 33, (6th update; record unchanged) check set3_p on record_samp.py: OK, passed
2022-10-27 16:30:16,260 TADA INFO assertion 34, (6th update; record unchanged) check set3_c on record_samp.py: OK, passed
2022-10-27 16:30:16,261 __main__ INFO 6th update on the updator...
2022-10-27 16:30:23,470 TADA INFO assertion 35, (6th update; record unchanged) check set1 on record_agg.py: OK, passed
2022-10-27 16:30:23,470 TADA INFO assertion 36, (6th update; record unchanged) check set3_p on record_agg.py: OK, passed
2022-10-27 16:30:23,470 TADA INFO assertion 37, (6th update; record unchanged) check set3_c on record_agg.py: OK, passed
2022-10-27 16:30:23,471 TADA INFO test ldms_record_test ended
2022-10-27 16:30:34 INFO: ----------------------------------------------
2022-10-27 16:30:35 INFO: ======== ldms_schema_digest_test ========
2022-10-27 16:30:35 INFO: CMD: python3 ldms_schema_digest_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldms_schema_digest_test
2022-10-27 16:30:35,732 TADA INFO starting test `ldms_schema_digest_test`
2022-10-27 16:30:35,732 TADA INFO   test-id: cd0193d30f07785c60eb06055afc2437150de3dd3fcbec88aa4ef78bda2a1667
2022-10-27 16:30:35,732 TADA INFO   test-suite: LDMSD
2022-10-27 16:30:35,732 TADA INFO   test-name: ldms_schema_digest_test
2022-10-27 16:30:35,732 TADA INFO   test-user: narate
2022-10-27 16:30:35,732 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:30:35,733 __main__ INFO -- Get or create the cluster --
2022-10-27 16:30:43,282 __main__ INFO -- Start daemons --
2022-10-27 16:30:46,523 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:30:51,649 TADA INFO assertion 1, No schema digest from ldms_ls -v sampler: verified, passed
2022-10-27 16:30:51,779 TADA INFO assertion 2, Schema digest from ldms_ls -vv sampler is not empty: verified, passed
2022-10-27 16:30:51,895 TADA INFO assertion 3, Schema digest from ldms_ls -vv agg-1 is not empty: verified, passed
2022-10-27 16:30:52,069 TADA INFO assertion 4, Schema digest from Python ldms dir agg-1 is not empty: verified, passed
2022-10-27 16:30:52,069 TADA INFO assertion 5, Schema digest from Python ldms lokoup agg-1 is not empty: verified, passed
2022-10-27 16:30:52,070 TADA INFO assertion 6, All digests of the same set are the same: , passed
2022-10-27 16:30:54,499 TADA INFO assertion 7, Sets of same schema yield the same digest: check, passed
2022-10-27 16:30:54,499 TADA INFO assertion 8, Different schema (1-off metric) yield different digest: check, passed
2022-10-27 16:30:54,500 TADA INFO test ldms_schema_digest_test ended
2022-10-27 16:31:06 INFO: ----------------------------------------------
2022-10-27 16:31:07 INFO: ======== ldmsd_decomp_test ========
2022-10-27 16:31:07 INFO: CMD: python3 ldmsd_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldmsd_decomp_test
2022-10-27 16:31:08,191 TADA INFO starting test `ldmsd_decomp_test`
2022-10-27 16:31:08,191 TADA INFO   test-id: 2ad8c93a50196c995cbcac4effe8638d2f7469cadbe2e39d20aaae956c3e3fd0
2022-10-27 16:31:08,191 TADA INFO   test-suite: LDMSD
2022-10-27 16:31:08,191 TADA INFO   test-name: ldmsd_decomp_test
2022-10-27 16:31:08,191 TADA INFO   test-user: narate
2022-10-27 16:31:08,191 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:31:08,192 __main__ INFO -- Get or create the cluster --
2022-10-27 16:31:23,861 __main__ INFO -- Start daemons --
2022-10-27 16:31:34,118 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:32:28,793 TADA INFO assertion 1, `as_is` decomposition, test_sampler_8d2b8bd sos schema check: OK, passed
2022-10-27 16:32:28,793 TADA INFO assertion 2, `as_is` decomposition, test_sampler_95772b6 sos schema check: OK, passed
2022-10-27 16:32:28,793 TADA INFO assertion 3, `as_is` decomposition, record_sampler_e1f021f sos schema check: OK, passed
2022-10-27 16:32:28,793 TADA INFO assertion 4, `static` decomposition, fill sos schema check: OK, passed
2022-10-27 16:32:28,793 TADA INFO assertion 5, `static` decomposition, filter sos schema check: OK, passed
2022-10-27 16:32:28,794 TADA INFO assertion 6, `static` decomposition, record sos schema check: OK, passed
2022-10-27 16:32:28,794 TADA INFO assertion 7, `as_is` decomposition, test_sampler_8d2b8bd csv schema check: OK, passed
2022-10-27 16:32:28,794 TADA INFO assertion 8, `as_is` decomposition, test_sampler_95772b6 csv schema check: OK, passed
2022-10-27 16:32:28,794 TADA INFO assertion 9, `as_is` decomposition, record_sampler_e1f021f csv schema check: OK, passed
2022-10-27 16:32:28,794 TADA INFO assertion 10, `static` decomposition, fill csv schema check: OK, passed
2022-10-27 16:32:28,795 TADA INFO assertion 11, `static` decomposition, filter csv schema check: OK, passed
2022-10-27 16:32:28,795 TADA INFO assertion 12, `static` decomposition, record csv schema check: OK, passed
2022-10-27 16:32:28,795 TADA INFO assertion 13, `as_is` decomposition, test_sampler_8d2b8bd kafka schema check: OK, passed
2022-10-27 16:32:28,795 TADA INFO assertion 14, `as_is` decomposition, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-27 16:32:28,795 TADA INFO assertion 15, `as_is` decomposition, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-27 16:32:28,795 TADA INFO assertion 16, `static` decomposition, fill kafka schema check: OK, passed
2022-10-27 16:32:28,796 TADA INFO assertion 17, `static` decomposition, filter kafka schema check: OK, passed
2022-10-27 16:32:28,796 TADA INFO assertion 18, `static` decomposition, record kafka schema check: OK, passed
2022-10-27 16:32:28,797 TADA INFO assertion 19, `as_is` decomposition, test_sampler_8d2b8bd sos data check: OK, passed
2022-10-27 16:32:28,798 TADA INFO assertion 20, `as_is` decomposition, test_sampler_95772b6 sos data check: OK, passed
2022-10-27 16:32:28,866 TADA INFO assertion 21, `as_is` decomposition, record_sampler_e1f021f sos data check: OK, passed
2022-10-27 16:32:28,870 TADA INFO assertion 22, `static` decomposition, fill sos data check: OK, passed
2022-10-27 16:32:28,873 TADA INFO assertion 23, `static` decomposition, filter sos data check: OK, passed
2022-10-27 16:32:28,880 TADA INFO assertion 24, `static` decomposition, record sos data check: OK, passed
2022-10-27 16:32:28,882 TADA INFO assertion 25, `as_is` decomposition, test_sampler_8d2b8bd csv data check: OK, passed
2022-10-27 16:32:28,883 TADA INFO assertion 26, `as_is` decomposition, test_sampler_95772b6 csv data check: OK, passed
2022-10-27 16:32:28,954 TADA INFO assertion 27, `as_is` decomposition, record_sampler_e1f021f csv data check: OK, passed
2022-10-27 16:32:28,958 TADA INFO assertion 28, `static` decomposition, fill csv data check: OK, passed
2022-10-27 16:32:28,960 TADA INFO assertion 29, `static` decomposition, filter csv data check: OK, passed
2022-10-27 16:32:28,968 TADA INFO assertion 30, `static` decomposition, record csv data check: OK, passed
2022-10-27 16:32:28,969 TADA INFO assertion 31, `as_is` decomposition, test_sampler_8d2b8bd kafka data check: OK, passed
2022-10-27 16:32:28,969 TADA INFO assertion 32, `as_is` decomposition, test_sampler_95772b6 kafka data check: OK, passed
2022-10-27 16:32:28,997 TADA INFO assertion 33, `as_is` decomposition, record_sampler_e1f021f kafka data check: OK, passed
2022-10-27 16:32:28,999 TADA INFO assertion 34, `static` decomposition, fill kafka data check: OK, passed
2022-10-27 16:32:29,001 TADA INFO assertion 35, `static` decomposition, filter kafka data check: OK, passed
2022-10-27 16:32:29,006 TADA INFO assertion 36, `static` decomposition, record kafka data check: OK, passed
2022-10-27 16:32:29,006 TADA INFO test ldmsd_decomp_test ended
2022-10-27 16:32:29,007 TADA INFO test ldmsd_decomp_test ended
2022-10-27 16:32:44 INFO: ----------------------------------------------
2022-10-27 16:32:45 INFO: ======== ldmsd_stream_dir_test ========
2022-10-27 16:32:45 INFO: CMD: python3 ldmsd_stream_dir_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldmsd_stream_dir_test
2022-10-27 16:32:45,734 __main__ INFO -- Get or create the cluster --
2022-10-27 16:32:45,734 TADA INFO starting test `ldmsd_stream_dir`
2022-10-27 16:32:45,734 TADA INFO   test-id: ae73ae3950246acdc97fa3802e88b6568a9c310c72459d2cbdba0eb58b004660
2022-10-27 16:32:45,734 TADA INFO   test-suite: LDMSD
2022-10-27 16:32:45,734 TADA INFO   test-name: ldmsd_stream_dir
2022-10-27 16:32:45,734 TADA INFO   test-user: narate
2022-10-27 16:32:45,734 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:32:54,173 __main__ INFO -- Start daemons --
2022-10-27 16:32:57,940 __main__ INFO waiting ... for all LDMSDs to start
2022-10-27 16:32:58,245 __main__ INFO All LDMSDs are up.
2022-10-27 16:32:59,479 TADA INFO assertion 1, No Stream data: {} == {}, passed
2022-10-27 16:33:00,803 TADA INFO assertion 2, stream_dir -- one stream message: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666906379, 'last_ts': 1666906379, 'count': 1, 'total_bytes': 6}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666906379, 'last_ts': 1666906379, 'count': 1, 'total_bytes': 6}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1666906379, 'last_ts': 1666906379}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 1, 'total_bytes': 6, 'first_ts': 1666906379, 'last_ts': 1666906379}}}, passed
2022-10-27 16:33:03,226 TADA INFO assertion 3, stream_dir --  multiple stream messages: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666906379, 'last_ts': 1666906381, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.5, 'bytes/sec': 9.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666906379, 'last_ts': 1666906381, 'count': 3, 'total_bytes': 18, 'msg/sec': 1.5, 'bytes/sec': 9.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666906379, 'last_ts': 1666906381, 'bytes/sec': 9.0, 'msg/sec': 1.5}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666906379, 'last_ts': 1666906381, 'bytes/sec': 9.0, 'msg/sec': 1.5}}}, passed
2022-10-27 16:33:04,452 TADA INFO assertion 4, prdcr_stream_dir to agg -- one producer: {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.5, 'total_bytes': 18, 'last_ts': 1666906381, 'first_ts': 1666906379, 'bytes/sec': 9.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'msg/sec': 1.5, 'total_bytes': 18, 'last_ts': 1666906381, 'first_ts': 1666906379, 'bytes/sec': 9.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666906379, 'last_ts': 1666906381, 'bytes/sec': 9.0, 'msg/sec': 1.5}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666906379, 'last_ts': 1666906381, 'bytes/sec': 9.0, 'msg/sec': 1.5}}}}, passed
2022-10-27 16:33:08,253 TADA INFO assertion 5, stream_dir -- mulitple streams: {'bar': {'mode': 'not subscribed', 'info': {'first_ts': 1666906385, 'last_ts': 1666906387, 'count': 3, 'total_bytes': 48, 'msg/sec': 1.5, 'bytes/sec': 24.0}, 'publishers': {}}, 'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666906384, 'last_ts': 1666906385, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {}}, '_AGGREGATED_': {'info': {'first_ts': 1666906384, 'last_ts': 1666906387, 'count': 5, 'total_bytes': 60, 'msg/sec': 1.666667, 'bytes/sec': 20.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666906384, 'last_ts': 1666906385, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {}}, 'bar': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1666906385, 'last_ts': 1666906387, 'bytes/sec': 24.0, 'msg/sec': 1.5}, 'publishers': {}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1666906384, 'last_ts': 1666906387, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}, passed
2022-10-27 16:33:09,464 TADA INFO assertion 6, prdcr_stream_dir to agg -- two producers: {'foo': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 2.0, 'total_bytes': 12, 'last_ts': 1666906385, 'first_ts': 1666906384, 'bytes/sec': 12.0, 'count': 2}}, 'samplerd-1': {'mode': 'not subscribed', 'info': {'msg/sec': 1.5, 'total_bytes': 18, 'last_ts': 1666906381, 'first_ts': 1666906379, 'bytes/sec': 9.0, 'count': 3}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'msg/sec': 1.5, 'total_bytes': 48, 'last_ts': 1666906387, 'first_ts': 1666906385, 'bytes/sec': 24.0, 'count': 3}}}, '_AGGREGATED_': {'samplerd-2': {'info': {'msg/sec': 1.666667, 'total_bytes': 60, 'last_ts': 1666906387, 'first_ts': 1666906384, 'bytes/sec': 20.0, 'count': 5}}, 'samplerd-1': {'info': {'msg/sec': 1.5, 'total_bytes': 18, 'last_ts': 1666906381, 'first_ts': 1666906379, 'bytes/sec': 9.0, 'count': 3}}}} == {'foo': {'samplerd-1': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666906379, 'last_ts': 1666906381, 'bytes/sec': 9.0, 'msg/sec': 1.5}}, 'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666906384, 'last_ts': 1666906385, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, 'bar': {'samplerd-2': {'mode': 'not subscribed', 'info': {'count': 3, 'total_bytes': 48, 'first_ts': 1666906385, 'last_ts': 1666906387, 'bytes/sec': 24.0, 'msg/sec': 1.5}}}, '_AGGREGATED_': {'samplerd-1': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666906379, 'last_ts': 1666906381, 'bytes/sec': 9.0, 'msg/sec': 1.5}}, 'samplerd-2': {'info': {'count': 5, 'total_bytes': 60, 'first_ts': 1666906384, 'last_ts': 1666906387, 'bytes/sec': 20.0, 'msg/sec': 1.666667}}}}, passed
2022-10-27 16:33:13,142 TADA INFO assertion 7, stream_dir to agg after one producer republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666906390, 'last_ts': 1666906391, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1666906390, 'last_ts': 1666906391, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}}}, '_AGGREGATED_': {'info': {'first_ts': 1666906390, 'last_ts': 1666906391, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666906390, 'last_ts': 1666906391, 'bytes/sec': 12.0, 'msg/sec': 2.0}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666906390, 'last_ts': 1666906391, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}}, '_AGGREGATED_': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666906390, 'last_ts': 1666906391, 'bytes/sec': 12.0, 'msg/sec': 2.0}}}, passed
2022-10-27 16:33:14,699 TADA INFO assertion 8, stream_dir to agg after two producers republished stream: {'foo': {'mode': 'not subscribed', 'info': {'first_ts': 1666906390, 'last_ts': 1666906393, 'count': 5, 'total_bytes': 30, 'msg/sec': 1.666667, 'bytes/sec': 10.0}, 'publishers': {'samplerd-1': {'info': {'first_ts': 1666906390, 'last_ts': 1666906391, 'count': 2, 'total_bytes': 12, 'msg/sec': 2.0, 'bytes/sec': 12.0}}, 'samplerd-2': {'info': {'first_ts': 1666906393, 'last_ts': 1666906393, 'count': 3, 'total_bytes': 18}}}}, '_AGGREGATED_': {'info': {'first_ts': 1666906390, 'last_ts': 1666906393, 'count': 5, 'total_bytes': 30, 'msg/sec': 1.666667, 'bytes/sec': 10.0}}} == {'foo': {'mode': 'not subscribed', 'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1666906390, 'last_ts': 1666906393, 'bytes/sec': 10.0, 'msg/sec': 1.666667}, 'publishers': {'samplerd-1': {'info': {'count': 2, 'total_bytes': 12, 'first_ts': 1666906390, 'last_ts': 1666906391, 'bytes/sec': 12.0, 'msg/sec': 2.0}}, 'samplerd-2': {'info': {'count': 3, 'total_bytes': 18, 'first_ts': 1666906393, 'last_ts': 1666906393}}}}, '_AGGREGATED_': {'info': {'count': 5, 'total_bytes': 30, 'first_ts': 1666906390, 'last_ts': 1666906393, 'bytes/sec': 10.0, 'msg/sec': 1.666667}}}, passed
2022-10-27 16:33:14,700 TADA INFO test ldmsd_stream_dir ended
2022-10-27 16:33:26 INFO: ----------------------------------------------
2022-10-27 16:33:27 INFO: ======== store_list_record_test ========
2022-10-27 16:33:27 INFO: CMD: python3 store_list_record_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/store_list_record_test
2022-10-27 16:33:28,283 __main__ INFO -- Get or create the cluster --
2022-10-27 16:33:28,283 TADA INFO starting test `store_sos_lists_test`
2022-10-27 16:33:28,283 TADA INFO   test-id: 4e4ff0c370738ad52afa45f492219a664dcb42c1fa7b63505ed98c572b55bf53
2022-10-27 16:33:28,283 TADA INFO   test-suite: LDMSD
2022-10-27 16:33:28,284 TADA INFO   test-name: store_sos_lists_test
2022-10-27 16:33:28,284 TADA INFO   test-user: narate
2022-10-27 16:33:28,284 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:33:35,644 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:33:39,419 __main__ INFO All sampler daemons are up.
2022-10-27 16:33:39,527 TADA INFO assertion 1, aggregator with store_sos has started properly.: agg_sos.check_ldmsd(), passed
2022-10-27 16:33:39,640 TADA INFO assertion 2, aggregator with store_csv has started properly.: agg_csv.check_ldmsd(), passed
2022-10-27 16:33:52,201 TADA INFO assertion 3, store_sos is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-27 16:33:55,573 TADA INFO assertion 4, store_sos stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-27 16:34:04,435 TADA INFO assertion 5, store_sos stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-27 16:34:05,860 TADA INFO assertion 6, store_csv is storing data.: agg.file_exists(a) for a in db_paths, passed
2022-10-27 16:34:17,110 TADA INFO assertion 7, store_csv stores data correctly.: verify_data(db) for db in all_db, passed
2022-10-27 16:34:26,707 TADA INFO assertion 8, store_csv stores data after restarted correctly.: verify_data(db) for db in all_db, passed
2022-10-27 16:34:26,707 TADA INFO test store_sos_lists_test ended
2022-10-27 16:34:40 INFO: ----------------------------------------------
2022-10-27 16:34:40 INFO: ======== maestro_raft_test ========
2022-10-27 16:34:40 INFO: CMD: python3 maestro_raft_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/maestro_raft_test
2022-10-27 16:34:41,576 TADA INFO starting test `maestro_raft_test`
2022-10-27 16:34:41,577 TADA INFO   test-id: 6262b40ed666f4b02ff13c6fa163f9d9ccf76f8001eab44c8ac7313a7c31db67
2022-10-27 16:34:41,577 TADA INFO   test-suite: LDMSD
2022-10-27 16:34:41,577 TADA INFO   test-name: maestro_raft_test
2022-10-27 16:34:41,577 TADA INFO   test-user: narate
2022-10-27 16:34:41,577 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:34:51,588 __main__ INFO -- Get or create cluster --
2022-10-27 16:35:26,191 __main__ INFO -- Start daemons --
2022-10-27 16:36:37,304 __main__ INFO -- making known hosts (ssh) --
2022-10-27 16:36:44,205 __main__ INFO ... make sure ldmsd's are up
2022-10-27 16:36:59,079 TADA INFO assertion 1, Statuses of maestros, 1 leader + 2 followers: [('FOLLOWER', 2), ('LEADER', 1)], passed
2022-10-27 16:37:11,461 TADA INFO assertion 2, All ldmsds are up and configured: sets verified, passed
2022-10-27 16:37:11,749 TADA INFO assertion 3, Data are being stored: data check, passed
2022-10-27 16:37:16,642 TADA INFO assertion 4, New leader elected: checked, passed
2022-10-27 16:37:28,401 TADA INFO assertion 5, Restarted ldmsd is configured: sets verified, passed
2022-10-27 16:37:28,678 TADA INFO assertion 6, New data are presented in the store: data check, passed
2022-10-27 16:37:39,671 TADA INFO assertion 7, The restarted maestro becomes a follower: checked, passed
---Wait for config to write to file---
2022-10-27 16:37:39,672 TADA INFO test maestro_raft_test ended
2022-10-27 16:38:01 INFO: ----------------------------------------------
2022-10-27 16:38:01 INFO: ======== ovis_json_test ========
2022-10-27 16:38:01 INFO: CMD: python3 ovis_json_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ovis_json_test
2022-10-27 16:38:02,624 __main__ INFO -- Create the cluster -- 
2022-10-27 16:38:07,991 TADA INFO starting test `ovis_json_test`
2022-10-27 16:38:07,992 TADA INFO   test-id: 2628a84fc92424cfab191313f464fc9267af2a8842d40b50fbc41c0e9189cea4
2022-10-27 16:38:07,992 TADA INFO   test-suite: OVIS-LIB
2022-10-27 16:38:07,992 TADA INFO   test-name: ovis_json_test
2022-10-27 16:38:07,992 TADA INFO   test-user: narate
2022-10-27 16:38:07,992 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:38:07,993 TADA INFO assertion 1, Test creating a JSON integer entity: (type is JSON_INT_VALUE) && (1 == e->value.int_), passed
2022-10-27 16:38:07,993 TADA INFO assertion 2, Test creating a JSON boolean entity: (type is JSON_BOOL_VALUE) && (1 == e->value.bool_), passed
2022-10-27 16:38:07,993 TADA INFO assertion 3, Test creating a JSON float entity: (type is JSON_FLOAT_VALUE) && (1.1 == e->value.double_), passed
2022-10-27 16:38:07,993 TADA INFO assertion 4, Test creating a JSON string entity: (type is JSON_STRING_VALUE) && (foo == e->value.str_->str), passed
2022-10-27 16:38:07,993 TADA INFO assertion 5, Test creating a JSON attribute entity: (type is JSON_ATTR_VALUE) && (name == <attr name>) && (value == <attr value>), passed
2022-10-27 16:38:07,994 TADA INFO assertion 6, Test creating a JSON list entity: (type is JSON_LIST_VALUE) && (0 == Number of elements) && (list is empty), passed
2022-10-27 16:38:07,994 TADA INFO assertion 7, Test creating a JSON dictionary entity: (type is JSON_DICT_VALUE) && (dict table is empty), passed
2022-10-27 16:38:07,994 TADA INFO assertion 8, Test creating a JSON null entity: (type is JSON_NULL_VALUE) && (0 == e->value.int_), passed
2022-10-27 16:38:07,994 TADA INFO assertion 9, Test parsing a JSON integer string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 16:38:07,994 TADA INFO assertion 10, Test parsing a JSON false boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 16:38:07,994 TADA INFO assertion 11, Test parsing a JSON true boolean string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 16:38:07,994 TADA INFO assertion 12, Test parsing a JSON float string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 16:38:07,994 TADA INFO assertion 13, Test parsing a JSON string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 16:38:07,995 TADA INFO assertion 15, Test parsing a JSON dict string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 16:38:07,995 TADA INFO assertion 16, Test parsing a JSON null string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 16:38:07,995 TADA INFO assertion 17, Test parsing an invalid string: (0 == json_parse_buffer()) && is_same_entity(expected, o), passed
2022-10-27 16:38:07,995 TADA INFO assertion 17, Test parsing an invalid string: 0 != json_parse_buffer(), passed
2022-10-27 16:38:07,995 TADA INFO assertion 18, Test dumping a JSON integer entity: 1 == 1, passed
2022-10-27 16:38:07,995 TADA INFO assertion 19, Test dumping a JSON false boolean entity: false == false, passed
2022-10-27 16:38:07,996 TADA INFO assertion 20, Test dumping a JSON true boolean entity: true == true, passed
2022-10-27 16:38:07,996 TADA INFO assertion 21, Test dumping a JSON float entity: 1.100000 == 1.100000, passed
2022-10-27 16:38:07,996 TADA INFO assertion 22, Test dumping a JSON string entity: "foo" == "foo", passed
2022-10-27 16:38:07,996 TADA INFO assertion 23, Test dumping a JSON attr entity: "name":"foo" == jb->buf, passed
2022-10-27 16:38:07,996 TADA INFO assertion 24, Test dumping a JSON list entity: [1,false,1.100000,"foo",[],{},null] == [1,false,1.100000,"foo",[],{},null], passed
2022-10-27 16:38:07,996 TADA INFO assertion 25, Test dumping a JSON dict entity: {"int":1,"bool":true,"float":1.100000,"string":"foo","list":[1,false,1.100000,"foo",[],{},null],"dict":{"attr_1":"value_1"},"null":null} == {"null":null,"list":[1,false,1.100000,"foo",[],{},null],"string":"foo","float":1.100000,"bool":true,"dict":{"attr_1":"value_1"},"int":1}, passed
2022-10-27 16:38:07,996 TADA INFO assertion 26, Test dumping a JSON null entity: null == null, passed
2022-10-27 16:38:07,997 TADA INFO assertion 27, Test dumping a JSON entity to a non-empty jbuf: This is a book."FOO" == This is a book."FOO", passed
2022-10-27 16:38:07,997 TADA INFO assertion 28, Test copying a JSON integer entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,997 TADA INFO assertion 29, Test copying a JSON false boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,997 TADA INFO assertion 30, Test copying a JSON true boolean entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,997 TADA INFO assertion 31, Test copying a JSON float entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,997 TADA INFO assertion 32, Test copying a JSON string entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,997 TADA INFO assertion 33, Test copying a JSON attribute entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,998 TADA INFO assertion 34, Test copying a JSON list entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,998 TADA INFO assertion 35, Test copying a JSON dict entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,998 TADA INFO assertion 36, Test copying a JSON null entity: is_same_entity(expected, json_entity_copy(expected), passed
2022-10-27 16:38:07,998 TADA INFO assertion 37, Test obtaining the number of attributes: 7 == json_attr_count(dict), passed
2022-10-27 16:38:07,998 TADA INFO assertion 38, Test finding an existing attribute: 0 != json_attr_find(), passed
2022-10-27 16:38:07,998 TADA INFO assertion 39, Test finding a non-existng attribute: 0 == json_attr_find(), passed
2022-10-27 16:38:07,998 TADA INFO assertion 40, Test finding the value of an existing attribute: 0 != json_value_find(), passed
2022-10-27 16:38:07,999 TADA INFO assertion 41, Test finding the value of a non-existing attribute: 0 == json_value_find(), passed
2022-10-27 16:38:07,999 TADA INFO assertion 42, Test adding a new attribute to a dictionary: (0 == json_attr_add() && (0 != json_attr_find()), passed
2022-10-27 16:38:07,999 TADA INFO assertion 43, Test replacing the value of an existing attribute: (0 == json_attr_add()) && (0 != json_value_find()) && (is_same_entity(old_v, new_v)), passed
2022-10-27 16:38:07,999 TADA INFO assertion 44, Test removing an existing attribute: (0 = json_attr_rem()) && (0 == json_attr_find()), passed
2022-10-27 16:38:07,999 TADA INFO assertion 45, Test removing a non-existing attribute: (ENOENT == json_attr_rem()), passed
2022-10-27 16:38:07,999 TADA INFO assertion 46, Test creating a dictionary by json_dict_build: expected == json_dict_build(...), passed
2022-10-27 16:38:08,000 TADA INFO assertion 47, Test adding attributes and replacing attribute values by json_dict_build: expected == json_dict_build(d, ...), passed
2022-10-27 16:38:08,000 TADA INFO assertion 48, Test json_dict_merge(): The merged dictionary is correct., passed
2022-10-27 16:38:08,000 TADA INFO assertion 49, Test json_list_len(): 7 == json_list_len(), passed
2022-10-27 16:38:08,000 TADA INFO assertion 50, Test adding items to a list: 0 == strcmp(exp_str, json_entity_dump(l)->buf, passed
2022-10-27 16:38:08,000 TADA INFO assertion 51, Test removing an existing item by json_item_rem(): 0 == json_item_rem(), passed
2022-10-27 16:38:08,000 TADA INFO assertion 52, Test removing a non-existing item by json_item_rem(): ENOENT == json_item_rem(), passed
2022-10-27 16:38:08,000 TADA INFO assertion 53, Test popping an existing item from a list by json_item_pop(): NULL == json_item_pop(len + 3), passed
2022-10-27 16:38:08,001 TADA INFO assertion 54, Test popping a non-existing item from a list by json_item_pop(): NULL != json_item_pop(len - 1), passed
2022-10-27 16:38:08,001 TADA INFO test ovis_json_test ended
2022-10-27 16:38:18 INFO: ----------------------------------------------
2022-10-27 16:38:19 INFO: ======== updtr_add_test ========
2022-10-27 16:38:19 INFO: CMD: python3 updtr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/updtr_add_test
2022-10-27 16:38:20,332 __main__ INFO -- Get or create the cluster --
2022-10-27 16:38:20,332 TADA INFO starting test `updtr_add test`
2022-10-27 16:38:20,333 TADA INFO   test-id: 7caae2c96ef73d9e478cc8fda6c10c72d82b4f6e08b1629767479f597a4f5c64
2022-10-27 16:38:20,333 TADA INFO   test-suite: LDMSD
2022-10-27 16:38:20,333 TADA INFO   test-name: updtr_add test
2022-10-27 16:38:20,333 TADA INFO   test-user: narate
2022-10-27 16:38:20,333 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:38:28,547 __main__ INFO -- Start daemons --
2022-10-27 16:38:32,320 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:38:32,639 __main__ INFO All LDMSDs are up.
2022-10-27 16:38:33,864 TADA INFO assertion 1, Add an updater with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:38:35,099 TADA INFO assertion 2, Add an updater with a zero interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:38:36,318 TADA INFO assertion 3, Add an updater with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:38:37,532 TADA INFO assertion 4, Add an updater with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-27 16:38:38,746 TADA INFO assertion 5, Add an updater with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:38:41,184 TADA INFO assertion 6, Add an updater without an offset: report(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'without_offset', 'interval': '1000000', 'offset': '0', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 16:38:43,619 TADA INFO assertion 7, Add an updater with a valid offset: report(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'with_offset', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 16:38:44,830 TADA INFO assertion 8, Add an updater with an existing name: report(rc = 17) == expect(rc = 17), passed
2022-10-27 16:38:44,830 __main__ INFO --- done ---
2022-10-27 16:38:44,831 TADA INFO test updtr_add test ended
2022-10-27 16:38:57 INFO: ----------------------------------------------
2022-10-27 16:38:57 INFO: ======== updtr_del_test ========
2022-10-27 16:38:57 INFO: CMD: python3 updtr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/updtr_del_test
2022-10-27 16:38:58,572 __main__ INFO -- Get or create the cluster --
2022-10-27 16:38:58,572 TADA INFO starting test `updtr_add test`
2022-10-27 16:38:58,572 TADA INFO   test-id: 94eaa7e5471585cd1b497a8929f065f232d9f02ccd0c509c56df31f8801f0550
2022-10-27 16:38:58,572 TADA INFO   test-suite: LDMSD
2022-10-27 16:38:58,572 TADA INFO   test-name: updtr_add test
2022-10-27 16:38:58,572 TADA INFO   test-user: narate
2022-10-27 16:38:58,572 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:39:06,347 __main__ INFO -- Start daemons --
2022-10-27 16:39:10,067 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:39:10,373 __main__ INFO All LDMSDs are up.
2022-10-27 16:39:11,585 TADA INFO assertion 1, updtr_del a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 16:39:12,803 TADA INFO assertion 2, updtr_del a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 16:39:14,008 TADA INFO assertion 3, updtr_del a stopped updater: report(rc = 0) == expect(rc = 0), passed
2022-10-27 16:39:15,219 TADA INFO assertion 4, updtr_del a just-added updater: report(rc = 0) == expect(rc = 0), passed
2022-10-27 16:39:15,220 __main__ INFO --- done ---
2022-10-27 16:39:15,220 TADA INFO test updtr_add test ended
2022-10-27 16:39:27 INFO: ----------------------------------------------
2022-10-27 16:39:28 INFO: ======== updtr_match_add_test ========
2022-10-27 16:39:28 INFO: CMD: python3 updtr_match_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/updtr_match_add_test
2022-10-27 16:39:28,942 __main__ INFO -- Get or create the cluster --
2022-10-27 16:39:28,943 TADA INFO starting test `updtr_add test`
2022-10-27 16:39:28,943 TADA INFO   test-id: 13185d3a72c4ea72b58b78d351f28ae27acd712ab060572501f767ea6b4503d7
2022-10-27 16:39:28,943 TADA INFO   test-suite: LDMSD
2022-10-27 16:39:28,943 TADA INFO   test-name: updtr_add test
2022-10-27 16:39:28,943 TADA INFO   test-user: narate
2022-10-27 16:39:28,943 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:39:36,768 __main__ INFO -- Start daemons --
2022-10-27 16:39:40,467 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:39:40,768 __main__ INFO All LDMSDs are up.
2022-10-27 16:39:41,978 TADA INFO assertion 1, updtr_match_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:39:43,198 TADA INFO assertion 2, updtr_match_add with an invalid match: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:39:44,409 TADA INFO assertion 3, updtr_match_add of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 16:39:45,630 TADA INFO assertion 4, A success updtr_match_add: report(rc = 0) == expect(rc = 0), passed
2022-10-27 16:39:46,834 TADA INFO assertion 5, updtr_match_add of a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 16:39:46,834 __main__ INFO --- done ---
2022-10-27 16:39:46,835 TADA INFO test updtr_add test ended
2022-10-27 16:39:58 INFO: ----------------------------------------------
2022-10-27 16:39:59 INFO: ======== updtr_match_del_test ========
2022-10-27 16:39:59 INFO: CMD: python3 updtr_match_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/updtr_match_del_test
2022-10-27 16:40:00,529 __main__ INFO -- Get or create the cluster --
2022-10-27 16:40:00,530 TADA INFO starting test `updtr_add test`
2022-10-27 16:40:00,530 TADA INFO   test-id: 724df46692aab4d880f495ff6be53b6a2ce9b5351949e808a3026ae0488dd253
2022-10-27 16:40:00,530 TADA INFO   test-suite: LDMSD
2022-10-27 16:40:00,530 TADA INFO   test-name: updtr_add test
2022-10-27 16:40:00,530 TADA INFO   test-user: narate
2022-10-27 16:40:00,530 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:40:08,374 __main__ INFO -- Start daemons --
2022-10-27 16:40:12,051 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:40:12,379 __main__ INFO All LDMSDs are up.
2022-10-27 16:40:13,605 TADA INFO assertion 1, Send updtr_match_del with an invalid regex: report(rc = 2) == expect(rc = 22), passed
2022-10-27 16:40:14,815 TADA INFO assertion 2, Send updtr_match_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 16:40:16,033 TADA INFO assertion 3, Send updtr_match_del with a non-existing inst match: report(rc = 2) == expect(rc = 2), passed
2022-10-27 16:40:17,251 TADA INFO assertion 4, Send updtr_match_del with a non-existing schema match: report(rc = 2) == expect(rc = 2), passed
2022-10-27 16:40:18,461 TADA INFO assertion 5, Send updater_match_del with an invalid match type: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:40:19,681 TADA INFO assertion 6, Send updater_match_del with a valid regex of the inst type: report(rc = 0) == expect(rc = 0), passed
2022-10-27 16:40:20,913 TADA INFO assertion 7, Send updater_match_del with a valid regex of the schema type: report(rc = 0) == expect(rc = 0), passed
2022-10-27 16:40:20,913 __main__ INFO --- done ---
2022-10-27 16:40:20,913 TADA INFO test updtr_add test ended
2022-10-27 16:40:33 INFO: ----------------------------------------------
2022-10-27 16:40:33 INFO: ======== updtr_prdcr_add_test ========
2022-10-27 16:40:33 INFO: CMD: python3 updtr_prdcr_add_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/updtr_prdcr_add_test
2022-10-27 16:40:34,669 __main__ INFO -- Get or create the cluster --
2022-10-27 16:40:34,669 TADA INFO starting test `updtr_add test`
2022-10-27 16:40:34,670 TADA INFO   test-id: 1122075a74edbc39fb11e249ecce3faa7e5c51564714ae45e551bbc278ffc5ca
2022-10-27 16:40:34,670 TADA INFO   test-suite: LDMSD
2022-10-27 16:40:34,670 TADA INFO   test-name: updtr_add test
2022-10-27 16:40:34,670 TADA INFO   test-user: narate
2022-10-27 16:40:34,670 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:40:42,456 __main__ INFO -- Start daemons --
2022-10-27 16:40:46,102 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:40:46,390 __main__ INFO All LDMSDs are up.
2022-10-27 16:40:47,594 TADA INFO assertion 1, Send updtr_prdcr_add with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:40:50,013 TADA INFO assertion 2, Send updtr_prdcr_add with a regex matching no prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': []}]), passed
2022-10-27 16:40:52,430 TADA INFO assertion 3, Send updtr_prdcdr_add with a regex matching some prdcrs: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 16:40:53,641 TADA INFO assertion 4, Send updtr_prdcdr_add to a running updtr: report(rc = 16) == expect(rc = 16), passed
2022-10-27 16:40:54,850 TADA INFO assertion 5, Send updtr_prdcr_add to a not-existing updtr: report(rc = 2) == expect(rc = 2), passed
2022-10-27 16:40:54,850 __main__ INFO --- done ---
2022-10-27 16:40:54,850 TADA INFO test updtr_add test ended
2022-10-27 16:41:06 INFO: ----------------------------------------------
2022-10-27 16:41:07 INFO: ======== updtr_prdcr_del_test ========
2022-10-27 16:41:07 INFO: CMD: python3 updtr_prdcr_del_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/updtr_prdcr_del_test
2022-10-27 16:41:08,512 __main__ INFO -- Get or create the cluster --
2022-10-27 16:41:08,513 TADA INFO starting test `updtr_add test`
2022-10-27 16:41:08,513 TADA INFO   test-id: 3a72b77c1884ab02da0fd0087e0b48065643f7a680ac226d07b3d350f1dc1138
2022-10-27 16:41:08,513 TADA INFO   test-suite: LDMSD
2022-10-27 16:41:08,513 TADA INFO   test-name: updtr_add test
2022-10-27 16:41:08,513 TADA INFO   test-user: narate
2022-10-27 16:41:08,513 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:41:16,398 __main__ INFO -- Start daemons --
2022-10-27 16:41:20,071 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:41:20,399 __main__ INFO All LDMSDs are up.
2022-10-27 16:41:21,612 TADA INFO assertion 1, Send updtr_prdcr_del with an invalid regex: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:41:22,833 TADA INFO assertion 2, Send updtr_prdcr_del to a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 16:41:24,049 TADA INFO assertion 3, Send updtr_prdcr_del to a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 16:41:26,500 TADA INFO assertion 4, Send updtr_prdcr_del successfully: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}], passed
2022-10-27 16:41:26,500 __main__ INFO --- done ---
2022-10-27 16:41:26,500 TADA INFO test updtr_add test ended
2022-10-27 16:41:38 INFO: ----------------------------------------------
2022-10-27 16:41:39 INFO: ======== updtr_start_test ========
2022-10-27 16:41:39 INFO: CMD: python3 updtr_start_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/updtr_start_test
2022-10-27 16:41:40,136 __main__ INFO -- Get or create the cluster --
2022-10-27 16:41:40,136 TADA INFO starting test `updtr_add test`
2022-10-27 16:41:40,136 TADA INFO   test-id: 46fae37b0744c4aff5d0c4fdb97eb170edbbcbf63954cda69a4c913cc5e1cacc
2022-10-27 16:41:40,136 TADA INFO   test-suite: LDMSD
2022-10-27 16:41:40,136 TADA INFO   test-name: updtr_add test
2022-10-27 16:41:40,136 TADA INFO   test-user: narate
2022-10-27 16:41:40,137 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:41:47,893 __main__ INFO -- Start daemons --
2022-10-27 16:41:51,531 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:41:51,844 __main__ INFO All LDMSDs are up.
2022-10-27 16:41:53,066 TADA INFO assertion 1, updtr_start with a negative interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:41:54,278 TADA INFO assertion 2, updtr_start with an alphabet interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:41:55,494 TADA INFO assertion 3, updtr_start with a negative offset: report(rc = 0) == expect(rc = 0), passed
2022-10-27 16:41:56,714 TADA INFO assertion 4, updtr_start with an alphabet offset: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:41:57,950 TADA INFO assertion 5, updtr_start without an offset larger than interval: report(rc = 22) == expect(rc = 22), passed
2022-10-27 16:42:00,389 TADA INFO assertion 6, updtr_start that changes offset to no offset: report(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'offset2none', 'interval': '1000000', 'offset': '0', 'sync': 'false', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 16:42:01,612 TADA INFO assertion 7, updtr_start of a non-existing updater: report(rc = 2) == expect(rc = 2), passed
2022-10-27 16:42:04,033 TADA INFO assertion 8, updtr_start with a valid interval: report(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_int', 'interval': '2000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 16:42:06,453 TADA INFO assertion 9, updtr_start with a valid offset: report(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'valid_offset', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 16:42:08,907 TADA INFO assertion 10, updtr_start without giving interval and offset: report(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}]) == expect(rc = 0, status = [{'name': 'all', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': []}], passed
2022-10-27 16:42:10,125 TADA INFO assertion 11, updtr_start a running updater: report(rc = 16) == expect(rc = 16), passed
2022-10-27 16:42:10,126 __main__ INFO --- done ---
2022-10-27 16:42:10,126 TADA INFO test updtr_add test ended
2022-10-27 16:42:22 INFO: ----------------------------------------------
2022-10-27 16:42:23 INFO: ======== updtr_status_test ========
2022-10-27 16:42:23 INFO: CMD: python3 updtr_status_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/updtr_status_test
2022-10-27 16:42:23,795 __main__ INFO -- Get or create the cluster --
2022-10-27 16:42:23,795 TADA INFO starting test `updtr_status test`
2022-10-27 16:42:23,796 TADA INFO   test-id: 5e7afbf191e72b20e1626441b3b0ea5c093a1b052a5b7ce3d0e996d07f80c8df
2022-10-27 16:42:23,796 TADA INFO   test-suite: LDMSD
2022-10-27 16:42:23,796 TADA INFO   test-name: updtr_status test
2022-10-27 16:42:23,796 TADA INFO   test-user: narate
2022-10-27 16:42:23,796 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:42:33,923 __main__ INFO -- Start daemons --
2022-10-27 16:42:38,847 __main__ INFO Waiting ... for all LDMSDs to start
2022-10-27 16:42:39,278 __main__ INFO All LDMSDs are up.
2022-10-27 16:42:40,507 TADA INFO assertion 1, Send 'updtr_status' to an LDMSD without any Updaters: [], passed
2022-10-27 16:42:41,726 TADA INFO assertion 2, Send 'updtr_status name=foo', where updtr 'foo' doesn't exist.: report(updtr 'foo' doesn't exist.) == expect(updtr 'foo' doesn't exist.), passed
2022-10-27 16:42:42,942 TADA INFO assertion 3, Send 'updtr_status name=all', where 'all' exists.: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 16:42:44,155 TADA INFO assertion 4, Send 'updtr_status' to an LDMSD with a single Updater: report([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'agg11', 'interval': '1000000', 'offset': '200000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'agg11', 'host': 'L1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 16:42:45,373 TADA INFO assertion 5, Send 'updtr_status' to an LDMSD with 2 updaters: report([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]) == expect([{'name': 'meminfo', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'RUNNING', 'producers': [{'name': 'sampler-1', 'host': 'sampler-1', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}, {'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}, {'name': 'sampler-2', 'interval': '1000000', 'offset': '100000', 'sync': 'true', 'mode': 'Pull', 'auto': 'false', 'state': 'STOPPED', 'producers': [{'name': 'sampler-2', 'host': 'sampler-2', 'port': 10000, 'transport': 'sock', 'state': 'CONNECTED'}]}]), passed
2022-10-27 16:42:45,373 __main__ INFO --- done ---
2022-10-27 16:42:45,374 TADA INFO test updtr_status test ended
2022-10-27 16:42:58 INFO: ----------------------------------------------
2022-10-27 16:42:59 INFO: ======== ldmsd_flex_decomp_test ========
2022-10-27 16:42:59 INFO: CMD: python3 ldmsd_flex_decomp_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldmsd_flex_decomp_test
2022-10-27 16:42:59,858 TADA INFO starting test `ldmsd_flex_decomp_test`
2022-10-27 16:42:59,858 TADA INFO   test-id: dd81a2f515bb925ba9fb80149cbd40e3dfba73e8caf3f017a8a398eb9e20f6c4
2022-10-27 16:42:59,859 TADA INFO   test-suite: LDMSD
2022-10-27 16:42:59,859 TADA INFO   test-name: ldmsd_flex_decomp_test
2022-10-27 16:42:59,859 TADA INFO   test-user: narate
2022-10-27 16:42:59,859 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:42:59,860 __main__ INFO -- Get or create the cluster --
2022-10-27 16:43:15,460 __main__ INFO -- Start daemons --
2022-10-27 16:43:25,745 __main__ INFO ... wait a bit to make sure ldmsd's are up
2022-10-27 16:44:14,869 TADA INFO assertion 1, test_sampler_95772b6 sos schema check: OK, passed
2022-10-27 16:44:14,870 TADA INFO assertion 2, record_sampler_e1f021f sos schema check: OK, passed
2022-10-27 16:44:14,870 TADA INFO assertion 3, fill sos schema check: OK, passed
2022-10-27 16:44:14,870 TADA INFO assertion 4, filter sos schema check: OK, passed
2022-10-27 16:44:14,870 TADA INFO assertion 5, record sos schema check: OK, passed
2022-10-27 16:44:14,870 TADA INFO assertion 6, test_sampler_95772b6 csv schema check: OK, passed
2022-10-27 16:44:14,870 TADA INFO assertion 7, record_sampler_e1f021f csv schema check: OK, passed
2022-10-27 16:44:14,871 TADA INFO assertion 8, fill csv schema check: OK, passed
2022-10-27 16:44:14,871 TADA INFO assertion 9, filter csv schema check: OK, passed
2022-10-27 16:44:14,871 TADA INFO assertion 10, record csv schema check: OK, passed
2022-10-27 16:44:14,871 TADA INFO assertion 11, test_sampler_95772b6 kafka schema check: OK, passed
2022-10-27 16:44:14,871 TADA INFO assertion 12, record_sampler_e1f021f kafka schema check: OK, passed
2022-10-27 16:44:14,871 TADA INFO assertion 13, fill kafka schema check: OK, passed
2022-10-27 16:44:14,872 TADA INFO assertion 14, filter kafka schema check: OK, passed
2022-10-27 16:44:14,872 TADA INFO assertion 15, record kafka schema check: OK, passed
2022-10-27 16:44:14,873 TADA INFO assertion 16, test_sampler_95772b6 sos data check: OK, passed
2022-10-27 16:44:14,941 TADA INFO assertion 17, record_sampler_e1f021f sos data check: OK, passed
2022-10-27 16:44:14,944 TADA INFO assertion 18, fill sos data check: OK, passed
2022-10-27 16:44:14,945 TADA INFO assertion 19, filter sos data check: OK, passed
2022-10-27 16:44:14,953 TADA INFO assertion 20, record sos data check: OK, passed
2022-10-27 16:44:14,955 TADA INFO assertion 21, test_sampler_95772b6 csv data check: OK, passed
2022-10-27 16:44:15,016 TADA INFO assertion 22, record_sampler_e1f021f csv data check: OK, passed
2022-10-27 16:44:15,019 TADA INFO assertion 23, fill csv data check: OK, passed
2022-10-27 16:44:15,020 TADA INFO assertion 24, filter csv data check: OK, passed
2022-10-27 16:44:15,029 TADA INFO assertion 25, record csv data check: OK, passed
2022-10-27 16:44:15,029 TADA INFO assertion 26, test_sampler_95772b6 kafka data check: OK, passed
2022-10-27 16:44:15,052 TADA INFO assertion 27, record_sampler_e1f021f kafka data check: OK, passed
2022-10-27 16:44:15,053 TADA INFO assertion 28, fill kafka data check: OK, passed
2022-10-27 16:44:15,054 TADA INFO assertion 29, filter kafka data check: OK, passed
2022-10-27 16:44:15,058 TADA INFO assertion 30, record kafka data check: OK, passed
2022-10-27 16:44:15,058 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-27 16:44:15,058 TADA INFO test ldmsd_flex_decomp_test ended
2022-10-27 16:44:30 INFO: ----------------------------------------------
2022-10-27 16:44:30 INFO: ======== ldms_set_info_test ========
2022-10-27 16:44:30 INFO: CMD: python3 ldms_set_info_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/ldms_set_info_test
2022-10-27 16:44:41,340 TADA INFO starting test `ldms_set_info_test`
2022-10-27 16:44:41,340 TADA INFO   test-id: aadb6fd09a86466143a9d3721e6c31e82283ac85a114f811218244f3d28119e2
2022-10-27 16:44:41,340 TADA INFO   test-suite: LDMSD
2022-10-27 16:44:41,340 TADA INFO   test-name: ldms_set_info_test
2022-10-27 16:44:41,340 TADA INFO   test-user: narate
2022-10-27 16:44:41,341 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:44:41,341 TADA INFO assertion 1, Adding set info key value pairs : -, passed
2022-10-27 16:44:41,341 TADA INFO assertion 2, Reset value of an existing pair : -, passed
2022-10-27 16:44:41,341 TADA INFO assertion 3, Get a value : -, passed
2022-10-27 16:44:41,342 TADA INFO assertion 4, Unset a pair : -, passed
2022-10-27 16:44:41,342 TADA INFO assertion 5, Traverse the local set info : -, passed
2022-10-27 16:44:41,342 TADA INFO assertion 6, Verifying the set info at the 1st level : -, passed
2022-10-27 16:44:41,342 TADA INFO assertion 7, Server resetting a key : -, passed
2022-10-27 16:44:41,342 TADA INFO assertion 8, Server unset a key : -, passed
2022-10-27 16:44:41,342 TADA INFO assertion 9, Server add a key : -, passed
2022-10-27 16:44:41,343 TADA INFO assertion 10, Adding a key : -, passed
2022-10-27 16:44:41,343 TADA INFO assertion 11, Add a key that is already in the remote list : -, passed
2022-10-27 16:44:41,343 TADA INFO assertion 12, Unset a key that appears in both local and remote list : -, passed
2022-10-27 16:44:41,343 TADA INFO assertion 13, Verifying the set_info at the 2nd level : -, passed
2022-10-27 16:44:41,343 TADA INFO assertion 14, Test set info propagation: resetting a key on the set origin : -, passed
2022-10-27 16:44:41,343 TADA INFO assertion 15, Test set info propagation: unsetting a key on the set origin : -, passed
2022-10-27 16:44:41,343 TADA INFO assertion 16, Test set info propagation: adding a key on the set origin : -, passed
2022-10-27 16:44:41,344 TADA INFO test ldms_set_info_test ended
2022-10-27 16:44:52 INFO: ----------------------------------------------
2022-10-27 16:44:52 INFO: ======== slurm_sampler2_test ========
2022-10-27 16:44:52 INFO: CMD: python3 slurm_sampler2_test --prefix /home/narate/cron/ldms-test/ldms-containers/ovis --runtime docker --image ovishpc/ldms-dev --src /mnt/300G/data --data_root /mnt/300G/data/2022-10-27-154535/data/slurm_sampler2_test
2022-10-27 16:44:53,688 TADA INFO starting test `slurm_sampler2_test`
2022-10-27 16:44:53,688 TADA INFO   test-id: cb5f93d0ef16b2d4cec41c9f1475af9d4cb46759b859a97d2973b925254af827
2022-10-27 16:44:53,689 TADA INFO   test-suite: LDMSD
2022-10-27 16:44:53,689 TADA INFO   test-name: slurm_sampler2_test
2022-10-27 16:44:53,689 TADA INFO   test-user: narate
2022-10-27 16:44:53,689 TADA INFO   commit-id: e9dd1b7a074711b5723f38b89fca5b30b89590a9
2022-10-27 16:44:53,689 __main__ INFO -- Get or create the cluster --
2022-10-27 16:45:07,672 __main__ INFO -- Add users --
2022-10-27 16:45:12,852 __main__ INFO -- Preparing job script & programs --
2022-10-27 16:45:13,593 __main__ INFO -- Start daemons --
2022-10-27 16:45:35,529 TADA INFO assertion 1, Processing the stream data from slurm_notifier: The metric values are as expected on all nodes., passed
2022-10-27 16:45:39,228 TADA INFO assertion 2.1, Deleting completed jobs -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 16:45:40,845 TADA INFO assertion 2.2, Deleting completed jobs -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 16:45:42,493 TADA INFO assertion 2.3, Deleting completed jobs -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 16:45:44,220 TADA INFO assertion 2.4, Deleting completed jobs -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 16:45:45,882 TADA INFO assertion 2.5, Deleting completed jobs -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 16:45:49,539 TADA INFO assertion 3.1, Expanding the set heap -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 16:45:51,216 TADA INFO assertion 3.2, Expanding the set heap -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 16:45:54,206 TADA INFO assertion 3.3, Expanding the set heap -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 16:45:57,210 TADA INFO assertion 3.4, Expanding the set heap -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 16:45:58,853 TADA INFO assertion 3.5, Expanding the set heap -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 16:46:05,065 TADA INFO assertion 4.1, Multi-tenant -- job_init: The metric values are as expected on all nodes., passed
2022-10-27 16:46:06,685 TADA INFO assertion 4.2, Multi-tenant -- step_init: The metric values are as expected on all nodes., passed
2022-10-27 16:46:09,285 TADA INFO assertion 4.3, Multi-tenant -- task_init: The metric values are as expected on all nodes., passed
2022-10-27 16:46:11,812 TADA INFO assertion 4.4, Multi-tenant -- task_exit: The metric values are as expected on all nodes., passed
2022-10-27 16:46:13,532 TADA INFO assertion 4.5, Multi-tenant -- job_exit: The metric values are as expected on all nodes., passed
2022-10-27 16:46:13,533 TADA INFO test slurm_sampler2_test ended
2022-10-27 16:46:27 INFO: ----------------------------------------------
2022-10-27 16:46:28 INFO: ======== test-ldms ========
2022-10-27 16:46:28 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-ldms/test.sh
2022-10-27T16:46:28-05:00 INFO: starting test-samp-1
a8dbae6ace6f9d8ff7082143656fc1166b081f4de35fe77788154c2daa9ad1da
2022-10-27T16:46:31-05:00 INFO: starting test-samp-2
1c5b96c0054e2a8f7afa846f9044cf75cd40651edfb0a40a63b0f12da9ce2032
2022-10-27T16:46:32-05:00 INFO: starting test-samp-3
d17063204f275ebade83222e952e9390e5c951364c7d30858552c4586e0ca892
2022-10-27T16:46:34-05:00 INFO: starting test-samp-4
67cf7342f425cf8926720b24030ab025aaa07ee9d3c6fa3f7b85c82c51facc40
2022-10-27T16:46:36-05:00 INFO: test-samp-1 is running
2022-10-27T16:46:36-05:00 INFO: test-samp-2 is running
2022-10-27T16:46:36-05:00 INFO: test-samp-3 is running
2022-10-27T16:46:36-05:00 INFO: test-samp-4 is running
2022-10-27T16:46:36-05:00 INFO: starting test-agg-11
0793691c74ae31aed5bae5e4f9b7ca16c6825bc7f35fd1b7eb29f93d3cdff679
2022-10-27T16:46:38-05:00 INFO: starting test-agg-12
39b4672375d0176ec5a02c703a864445c9b29188e558b70b92b1e07c89ed2536
2022-10-27T16:46:40-05:00 INFO: test-agg-11 is running
2022-10-27T16:46:40-05:00 INFO: test-agg-12 is running
2022-10-27T16:46:40-05:00 INFO: starting test-agg-2
77f8b10ec64e263ec268d3ca37a4d696ce80fc6962cbceb647bca6f0ab1471c0
2022-10-27T16:46:42-05:00 INFO: test-agg-2 is running
2022-10-27T16:46:42-05:00 INFO: Collecting data (into SOS)
2022-10-27T16:46:52-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T16:46:54-05:00 INFO: check rc: 0
2022-10-27T16:46:54-05:00 INFO: Cleaning up ...
test-samp-1
test-samp-2
test-samp-3
test-samp-4
test-agg-11
test-agg-12
test-agg-2
2022-10-27T16:46:58-05:00 INFO: DONE
2022-10-27 16:47:08 INFO: ----------------------------------------------
2022-10-27 16:47:08 INFO: ======== test-maestro ========
2022-10-27 16:47:08 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro/test.sh
2022-10-27T16:47:08-05:00 INFO: starting mtest-maestro
c0dd8a20044e6444ba956d75c46d71566837dea8095b95a937eabc4c6cce0bea
2022-10-27T16:47:11-05:00 INFO: starting mtest-samp-1
817d1e15ffa274c99f7b30df7af7faa7b86f5f56f24893fc90f59fa34442b63e
2022-10-27T16:47:12-05:00 INFO: starting mtest-samp-2
0b52676fcd8427bb8bdad978b3a475320f5f1230a4bc6c355511c86878ff77ab
2022-10-27T16:47:14-05:00 INFO: starting mtest-samp-3
d8c55ea70d63967899bf02b43b6563040186daa5873a156ffe5f21cff2f1bce9
2022-10-27T16:47:16-05:00 INFO: starting mtest-samp-4
ecfb0922c59220fa42194f4602cf23ece452e4b9223c41a607d46998be46a5c7
2022-10-27T16:47:17-05:00 INFO: mtest-samp-1 is running
2022-10-27T16:47:17-05:00 INFO: mtest-samp-2 is running
2022-10-27T16:47:17-05:00 INFO: mtest-samp-3 is running
2022-10-27T16:47:17-05:00 INFO: mtest-samp-4 is running
2022-10-27T16:47:17-05:00 INFO: starting mtest-agg-11
076154e582355bfb5574f9a454f20bf1619df0e133b30165f95cb92f1e48148d
2022-10-27T16:47:19-05:00 INFO: starting mtest-agg-12
88832825796d9c2947f447974506534ea95dbd778869e67cf5434b5796589b17
2022-10-27T16:47:20-05:00 INFO: mtest-agg-11 is running
2022-10-27T16:47:20-05:00 INFO: mtest-agg-12 is running
2022-10-27T16:47:20-05:00 INFO: starting mtest-agg-2
e128d9d6eb868da874b73196321d098d45e8de1af98d44208ccf320f85b78b93
2022-10-27T16:47:22-05:00 INFO: mtest-agg-2 is running
2022-10-27T16:47:22-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T16:47:33-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T16:47:35-05:00 INFO: sos check rc: 0
2022-10-27T16:47:36-05:00 INFO: starting mtest-ui
cb7e8372a25e64e82b83c43c687b1604b0dca40b2cd9e4524b35c6e7f81f6b33
2022-10-27T16:47:43-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4367944, 1666907245001.3188], [4367944, 1666907245001.628], [4368316, 1666907246000.5818], [4368316, 1666907246001.3381], [4368316, 1666907246001.4038], [4368316, 1666907246001.78], [4368316, 1666907247001.5051], [4368316, 1666907247001.562], [4368316, 1666907247001.564], [4368316, 1666907247001.933], [4368316, 1666907248001.107], [4368316, 1666907248001.654], [4368316, 1666907248001.678], [4368316, 1666907248002.083], [4368316, 1666907249001.2532], [4368316, 1666907249001.2878], [4368316, 1666907249001.289], [4368316, 1666907249001.3289], [4368316, 1666907250001.322], [4368316, 1666907250001.3818], [4368316, 1666907250001.4001], [4368316, 1666907250001.465], [4368316, 1666907251000.997], [4368316, 1666907251001.4521], [4368316, 1666907251001.496], [4368316, 1666907251001.598], [4368316, 1666907252001.334], [4368316, 1666907252001.523], [4368316, 1666907252001.604], [4368316, 1666907252001.606]]}, {"target": "component_id", "datapoints": [[3, 1666907245001.3188], [1, 1666907245001.628], [3, 1666907246000.5818], [4, 1666907246001.3381], [2, 1666907246001.4038], [1, 1666907246001.78], [4, 1666907247001.5051], [3, 1666907247001.562], [2, 1666907247001.564], [1, 1666907247001.933], [3, 1666907248001.107], [4, 1666907248001.654], [2, 1666907248001.678], [1, 1666907248002.083], [1, 1666907249001.2532], [3, 1666907249001.2878], [2, 1666907249001.289], [4, 1666907249001.3289], [2, 1666907250001.322], [3, 1666907250001.3818], [1, 1666907250001.4001], [4, 1666907250001.465], [1, 1666907251000.997], [2, 1666907251001.4521], [3, 1666907251001.496], [4, 1666907251001.598], [4, 1666907252001.334], [3, 1666907252001.523], [2, 1666907252001.604], [1, 1666907252001.606]]}, {"target": "job_id", "datapoints": [[0, 1666907245001.3188], [0, 1666907245001.628], [0, 1666907246000.5818], [0, 1666907246001.3381], [0, 1666907246001.4038], [0, 1666907246001.78], [0, 1666907247001.5051], [0, 1666907247001.562], [0, 1666907247001.564], [0, 1666907247001.933], [0, 1666907248001.107], [0, 1666907248001.654], [0, 1666907248001.678], [0, 1666907248002.083], [0, 1666907249001.2532], [0, 1666907249001.2878], [0, 1666907249001.289], [0, 1666907249001.3289], [0, 1666907250001.322], [0, 1666907250001.3818], [0, 1666907250001.4001], [0, 1666907250001.465], [0, 1666907251000.997], [0, 1666907251001.4521], [0, 1666907251001.496], [0, 1666907251001.598], [0, 1666907252001.334], [0, 1666907252001.523], [0, 1666907252001.604], [0, 1666907252001.606]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T16:47:45-05:00 INFO: query check RC: 0
ecca6eb225169733eece91db06bd5f9e611a0fe29f8808f294bb350219ae7281
2022-10-27T16:48:17-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2495    770 --:--:-- --:--:-- --:--:--  3280
{"datasource":{"id":1,"uid":"PJ3j2AN4z","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T16:48:18-05:00 INFO: Checking grafana data
2022-10-27T16:48:18-05:00 INFO: Grafana data check, rc: 0
2022-10-27T16:48:18-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T16:48:23-05:00 INFO: DONE
2022-10-27 16:48:33 INFO: ----------------------------------------------
2022-10-27 16:48:33 INFO: ======== test-maestro-hostmunge ========
2022-10-27 16:48:33 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-hostmunge/test.sh
2022-10-27T16:48:33-05:00 INFO: Checking munge on localhost
2022-10-27T16:48:33-05:00 INFO: munge encode/decode successfully
2022-10-27T16:48:33-05:00 INFO: starting mtest-maestro
17ee4fce15131f1c649df79d5a42e0cd1d70b46998393a6d261620b9dabb0011
2022-10-27T16:48:35-05:00 INFO: starting mtest-samp-1
eb58609244803976d1c474dd4a124a74e9ad3e00dd4b225890484c384adbeb53
2022-10-27T16:48:37-05:00 INFO: starting mtest-samp-2
d891dcde4ffd636ffdffc6b07133699340511dbb26cfb2100d3cb60ca492249a
2022-10-27T16:48:39-05:00 INFO: starting mtest-samp-3
250de917fbeedebee322e9bd8498f53cfd2ae7f84146c0acb81dc662de5e1925
2022-10-27T16:48:41-05:00 INFO: starting mtest-samp-4
34d3bbc70bce487cd7544ba5d112f8338b673b43d7a6b38246b0d39645531e1c
2022-10-27T16:48:42-05:00 INFO: mtest-samp-1 is running
2022-10-27T16:48:42-05:00 INFO: mtest-samp-2 is running
2022-10-27T16:48:42-05:00 INFO: mtest-samp-3 is running
2022-10-27T16:48:42-05:00 INFO: mtest-samp-4 is running
2022-10-27T16:48:42-05:00 INFO: starting mtest-agg-11
4ad01ea138bee924b7dfb6e091c954c869326f08305f66b06f3274600313f350
2022-10-27T16:48:44-05:00 INFO: starting mtest-agg-12
1b7f763349429121cdf9333e304a65736d0edca6183ec88c104d76b8745f38c7
2022-10-27T16:48:45-05:00 INFO: mtest-agg-11 is running
2022-10-27T16:48:45-05:00 INFO: mtest-agg-12 is running
2022-10-27T16:48:45-05:00 INFO: starting mtest-agg-2
cd9bf3553679eb20a45153487bf471cb283b4397d07aef06d7a10eb9d0955dfb
2022-10-27T16:48:47-05:00 INFO: mtest-agg-2 is running
2022-10-27T16:48:47-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T16:48:58-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T16:49:00-05:00 INFO: sos check rc: 0
2022-10-27T16:49:01-05:00 INFO: starting mtest-ui
38c22c9a994409ab62bab44e38cade6d1e1ebff61656d9623effc06797b2988e
2022-10-27T16:49:03-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4368256, 1666907331000.553], [4368256, 1666907331001.325], [4368256, 1666907331001.4148], [4368256, 1666907331001.618], [4368532, 1666907332001.3262], [4368532, 1666907332001.3271], [4368532, 1666907332001.553], [4368532, 1666907332001.575], [4368628, 1666907333001.477], [4368628, 1666907333001.486], [4368628, 1666907333001.487], [4368628, 1666907333001.6938], [4368628, 1666907334001.325], [4368628, 1666907334001.632], [4368628, 1666907334001.636], [4368628, 1666907334001.639], [4368628, 1666907335000.906], [4368628, 1666907335001.2988], [4368628, 1666907335001.324], [4368628, 1666907335001.7842], [4368628, 1666907336001.4421], [4368628, 1666907336001.4421], [4368628, 1666907336001.447], [4368628, 1666907336001.925], [4368628, 1666907337001.6], [4368628, 1666907337001.6052], [4368628, 1666907337001.607], [4368628, 1666907337001.7642]]}, {"target": "component_id", "datapoints": [[1, 1666907331000.553], [4, 1666907331001.325], [2, 1666907331001.4148], [3, 1666907331001.618], [3, 1666907332001.3262], [4, 1666907332001.3271], [1, 1666907332001.553], [2, 1666907332001.575], [4, 1666907333001.477], [3, 1666907333001.486], [1, 1666907333001.487], [2, 1666907333001.6938], [3, 1666907334001.325], [4, 1666907334001.632], [1, 1666907334001.636], [2, 1666907334001.639], [1, 1666907335000.906], [3, 1666907335001.2988], [4, 1666907335001.324], [2, 1666907335001.7842], [1, 1666907336001.4421], [3, 1666907336001.4421], [4, 1666907336001.447], [2, 1666907336001.925], [3, 1666907337001.6], [4, 1666907337001.6052], [1, 1666907337001.607], [2, 1666907337001.7642]]}, {"target": "job_id", "datapoints": [[0, 1666907331000.553], [0, 1666907331001.325], [0, 1666907331001.4148], [0, 1666907331001.618], [0, 1666907332001.3262], [0, 1666907332001.3271], [0, 1666907332001.553], [0, 1666907332001.575], [0, 1666907333001.477], [0, 1666907333001.486], [0, 1666907333001.487], [0, 1666907333001.6938], [0, 1666907334001.325], [0, 1666907334001.632], [0, 1666907334001.636], [0, 1666907334001.639], [0, 1666907335000.906], [0, 1666907335001.2988], [0, 1666907335001.324], [0, 1666907335001.7842], [0, 1666907336001.4421], [0, 1666907336001.4421], [0, 1666907336001.447], [0, 1666907336001.925], [0, 1666907337001.6], [0, 1666907337001.6052], [0, 1666907337001.607], [0, 1666907337001.7642]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T16:49:05-05:00 INFO: query check RC: 0
576bbbde0d00ee209f0225f8afdee3b4821ccae37453bdf52c7c1854ab06b6f8
2022-10-27T16:49:37-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2447    755 --:--:-- --:--:-- --:--:--  3214
{"datasource":{"id":1,"uid":"Xw5RoAHVz","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T16:49:38-05:00 INFO: Checking grafana data
2022-10-27T16:49:38-05:00 INFO: Grafana data check, rc: 0
2022-10-27T16:49:38-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T16:49:43-05:00 INFO: DONE
2022-10-27 16:49:53 INFO: ----------------------------------------------
2022-10-27 16:49:53 INFO: ======== test-maestro-munge ========
2022-10-27 16:49:53 INFO: CMD: /home/narate/cron/ldms-test/ldms-containers/test/test-maestro-munge/test.sh
1+0 records in
1+0 records out
4096 bytes (4.1 kB, 4.0 KiB) copied, 0.00030953 s, 13.2 MB/s
2022-10-27T16:49:55-05:00 INFO: starting mtest-maestro
3a471c471022e01772084631ae03b3e7f99fe24a3c9ad4341b93284bf2e12884
2022-10-27T16:49:57-05:00 INFO: starting mtest-samp-1
9a7208c3b91451c29395c4badd0a201abac54171f449275788fb2837d3215189
2022-10-27T16:49:58-05:00 INFO: starting mtest-samp-2
75ec0ec3d1c66cef1ede4ba76ab7a265620dd18863066ba3b8aa11e89cc9aa31
2022-10-27T16:50:00-05:00 INFO: starting mtest-samp-3
760b8dd7d12e139aee2c7be0099e31ea0c61f45a05b9acb99303a9fd6ca97a0f
2022-10-27T16:50:02-05:00 INFO: starting mtest-samp-4
4d88cc8926c7ab0682056d7504701a5efefa68c97a6415152d41c5aeab8c68fe
2022-10-27T16:50:03-05:00 INFO: mtest-samp-1 is running
2022-10-27T16:50:03-05:00 INFO: mtest-samp-2 is running
2022-10-27T16:50:03-05:00 INFO: mtest-samp-3 is running
2022-10-27T16:50:03-05:00 INFO: mtest-samp-4 is running
2022-10-27T16:50:04-05:00 INFO: starting mtest-agg-11
8911fa0a2397ffdf03751a743899a80fb9491ea56d8c08de8661f8443ceab250
2022-10-27T16:50:05-05:00 INFO: starting mtest-agg-12
645c7677767f31271115e42df30a7aaeac39f488907e8c3c96b4c69d6973a4bd
2022-10-27T16:50:06-05:00 INFO: mtest-agg-11 is running
2022-10-27T16:50:07-05:00 INFO: mtest-agg-12 is running
2022-10-27T16:50:07-05:00 INFO: starting mtest-agg-2
702a77ffd35176dcb17117d21812df773eafa0bb6269bf429604b01b8f183fbd
2022-10-27T16:50:08-05:00 INFO: mtest-agg-2 is running
2022-10-27T16:50:08-05:00 INFO: Collecting data (into SOS)
mtest-agg-11
mtest-agg-12
2022-10-27T16:50:20-05:00 INFO: Checking SOS data
Component IDs: {1, 2, 3, 4}
2022-10-27T16:50:22-05:00 INFO: sos check rc: 0
2022-10-27T16:50:23-05:00 INFO: starting mtest-ui
6d8720225230c6088c87eba4dd828b089123e792572fd433b84c49bd076f0cad
2022-10-27T16:50:25-05:00 INFO: Checking query from mtest-ui: http://mtest-ui/grafana/query
query results: b'[{"target": "Active", "datapoints": [[4368572, 1666907413001.557], [4368572, 1666907413001.564], [4368572, 1666907413001.603], [4368572, 1666907413001.606], [4368944, 1666907414001.716], [4368944, 1666907414001.719], [4368944, 1666907414001.7542], [4368944, 1666907414001.7651], [4368944, 1666907415001.3271], [4368944, 1666907415001.728], [4368944, 1666907415001.839], [4368944, 1666907415001.843], [4368944, 1666907416001.468], [4368944, 1666907416001.77], [4368944, 1666907416001.98], [4368944, 1666907416001.981], [4368944, 1666907417001.614], [4368944, 1666907417001.616], [4368944, 1666907417002.113], [4368944, 1666907417002.1208], [4368944, 1666907418000.957], [4368944, 1666907418001.272], [4368944, 1666907418001.281], [4368944, 1666907418001.74]]}, {"target": "component_id", "datapoints": [[4, 1666907413001.557], [1, 1666907413001.564], [2, 1666907413001.603], [3, 1666907413001.606], [4, 1666907414001.716], [1, 1666907414001.719], [2, 1666907414001.7542], [3, 1666907414001.7651], [2, 1666907415001.3271], [3, 1666907415001.728], [1, 1666907415001.839], [4, 1666907415001.843], [2, 1666907416001.468], [3, 1666907416001.77], [4, 1666907416001.98], [1, 1666907416001.981], [2, 1666907417001.614], [3, 1666907417001.616], [4, 1666907417002.113], [1, 1666907417002.1208], [2, 1666907418000.957], [4, 1666907418001.272], [1, 1666907418001.281], [3, 1666907418001.74]]}, {"target": "job_id", "datapoints": [[0, 1666907413001.557], [0, 1666907413001.564], [0, 1666907413001.603], [0, 1666907413001.606], [0, 1666907414001.716], [0, 1666907414001.719], [0, 1666907414001.7542], [0, 1666907414001.7651], [0, 1666907415001.3271], [0, 1666907415001.728], [0, 1666907415001.839], [0, 1666907415001.843], [0, 1666907416001.468], [0, 1666907416001.77], [0, 1666907416001.98], [0, 1666907416001.981], [0, 1666907417001.614], [0, 1666907417001.616], [0, 1666907417002.113], [0, 1666907417002.1208], [0, 1666907418000.957], [0, 1666907418001.272], [0, 1666907418001.281], [0, 1666907418001.74]]}]'
comp_ids:{1, 2, 3, 4}
2022-10-27T16:50:27-05:00 INFO: query check RC: 0
9edc0ff8f6d4c655c554def2e6bc0ec5cca1cfcfa37743029d3ea0f00806ad3e
2022-10-27T16:50:58-05:00 INFO: Adding DSOS data source in Grafana
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   479  100   366  100   113   2455    758 --:--:-- --:--:-- --:--:--  3214100   479  100   366  100   113   2453    757 --:--:-- --:--:-- --:--:--  3214
{"datasource":{"id":1,"uid":"NMrio0HVk","orgId":1,"name":"SOS-2","type":"dsosds","typeLogoUrl":"","access":"proxy","url":"http://mtest-ui/grafana","user":"","database":"","basicAuth":false,"basicAuthUser":"","withCredentials":false,"isDefault":true,"jsonData":{},"secureJsonFields":{},"version":1,"readOnly":false},"id":1,"message":"Datasource added","name":"SOS-2"}
2022-10-27T16:50:59-05:00 INFO: Checking grafana data
2022-10-27T16:51:00-05:00 INFO: Grafana data check, rc: 0
2022-10-27T16:51:00-05:00 INFO: Cleaning up ...
mtest-samp-1
mtest-samp-2
mtest-samp-3
mtest-samp-4
mtest-agg-11
mtest-agg-12
mtest-agg-2
mtest-maestro
mtest-ui
mtest-grafana
2022-10-27T16:51:04-05:00 INFO: DONE
2022-10-27 16:51:14 INFO: ----------------------------------------------
2022-10-27 16:51:14 INFO: ==== Summary ====
ldmsd_ctrl_test: [01;32mPASSED[0m
papi_store_test: [01;32mPASSED[0m
updtr_status_test: [01;32mPASSED[0m
ldmsd_auth_ovis_test: [01;32mPASSED[0m
store_app_test: [01;32mPASSED[0m
store_list_record_test: [01;32mPASSED[0m
set_array_test: [01;32mPASSED[0m
ovis_ev_test: [01;32mPASSED[0m
setgroup_test: [01;32mPASSED[0m
ldms_list_test: [01;32mPASSED[0m
slurm_stream_test: [01;32mPASSED[0m
maestro_cfg_test: [01;32mPASSED[0m
ldms_set_info_test: [01;32mPASSED[0m
spank_notifier_test: [01;32mPASSED[0m
agg_slurm_test: [01;32mPASSED[0m
updtr_match_add_test: [01;32mPASSED[0m
updtr_match_del_test: [01;32mPASSED[0m
ldmsd_stream_dir_test: [01;32mPASSED[0m
direct_prdcr_subscribe_test: [01;32mPASSED[0m
ldmsd_auth_test: [01;32mPASSED[0m
cont-test-maestro-munge: [01;32mPASSED[0m
cont-test-ldms: [01;32mPASSED[0m
prdcr_subscribe_test: [01;32mPASSED[0m
cont-test-maestro-hostmunge: [01;32mPASSED[0m
maestro_raft_test: [01;32mPASSED[0m
updtr_start_test: [01;32mPASSED[0m
failover_test: [01;32mPASSED[0m
ldms_record_test: [01;32mPASSED[0m
cont-test-maestro: [01;32mPASSED[0m
ldmsd_decomp_test: [01;32mPASSED[0m
ldmsd_flex_decomp_test: [01;32mPASSED[0m
quick_set_add_rm_test: [01;32mPASSED[0m
updtr_prdcr_del_test: [01;32mPASSED[0m
updtr_prdcr_add_test: [01;32mPASSED[0m
mt-slurm-test: [01;32mPASSED[0m
ovis_json_test: [01;32mPASSED[0m
papi_sampler_test: [01;32mPASSED[0m
syspapi_test: [01;32mPASSED[0m
updtr_del_test: [01;32mPASSED[0m
ldmsd_autointerval_test: [01;32mPASSED[0m
updtr_add_test: [01;32mPASSED[0m
ldmsd_stream_test: [01;32mPASSED[0m
direct_ldms_ls_conn_test: [01;32mPASSED[0m
set_array_hang_test: [01;32mPASSED[0m
slurm_sampler2_test: [01;31mFAILED[0m
ldms_schema_digest_test: [01;32mPASSED[0m
agg_test: [01;32mPASSED[0m
------------------------------------------
Total tests passed: 46/47
------------------------------------------
